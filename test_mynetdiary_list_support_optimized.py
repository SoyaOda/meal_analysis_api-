#!/usr/bin/env python3
"""
MyNetDiary List Support DB Optimized Test Script

search_name_listé…åˆ—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«æœ€é©åŒ–ã•ã‚ŒãŸ7æ®µéšæ¤œç´¢æˆ¦ç•¥ã®ãƒ†ã‚¹ãƒˆ
ä»£æ›¿åæ¤œç´¢ã®åŠ¹æœã‚’é‡ç‚¹çš„ã«æ¤œè¨¼
"""

import requests
import json
from datetime import datetime
from typing import List, Dict, Any

# Elasticsearchç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ç”¨
ELASTICSEARCH_URL = "http://localhost:9200"
INDEX_NAME = "mynetdiary_list_support_db"

def elasticsearch_search_optimized(query: str, size: int = 10) -> Dict[str, Any]:
    """search_name_listé…åˆ—ã«æœ€é©åŒ–ã•ã‚ŒãŸ7æ®µéšæ¤œç´¢æˆ¦ç•¥"""

    search_body = {
        "query": {
            "bool": {
                "should": [
                    # Tier 1: Exact Match (search_name_listé…åˆ—è¦ç´ ) - Score: 15+
                    {"match_phrase": {"search_name_list": {"query": query, "boost": 15}}},
                    # Tier 1b: Exact Match (search_nameæ–‡å­—åˆ—) - Score: 15+ (fallback)
                    {"match_phrase": {"search_name": {"query": query, "boost": 15}}},

                    # Tier 2: Exact Match (description) - Score: 12+
                    {"match_phrase": {"description": {"query": query, "boost": 12}}},

                    # Tier 3: Phrase Match (search_name_listé…åˆ—è¦ç´ ) - Score: 10+
                    {"match": {"search_name_list": {"query": query, "boost": 10}}},
                    # Tier 3b: Phrase Match (search_nameæ–‡å­—åˆ—) - Score: 10+ (fallback)
                    {"match": {"search_name": {"query": query, "boost": 10}}},

                    # Tier 4: Phrase Match (description) - Score: 8+
                    {"match": {"description": {"query": query, "boost": 8}}},

                    # Tier 5: Term Match (search_name_listè¦ç´ ã®å®Œå…¨ä¸€è‡´) - Score: 6+
                    {"term": {"search_name_list.keyword": {"value": query, "boost": 6}}},
                    # Tier 5b: Term Match (search_nameæ–‡å­—åˆ—ã®å®Œå…¨ä¸€è‡´) - Score: 6+ (fallback)
                    {"term": {"search_name.keyword": {"value": query, "boost": 6}}},

                    # Tier 6: Multi-field match (é…åˆ—ã¨æ–‡å­—åˆ—ä¸¡å¯¾å¿œ) - Score: 4+
                    {"multi_match": {
                        "query": query,
                        "fields": ["search_name_list^3", "search_name^3", "description^2", "original_name"],
                        "boost": 4
                    }},

                    # Tier 7: Fuzzy Match (search_name_listé…åˆ—è¦ç´ ) - Score: 2+
                    {"fuzzy": {"search_name_list": {"value": query, "boost": 2}}},
                    # Tier 7b: Fuzzy Match (search_nameæ–‡å­—åˆ—) - Score: 2+ (fallback)
                    {"fuzzy": {"search_name": {"value": query, "boost": 2}}}
                ]
            }
        },
        "size": size,
        "_source": ["search_name", "search_name_list", "description", "original_name", "nutrition", "processing_method"]
    }

    try:
        response = requests.post(
            f"{ELASTICSEARCH_URL}/{INDEX_NAME}/_search",
            headers={"Content-Type": "application/json"},
            data=json.dumps(search_body)
        )
        return response.json()
    except Exception as e:
        return {"error": str(e)}

def format_nutrition_info(nutrition: Dict[str, float]) -> str:
    """æ „é¤Šæƒ…å ±ã‚’è¦‹ã‚„ã™ã„å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    return f"ğŸ½ {nutrition.get('calories', 0):.1f}kcal | ğŸ¥© {nutrition.get('protein', 0):.1f}g | ğŸ {nutrition.get('carbs', 0):.1f}g | ğŸ§ˆ {nutrition.get('fat', 0):.1f}g"

def test_alternative_names_query(query: str, expected_alternatives: List[str]) -> Dict[str, Any]:
    """ä»£æ›¿åæ¤œç´¢ã®åŠ¹æœã‚’ãƒ†ã‚¹ãƒˆ"""
    print(f"\n{'='*80}")
    print(f"ğŸ” ä»£æ›¿åãƒ†ã‚¹ãƒˆ: '{query}'")
    print(f"ğŸ“ æœŸå¾…ã™ã‚‹ä»£æ›¿å: {', '.join(expected_alternatives)}")
    print(f"{'='*80}")

    result = elasticsearch_search_optimized(query, size=15)

    if "error" in result:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
        return {"query": query, "error": result["error"], "results": []}

    hits = result.get("hits", {}).get("hits", [])
    total_hits = result.get("hits", {}).get("total", {}).get("value", 0)

    print(f"ğŸ“Š ç·æ¤œç´¢çµæœæ•°: {total_hits}")
    print(f"ğŸ“‹ è¡¨ç¤ºçµæœæ•°: {len(hits)}")

    processed_results = []
    alternative_matches = []

    for i, hit in enumerate(hits, 1):
        source = hit["_source"]
        score = hit["_score"]

        search_name = source.get("search_name", "Unknown")
        search_name_list = source.get("search_name_list", [])
        description = source.get("description", "No description")
        original_name = source.get("original_name", "No original name")
        nutrition = source.get("nutrition", {})
        processing_method = source.get("processing_method", "Unknown")

        # ä»£æ›¿åãƒãƒƒãƒãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
        is_alternative_match = any(alt.lower() in ' '.join(search_name_list).lower() for alt in expected_alternatives)
        if is_alternative_match:
            alternative_matches.append(i)

        print(f"\nğŸ† çµæœ #{i} (ã‚¹ã‚³ã‚¢: {score:.2f}) {'ğŸ¯' if is_alternative_match else ''}")
        print(f"   ğŸ”¸ æ¤œç´¢å: '{search_name}'")
        print(f"   ğŸ”¸ æ¤œç´¢åãƒªã‚¹ãƒˆ: {search_name_list}")
        print(f"   ğŸ”¸ èª¬æ˜: '{description}'")
        print(f"   ğŸ”¸ å…ƒã®åå‰: '{original_name}'")
        print(f"   ğŸ”¸ æ „é¤Šæƒ…å ±: {format_nutrition_info(nutrition)}")
        print(f"   ğŸ”¸ å‡¦ç†æ–¹æ³•: {processing_method}")

        processed_results.append({
            "rank": i,
            "score": score,
            "search_name": search_name,
            "search_name_list": search_name_list,
            "description": description,
            "original_name": original_name,
            "nutrition": nutrition,
            "processing_method": processing_method,
            "is_alternative_match": is_alternative_match
        })

    # ä»£æ›¿åãƒãƒƒãƒãƒ³ã‚°åŠ¹æœã®åˆ†æ
    print(f"\nğŸ“ˆ ä»£æ›¿åãƒãƒƒãƒãƒ³ã‚°åˆ†æ:")
    print(f"   ğŸ¯ ä»£æ›¿åãƒãƒƒãƒã—ãŸçµæœ: {len(alternative_matches)} / {len(hits)}")
    if alternative_matches:
        print(f"   ğŸ“ ãƒãƒƒãƒã—ãŸé †ä½: {', '.join(f'#{pos}' for pos in alternative_matches)}")
        top_alt_rank = min(alternative_matches)
        print(f"   ğŸ¥‡ æœ€é«˜é †ä½ã®ä»£æ›¿åãƒãƒƒãƒ: #{top_alt_rank}")

    return {
        "query": query,
        "expected_alternatives": expected_alternatives,
        "total_hits": total_hits,
        "displayed_results": len(hits),
        "alternative_matches_count": len(alternative_matches),
        "alternative_matches_ranks": alternative_matches,
        "results": processed_results
    }

def run_alternative_names_test() -> Dict[str, Any]:
    """ä»£æ›¿åã«ç‰¹åŒ–ã—ãŸãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("ğŸš€ MyNetDiary List Support DB ä»£æ›¿åæœ€é©åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ—„ï¸ å¯¾è±¡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {INDEX_NAME}")

    # ä»£æ›¿åãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆREADMEã§è¨€åŠã•ã‚Œã¦ã„ã‚‹ä»£æ›¿åï¼‰
    alternative_test_cases = [
        # ãƒãƒƒã‚¯ãƒ”ãƒ¼/ã‚¬ãƒ«ãƒãƒ³ã‚¾è±†ãƒ†ã‚¹ãƒˆ
        ("chickpeas", ["chickpea", "garbanzo", "garbanzo beans"]),
        ("garbanzo beans", ["chickpea", "chickpeas", "garbanzo"]),
        ("garbanzo", ["chickpea", "chickpeas", "garbanzo beans"]),

        # å…·ä½“çš„ãªé£Ÿæã§ã®ç²¾åº¦ãƒ†ã‚¹ãƒˆ
        ("tomato", ["tomato", "tomatoes"]),
        ("tomatoes", ["tomato"]),
        ("chicken breast", ["chicken", "breast"]),
        ("brown rice", ["rice", "brown"]),

        # éƒ¨åˆ†ä¸€è‡´ãƒ†ã‚¹ãƒˆ
        ("beans", ["black beans", "kidney beans", "fava beans", "garbanzo beans"]),
        ("rice", ["brown rice", "white rice", "rice flour"]),
    ]

    all_results = []

    for query, expected_alternatives in alternative_test_cases:
        result = test_alternative_names_query(query, expected_alternatives)
        all_results.append(result)

    # ä»£æ›¿åæ¤œç´¢åŠ¹æœã®ã‚µãƒãƒªãƒ¼
    print(f"\n{'='*80}")
    print("ğŸ“Š ä»£æ›¿åæ¤œç´¢åŠ¹æœã‚µãƒãƒªãƒ¼")
    print(f"{'='*80}")

    total_tests = len(all_results)
    successful_alternative_searches = len([r for r in all_results if r.get("alternative_matches_count", 0) > 0])

    print(f"ğŸ”¢ ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
    print(f"âœ… ä»£æ›¿åãƒãƒƒãƒæˆåŠŸ: {successful_alternative_searches}")
    print(f"âŒ ä»£æ›¿åãƒãƒƒãƒå¤±æ•—: {total_tests - successful_alternative_searches}")
    print(f"ğŸ“ˆ ä»£æ›¿åæ¤œç´¢æˆåŠŸç‡: {(successful_alternative_searches/total_tests)*100:.1f}%")

    # è©³ç´°çµ±è¨ˆ
    all_alternative_matches = [r.get("alternative_matches_count", 0) for r in all_results]
    avg_alternative_matches = sum(all_alternative_matches) / len(all_alternative_matches)

    print(f"ğŸ¯ å¹³å‡ä»£æ›¿åãƒãƒƒãƒæ•°: {avg_alternative_matches:.1f}")

    # ãƒˆãƒƒãƒ—é †ä½ã§ã®ä»£æ›¿åãƒãƒƒãƒåˆ†æ
    top_rank_matches = [min(r.get("alternative_matches_ranks", [999])) for r in all_results if r.get("alternative_matches_ranks")]
    if top_rank_matches:
        avg_top_rank = sum(top_rank_matches) / len(top_rank_matches)
        print(f"ğŸ¥‡ ä»£æ›¿åãƒãƒƒãƒå¹³å‡æœ€é«˜é †ä½: {avg_top_rank:.1f}")

    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"mynetdiary_list_support_alternative_names_test_{timestamp}.json"

    test_summary = {
        "timestamp": timestamp,
        "index_name": INDEX_NAME,
        "test_type": "alternative_names_optimization",
        "total_tests": total_tests,
        "successful_alternative_searches": successful_alternative_searches,
        "success_rate_percent": (successful_alternative_searches/total_tests)*100,
        "avg_alternative_matches": avg_alternative_matches,
        "avg_top_rank": sum(top_rank_matches) / len(top_rank_matches) if top_rank_matches else None,
        "detailed_results": all_results
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(test_summary, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {output_file}")

    return test_summary

if __name__ == "__main__":
    print("ğŸ” MyNetDiary List Support DB ä»£æ›¿åæœ€é©åŒ–ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("="*80)
    print("ğŸ¯ search_name_listé…åˆ—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ´»ç”¨ã«ã‚ˆã‚‹ä»£æ›¿åæ¤œç´¢æ”¹å–„ãƒ†ã‚¹ãƒˆ")
    print("ğŸ“– READMEã®7æ®µéšæ¤œç´¢æˆ¦ç•¥ + é…åˆ—å½¢å¼å¯¾å¿œ")
    print("="*80)

    # ä»£æ›¿åæœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = run_alternative_names_test()

    print(f"\nğŸ‰ ä»£æ›¿åæœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†!")
    print(f"ğŸ“Š æˆåŠŸç‡: {results['success_rate_percent']:.1f}%")
    if results.get('avg_top_rank'):
        print(f"ğŸ¥‡ å¹³å‡æœ€é«˜é †ä½: {results['avg_top_rank']:.1f}")