================================================================================
MEAL ANALYSIS API v2.0 - 戦略的マルチDB栄養検索システム アーキテクチャ分析
================================================================================
生成日時: 2025-06-10 17:11:57
分析対象: test_multi_db_nutrition_search.py実行時に呼び出される全ファイル
================================================================================

🚀 STRATEGIC MULTI-DB ELASTICSEARCH SEARCH ARCHITECTURE OVERVIEW
------------------------------------------------------------

🔄 STRATEGIC SEARCH EXECUTION FLOW:
1. test_multi_db_nutrition_search.py → FastAPI /complete endpoint
2. Phase1: Gemini AI画像分析 → 料理・食材識別
3. 戦略的Elasticsearch検索:
   📍 DISH戦略: EatThisMuch dish → EatThisMuch branded (fallback)
   🥕 INGREDIENT戦略: EatThisMuch ingredient → Multi-DB (MyNetDiary/YAZIO/branded)
4. 栄養データ統合・結果保存

🏗️ COMPONENT-BASED ARCHITECTURE v2.0:
├── Test Layer
│   └── test_multi_db_nutrition_search.py (戦略的検索テスト実行)
├── FastAPI Application Layer (app_v2)
│   ├── main/app.py (Server, CORS, routing)
│   └── api/v1/endpoints/meal_analysis.py (Complete analysis endpoint)
├── Pipeline Management Layer
│   ├── orchestrator.py (MealAnalysisPipeline - 全フェーズ統制)
│   └── result_manager.py (ResultManager - 結果保存・管理)
├── Component Layer
│   ├── base.py (BaseComponent - コンポーネント基底クラス)
│   ├── phase1_component.py (Phase1Component - Gemini AI分析)
│   └── elasticsearch_nutrition_search_component.py (戦略的検索エンジン)
├── Data Model Layer
│   ├── nutrition_search_models.py (NutritionMatch, NutritionQueryInput/Output)
│   └── phase1_models.py (Phase1Input/Output, Dish, Ingredient)
├── Elasticsearch Infrastructure
│   ├── create_elasticsearch_index.py (インデックス作成・管理)
│   └── elasticsearch-8.10.4/ (Elasticsearchサーバー)
└── Data Layer
    ├── yazio_db.json (1,825項目 - バランス食品)
    ├── mynetdiary_db.json (1,142項目 - 科学的データ)
    └── eatthismuch_db.json (8,878項目 - 最大データベース)

🎯 STRATEGIC SEARCH FEATURES:
- 🔥 Dish検索戦略: EatThisMuch dish (メイン) + branded (補助)
- 🥕 Ingredient検索戦略: EatThisMuch ingredient (メイン) + Multi-DB (補助)
- ⚡ 高速化: 677ms → 381ms (44%向上)
- 📊 最適化結果: 144件 → 50件 (関連性重視)
- 🎯 戦略的分散: EatThisMuch 72%, MyNetDiary/YAZIO 各14%
- 📈 品質向上: スコア閾値20.0による動的フォールバック
- 💾 詳細メタデータ: 戦略フェーズ・ソース情報追跡

🔧 TECHNICAL SPECIFICATIONS:
- Search Engine: Elasticsearch 8.10.4 (11,845ドキュメント)
- AI Service: Google Vertex AI (Gemini 2.5 Flash)
- Web Framework: FastAPI 0.104+ (async/await)
- Architecture: Component-based Pipeline Pattern
- Data Format: JSON (100g正規化栄養データ)
- Search Strategy: BM25F + Multi-Signal Boosting + Strategic Filtering
- Performance: 90.9% match rate, sub-second response times

🚀 STRATEGIC IMPROVEMENTS vs LEGACY:
- 戦略的データベース選択 (EatThisMuchを中心とした最適化)
- スコアベースフォールバック (低品質時の自動補完)
- 効率的リソース使用 (必要データのみ取得)
- 構造化メタデータ (検索プロセス追跡可能)
- スケーラブル設計 (新戦略・DBの容易追加)

================================================================================

📁 テスト実行ファイル
============================================================

📄 FILE: test_multi_db_nutrition_search.py
--------------------------------------------------
ファイルサイズ: 19,963 bytes
最終更新: 2025-06-10 14:55:21
存在: ✅

CONTENT:
```python
#!/usr/bin/env python3
"""
Multi-Database Nutrition Search Test v3.0 - Multi-DB Elasticsearch Edition

ElasticsearchNutritionSearchComponentのマルチデータベース検索機能を使用して
3つのデータベース（yazio, mynetdiary, eatthismuch）から各3つずつ
栄養データベース検索結果を取得してテストするスクリプト
"""

import requests
import json
import time
import os
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional

# Elasticsearch Nutrition Search Component
from app_v2.components.elasticsearch_nutrition_search_component import ElasticsearchNutritionSearchComponent
from app_v2.models.nutrition_search_models import NutritionQueryInput

# API設定（新しいアーキテクチャ版）
BASE_URL = "http://localhost:8000/api/v1"

# テスト画像のパス
image_path = "test_images/food3.jpg"

async def test_multi_db_elasticsearch_nutrition_search():
    """マルチデータベースElasticsearch栄養検索をテスト"""
    
    print("=== Multi-Database Nutrition Search Test v3.0 - Multi-DB Elasticsearch Edition ===")
    print(f"Using image: {image_path}")
    print("🔍 Testing Multi-Database Elasticsearch-powered nutrition search")
    print("📊 Each query will return up to 3 results from each of 3 databases (yazio, mynetdiary, eatthismuch)")
    
    try:
        # 完全分析エンドポイントを呼び出してPhase1結果を取得
        with open(image_path, "rb") as f:
            files = {"image": ("food3.jpg", f, "image/jpeg")}
            data = {"save_results": True}
            
            print("Starting complete analysis to get Phase1 results...")
            start_time = time.time()
            response = requests.post(f"{BASE_URL}/meal-analyses/complete", files=files, data=data)
            end_time = time.time()
        
        print(f"Status Code: {response.status_code}")
        print(f"Response Time: {end_time - start_time:.2f}s")
        
        if response.status_code != 200:
            print("❌ Failed to get Phase1 results!")
            print(f"Error: {response.text}")
            return False
        
        result = response.json()
        analysis_id = result.get("analysis_id")
        print(f"Analysis ID: {analysis_id}")
        
        # Phase1結果から検索クエリを抽出
        phase1_result = result.get("phase1_result", {})
        dishes = phase1_result.get("dishes", [])
        
        all_queries = []
        dish_names = []
        ingredient_names = []
        
        for dish in dishes:
            dish_name = dish.get("dish_name")
            if dish_name:
                dish_names.append(dish_name)
                all_queries.append(dish_name)
            
            ingredients = dish.get("ingredients", [])
            for ingredient in ingredients:
                ingredient_name = ingredient.get("ingredient_name")
                if ingredient_name:
                    ingredient_names.append(ingredient_name)
                    all_queries.append(ingredient_name)
        
        # 重複を除去
        all_queries = list(set(all_queries))
        dish_names = list(set(dish_names))
        ingredient_names = list(set(ingredient_names))
        
        print(f"\n📊 Extracted Search Queries:")
        print(f"- Total dishes: {len(dish_names)}")
        print(f"- Total ingredients: {len(ingredient_names)}")
        print(f"- Total unique queries: {len(all_queries)}")
        
        if len(all_queries) == 0:
            print("❌ No search queries extracted from Phase1 results!")
            return False
        
        # ElasticsearchNutritionSearchComponentをマルチデータベースモードで初期化
        print(f"\n🔧 Initializing ElasticsearchNutritionSearchComponent (Multi-DB Mode)...")
        es_component = ElasticsearchNutritionSearchComponent(
            multi_db_search_mode=True,  # マルチDBモードを有効化
            results_per_db=5  # 各データベースから5つずつ結果を取得
        )
        
        # 検索入力データを作成
        nutrition_query_input = NutritionQueryInput(
            ingredient_names=ingredient_names,
            dish_names=dish_names,
            preferred_source="elasticsearch"
        )
        
        print(f"📝 Query Input:")
        print(f"- Ingredient names: {len(ingredient_names)} items")
        print(f"- Dish names: {len(dish_names)} items")
        print(f"- Total search terms: {len(nutrition_query_input.get_all_search_terms())}")
        print(f"- Multi-DB search mode: Enabled")
        print(f"- Results per database: 5")
        print(f"- Target databases: yazio, mynetdiary, eatthismuch")
        
        # Elasticsearch マルチDB検索を実行
        print(f"\n🔍 Starting Multi-Database Elasticsearch nutrition search...")
        search_start_time = time.time()
        
        search_results = await es_component.execute(nutrition_query_input)
        
        search_end_time = time.time()
        search_time = search_end_time - search_start_time
        
        print(f"✅ Multi-DB Elasticsearch search completed in {search_time:.3f}s")
        
        # 結果の分析
        matches = search_results.matches
        search_summary = search_results.search_summary
        
        print(f"\n📈 Multi-DB Elasticsearch Search Results Summary:")
        print(f"- Total queries: {search_summary.get('total_searches', 0)}")
        print(f"- Successful matches: {search_summary.get('successful_matches', 0)}")
        print(f"- Failed searches: {search_summary.get('failed_searches', 0)}")
        print(f"- Match rate: {search_summary.get('match_rate_percent', 0):.1f}%")
        print(f"- Search time: {search_summary.get('search_time_ms', 0)}ms")
        print(f"- Search method: {search_summary.get('search_method', 'unknown')}")
        print(f"- Database source: {search_summary.get('database_source', 'unknown')}")
        print(f"- Total indexed documents: {search_summary.get('total_indexed_documents', 0)}")
        print(f"- Results per database: {search_summary.get('results_per_db', 0)}")
        print(f"- Target databases: {search_summary.get('target_databases', [])}")
        print(f"- Total results: {search_summary.get('total_results', 0)}")
        
        # データベース別統計の詳細計算
        db_detailed_stats = {"yazio": 0, "mynetdiary": 0, "eatthismuch": 0, "unknown": 0}
        source_distribution = {}
        query_results_breakdown = {}
        
        total_individual_results = 0
        for query, match_results in matches.items():
            if isinstance(match_results, list):
                # マルチDB検索の場合、リスト形式で結果が返される
                query_results_breakdown[query] = len(match_results)
                total_individual_results += len(match_results)
                
                for match in match_results:
                    source = match.source
                    if "elasticsearch_" in source:
                        db_name = source.replace("elasticsearch_", "")
                        if db_name in db_detailed_stats:
                            db_detailed_stats[db_name] += 1
                        else:
                            db_detailed_stats["unknown"] += 1
                    
                    if source not in source_distribution:
                        source_distribution[source] = 0
                    source_distribution[source] += 1
            else:
                # 単一結果の場合（従来形式）
                query_results_breakdown[query] = 1
                total_individual_results += 1
                source = match_results.source
                if source not in source_distribution:
                    source_distribution[source] = 0
                source_distribution[source] += 1
        
        print(f"\n📊 Detailed Database Source Distribution:")
        for source, count in source_distribution.items():
            percentage = (count / total_individual_results) * 100 if total_individual_results > 0 else 0
            print(f"- {source}: {count} results ({percentage:.1f}%)")
        
        print(f"\n📋 Per-Query Results Breakdown:")
        for query, result_count in query_results_breakdown.items():
            query_type = "dish" if query in dish_names else "ingredient"
            print(f"- '{query}' ({query_type}): {result_count} results")
        
        print(f"\n🔍 Top Multi-DB Match Results (showing first 5 queries):")
        for i, (query, match_results) in enumerate(list(matches.items())[:5], 1):
            query_type = "dish" if query in dish_names else "ingredient"
            print(f"\n{i:2d}. Query: '{query}' ({query_type})")
            
            if isinstance(match_results, list):
                print(f"    Found {len(match_results)} results from multiple databases:")
                for j, match in enumerate(match_results, 1):
                    print(f"    {j}. {match.search_name} (score: {match.score:.3f})")
                    print(f"       Source: {match.source}")
                    print(f"       Data type: {match.data_type}")
                    
                    nutrition = match.nutrition
                    if nutrition:
                        calories = nutrition.get('calories', 0)
                        protein = nutrition.get('protein', 0)
                        fat = nutrition.get('fat', 0)
                        carbs = nutrition.get('carbs', nutrition.get('carbohydrates', 0))
                        print(f"       Nutrition (100g): {calories:.1f} kcal, P:{protein:.1f}g, F:{fat:.1f}g, C:{carbs:.1f}g")
            else:
                # 単一結果の場合
                print(f"    Single result: {match_results.search_name} (score: {match_results.score:.3f})")
                print(f"    Source: {match_results.source}")
        
        if len(matches) > 5:
            print(f"\n    ... and {len(matches) - 5} more queries with results")
        
        # 警告とエラーの表示
        if search_results.warnings:
            print(f"\n⚠️  Warnings:")
            for warning in search_results.warnings:
                print(f"   - {warning}")
        
        if search_results.errors:
            print(f"\n❌ Errors:")
            for error in search_results.errors:
                print(f"   - {error}")
        
        # 詳細結果をファイルに保存
        await save_multi_db_elasticsearch_results(analysis_id, search_results, all_queries, dish_names, ingredient_names)
        
        return True
        
    except Exception as e:
        print(f"❌ Error during Multi-DB Elasticsearch nutrition search: {e}")
        import traceback
        traceback.print_exc()
        return False

async def save_multi_db_elasticsearch_results(analysis_id: str, search_results, all_queries: List[str], dish_names: List[str], ingredient_names: List[str]):
    """マルチデータベースElasticsearch検索結果をファイルに保存"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"analysis_results/multi_db_elasticsearch_search_{analysis_id}_{timestamp}"
    os.makedirs(results_dir, exist_ok=True)
    
    # 検索結果を辞書形式に変換
    matches_dict = {}
    for query, match_results in search_results.matches.items():
        if isinstance(match_results, list):
            # マルチDB結果の場合
            matches_dict[query] = []
            for match in match_results:
                matches_dict[query].append({
                    "id": match.id,
                    "search_name": match.search_name,
                    "description": match.description,
                    "data_type": match.data_type,
                    "source": match.source,
                    "nutrition": match.nutrition,
                    "weight": match.weight,
                    "score": match.score,
                    "search_metadata": match.search_metadata
                })
        else:
            # 単一結果の場合
            matches_dict[query] = {
                "id": match_results.id,
                "search_name": match_results.search_name,
                "description": match_results.description,
                "data_type": match_results.data_type,
                "source": match_results.source,
                "nutrition": match_results.nutrition,
                "weight": match_results.weight,
                "score": match_results.score,
                "search_metadata": match_results.search_metadata
            }
    
    # 1. 全検索結果をJSONで保存
    results_file = os.path.join(results_dir, "multi_db_elasticsearch_search_results.json")
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            "analysis_id": analysis_id,
            "timestamp": timestamp,
            "search_method": "elasticsearch_multi_db",
            "input_queries": {
                "all_queries": all_queries,
                "dish_names": dish_names,
                "ingredient_names": ingredient_names
            },
            "search_summary": search_results.search_summary,
            "matches": matches_dict,
            "warnings": search_results.warnings,
            "errors": search_results.errors
        }, f, indent=2, ensure_ascii=False)
    
    # 2. 検索サマリーをマークダウンで保存
    summary_file = os.path.join(results_dir, "multi_db_elasticsearch_summary.md")
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(f"# Multi-Database Elasticsearch Nutrition Search Results\n\n")
        f.write(f"**Analysis ID:** {analysis_id}\n")
        f.write(f"**Timestamp:** {timestamp}\n")
        f.write(f"**Search Method:** Multi-Database Elasticsearch\n")
        f.write(f"**Total Queries:** {len(all_queries)}\n")
        f.write(f"**Results per Database:** 5\n")
        f.write(f"**Target Databases:** yazio, mynetdiary, eatthismuch\n\n")
        
        # 検索サマリー
        summary = search_results.search_summary
        f.write(f"## Search Summary\n\n")
        f.write(f"- **Total searches:** {summary.get('total_searches', 0)}\n")
        f.write(f"- **Successful matches:** {summary.get('successful_matches', 0)}\n")
        f.write(f"- **Failed searches:** {summary.get('failed_searches', 0)}\n")
        f.write(f"- **Match rate:** {summary.get('match_rate_percent', 0):.1f}%\n")
        f.write(f"- **Search time:** {summary.get('search_time_ms', 0)}ms\n")
        f.write(f"- **Database source:** {summary.get('database_source', 'unknown')}\n")
        f.write(f"- **Total indexed documents:** {summary.get('total_indexed_documents', 0)}\n")
        f.write(f"- **Results per database:** {summary.get('results_per_db', 0)}\n")
        f.write(f"- **Target databases:** {', '.join(summary.get('target_databases', []))}\n")
        f.write(f"- **Total results:** {summary.get('total_results', 0)}\n\n")
        
        # ソース分布
        source_distribution = {}
        total_individual_results = 0
        for match_results in search_results.matches.values():
            if isinstance(match_results, list):
                total_individual_results += len(match_results)
                for match in match_results:
                    source = match.source
                    if source not in source_distribution:
                        source_distribution[source] = 0
                    source_distribution[source] += 1
            else:
                total_individual_results += 1
                source = match_results.source
                if source not in source_distribution:
                    source_distribution[source] = 0
                source_distribution[source] += 1
        
        f.write(f"## Source Database Distribution\n\n")
        for source, count in source_distribution.items():
            percentage = (count / total_individual_results) * 100 if total_individual_results > 0 else 0
            f.write(f"- **{source}:** {count} results ({percentage:.1f}%)\n")
        f.write(f"\n")
        
        # 詳細結果
        f.write(f"## Multi-DB Match Results Detail\n\n")
        for i, (query, match_results) in enumerate(search_results.matches.items(), 1):
            query_type = "dish" if query in dish_names else "ingredient"
            f.write(f"### {i}. {query} ({query_type})\n\n")
            
            if isinstance(match_results, list):
                f.write(f"**Found {len(match_results)} results from multiple databases:**\n\n")
                for j, match in enumerate(match_results, 1):
                    f.write(f"#### Result {j}\n")
                    f.write(f"- **Match:** {match.search_name}\n")
                    f.write(f"- **Score:** {match.score:.3f}\n")
                    f.write(f"- **Source:** {match.source}\n")
                    f.write(f"- **Data Type:** {match.data_type}\n")
                    
                    if match.nutrition:
                        nutrition = match.nutrition
                        calories = nutrition.get('calories', 0)
                        protein = nutrition.get('protein', 0)
                        fat = nutrition.get('fat', 0)
                        carbs = nutrition.get('carbs', nutrition.get('carbohydrates', 0))
                        f.write(f"- **Nutrition (100g):** {calories:.1f} kcal, P:{protein:.1f}g, F:{fat:.1f}g, C:{carbs:.1f}g\n")
                    
                    if match.description:
                        f.write(f"- **Description:** {match.description}\n")
                    
                    f.write(f"\n")
            else:
                # 単一結果の場合
                f.write(f"**Single result:**\n")
                f.write(f"- **Match:** {match_results.search_name}\n")
                f.write(f"- **Score:** {match_results.score:.3f}\n")
                f.write(f"- **Source:** {match_results.source}\n")
                f.write(f"- **Data Type:** {match_results.data_type}\n")
                
                if match_results.nutrition:
                    nutrition = match_results.nutrition
                    calories = nutrition.get('calories', 0)
                    protein = nutrition.get('protein', 0)
                    fat = nutrition.get('fat', 0)
                    carbs = nutrition.get('carbs', nutrition.get('carbohydrates', 0))
                    f.write(f"- **Nutrition (100g):** {calories:.1f} kcal, P:{protein:.1f}g, F:{fat:.1f}g, C:{carbs:.1f}g\n")
                
                if match_results.description:
                    f.write(f"- **Description:** {match_results.description}\n")
                
                f.write(f"\n")
        
        # 警告とエラー
        if search_results.warnings:
            f.write(f"## Warnings\n\n")
            for warning in search_results.warnings:
                f.write(f"- {warning}\n")
            f.write(f"\n")
        
        if search_results.errors:
            f.write(f"## Errors\n\n")
            for error in search_results.errors:
                f.write(f"- {error}\n")
            f.write(f"\n")
    
    print(f"\n💾 Multi-DB Elasticsearch results saved to:")
    print(f"   📁 {results_dir}/")
    print(f"   📄 multi_db_elasticsearch_search_results.json")
    print(f"   📄 multi_db_elasticsearch_summary.md")

if __name__ == "__main__":
    print("🚀 Starting Multi-Database Elasticsearch Nutrition Search Test")
    success = asyncio.run(test_multi_db_elasticsearch_nutrition_search())
    
    if success:
        print("\n✅ Multi-Database Elasticsearch nutrition search test completed successfully!")
        print("🎯 Each query returned up to 3 results from each of 3 databases (yazio, mynetdiary, eatthismuch)")
    else:
        print("\n❌ Multi-Database Elasticsearch nutrition search test failed!") 
```

============================================================

📁 FastAPI アプリケーション層 (app_v2)
============================================================

📄 FILE: app_v2/main/app.py
--------------------------------------------------
ファイルサイズ: 2,030 bytes
最終更新: 2025-06-05 12:55:53
存在: ✅

CONTENT:
```python
import os
import logging
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from ..api.v1.endpoints import meal_analysis
from ..config import get_settings

# 環境変数の設定（既存のappと同じ）
os.environ.setdefault("USDA_API_KEY", "vSWtKJ3jYD0Cn9LRyVJUFkuyCt9p8rEtVXz74PZg")
os.environ.setdefault("GOOGLE_APPLICATION_CREDENTIALS", "/Users/odasoya/meal_analysis_api /service-account-key.json")
os.environ.setdefault("GEMINI_PROJECT_ID", "recording-diet-ai-3e7cf")
os.environ.setdefault("GEMINI_LOCATION", "us-central1")
os.environ.setdefault("GEMINI_MODEL_NAME", "gemini-2.5-flash-preview-05-20")

# ロギング設定
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# FastAPIアプリの作成
app = FastAPI(
    title="食事分析 API v2.0",
    description="コンポーネント化された食事分析システム",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS設定
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ルーターの登録
app.include_router(
    meal_analysis.router,
    prefix="/api/v1/meal-analyses",
    tags=["Complete Meal Analysis v2.0"]
)

# ルートエンドポイント
@app.get("/")
async def root():
    """ルートエンドポイント"""
    return {
        "message": "食事分析 API v2.0 - コンポーネント化版",
        "version": "2.0.0",
        "architecture": "Component-based Pipeline",
        "docs": "/docs"
    }

@app.get("/health")
async def health():
    """ヘルスチェック"""
    return {
        "status": "healthy",
        "version": "v2.0",
        "components": ["Phase1Component", "USDAQueryComponent"]
    }

if __name__ == "__main__":
    import uvicorn
    settings = get_settings()
    uvicorn.run(
        "app_v2.main.app:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=True
    ) 
```

============================================================

📄 FILE: app_v2/api/v1/endpoints/meal_analysis.py
--------------------------------------------------
ファイルサイズ: 2,696 bytes
最終更新: 2025-06-09 11:27:28
存在: ✅

CONTENT:
```python
from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse
from typing import Optional
import logging

from ....pipeline import MealAnalysisPipeline

logger = logging.getLogger(__name__)

router = APIRouter()


@router.post("/complete")
async def complete_meal_analysis(
    image: UploadFile = File(...),
    save_results: bool = Form(True),
    save_detailed_logs: bool = Form(True)
):
    """
    完全な食事分析を実行（v2.0 コンポーネント化版）
    
    - Phase 1: Gemini AIによる画像分析
    - USDA Query: 食材のUSDAデータベース照合
    - Phase 2: 計算戦略決定と栄養価精緻化 (TODO)
    - Nutrition Calculation: 最終栄養価計算 (TODO)
    
    Args:
        image: 分析対象の食事画像
        save_results: 結果を保存するかどうか (デフォルト: True)
        save_detailed_logs: 詳細ログを保存するかどうか (デフォルト: True)
    
    Returns:
        完全な分析結果と栄養価計算、詳細ログファイルパス
    """
    
    try:
        # 画像の検証
        if not image.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="アップロードされたファイルは画像である必要があります")
        
        # 画像データの読み込み
        image_data = await image.read()
        logger.info(f"Starting complete meal analysis pipeline v2.0 (detailed_logs: {save_detailed_logs})")
        
        # パイプラインの実行
        pipeline = MealAnalysisPipeline()
        result = await pipeline.execute_complete_analysis(
            image_bytes=image_data,
            image_mime_type=image.content_type,
            save_results=save_results,
            save_detailed_logs=save_detailed_logs
        )
        
        logger.info(f"Complete analysis pipeline v2.0 finished successfully")
        
        return JSONResponse(
            status_code=200,
            content=result
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Complete analysis failed: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Complete analysis failed: {str(e)}"
        )


@router.get("/health")
async def health_check():
    """ヘルスチェック"""
    return {"status": "healthy", "version": "v2.0", "message": "食事分析API v2.0 - コンポーネント化版"}


@router.get("/pipeline-info")
async def get_pipeline_info():
    """パイプライン情報の取得"""
    pipeline = MealAnalysisPipeline()
    return pipeline.get_pipeline_info() 
```

============================================================

📁 パイプライン統制層
============================================================

📄 FILE: app_v2/pipeline/__init__.py
--------------------------------------------------
ファイルサイズ: 142 bytes
最終更新: 2025-06-05 13:08:07
存在: ✅

CONTENT:
```python
from .orchestrator import MealAnalysisPipeline
from .result_manager import ResultManager

__all__ = ["MealAnalysisPipeline", "ResultManager"] 
```

============================================================

📄 FILE: app_v2/pipeline/orchestrator.py
--------------------------------------------------
ファイルサイズ: 14,879 bytes
最終更新: 2025-06-10 14:54:56
存在: ✅

CONTENT:
```python
import uuid
import json
from datetime import datetime
from typing import Optional, Dict, Any
import logging

from ..components import Phase1Component, USDAQueryComponent, LocalNutritionSearchComponent, ElasticsearchNutritionSearchComponent
from ..models import (
    Phase1Input, Phase1Output,
    USDAQueryInput, USDAQueryOutput,
    NutritionQueryInput
)
from ..config import get_settings
from .result_manager import ResultManager

logger = logging.getLogger(__name__)


class MealAnalysisPipeline:
    """
    食事分析パイプラインのオーケストレーター
    
    4つのフェーズを統合して完全な分析を実行します。
    """
    
    def __init__(self, use_local_nutrition_search: Optional[bool] = None, use_elasticsearch_search: Optional[bool] = None):
        """
        パイプラインの初期化
        
        Args:
            use_local_nutrition_search: ローカル栄養データベース検索を使用するかどうか（レガシー）
            use_elasticsearch_search: Elasticsearch栄養データベース検索を使用するかどうか
                                    None: 設定ファイルから自動取得
                                    True: ElasticsearchNutritionSearchComponent使用（推奨）
                                    False: 従来のUSDAQueryComponent使用
        """
        self.pipeline_id = str(uuid.uuid4())[:8]
        self.settings = get_settings()
        
        # Elasticsearch検索優先度の決定
        if use_elasticsearch_search is not None:
            self.use_elasticsearch_search = use_elasticsearch_search
        elif hasattr(self.settings, 'USE_ELASTICSEARCH_SEARCH'):
            self.use_elasticsearch_search = self.settings.USE_ELASTICSEARCH_SEARCH
        else:
            # デフォルトはElasticsearch使用
            self.use_elasticsearch_search = True
        
        # レガシー互換性の処理
        if use_local_nutrition_search is not None and use_elasticsearch_search is None:
            # 旧パラメータが指定された場合はそちらを優先
            if use_local_nutrition_search:
                self.use_elasticsearch_search = False
                self.use_local_nutrition_search = True
            else:
                self.use_elasticsearch_search = False
                self.use_local_nutrition_search = False
        else:
            self.use_local_nutrition_search = not self.use_elasticsearch_search and (
                use_local_nutrition_search or getattr(self.settings, 'USE_LOCAL_NUTRITION_SEARCH', False)
            )
        
        # コンポーネントの初期化
        self.phase1_component = Phase1Component()
        
        # 栄養データベース検索コンポーネントの選択
        if self.use_elasticsearch_search:
            self.nutrition_search_component = ElasticsearchNutritionSearchComponent(
                multi_db_search_mode=True,
                results_per_db=5
            )
            self.search_component_name = "ElasticsearchNutritionSearchComponent"
            logger.info("Using Elasticsearch nutrition database search (high-performance, multi-DB mode)")
        elif self.use_local_nutrition_search:
            self.nutrition_search_component = LocalNutritionSearchComponent()
            self.search_component_name = "LocalNutritionSearchComponent"
            logger.info("Using local nutrition database search (nutrition_db_experiment)")
        else:
            self.nutrition_search_component = USDAQueryComponent()
            self.search_component_name = "USDAQueryComponent"
            logger.info("Using traditional USDA API search")
            
        # TODO: Phase2ComponentとNutritionCalculationComponentを追加
        
        self.logger = logging.getLogger(f"{__name__}.{self.pipeline_id}")
        
    async def execute_complete_analysis(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        optional_text: Optional[str] = None,
        save_results: bool = True,
        save_detailed_logs: bool = True
    ) -> Dict[str, Any]:
        """
        完全な食事分析を実行
        
        Args:
            image_bytes: 画像データ
            image_mime_type: 画像のMIMEタイプ
            optional_text: オプションのテキスト
            save_results: 結果を保存するかどうか
            save_detailed_logs: 詳細ログを保存するかどうか
            
        Returns:
            完全な分析結果
        """
        analysis_id = str(uuid.uuid4())[:8]
        start_time = datetime.now()
        
        # ResultManagerの初期化
        result_manager = ResultManager(analysis_id) if save_detailed_logs else None
        
        self.logger.info(f"[{analysis_id}] Starting complete meal analysis pipeline")
        if self.use_elasticsearch_search:
            self.logger.info(f"[{analysis_id}] Nutrition search method: Elasticsearch (high-performance)")
        elif self.use_local_nutrition_search:
            self.logger.info(f"[{analysis_id}] Nutrition search method: Local Database")
        else:
            self.logger.info(f"[{analysis_id}] Nutrition search method: USDA API")
        
        try:
            # === Phase 1: 画像分析 ===
            self.logger.info(f"[{analysis_id}] Phase 1: Image analysis")
            
            phase1_input = Phase1Input(
                image_bytes=image_bytes,
                image_mime_type=image_mime_type,
                optional_text=optional_text
            )
            
            # Phase1の詳細ログを作成
            phase1_log = result_manager.create_execution_log("Phase1Component", f"{analysis_id}_phase1") if result_manager else None
            
            phase1_result = await self.phase1_component.execute(phase1_input, phase1_log)
            
            self.logger.info(f"[{analysis_id}] Phase 1 completed - Detected {len(phase1_result.dishes)} dishes")
            
            # === Nutrition Search Phase: データベース照合 ===
            if self.use_elasticsearch_search:
                search_phase_name = "Elasticsearch Search"
            elif self.use_local_nutrition_search:
                search_phase_name = "Local Nutrition Search"
            else:
                search_phase_name = "USDA Query"
                
            self.logger.info(f"[{analysis_id}] {search_phase_name} Phase: Database matching")
            
            # === 統一された栄養検索入力を作成 ===
            if self.use_elasticsearch_search or self.use_local_nutrition_search:
                # Elasticsearch検索またはローカル検索の場合はNutritionQueryInputを使用
                preferred_source = "elasticsearch" if self.use_elasticsearch_search else "local_database"
                nutrition_search_input = NutritionQueryInput(
                    ingredient_names=phase1_result.get_all_ingredient_names(),
                    dish_names=phase1_result.get_all_dish_names(),
                    preferred_source=preferred_source
                )
            else:
                # USDA検索の場合はUSDAQueryInputを使用（レガシー互換性）
                nutrition_search_input = USDAQueryInput(
                    ingredient_names=phase1_result.get_all_ingredient_names(),
                    dish_names=phase1_result.get_all_dish_names()
                )
            
            # Nutrition Searchの詳細ログを作成
            search_log = result_manager.create_execution_log(self.search_component_name, f"{analysis_id}_nutrition_search") if result_manager else None
            
            nutrition_search_result = await self.nutrition_search_component.execute(nutrition_search_input, search_log)
            
            self.logger.info(f"[{analysis_id}] {search_phase_name} completed - {nutrition_search_result.get_match_rate():.1%} match rate")
            
            # === 暫定的な結果の構築 (Phase2とNutritionは後で追加) ===
            
            # Phase1の結果を辞書形式に変換（検索特化）
            phase1_dict = {
                "dishes": [
                    {
                        "dish_name": dish.dish_name,
                        "ingredients": [
                            {
                                "ingredient_name": ing.ingredient_name
                            }
                            for ing in dish.ingredients
                        ]
                    }
                    for dish in phase1_result.dishes
                ]
            }
            
            # 簡単な栄養計算（暫定）
            total_calories = sum(
                len(dish.ingredients) * 50  # 仮の計算
                for dish in phase1_result.dishes
            )
            
            # 検索方法の特定
            if self.use_elasticsearch_search:
                search_method = "elasticsearch"
                search_api_method = "elasticsearch"
            elif self.use_local_nutrition_search:
                search_method = "local_nutrition_database"
                search_api_method = "local_database"
            else:
                search_method = "usda_api"
                search_api_method = "usda_api"
            
            # 完全分析結果の構築
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            complete_result = {
                "analysis_id": analysis_id,
                "phase1_result": phase1_dict,
                "nutrition_search_result": {
                    "matches_count": len(nutrition_search_result.matches),
                    "match_rate": nutrition_search_result.get_match_rate(),
                    "search_summary": nutrition_search_result.search_summary,
                    "search_method": search_method
                },
                # レガシー互換性のため、usdaキーも残す
                "usda_result": {
                    "matches_count": len(nutrition_search_result.matches),
                    "match_rate": nutrition_search_result.get_match_rate(),
                    "search_summary": nutrition_search_result.search_summary
                },
                "processing_summary": {
                    "total_dishes": len(phase1_result.dishes),
                    "total_ingredients": len(phase1_result.get_all_ingredient_names()),
                    "nutrition_search_match_rate": f"{len(nutrition_search_result.matches)}/{len(nutrition_search_input.get_all_search_terms())} ({nutrition_search_result.get_match_rate():.1%})",
                    "usda_match_rate": f"{len(nutrition_search_result.matches)}/{len(nutrition_search_input.get_all_search_terms())} ({nutrition_search_result.get_match_rate():.1%})",  # レガシー互換性
                    "total_calories": total_calories,
                    "pipeline_status": "completed",
                    "processing_time_seconds": processing_time,
                    "search_method": search_method
                },
                # 暫定的な最終結果
                "final_nutrition_result": {
                    "dishes": phase1_dict["dishes"],
                    "total_meal_nutrients": {
                        "calories_kcal": total_calories,
                        "protein_g": total_calories * 0.15,  # 仮の値
                        "carbohydrates_g": total_calories * 0.55,  # 仮の値
                        "fat_g": total_calories * 0.30,  # 仮の値
                    }
                },
                "metadata": {
                    "pipeline_version": "v2.0",
                    "timestamp": datetime.now().isoformat(),
                    "components_used": ["Phase1Component", self.search_component_name],
                    "nutrition_search_method": search_api_method
                }
            }
            
            # ResultManagerに最終結果を設定
            if result_manager:
                result_manager.set_final_result(complete_result)
                result_manager.finalize_pipeline()
            
            # 結果の保存
            saved_files = {}
            if save_detailed_logs and result_manager:
                # 新しいフェーズ別保存方式
                saved_files = result_manager.save_phase_results()
                complete_result["analysis_folder"] = result_manager.get_analysis_folder_path()
                complete_result["saved_files"] = saved_files
                
                logger.info(f"[{analysis_id}] Detailed logs saved to folder: {result_manager.get_analysis_folder_path()}")
                logger.info(f"[{analysis_id}] Saved {len(saved_files)} files across all phases")
            
            if save_results:
                # 通常の結果保存（互換性維持）
                saved_file = f"analysis_results/meal_analysis_{analysis_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                complete_result["legacy_saved_to"] = saved_file
            
            self.logger.info(f"[{analysis_id}] Complete analysis pipeline finished successfully in {processing_time:.2f}s")
            
            return complete_result
            
        except Exception as e:
            self.logger.error(f"[{analysis_id}] Complete analysis failed: {str(e)}", exc_info=True)
            
            # エラー時もResultManagerを保存
            if result_manager:
                result_manager.set_final_result({"error": str(e), "timestamp": datetime.now().isoformat()})
                result_manager.finalize_pipeline()
                error_saved_files = result_manager.save_phase_results()
                self.logger.info(f"[{analysis_id}] Error analysis logs saved to folder: {result_manager.get_analysis_folder_path()}")
            
            raise
    
    def get_pipeline_info(self) -> Dict[str, Any]:
        """パイプライン情報を取得"""
        if self.use_elasticsearch_search:
            search_method = "elasticsearch"
        elif self.use_local_nutrition_search:
            search_method = "local_database"
        else:
            search_method = "usda_api"
            
        return {
            "pipeline_id": self.pipeline_id,
            "version": "v2.0",
            "nutrition_search_method": search_method,
            "components": [
                {
                    "component_name": "Phase1Component",
                    "component_type": "analysis",
                    "execution_count": 0
                },
                {
                    "component_name": self.search_component_name,
                    "component_type": "nutrition_search",
                    "execution_count": 0
                }
            ]
        } 
```

============================================================

📄 FILE: app_v2/pipeline/result_manager.py
--------------------------------------------------
ファイルサイズ: 36,336 bytes
最終更新: 2025-06-10 14:06:44
存在: ✅

CONTENT:
```python
import json
import os
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class DetailedExecutionLog:
    """各コンポーネントの詳細実行ログ"""
    
    def __init__(self, component_name: str, execution_id: str):
        self.component_name = component_name
        self.execution_id = execution_id
        self.execution_start_time = datetime.now()
        self.execution_end_time = None
        self.input_data = {}
        self.output_data = {}
        self.processing_details = {}
        self.prompts_used = {}
        self.reasoning = {}
        self.confidence_scores = {}
        self.warnings = []
        self.errors = []
        
    def set_input(self, input_data: Dict[str, Any]):
        """入力データを記録（機密情報は除外）"""
        # 画像データは大きすぎるので、メタデータのみ保存
        safe_input = {}
        for key, value in input_data.items():
            if key == 'image_bytes':
                safe_input[key] = {
                    "size_bytes": len(value) if value else 0,
                    "type": "binary_image_data"
                }
            else:
                safe_input[key] = value
        self.input_data = safe_input
    
    def set_output(self, output_data: Dict[str, Any]):
        """出力データを記録"""
        self.output_data = output_data
        
    def add_prompt(self, prompt_name: str, prompt_content: str, variables: Dict[str, Any] = None):
        """使用されたプロンプトを記録"""
        self.prompts_used[prompt_name] = {
            "content": prompt_content,
            "variables": variables or {},
            "timestamp": datetime.now().isoformat()
        }
    
    def add_reasoning(self, decision_point: str, reason: str, confidence: float = None):
        """推論理由を記録"""
        self.reasoning[decision_point] = {
            "reason": reason,
            "confidence": confidence,
            "timestamp": datetime.now().isoformat()
        }
    
    def add_processing_detail(self, detail_key: str, detail_value: Any):
        """処理詳細を記録"""
        self.processing_details[detail_key] = detail_value
    
    def add_confidence_score(self, metric_name: str, score: float):
        """信頼度スコアを記録"""
        self.confidence_scores[metric_name] = score
    
    def add_warning(self, warning: str):
        """警告を記録"""
        self.warnings.append({
            "message": warning,
            "timestamp": datetime.now().isoformat()
        })
    
    def add_error(self, error: str):
        """エラーを記録"""
        self.errors.append({
            "message": error,
            "timestamp": datetime.now().isoformat()
        })
    
    def finalize(self):
        """実行完了時の最終処理"""
        self.execution_end_time = datetime.now()
    
    def get_execution_time(self) -> float:
        """実行時間を取得（秒）"""
        if self.execution_end_time:
            return (self.execution_end_time - self.execution_start_time).total_seconds()
        return 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        """辞書形式で取得"""
        return {
            "component_name": self.component_name,
            "execution_id": self.execution_id,
            "execution_start_time": self.execution_start_time.isoformat(),
            "execution_end_time": self.execution_end_time.isoformat() if self.execution_end_time else None,
            "execution_time_seconds": self.get_execution_time(),
            "input_data": self.input_data,
            "output_data": self.output_data,
            "processing_details": self.processing_details,
            "prompts_used": self.prompts_used,
            "reasoning": self.reasoning,
            "confidence_scores": self.confidence_scores,
            "warnings": self.warnings,
            "errors": self.errors
        }


class ResultManager:
    """解析結果と詳細ログの管理クラス（フェーズ別整理版）"""
    
    def __init__(self, analysis_id: str, save_directory: str = "analysis_results"):
        self.analysis_id = analysis_id
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # 実行ごとのフォルダを作成
        self.analysis_folder_name = f"analysis_{self.timestamp}_{self.analysis_id}"
        self.analysis_dir = Path(save_directory) / self.analysis_folder_name
        self.analysis_dir.mkdir(parents=True, exist_ok=True)
        
        # 各フェーズのフォルダを作成
        self.phase1_dir = self.analysis_dir / "phase1"
        self.nutrition_search_dir = self.analysis_dir / "nutrition_search_query"
        self.phase2_dir = self.analysis_dir / "phase2"
        self.nutrition_dir = self.analysis_dir / "nutrition_calculation"
        
        for phase_dir in [self.phase1_dir, self.nutrition_search_dir, self.phase2_dir, self.nutrition_dir]:
            phase_dir.mkdir(exist_ok=True)
        
        self.pipeline_start_time = datetime.now()
        self.pipeline_end_time = None
        self.execution_logs: List[DetailedExecutionLog] = []
        self.final_result = {}
        self.pipeline_metadata = {
            "analysis_id": analysis_id,
            "version": "v2.0",
            "analysis_folder": self.analysis_folder_name,
            "pipeline_start_time": self.pipeline_start_time.isoformat()
        }
        
    def create_execution_log(self, component_name: str, execution_id: str) -> DetailedExecutionLog:
        """新しい実行ログを作成"""
        log = DetailedExecutionLog(component_name, execution_id)
        self.execution_logs.append(log)
        return log
    
    def set_final_result(self, result: Dict[str, Any]):
        """最終結果を設定"""
        self.final_result = result
        
    def finalize_pipeline(self):
        """パイプライン完了時の最終処理"""
        self.pipeline_end_time = datetime.now()
        self.pipeline_metadata["pipeline_end_time"] = self.pipeline_end_time.isoformat()
        self.pipeline_metadata["total_execution_time_seconds"] = (
            self.pipeline_end_time - self.pipeline_start_time
        ).total_seconds()
    
    def save_phase_results(self) -> Dict[str, str]:
        """フェーズ別に結果を保存"""
        saved_files = {}
        
        # 実行されたコンポーネントのログを処理
        executed_components = set()
        for log in self.execution_logs:
            if log.component_name == "Phase1Component":
                files = self._save_phase1_results(log)
                saved_files.update(files)
                executed_components.add("Phase1Component")
            elif log.component_name in ["USDAQueryComponent", "LocalNutritionSearchComponent", "ElasticsearchNutritionSearchComponent"]:
                files = self._save_nutrition_search_results(log)
                saved_files.update(files)
                executed_components.add(log.component_name)
            elif log.component_name == "Phase2Component":
                files = self._save_phase2_results(log)
                saved_files.update(files)
                executed_components.add("Phase2Component")
            elif log.component_name == "NutritionCalculationComponent":
                files = self._save_nutrition_results(log)
                saved_files.update(files)
                executed_components.add("NutritionCalculationComponent")
        
        # 未実装/未実行のコンポーネントにプレースホルダーファイルを作成
        if "Phase2Component" not in executed_components:
            placeholder_log = DetailedExecutionLog("Phase2Component", f"{self.analysis_id}_phase2_placeholder")
            placeholder_log.input_data = {"note": "Phase2Component not yet implemented"}
            placeholder_log.output_data = {"note": "Phase2Component not yet implemented"}
            placeholder_log.finalize()
            files = self._save_phase2_results(placeholder_log)
            saved_files.update(files)
        
        if "NutritionCalculationComponent" not in executed_components:
            placeholder_log = DetailedExecutionLog("NutritionCalculationComponent", f"{self.analysis_id}_nutrition_placeholder")
            placeholder_log.input_data = {"note": "NutritionCalculationComponent not yet implemented"}
            placeholder_log.output_data = {"note": "NutritionCalculationComponent not yet implemented"}
            placeholder_log.finalize()
            files = self._save_nutrition_results(placeholder_log)
            saved_files.update(files)
        
        # パイプライン全体のサマリーを保存
        summary_files = self._save_pipeline_summary()
        saved_files.update(summary_files)
        
        return saved_files
    
    def _save_phase1_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """Phase1の結果を保存"""
        files = {}
        
        # 1. JSON形式の入出力データ
        input_output_file = self.phase1_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time()
            }, f, indent=2, ensure_ascii=False)
        files["phase1_input_output"] = str(input_output_file)
        
        # 2. プロンプトと推論理由のマークダウン
        prompts_md_file = self.phase1_dir / "prompts_and_reasoning.md"
        prompts_content = self._generate_phase1_prompts_md(log)
        with open(prompts_md_file, 'w', encoding='utf-8') as f:
            f.write(prompts_content)
        files["phase1_prompts_md"] = str(prompts_md_file)
        
        # 3. 検出された料理・食材のテキスト
        detected_items_file = self.phase1_dir / "detected_items.txt"
        detected_content = self._generate_phase1_detected_items_txt(log)
        with open(detected_items_file, 'w', encoding='utf-8') as f:
            f.write(detected_content)
        files["phase1_detected_txt"] = str(detected_items_file)
        
        return files
    
    def _save_nutrition_search_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """栄養データベース検索の結果を保存（USDAQueryComponent、LocalNutritionSearchComponent、ElasticsearchNutritionSearchComponent対応）"""
        files = {}
        
        # 検索方法の判定
        search_method = "unknown"
        db_source = "unknown"
        
        if log.component_name == "USDAQueryComponent":
            search_method = "usda_api"
            db_source = "usda_database"
        elif log.component_name == "LocalNutritionSearchComponent":
            search_method = "local_search"
            db_source = "local_nutrition_database"
        elif log.component_name == "ElasticsearchNutritionSearchComponent":
            search_method = "elasticsearch"
            db_source = "elasticsearch_nutrition_db"
        
        # 1. JSON形式の入出力データ（検索方法情報を含む）
        input_output_file = self.nutrition_search_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time(),
                "search_metadata": {
                    "component_name": log.component_name,
                    "search_method": search_method,
                    "database_source": db_source,
                    "timestamp": log.execution_end_time.isoformat() if log.execution_end_time else None
                }
            }, f, indent=2, ensure_ascii=False)
        files["nutrition_search_input_output"] = str(input_output_file)
        
        # 2. 検索結果の詳細マークダウン
        search_results_md_file = self.nutrition_search_dir / "search_results.md"
        search_content = self._generate_nutrition_search_results_md(log, search_method, db_source)
        with open(search_results_md_file, 'w', encoding='utf-8') as f:
            f.write(search_content)
        files["nutrition_search_results_md"] = str(search_results_md_file)
        
        # 3. マッチ詳細のテキスト
        match_details_file = self.nutrition_search_dir / "match_details.txt"
        match_content = self._generate_nutrition_match_details_txt(log, search_method, db_source)
        with open(match_details_file, 'w', encoding='utf-8') as f:
            f.write(match_content)
        files["nutrition_search_match_details"] = str(match_details_file)
        
        return files
    
    def _save_phase2_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """Phase2の結果を保存（将来実装用）"""
        files = {}
        
        # 1. JSON形式の入出力データ
        input_output_file = self.phase2_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time(),
                "note": "Phase2Component is not yet implemented"
            }, f, indent=2, ensure_ascii=False)
        files["phase2_input_output"] = str(input_output_file)
        
        # 2. 戦略決定のマークダウン
        strategy_md_file = self.phase2_dir / "strategy_decisions.md"
        with open(strategy_md_file, 'w', encoding='utf-8') as f:
            f.write("# Phase2 Strategy Decisions\n\n*Phase2Component is not yet implemented*\n")
        files["phase2_strategy_md"] = str(strategy_md_file)
        
        # 3. 選択項目のテキスト
        selected_items_file = self.phase2_dir / "selected_items.txt"
        with open(selected_items_file, 'w', encoding='utf-8') as f:
            f.write("Phase2Component is not yet implemented\n")
        files["phase2_items_txt"] = str(selected_items_file)
        
        return files
    
    def _save_nutrition_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """栄養計算の結果を保存（将来実装用）"""
        files = {}
        
        # 1. JSON形式の入出力データ
        input_output_file = self.nutrition_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time(),
                "note": "NutritionCalculationComponent is not yet implemented"
            }, f, indent=2, ensure_ascii=False)
        files["nutrition_input_output"] = str(input_output_file)
        
        # 2. 計算式のマークダウン
        formulas_md_file = self.nutrition_dir / "calculation_formulas.md"
        with open(formulas_md_file, 'w', encoding='utf-8') as f:
            f.write("# Nutrition Calculation Formulas\n\n*NutritionCalculationComponent is not yet implemented*\n")
        files["nutrition_formulas_md"] = str(formulas_md_file)
        
        # 3. 栄養サマリーのテキスト
        summary_txt_file = self.nutrition_dir / "nutrition_summary.txt"
        with open(summary_txt_file, 'w', encoding='utf-8') as f:
            f.write("NutritionCalculationComponent is not yet implemented\n")
        files["nutrition_summary_txt"] = str(summary_txt_file)
        
        return files
    
    def _save_pipeline_summary(self) -> Dict[str, str]:
        """パイプライン全体のサマリーを保存"""
        files = {}
        
        # 1. パイプラインサマリーJSON
        summary_file = self.analysis_dir / "pipeline_summary.json"
        summary_data = {
            "analysis_id": self.analysis_id,
            "timestamp": self.timestamp,
            "pipeline_metadata": self.pipeline_metadata,
            "execution_summary": {
                log.component_name: {
                    "execution_time": log.get_execution_time(),
                    "success": len(log.errors) == 0,
                    "warnings_count": len(log.warnings),
                    "errors_count": len(log.errors)
                }
                for log in self.execution_logs
            },
            "final_result": self.final_result
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)
        files["pipeline_summary"] = str(summary_file)
        
        # 2. 完全な詳細ログJSON
        complete_log_file = self.analysis_dir / "complete_analysis_log.json"
        complete_data = {
            "pipeline_metadata": self.pipeline_metadata,
            "execution_logs": [log.to_dict() for log in self.execution_logs],
            "final_result": self.final_result,
            "summary": {
                "total_components": len(self.execution_logs),
                "total_warnings": sum(len(log.warnings) for log in self.execution_logs),
                "total_errors": sum(len(log.errors) for log in self.execution_logs)
            }
        }
        
        with open(complete_log_file, 'w', encoding='utf-8') as f:
            json.dump(complete_data, f, indent=2, ensure_ascii=False)
        files["complete_log"] = str(complete_log_file)
        
        return files
    
    def _generate_phase1_prompts_md(self, log: DetailedExecutionLog) -> str:
        """Phase1のプロンプトと推論理由のマークダウンを生成"""
        content = f"""# Phase1: 画像分析 - プロンプトと推論

## 実行情報
- 実行ID: {log.execution_id}
- 開始時刻: {log.execution_start_time.isoformat()}
- 終了時刻: {log.execution_end_time.isoformat() if log.execution_end_time else 'N/A'}
- 実行時間: {log.get_execution_time():.2f}秒

## 使用されたプロンプト

"""
        
        # プロンプト情報
        for prompt_name, prompt_data in log.prompts_used.items():
            content += f"### {prompt_name.replace('_', ' ').title()}\n\n"
            content += f"**タイムスタンプ**: {prompt_data['timestamp']}\n\n"
            content += f"```\n{prompt_data['content']}\n```\n\n"
            
            if prompt_data.get('variables'):
                content += f"**変数**:\n"
                for var_name, var_value in prompt_data['variables'].items():
                    content += f"- {var_name}: {var_value}\n"
                content += "\n"
        
        # 推論理由
        content += "## AI推論の詳細\n\n"
        
        # 料理識別の推論
        dish_reasoning = [r for r in log.reasoning.items() if r[0].startswith('dish_identification_')]
        if dish_reasoning:
            content += "### 料理識別の推論\n\n"
            for decision_point, reasoning_data in dish_reasoning:
                dish_num = decision_point.split('_')[-1]
                content += f"**料理 {dish_num}**:\n"
                content += f"- 推論: {reasoning_data['reason']}\n"
                content += f"- タイムスタンプ: {reasoning_data['timestamp']}\n\n"
        
        # 食材選択の推論
        ingredient_reasoning = [r for r in log.reasoning.items() if r[0].startswith('ingredient_selection_')]
        if ingredient_reasoning:
            content += "### 食材選択の推論\n\n"
            for decision_point, reasoning_data in ingredient_reasoning:
                content += f"**{decision_point.replace('_', ' ').title()}**:\n"
                content += f"- 推論: {reasoning_data['reason']}\n"
                content += f"- タイムスタンプ: {reasoning_data['timestamp']}\n\n"
        
        # 警告とエラー
        if log.warnings:
            content += "## 警告\n\n"
            for warning in log.warnings:
                content += f"- {warning['message']} (at {warning['timestamp']})\n"
            content += "\n"
        
        if log.errors:
            content += "## エラー\n\n"
            for error in log.errors:
                content += f"- {error['message']} (at {error['timestamp']})\n"
            content += "\n"
        
        return content
    
    def _generate_phase1_detected_items_txt(self, log: DetailedExecutionLog) -> str:
        """Phase1で検出された料理・食材のテキストを生成（USDA検索特化）"""
        content = f"Phase1 検出結果 - {log.execution_start_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        content += "=" * 60 + "\n\n"
        
        if 'output_data' in log.output_data and 'dishes' in log.output_data['output_data']:
            dishes = log.output_data['output_data']['dishes']
            content += f"検出された料理数: {len(dishes)}\n\n"
            
            for i, dish in enumerate(dishes, 1):
                content += f"料理 {i}: {dish['dish_name']}\n"
                content += f"  食材数: {len(dish['ingredients'])}\n"
                content += "  食材詳細:\n"
                
                for j, ingredient in enumerate(dish['ingredients'], 1):
                    content += f"    {j}. {ingredient['ingredient_name']}\n"
                content += "\n"
        
        # USDA検索準備情報
        if 'usda_search_terms' in log.processing_details:
            search_terms = log.processing_details['usda_search_terms']
            content += f"USDA検索語彙 ({len(search_terms)}個):\n"
            for i, term in enumerate(search_terms, 1):
                content += f"  {i}. {term}\n"
            content += "\n"
        
        # 処理詳細
        if log.processing_details:
            content += "処理詳細:\n"
            for detail_key, detail_value in log.processing_details.items():
                if detail_key == 'usda_search_terms':
                    continue  # 既に上で表示済み
                if isinstance(detail_value, (dict, list)):
                    content += f"  {detail_key}: {json.dumps(detail_value, ensure_ascii=False)}\n"
                else:
                    content += f"  {detail_key}: {detail_value}\n"
        
        return content
    
    def _generate_nutrition_search_results_md(self, log: DetailedExecutionLog, search_method: str, db_source: str) -> str:
        """栄養データベース検索結果のマークダウンを生成（USDA/ローカル対応）"""
        content = []
        
        content.append(f"# Nutrition Database Search Results")
        content.append(f"")
        content.append(f"**Search Method:** {search_method}")
        content.append(f"**Database Source:** {db_source}")
        content.append(f"**Component:** {log.component_name}")
        content.append(f"**Execution Time:** {log.get_execution_time():.3f} seconds")
        content.append(f"**Timestamp:** {log.execution_start_time.isoformat()}")
        content.append(f"")
        
        # 入力データの表示
        if log.input_data:
            content.append(f"## Input Data")
            if 'ingredient_names' in log.input_data:
                ingredients = log.input_data['ingredient_names']
                content.append(f"**Ingredients ({len(ingredients)}):** {', '.join(ingredients)}")
            
            if 'dish_names' in log.input_data:
                dishes = log.input_data['dish_names']
                content.append(f"**Dishes ({len(dishes)}):** {', '.join(dishes)}")
            content.append(f"")
        
        # 出力データの表示
        if log.output_data and 'matches' in log.output_data:
            matches = log.output_data['matches']
            content.append(f"## Search Results")
            content.append(f"**Total Matches:** {len(matches)}")
            content.append(f"")
            
            for i, (search_term, match_data) in enumerate(matches.items(), 1):
                content.append(f"### {i}. {search_term}")
                if isinstance(match_data, dict):
                    content.append(f"**ID:** {match_data.get('id', 'N/A')}")
                    
                    # search_name と description を適切に表示
                    search_name = match_data.get('search_name', 'N/A')
                    description = match_data.get('description', None)
                    content.append(f"**Search Name:** {search_name}")
                    if description:
                        content.append(f"**Description:** {description}")
                    else:
                        content.append(f"**Description:** None")
                    
                    content.append(f"**Data Type:** {match_data.get('data_type', 'N/A')}")
                    content.append(f"**Source:** {match_data.get('source', 'N/A')}")
                    
                    # スコア情報を改善
                    score = match_data.get('score', 'N/A')
                    if score != 'N/A' and 'search_metadata' in match_data:
                        metadata = match_data['search_metadata']
                        score_breakdown = metadata.get('score_breakdown', {})
                        calculation = metadata.get('calculation', '')
                        match_type = score_breakdown.get('match_type', 'unknown')
                        
                        if calculation:
                            content.append(f"**Score:** {score} *({match_type}: {calculation})*")
                        else:
                            content.append(f"**Score:** {score} *(text similarity + data type priority)*")
                    else:
                        content.append(f"**Score:** {score}")
                    
                    if 'nutrients' in match_data and match_data['nutrients']:
                        content.append(f"**Nutrients ({len(match_data['nutrients'])}):**")
                        for nutrient in match_data['nutrients'][:5]:  # 最初の5つだけ表示
                            if isinstance(nutrient, dict):
                                name = nutrient.get('name', 'Unknown')
                                amount = nutrient.get('amount', 0)
                                unit = nutrient.get('unit_name', '')
                                content.append(f"  - {name}: {amount} {unit}")
                        if len(match_data['nutrients']) > 5:
                            content.append(f"  - ... and {len(match_data['nutrients']) - 5} more nutrients")
                content.append(f"")
        
        # 検索サマリー
        if log.output_data and 'search_summary' in log.output_data:
            summary = log.output_data['search_summary']
            content.append(f"## Search Summary")
            content.append(f"**Total Searches:** {summary.get('total_searches', 0)}")
            content.append(f"**Successful Matches:** {summary.get('successful_matches', 0)}")
            content.append(f"**Failed Searches:** {summary.get('failed_searches', 0)}")
            content.append(f"**Match Rate:** {summary.get('match_rate_percent', 0)}%")
            content.append(f"**Search Method:** {summary.get('search_method', 'unknown')}")
            content.append(f"")
        
        # 推論理由があれば表示
        if log.reasoning:
            content.append(f"## Search Reasoning")
            for decision_point, reason_data in log.reasoning.items():
                reason = reason_data.get('reason', '') if isinstance(reason_data, dict) else str(reason_data)
                content.append(f"**{decision_point}:** {reason}")
            content.append(f"")
        
        # 警告・エラーがあれば表示
        if log.warnings:
            content.append(f"## Warnings")
            for warning in log.warnings:
                content.append(f"- {warning}")
            content.append(f"")
        
        if log.errors:
            content.append(f"## Errors")
            for error in log.errors:
                content.append(f"- {error}")
            content.append(f"")
        
        return "\n".join(content)
    
    def _generate_nutrition_match_details_txt(self, log: DetailedExecutionLog, search_method: str, db_source: str) -> str:
        """栄養データベース検索のマッチ詳細テキストを生成（USDA/ローカル/マルチDB対応）"""
        lines = []
        
        lines.append(f"Nutrition Database Search Match Details")
        lines.append(f"=" * 50)
        lines.append(f"Search Method: {search_method}")
        lines.append(f"Database Source: {db_source}")
        lines.append(f"Component: {log.component_name}")
        lines.append(f"Execution Time: {log.get_execution_time():.3f} seconds")
        lines.append(f"Timestamp: {log.execution_start_time.isoformat()}")
        lines.append(f"")
        
        if log.output_data and 'matches' in log.output_data:
            matches = log.output_data['matches']
            
            # 総マッチ数を計算（単一結果とリスト結果両方に対応）
            total_matches = 0
            for match_data in matches.values():
                if isinstance(match_data, list):
                    total_matches += len(match_data)
                elif isinstance(match_data, dict):
                    total_matches += 1
            
            lines.append(f"Total Matches: {total_matches}")
            lines.append(f"")
            
            for search_term, match_data in matches.items():
                lines.append(f"Query: {search_term}")
                lines.append(f"-" * 30)
                
                # マルチDB検索結果（リスト形式）への対応
                if isinstance(match_data, list):
                    lines.append(f"  Found {len(match_data)} results from multiple databases:")
                    lines.append(f"")
                    
                    for i, match_item in enumerate(match_data, 1):
                        lines.append(f"  Result {i}:")
                        lines.append(f"    ID: {match_item.get('id', 'N/A')}")
                        
                        search_name = match_item.get('search_name', 'N/A')
                        description = match_item.get('description', None)
                        lines.append(f"    Search Name: {search_name}")
                        if description:
                            lines.append(f"    Description: {description}")
                        else:
                            lines.append(f"    Description: None")
                        
                        lines.append(f"    Data Type: {match_item.get('data_type', 'N/A')}")
                        lines.append(f"    Source: {match_item.get('source', 'N/A')}")
                        
                        # スコア情報
                        score = match_item.get('score', 'N/A')
                        if score != 'N/A' and 'search_metadata' in match_item:
                            metadata = match_item['search_metadata']
                            source_db = metadata.get('source_database', 'unknown')
                            lines.append(f"    Score: {score:.3f} (from {source_db})")
                        else:
                            lines.append(f"    Score: {score}")
                        
                        # 栄養情報（簡略版）
                        if 'nutrition' in match_item and match_item['nutrition']:
                            nutrition = match_item['nutrition']
                            calories = nutrition.get('calories', 0)
                            protein = nutrition.get('protein', 0)
                            fat = nutrition.get('fat', 0)
                            carbs = nutrition.get('carbs', 0)
                            lines.append(f"    Nutrition (100g): {calories:.1f} kcal, P:{protein:.1f}g, F:{fat:.1f}g, C:{carbs:.1f}g")
                        
                        lines.append(f"")
                
                # 単一結果（辞書形式）への対応（従来の方式）
                elif isinstance(match_data, dict):
                    lines.append(f"  ID: {match_data.get('id', 'N/A')}")
                    
                    search_name = match_data.get('search_name', 'N/A')
                    description = match_data.get('description', None)
                    lines.append(f"  Search Name: {search_name}")
                    if description:
                        lines.append(f"  Description: {description}")
                    else:
                        lines.append(f"  Description: None")
                    
                    lines.append(f"  Data Type: {match_data.get('data_type', 'N/A')}")
                    lines.append(f"  Source: {match_data.get('source', 'N/A')}")
                    
                    # スコア情報を改善
                    score = match_data.get('score', 'N/A')
                    if score != 'N/A' and 'search_metadata' in match_data:
                        metadata = match_data['search_metadata']
                        score_breakdown = metadata.get('score_breakdown', {})
                        calculation = metadata.get('calculation', '')
                        match_type = score_breakdown.get('match_type', 'unknown')
                        
                        if calculation:
                            lines.append(f"  Score: {score} ({match_type}: {calculation})")
                        else:
                            lines.append(f"  Score: {score} (text similarity + data type priority)")
                    else:
                        lines.append(f"  Score: {score}")
                    
                    if 'nutrients' in match_data and match_data['nutrients']:
                        lines.append(f"  Nutrients ({len(match_data['nutrients'])}):")
                        for nutrient in match_data['nutrients']:
                            if isinstance(nutrient, dict):
                                name = nutrient.get('name', 'Unknown')
                                amount = nutrient.get('amount', 0)
                                unit = nutrient.get('unit_name', '')
                                lines.append(f"    - {name}: {amount} {unit}")
                    
                    if 'original_data' in match_data:
                        original_data = match_data['original_data']
                        if isinstance(original_data, dict):
                            lines.append(f"  Original Data Source: {original_data.get('source', 'Unknown')}")
                            if search_method == "local_search":
                                lines.append(f"  Local DB Source: {original_data.get('db_source', 'Unknown')}")
                    
                    lines.append(f"")
        
        # 検索統計
        if log.output_data and 'search_summary' in log.output_data:
            summary = log.output_data['search_summary']
            lines.append(f"Search Statistics:")
            lines.append(f"  Total Searches: {summary.get('total_searches', 0)}")
            lines.append(f"  Successful Matches: {summary.get('successful_matches', 0)}")
            lines.append(f"  Failed Searches: {summary.get('failed_searches', 0)}")
            lines.append(f"  Match Rate: {summary.get('match_rate_percent', 0)}%")
            
            # マルチDB検索の場合の追加情報
            if 'target_databases' in summary:
                lines.append(f"  Target Databases: {', '.join(summary['target_databases'])}")
                lines.append(f"  Results per Database: {summary.get('results_per_db', 'N/A')}")
                lines.append(f"  Total Results: {summary.get('total_results', 'N/A')}")
            
            if search_method == "local_search":
                lines.append(f"  Total Database Items: {summary.get('total_database_items', 0)}")
        
        return "\n".join(lines)
    
    def get_analysis_folder_path(self) -> str:
        """解析フォルダパスを取得"""
        return str(self.analysis_dir) 
```

============================================================

📁 コンポーネント層 - Phase1
============================================================

📄 FILE: app_v2/components/__init__.py
--------------------------------------------------
ファイルサイズ: 713 bytes
最終更新: 2025-06-10 13:00:58
存在: ✅

CONTENT:
```python
from .base import BaseComponent
from .phase1_component import Phase1Component
from .usda_query_component import USDAQueryComponent
from .local_nutrition_search_component import LocalNutritionSearchComponent
from .elasticsearch_nutrition_search_component import ElasticsearchNutritionSearchComponent
# TODO: Phase2ComponentとNutritionCalculationComponentを実装
# from .phase2_component import Phase2Component
# from .nutrition_calc_component import NutritionCalculationComponent

__all__ = [
    "BaseComponent",
    "Phase1Component", 
    "USDAQueryComponent",
    "LocalNutritionSearchComponent",
    "ElasticsearchNutritionSearchComponent",
    # "Phase2Component",
    # "NutritionCalculationComponent"
] 
```

============================================================

📄 FILE: app_v2/components/base.py
--------------------------------------------------
ファイルサイズ: 6,824 bytes
最終更新: 2025-06-05 13:08:38
存在: ✅

CONTENT:
```python
from abc import ABC, abstractmethod
from typing import TypeVar, Generic, Any, Optional
import logging
from datetime import datetime

# 型変数の定義
InputType = TypeVar('InputType')
OutputType = TypeVar('OutputType')


class BaseComponent(ABC, Generic[InputType, OutputType]):
    """
    食事分析パイプラインのベースコンポーネント抽象クラス
    
    全てのコンポーネントはこのクラスを継承し、process メソッドを実装する必要があります。
    """
    
    def __init__(self, component_name: str, logger: Optional[logging.Logger] = None):
        """
        ベースコンポーネントの初期化
        
        Args:
            component_name: コンポーネント名
            logger: ロガーインスタンス（指定しない場合は自動生成）
        """
        self.component_name = component_name
        self.logger = logger or logging.getLogger(f"{__name__}.{component_name}")
        self.created_at = datetime.now()
        self.execution_count = 0
        self.current_execution_log = None  # 詳細ログ
        
    @abstractmethod
    async def process(self, input_data: InputType) -> OutputType:
        """
        メイン処理メソッド（抽象メソッド）
        
        Args:
            input_data: 入力データ
            
        Returns:
            OutputType: 処理結果
            
        Raises:
            ComponentError: 処理エラーが発生した場合
        """
        pass
    
    async def execute(self, input_data: InputType, execution_log: Optional['DetailedExecutionLog'] = None) -> OutputType:
        """
        ラップされた実行メソッド（ログ記録、エラーハンドリング付き）
        
        Args:
            input_data: 入力データ
            execution_log: 詳細実行ログ（オプション）
            
        Returns:
            OutputType: 処理結果
        """
        self.execution_count += 1
        execution_id = f"{self.component_name}_{self.execution_count}"
        
        # 詳細ログの設定
        if execution_log:
            self.current_execution_log = execution_log
            # 入力データを記録
            self.current_execution_log.set_input(self._safe_serialize_input(input_data))
        
        self.logger.info(f"[{execution_id}] Starting {self.component_name} processing")
        
        try:
            start_time = datetime.now()
            result = await self.process(input_data)
            end_time = datetime.now()
            
            processing_time = (end_time - start_time).total_seconds()
            self.logger.info(f"[{execution_id}] {self.component_name} completed in {processing_time:.2f}s")
            
            # 詳細ログに出力データを記録
            if self.current_execution_log:
                self.current_execution_log.set_output(self._safe_serialize_output(result))
                self.current_execution_log.finalize()
            
            return result
            
        except Exception as e:
            self.logger.error(f"[{execution_id}] {self.component_name} failed: {str(e)}", exc_info=True)
            
            # 詳細ログにエラーを記録
            if self.current_execution_log:
                self.current_execution_log.add_error(str(e))
                self.current_execution_log.finalize()
            
            raise ComponentError(f"{self.component_name} processing failed: {str(e)}") from e
        finally:
            self.current_execution_log = None
    
    def log_prompt(self, prompt_name: str, prompt_content: str, variables: dict = None):
        """プロンプトをログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_prompt(prompt_name, prompt_content, variables)
    
    def log_reasoning(self, decision_point: str, reason: str, confidence: float = None):
        """推論理由をログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_reasoning(decision_point, reason, confidence)
    
    def log_processing_detail(self, detail_key: str, detail_value: Any):
        """処理詳細をログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_processing_detail(detail_key, detail_value)
    
    def log_confidence_score(self, metric_name: str, score: float):
        """信頼度スコアをログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_confidence_score(metric_name, score)
    
    def log_warning(self, warning: str):
        """警告をログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_warning(warning)
    
    def _safe_serialize_input(self, input_data: InputType) -> dict:
        """入力データを安全にシリアライズ"""
        try:
            if hasattr(input_data, 'model_dump'):
                return input_data.model_dump()
            elif hasattr(input_data, '__dict__'):
                return input_data.__dict__
            else:
                return {"data": str(input_data)}
        except Exception as e:
            return {"serialization_error": str(e)}
    
    def _safe_serialize_output(self, output_data: OutputType) -> dict:
        """出力データを安全にシリアライズ"""
        try:
            if hasattr(output_data, 'model_dump'):
                return output_data.model_dump()
            elif hasattr(output_data, '__dict__'):
                return output_data.__dict__
            else:
                return {"data": str(output_data)}
        except Exception as e:
            return {"serialization_error": str(e)}
    
    def get_component_info(self) -> dict:
        """コンポーネント情報を取得"""
        return {
            "component_name": self.component_name,
            "created_at": self.created_at.isoformat(),
            "execution_count": self.execution_count,
            "component_type": self.__class__.__name__
        }


class ComponentError(Exception):
    """コンポーネント処理エラー"""
    
    def __init__(self, message: str, component_name: str = None, original_error: Exception = None):
        super().__init__(message)
        self.component_name = component_name
        self.original_error = original_error
        self.timestamp = datetime.now()
    
    def to_dict(self) -> dict:
        """エラー情報を辞書形式で取得"""
        return {
            "error_message": str(self),
            "component_name": self.component_name,
            "timestamp": self.timestamp.isoformat(),
            "original_error": str(self.original_error) if self.original_error else None
        } 
```

============================================================

📄 FILE: app_v2/components/phase1_component.py
--------------------------------------------------
ファイルサイズ: 5,285 bytes
最終更新: 2025-06-09 11:27:28
存在: ✅

CONTENT:
```python
import json
from typing import Optional

from .base import BaseComponent
from ..models.phase1_models import Phase1Input, Phase1Output, Dish, Ingredient
from ..services.gemini_service import GeminiService
from ..config import get_settings
from ..config.prompts import Phase1Prompts


class Phase1Component(BaseComponent[Phase1Input, Phase1Output]):
    """
    Phase1: 画像分析コンポーネント（USDA検索特化）
    
    Gemini AIを使用して食事画像を分析し、USDA検索に適した料理と食材名を識別します。
    """
    
    def __init__(self, gemini_service: Optional[GeminiService] = None):
        super().__init__("Phase1Component")
        
        # GeminiServiceの初期化
        if gemini_service is None:
            settings = get_settings()
            self.gemini_service = GeminiService(
                project_id=settings.GEMINI_PROJECT_ID,
                location=settings.GEMINI_LOCATION,
                model_name=settings.GEMINI_MODEL_NAME
            )
        else:
            self.gemini_service = gemini_service
    
    async def process(self, input_data: Phase1Input) -> Phase1Output:
        """
        Phase1の主処理: 画像分析（USDA検索特化）
        
        Args:
            input_data: Phase1Input (image_bytes, image_mime_type, optional_text)
            
        Returns:
            Phase1Output: 分析結果（料理名・食材名のみ）
        """
        self.logger.info(f"Starting Phase1 image analysis for USDA query generation")
        
        # プロンプト生成と記録
        system_prompt = Phase1Prompts.get_system_prompt()
        user_prompt = Phase1Prompts.get_user_prompt(input_data.optional_text)
        
        self.log_prompt("system_prompt", system_prompt)
        self.log_prompt("user_prompt", user_prompt, {
            "optional_text": input_data.optional_text,
            "image_mime_type": input_data.image_mime_type
        })
        
        # 画像情報のログ記録
        self.log_processing_detail("image_size_bytes", len(input_data.image_bytes))
        self.log_processing_detail("image_mime_type", input_data.image_mime_type)
        
        try:
            # Gemini AIによる画像分析
            self.log_processing_detail("gemini_api_call_start", "Calling Gemini API for image analysis")
            
            gemini_result = await self.gemini_service.analyze_phase1(
                image_bytes=input_data.image_bytes,
                image_mime_type=input_data.image_mime_type,
                optional_text=input_data.optional_text
            )
            
            self.log_processing_detail("gemini_raw_response", gemini_result)
            
            # 結果をPydanticモデルに変換
            dishes = []
            for dish_index, dish_data in enumerate(gemini_result.get("dishes", [])):
                ingredients = []
                for ingredient_index, ingredient_data in enumerate(dish_data.get("ingredients", [])):
                    ingredient = Ingredient(
                        ingredient_name=ingredient_data["ingredient_name"]
                    )
                    ingredients.append(ingredient)
                    
                    # 食材識別の推論理由をログ
                    self.log_reasoning(
                        f"ingredient_identification_dish{dish_index}_ingredient{ingredient_index}",
                        f"Identified ingredient '{ingredient_data['ingredient_name']}' for USDA search based on visual analysis"
                    )
                
                dish = Dish(
                    dish_name=dish_data["dish_name"],
                    ingredients=ingredients
                )
                dishes.append(dish)
                
                # 料理識別の推論理由をログ
                self.log_reasoning(
                    f"dish_identification_{dish_index}",
                    f"Identified dish as '{dish_data['dish_name']}' for USDA search based on visual characteristics"
                )
            
            # 分析統計の記録
            self.log_processing_detail("detected_dishes_count", len(dishes))
            self.log_processing_detail("total_ingredients_count", sum(len(dish.ingredients) for dish in dishes))
            
            # USDA検索適合性チェック
            search_terms = []
            for dish in dishes:
                search_terms.append(dish.dish_name)
                for ingredient in dish.ingredients:
                    search_terms.append(ingredient.ingredient_name)
            
            self.log_processing_detail("usda_search_terms", search_terms)
            self.log_reasoning(
                "usda_search_preparation",
                f"Generated {len(search_terms)} search terms for USDA database queries"
            )
            
            result = Phase1Output(
                dishes=dishes,
                warnings=[]
            )
            
            self.logger.info(f"Phase1 completed: identified {len(dishes)} dishes with {len(search_terms)} total search terms")
            return result
            
        except Exception as e:
            self.logger.error(f"Phase1 processing failed: {str(e)}")
            raise 
```

============================================================

📁 コンポーネント層 - 戦略的Elasticsearch検索
============================================================

📄 FILE: app_v2/components/elasticsearch_nutrition_search_component.py
--------------------------------------------------
ファイルサイズ: 28,363 bytes
最終更新: 2025-06-10 16:50:13
存在: ✅

CONTENT:
```python
#!/usr/bin/env python3
"""
Elasticsearch Nutrition Search Component

現状のqueryシステムをElasticsearchで高速化する新しいコンポーネント
Elasticsearch専用でフォールバック機能なし
"""

import os
import json
import asyncio
from typing import Optional, List, Dict, Any
from datetime import datetime

from .base import BaseComponent
from ..models.nutrition_search_models import (
    NutritionQueryInput, NutritionQueryOutput, NutritionMatch
)
from ..config import get_settings

# Elasticsearchクライアント
try:
    from elasticsearch import Elasticsearch
    ELASTICSEARCH_AVAILABLE = True
except ImportError:
    ELASTICSEARCH_AVAILABLE = False


class ElasticsearchNutritionSearchComponent(BaseComponent[NutritionQueryInput, NutritionQueryOutput]):
    """
    Elasticsearch専用栄養データベース検索コンポーネント
    
    現状のマルチデータベース検索システムをElasticsearchで高速化します。
    Elasticsearch専用でフォールバック機能は提供しません。
    """
    
    def __init__(self, elasticsearch_url: str = "http://localhost:9200", multi_db_search_mode: bool = False, results_per_db: int = 3):
        super().__init__("ElasticsearchNutritionSearchComponent")
        
        self.elasticsearch_url = elasticsearch_url
        self.es_client = None
        self.index_name = "nutrition_db"
        self.multi_db_search_mode = multi_db_search_mode
        self.results_per_db = results_per_db
        self.target_databases = ["yazio", "mynetdiary", "eatthismuch"]
        
        # Elasticsearchクライアントの初期化
        self._initialize_elasticsearch()
        
        self.logger.info(f"ElasticsearchNutritionSearchComponent initialized")
        self.logger.info(f"Elasticsearch available: {ELASTICSEARCH_AVAILABLE}")
        self.logger.info(f"ES client connected: {self.es_client is not None}")
        self.logger.info(f"Multi-DB search mode: {self.multi_db_search_mode}")
        self.logger.info(f"Results per database: {self.results_per_db}")
        
    def _initialize_elasticsearch(self):
        """Elasticsearchクライアントを初期化"""
        if not ELASTICSEARCH_AVAILABLE:
            self.logger.error("Elasticsearch library not available. Please install: pip install elasticsearch")
            return
        
        try:
            self.es_client = Elasticsearch([self.elasticsearch_url])
            
            # 接続テスト
            if self.es_client.ping():
                self.logger.info(f"Successfully connected to Elasticsearch at {self.elasticsearch_url}")
                
                # インデックス存在確認
                if self.es_client.indices.exists(index=self.index_name):
                    self.logger.info(f"Index '{self.index_name}' exists and ready")
                else:
                    self.logger.error(f"Index '{self.index_name}' does not exist. Please run create_elasticsearch_index.py first.")
                    self.es_client = None
            else:
                self.logger.error("Elasticsearch ping failed. Please ensure Elasticsearch is running.")
                self.es_client = None
                
        except Exception as e:
            self.logger.error(f"Failed to connect to Elasticsearch: {e}")
            self.es_client = None
    
    async def process(self, input_data: NutritionQueryInput) -> NutritionQueryOutput:
        """
        Elasticsearch検索の主処理
        
        Args:
            input_data: NutritionQueryInput
            
        Returns:
            NutritionQueryOutput: Elasticsearch検索結果
            
        Raises:
            RuntimeError: Elasticsearchが利用できない場合
        """
        # Elasticsearch利用可能性チェック
        if not ELASTICSEARCH_AVAILABLE:
            error_msg = "Elasticsearch library not available. Please install: pip install elasticsearch"
            self.logger.error(error_msg)
            return NutritionQueryOutput(
                matches={},
                search_summary={
                    "total_searches": 0,
                    "successful_matches": 0,
                    "failed_searches": 0,
                    "match_rate_percent": 0,
                    "search_method": "elasticsearch_unavailable",
                    "search_time_ms": 0
                },
                errors=[error_msg]
            )
        
        if not self.es_client:
            error_msg = "Elasticsearch client not initialized. Please check connection and index availability."
            self.logger.error(error_msg)
            return NutritionQueryOutput(
                matches={},
                search_summary={
                    "total_searches": 0,
                    "successful_matches": 0,
                    "failed_searches": 0,
                    "match_rate_percent": 0,
                    "search_method": "elasticsearch_connection_failed",
                    "search_time_ms": 0
                },
                errors=[error_msg]
            )
        
        search_terms = input_data.get_all_search_terms()
        self.logger.info(f"Starting Elasticsearch nutrition search for {len(search_terms)} terms")
        
        # 検索対象の詳細をログに記録
        self.log_processing_detail("search_terms", search_terms)
        self.log_processing_detail("ingredient_names", input_data.ingredient_names)
        self.log_processing_detail("dish_names", input_data.dish_names)
        self.log_processing_detail("total_search_terms", len(search_terms))
        self.log_processing_detail("multi_db_search_mode", self.multi_db_search_mode)
        self.log_processing_detail("results_per_db", self.results_per_db)
        
        if self.multi_db_search_mode:
            self.log_processing_detail("search_method", "elasticsearch_strategic")
            return await self._elasticsearch_strategic_search(input_data, search_terms)
        else:
            self.log_processing_detail("search_method", "elasticsearch_single")
            return await self._elasticsearch_search(input_data, search_terms)
    
    async def _elasticsearch_search(self, input_data: NutritionQueryInput, search_terms: List[str]) -> NutritionQueryOutput:
        """
        Elasticsearchを使用した単一結果検索（従来の方式）
        
        Args:
            input_data: 入力データ
            search_terms: 検索語彙リスト
            
        Returns:
            NutritionQueryOutput: Elasticsearch検索結果
        """
        matches = {}
        warnings = []
        errors = []
        successful_matches = 0
        total_searches = len(search_terms)
        
        start_time = datetime.now()
        
        # 各検索語彙についてElasticsearch検索を実行
        for search_index, search_term in enumerate(search_terms):
            self.logger.debug(f"Elasticsearch search for: {search_term}")
            
            self.log_processing_detail(f"es_search_{search_index}_term", search_term)
            
            try:
                # Elasticsearchクエリの構築
                es_query = self._build_elasticsearch_query(search_term, input_data)
                
                # 検索実行
                response = self.es_client.search(
                    index=self.index_name,
                    body=es_query
                )
                
                # 結果処理
                hits = response.get('hits', {}).get('hits', [])
                
                if hits:
                    # 最良のマッチを選択
                    best_hit = hits[0]
                    source = best_hit['_source']
                    score = best_hit['_score']
                    
                    match_result = self._convert_es_hit_to_nutrition_match(best_hit, search_term)
                    matches[search_term] = match_result
                    successful_matches += 1
                    
                    self.log_reasoning(
                        f"es_match_{search_index}",
                        f"Found Elasticsearch match for '{search_term}': {source.get('search_name', 'N/A')} (score: {score:.3f}, db: {source.get('source_db', 'N/A')})"
                    )
                    
                    self.logger.debug(f"ES match for '{search_term}': {source.get('search_name', 'N/A')} from {source.get('source_db', 'N/A')}")
                else:
                    self.log_reasoning(
                        f"es_no_match_{search_index}",
                        f"No Elasticsearch match found for '{search_term}'"
                    )
                    warnings.append(f"No Elasticsearch match found for: {search_term}")
                    
            except Exception as e:
                error_msg = f"Elasticsearch search error for '{search_term}': {str(e)}"
                self.logger.error(error_msg)
                errors.append(error_msg)
                
                self.log_reasoning(
                    f"es_search_error_{search_index}",
                    f"Elasticsearch search error for '{search_term}': {str(e)}"
                )
        
        end_time = datetime.now()
        search_time_ms = int((end_time - start_time).total_seconds() * 1000)
        
        # 検索サマリーを作成
        search_summary = {
            "total_searches": total_searches,
            "successful_matches": successful_matches,
            "failed_searches": total_searches - successful_matches,
            "match_rate_percent": round((successful_matches / total_searches) * 100, 1) if total_searches > 0 else 0,
            "search_method": "elasticsearch",
            "database_source": "elasticsearch_nutrition_db",
            "preferred_source": input_data.preferred_source,
            "search_time_ms": search_time_ms,
            "index_name": self.index_name,
            "total_indexed_documents": await self._get_total_document_count()
        }
        
        self.log_processing_detail("elasticsearch_search_summary", search_summary)
        
        result = NutritionQueryOutput(
            matches=matches,
            search_summary=search_summary,
            warnings=warnings if warnings else None,
            errors=errors if errors else None
        )
        
        self.logger.info(f"Elasticsearch nutrition search completed: {successful_matches}/{total_searches} matches ({result.get_match_rate():.1%}) in {search_time_ms}ms")
        
        return result
    
    async def _elasticsearch_strategic_search(self, input_data: NutritionQueryInput, search_terms: List[str]) -> NutritionQueryOutput:
        """
        戦略的Elasticsearch検索（dish/ingredient別の最適化された検索）
        
        Dish戦略:
        - メイン: EatThisMuch data_type=dish
        - 補助: EatThisMuch data_type=branded (スコアが低い場合)
        
        Ingredient戦略:
        - メイン: EatThisMuch data_type=ingredient  
        - 補助: MyNetDiary, YAZIO, EatThisMuch branded
        
        Args:
            input_data: 入力データ
            search_terms: 検索語彙リスト
            
        Returns:
            NutritionQueryOutput: 戦略的検索結果
        """
        matches = {}
        warnings = []
        errors = []
        successful_matches = 0
        total_searches = len(search_terms)
        
        start_time = datetime.now()
        
        # 各検索語彙について戦略的検索を実行
        for search_index, search_term in enumerate(search_terms):
            self.logger.debug(f"Strategic Elasticsearch search for: {search_term}")
            
            self.log_processing_detail(f"strategic_search_{search_index}_term", search_term)
            
            try:
                # クエリタイプを判定
                query_type = "dish" if search_term in input_data.dish_names else "ingredient"
                self.log_processing_detail(f"search_{search_index}_type", query_type)
                
                # 戦略的検索を実行
                if query_type == "dish":
                    strategic_results = await self._strategic_dish_search(search_term, input_data)
                else:
                    strategic_results = await self._strategic_ingredient_search(search_term, input_data)
                
                if strategic_results:
                    matches[search_term] = strategic_results
                    successful_matches += 1
                    
                    self.log_reasoning(
                        f"strategic_match_{search_index}",
                        f"Found strategic matches for '{search_term}' ({query_type}): {len(strategic_results)} results"
                    )
                else:
                    self.log_reasoning(
                        f"strategic_no_results_{search_index}",
                        f"No strategic results for '{search_term}' ({query_type})"
                    )
                    warnings.append(f"No strategic results found for: {search_term}")
                    
            except Exception as e:
                error_msg = f"Strategic Elasticsearch search error for '{search_term}': {str(e)}"
                self.logger.error(error_msg)
                errors.append(error_msg)
                
                self.log_reasoning(
                    f"strategic_search_error_{search_index}",
                    f"Strategic Elasticsearch search error for '{search_term}': {str(e)}"
                )
        
        end_time = datetime.now()
        search_time_ms = int((end_time - start_time).total_seconds() * 1000)
        
        # 戦略的検索サマリーを作成
        total_results = sum(len(result_list) if isinstance(result_list, list) else 1 for result_list in matches.values())
        
        search_summary = {
            "total_searches": total_searches,
            "successful_matches": successful_matches,
            "failed_searches": total_searches - successful_matches,
            "match_rate_percent": round((successful_matches / total_searches) * 100, 1) if total_searches > 0 else 0,
            "search_method": "elasticsearch_strategic",
            "database_source": "elasticsearch_nutrition_db",
            "preferred_source": input_data.preferred_source,
            "search_time_ms": search_time_ms,
            "index_name": self.index_name,
            "total_indexed_documents": await self._get_total_document_count(),
            "strategic_approach": {
                "dish_strategy": "eatthismuch_dish_primary + eatthismuch_branded_fallback",
                "ingredient_strategy": "eatthismuch_ingredient_primary + multi_db_fallback"
            },
            "total_results": total_results
        }
        
        self.log_processing_detail("elasticsearch_strategic_search_summary", search_summary)
        
        result = NutritionQueryOutput(
            matches=matches,
            search_summary=search_summary,
            warnings=warnings if warnings else None,
            errors=errors if errors else None
        )
        
        self.logger.info(f"Strategic Elasticsearch nutrition search completed: {successful_matches}/{total_searches} matches ({result.get_match_rate():.1%}) with {total_results} total results in {search_time_ms}ms")
        
        return result

    async def _strategic_dish_search(self, search_term: str, input_data: NutritionQueryInput) -> List[NutritionMatch]:
        """
        Dish検索戦略を実行
        
        戦略:
        1. EatThisMuch data_type=dish をメイン検索
        2. スコアが低い場合は EatThisMuch data_type=branded を補助検索
        
        Args:
            search_term: 検索語彙
            input_data: 入力データ
            
        Returns:
            List[NutritionMatch]: 戦略的検索結果
        """
        results = []
        MIN_SCORE_THRESHOLD = 20.0  # スコア閾値
        
        self.logger.info(f"Strategic dish search for '{search_term}': EatThisMuch dish -> branded fallback")
        
        # Step 1: EatThisMuch dish をメイン検索
        main_query = self._build_strategic_query(search_term, "eatthismuch", "dish")
        
        try:
            response = self.es_client.search(index=self.index_name, body=main_query)
            hits = response.get('hits', {}).get('hits', [])
            
            if hits:
                best_score = hits[0].get('_score', 0)
                self.logger.info(f"Dish main search: found {len(hits)} results, best score: {best_score}")
                
                if best_score >= MIN_SCORE_THRESHOLD:
                    # 高スコア: メイン結果のみ使用
                    for hit in hits[:self.results_per_db]:
                        match = self._convert_es_hit_to_nutrition_match(hit, search_term)
                        match.search_metadata["strategic_phase"] = "main_dish"
                        match.search_metadata["strategy_type"] = "dish_primary"
                        results.append(match)
                    
                    self.logger.info(f"High score dish results: using {len(results)} main results")
                    return results
                else:
                    # 低スコア: メイン結果を保持して補助検索も実行
                    for hit in hits[:max(1, self.results_per_db // 2)]:
                        match = self._convert_es_hit_to_nutrition_match(hit, search_term)
                        match.search_metadata["strategic_phase"] = "main_dish_low_score"
                        match.search_metadata["strategy_type"] = "dish_primary"
                        results.append(match)
        
        except Exception as e:
            self.logger.error(f"Error in dish main search: {e}")
        
        # Step 2: EatThisMuch branded を補助検索
        fallback_query = self._build_strategic_query(search_term, "eatthismuch", "branded")
        
        try:
            response = self.es_client.search(index=self.index_name, body=fallback_query)
            hits = response.get('hits', {}).get('hits', [])
            
            if hits:
                remaining_slots = self.results_per_db - len(results)
                for hit in hits[:remaining_slots]:
                    match = self._convert_es_hit_to_nutrition_match(hit, search_term)
                    match.search_metadata["strategic_phase"] = "fallback_branded"
                    match.search_metadata["strategy_type"] = "dish_fallback"
                    results.append(match)
                
                self.logger.info(f"Dish fallback search: added {min(len(hits), remaining_slots)} branded results")
        
        except Exception as e:
            self.logger.error(f"Error in dish fallback search: {e}")
        
        # スコア順でソート
        results.sort(key=lambda x: x.score, reverse=True)
        
        self.logger.info(f"Strategic dish search completed: {len(results)} total results")
        return results

    async def _strategic_ingredient_search(self, search_term: str, input_data: NutritionQueryInput) -> List[NutritionMatch]:
        """
        Ingredient検索戦略を実行
        
        戦略:
        1. EatThisMuch data_type=ingredient をメイン検索
        2. MyNetDiary, YAZIO, EatThisMuch branded を補助検索
        
        Args:
            search_term: 検索語彙
            input_data: 入力データ
            
        Returns:
            List[NutritionMatch]: 戦略的検索結果
        """
        results = []
        
        self.logger.info(f"Strategic ingredient search for '{search_term}': EatThisMuch ingredient -> multi-DB fallback")
        
        # Step 1: EatThisMuch ingredient をメイン検索
        main_query = self._build_strategic_query(search_term, "eatthismuch", "ingredient")
        
        try:
            response = self.es_client.search(index=self.index_name, body=main_query)
            hits = response.get('hits', {}).get('hits', [])
            
            if hits:
                # メイン結果を追加（最大半分のスロット使用）
                main_slots = max(1, self.results_per_db // 2)
                for hit in hits[:main_slots]:
                    match = self._convert_es_hit_to_nutrition_match(hit, search_term)
                    match.search_metadata["strategic_phase"] = "main_ingredient"
                    match.search_metadata["strategy_type"] = "ingredient_primary"
                    results.append(match)
                
                self.logger.info(f"Ingredient main search: added {len(results)} primary results")
        
        except Exception as e:
            self.logger.error(f"Error in ingredient main search: {e}")
        
        # Step 2: 補助データベース検索
        fallback_sources = [
            ("mynetdiary", "unified"),
            ("yazio", "unified"), 
            ("eatthismuch", "branded")
        ]
        
        remaining_slots = self.results_per_db - len(results)
        slots_per_source = max(1, remaining_slots // len(fallback_sources))
        
        for db_name, data_type in fallback_sources:
            if remaining_slots <= 0:
                break
                
            try:
                fallback_query = self._build_strategic_query(search_term, db_name, data_type)
                response = self.es_client.search(index=self.index_name, body=fallback_query)
                hits = response.get('hits', {}).get('hits', [])
                
                if hits:
                    current_slots = min(slots_per_source, remaining_slots)
                    for hit in hits[:current_slots]:
                        match = self._convert_es_hit_to_nutrition_match(hit, search_term)
                        match.search_metadata["strategic_phase"] = "fallback_multi_db"
                        match.search_metadata["strategy_type"] = "ingredient_fallback"
                        match.search_metadata["fallback_source"] = f"{db_name}_{data_type}"
                        results.append(match)
                    
                    remaining_slots -= len(hits[:current_slots])
                    self.logger.info(f"Ingredient fallback ({db_name}_{data_type}): added {len(hits[:current_slots])} results")
            
            except Exception as e:
                self.logger.error(f"Error in ingredient fallback search ({db_name}_{data_type}): {e}")
        
        # スコア順でソート
        results.sort(key=lambda x: x.score, reverse=True)
        
        self.logger.info(f"Strategic ingredient search completed: {len(results)} total results")
        return results

    def _build_strategic_query(self, search_term: str, target_db: str, data_type: str) -> Dict[str, Any]:
        """
        戦略的検索用のElasticsearchクエリを構築
        
        Args:
            search_term: 検索語彙
            target_db: ターゲットデータベース
            data_type: データタイプ
            
        Returns:
            Elasticsearchクエリ辞書
        """
        query = {
            "size": self.results_per_db,
            "query": {
                "bool": {
                    "must": [
                        {
                            "multi_match": {
                                "query": search_term,
                                "fields": [
                                    "search_name^3",
                                    "description^1"
                                ],
                                "type": "best_fields",
                                "fuzziness": "AUTO"
                            }
                        }
                    ],
                    "filter": [
                        {"term": {"source_db": target_db}},
                        {"term": {"data_type": data_type}}
                    ]
                }
            },
            "sort": [
                {"_score": {"order": "desc"}}
            ]
        }
        
        return query
    
    async def _get_total_document_count(self) -> int:
        """インデックス内の総ドキュメント数を取得"""
        try:
            stats = self.es_client.indices.stats(index=self.index_name)
            return stats["indices"][self.index_name]["total"]["docs"]["count"]
        except Exception as e:
            self.logger.warning(f"Failed to get document count: {e}")
            return 0
    
    def _build_elasticsearch_query(self, search_term: str, input_data: NutritionQueryInput) -> Dict[str, Any]:
        """
        Elasticsearch検索クエリを構築
        
        Args:
            search_term: 検索語彙
            input_data: 入力データ（検索タイプ判定用）
            
        Returns:
            Elasticsearchクエリ辞書
        """
        # 基本的なmulti_matchクエリ
        base_query = {
            "multi_match": {
                "query": search_term,
                "fields": [
                    "search_name^3",  # 検索名に高い重み
                    "search_name.exact^5"  # 完全一致に最高の重み
                ],
                "type": "best_fields",
                "fuzziness": "AUTO",
                "operator": "OR"
            }
        }
        
        # データタイプとソースデータベースフィルタ
        filters = []
        
        # dish_namesに含まれる場合は料理データを優先
        if search_term in input_data.dish_names:
            filters.append({"term": {"data_type": "dish"}})
        # ingredient_namesに含まれる場合は食材データを優先
        elif search_term in input_data.ingredient_names:
            filters.append({"term": {"data_type": "ingredient"}})
        
        # 優先ソースの設定
        if input_data.preferred_source and input_data.preferred_source != "elasticsearch":
            source_mapping = {
                "yazio": "yazio",
                "mynetdiary": "mynetdiary", 
                "eatthismuch": "eatthismuch"
            }
            if input_data.preferred_source in source_mapping:
                filters.append({"term": {"source_db": source_mapping[input_data.preferred_source]}})
        
        # フィルタがある場合はboolクエリでラップ
        if filters:
            query = {
                "bool": {
                    "must": [base_query],
                    "should": filters,  # shouldで優先度付け
                    "boost": 1.2
                }
            }
        else:
            query = base_query
        
        return {
            "query": query,
            "size": 5,  # 上位5件を取得
            "_source": ["data_type", "id", "search_name", "nutrition", "weight", "source_db", "description"]
        }
    
    def _convert_es_hit_to_nutrition_match(self, hit: Dict[str, Any], search_term: str) -> NutritionMatch:
        """
        ElasticsearchヒットをNutritionMatchに変換
        
        Args:
            hit: Elasticsearchヒット
            search_term: 検索語彙
            
        Returns:
            NutritionMatch
        """
        source = hit['_source']
        score = hit['_score']
        
        # ソースデータベース情報を含める
        source_db = source.get('source_db', 'unknown')
        final_source = f"elasticsearch_{source_db}"
        
        return NutritionMatch(
            id=source.get('id', 0),
            search_name=source.get('search_name', search_term),
            description=source.get('description'),
            data_type=source.get('data_type', 'unknown'),
            source=final_source,
            nutrition=source.get('nutrition', {}),
            weight=source.get('weight'),
            score=score,
            search_metadata={
                "search_term": search_term,
                "elasticsearch_score": score,
                "search_method": "elasticsearch_multi_db" if self.multi_db_search_mode else "elasticsearch",
                "source_database": source_db,
                "index_name": self.index_name
            }
        ) 
```

============================================================

📄 FILE: app_v2/components/local_nutrition_search_component.py
--------------------------------------------------
ファイルサイズ: 21,683 bytes
最終更新: 2025-06-10 12:20:02
存在: ✅

CONTENT:
```python
#!/usr/bin/env python3
"""
Local Nutrition Search Component

USDA database queryを nutrition_db_experiment で実装したローカル検索システムに置き換える
"""

import os
import sys
import json
import asyncio
from typing import Optional, List, Dict, Any
from pathlib import Path

from .base import BaseComponent
from ..models.nutrition_search_models import (
    NutritionQueryInput, NutritionQueryOutput, NutritionMatch
)
from ..config import get_settings

# nutrition_db_experimentのパスを追加
NUTRITION_DB_EXPERIMENT_PATH = os.path.join(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
    "nutrition_db_experiment"
)
sys.path.append(NUTRITION_DB_EXPERIMENT_PATH)

class LocalNutritionSearchComponent(BaseComponent[NutritionQueryInput, NutritionQueryOutput]):
    """
    ローカル栄養データベース検索コンポーネント
    
    nutrition_db_experimentで実装したローカル検索システムを使用して食材名を検索し、
    純粋なローカル形式で結果を返します。
    """
    
    def __init__(self):
        super().__init__("LocalNutritionSearchComponent")
        
        # ローカル検索システムの初期化
        self._initialize_local_search_system()
        
        # unified_dbのみを使用
        self.unified_db_path = os.path.join(NUTRITION_DB_EXPERIMENT_PATH, "nutrition_db", "unified_nutrition_db.json")
        
        # ローカルデータベースの読み込み
        self.unified_database = self._load_unified_database()
        
        # nutrition_db_experimentのコンポーネント
        self.search_handler = None
        self.query_preprocessor = None
        
        self.logger.info(f"LocalNutritionSearchComponent initialized with {len(self.unified_database)} total items")
    
    def _initialize_local_search_system(self):
        """nutrition_db_experimentの検索システムを初期化"""
        try:
            # 検索システムのインポート（オプション）
            from api.search_handler import SearchHandler
            from api.query_preprocessor import QueryPreprocessor
            
            self.search_handler = SearchHandler()
            self.query_preprocessor = QueryPreprocessor()
            
            self.logger.info("Advanced local search system initialized")
        except ImportError as e:
            self.logger.warning(f"Advanced search system not available, will use direct database search: {e}")
        except Exception as e:
            self.logger.error(f"Failed to initialize advanced search system: {e}")
    
    def _load_unified_database(self) -> List[Dict[str, Any]]:
        """unified_nutrition_db.jsonを読み込み"""
        try:
            if os.path.exists(self.unified_db_path):
                with open(self.unified_db_path, 'r', encoding='utf-8') as f:
                    database = json.load(f)
                self.logger.info(f"Loaded unified_db: {len(database)} items")
                return database
            else:
                self.logger.warning(f"Unified database file not found: {self.unified_db_path}")
                return []
        except Exception as e:
            self.logger.error(f"Error loading unified_db: {e}")
            return []
    
    async def process(self, input_data: NutritionQueryInput) -> NutritionQueryOutput:
        """
        ローカル検索の主処理（純粋なローカル形式）
        
        Args:
            input_data: NutritionQueryInput
            
        Returns:
            NutritionQueryOutput: 純粋なローカル検索結果
        """
        self.logger.info(f"Starting local nutrition search for {len(input_data.get_all_search_terms())} terms")
        
        # input_dataを保存してスコア計算で使用
        self._current_input_data = input_data
        
        search_terms = input_data.get_all_search_terms()
        
        # 検索対象の詳細をログに記録
        self.log_processing_detail("search_terms", search_terms)
        self.log_processing_detail("ingredient_names", input_data.ingredient_names)
        self.log_processing_detail("dish_names", input_data.dish_names)
        self.log_processing_detail("total_search_terms", len(search_terms))
        self.log_processing_detail("search_method", "local_nutrition_database")
        self.log_processing_detail("preferred_source", input_data.preferred_source)
        
        matches = {}
        warnings = []
        errors = []
        
        successful_matches = 0
        total_searches = len(search_terms)
        
        # 各検索語彙について照合を実行
        for search_index, search_term in enumerate(search_terms):
            self.logger.debug(f"Searching local database for: {search_term}")
            
            # 検索開始をログ
            self.log_processing_detail(f"search_{search_index}_term", search_term)
            self.log_processing_detail(f"search_{search_index}_start", f"Starting local search for '{search_term}'")
            
            try:
                # ローカル検索の実行
                if self.search_handler and self.query_preprocessor:
                    # 高度な検索システムを使用
                    match_result = await self._advanced_local_search(search_term, search_index, input_data)
                else:
                    # フォールバック: シンプルな文字列マッチング
                    match_result = await self._simple_local_search(search_term, search_index, input_data)
                
                if match_result:
                    matches[search_term] = match_result
                    successful_matches += 1
                    self.logger.debug(f"Found local match for '{search_term}': ID {match_result.id}")
                else:
                    self.log_reasoning(
                        f"no_match_{search_index}",
                        f"No local database match found for '{search_term}' - may not exist in local nutrition database"
                    )
                    self.logger.warning(f"No local match found for: {search_term}")
                    warnings.append(f"No local match found for: {search_term}")
                    
            except Exception as e:
                error_msg = f"Local search error for '{search_term}': {str(e)}"
                self.logger.error(error_msg)
                errors.append(error_msg)
                
                # エラーの詳細をログ
                self.log_reasoning(
                    f"search_error_{search_index}",
                    f"Local database search error for '{search_term}': {str(e)}"
                )
        
        # 検索サマリーを作成（純粋なローカル形式）
        search_summary = {
            "total_searches": total_searches,
            "successful_matches": successful_matches,
            "failed_searches": total_searches - successful_matches,
            "match_rate_percent": round((successful_matches / total_searches) * 100, 1) if total_searches > 0 else 0,
            "search_method": "local_nutrition_database",
            "database_source": "nutrition_db_experiment",
            "preferred_source": input_data.preferred_source,
            "total_database_items": len(self.unified_database)
        }
        
        # 全体的な検索成功率をログ
        overall_success_rate = successful_matches / total_searches if total_searches > 0 else 0
        self.log_processing_detail("search_summary", search_summary)
        
        # 検索品質の評価をログ
        if overall_success_rate >= 0.8:
            self.log_reasoning("search_quality", "Excellent local search results with high match rate")
        elif overall_success_rate >= 0.6:
            self.log_reasoning("search_quality", "Good local search results with acceptable match rate")
        elif overall_success_rate >= 0.4:
            self.log_reasoning("search_quality", "Moderate local search results, some items may need manual review")
        else:
            self.log_reasoning("search_quality", "Poor local search results, many items not found in local database")
        
        result = NutritionQueryOutput(
            matches=matches,
            search_summary=search_summary,
            warnings=warnings if warnings else None,
            errors=errors if errors else None
        )
        
        self.logger.info(f"Local nutrition search completed: {successful_matches}/{total_searches} matches ({result.get_match_rate():.1%})")
        
        return result
    
    async def _advanced_local_search(self, search_term: str, search_index: int, input_data: NutritionQueryInput) -> Optional[NutritionMatch]:
        """
        nutrition_db_experimentの高度な検索システムを使用したローカル検索
        
        Args:
            search_term: 検索語彙
            search_index: 検索インデックス（ログ用）
            input_data: 入力データ（検索タイプ判定用）
            
        Returns:
            NutritionMatch または None
        """
        try:
            from api.search_handler import SearchRequest
            
            # 検索タイプの決定（料理か食材かの推定）
            db_type_filter = None  # 全データベースを検索
            
            # dish_namesに含まれる場合は料理として優先検索
            if search_term in input_data.dish_names:
                db_type_filter = "dish"
                self.log_processing_detail(f"search_{search_index}_type", "dish")
            elif search_term in input_data.ingredient_names:
                db_type_filter = "ingredient"
                self.log_processing_detail(f"search_{search_index}_type", "ingredient")
            
            # 検索リクエストの作成
            request = SearchRequest(
                query=search_term,
                db_type_filter=db_type_filter,
                size=5  # 上位5件を取得
            )
            
            # 検索実行
            response = self.search_handler.search(request)
            
            # 検索結果の詳細をログ
            self.log_processing_detail(f"search_{search_index}_results_count", response.total_hits)
            self.log_processing_detail(f"search_{search_index}_processing_time_ms", response.took_ms)
            self.log_processing_detail(f"search_{search_index}_processed_query", response.query_info.get('processed_query'))
            
            if response.results:
                # nutrition_db_experimentの検索システムが模擬データを返した場合は、実際のデータベース検索にフォールバック
                best_result = response.results[0]
                
                # 模擬データかどうかをチェック（IDが123456の場合は模擬データ）
                if best_result.get('id') == 123456:
                    self.logger.warning(f"nutrition_db_experiment returned mock data for '{search_term}', falling back to direct database search")
                    return await self._direct_database_search(search_term, search_index, input_data)
                
                # マッチ選択の推論理由をログ
                self.log_reasoning(
                    f"match_selection_{search_index}",
                    f"Selected local item '{best_result['search_name']}' (ID: {best_result['id']}) for search term '{search_term}' based on local search algorithm (score: {best_result.get('_score', 'N/A')})"
                )
                
                # 詳細なマッチ情報をログ
                self.log_processing_detail(f"search_{search_index}_selected_id", best_result['id'])
                self.log_processing_detail(f"search_{search_index}_selected_name", best_result['search_name'])
                self.log_processing_detail(f"search_{search_index}_data_type", best_result.get('data_type', 'unknown'))
                self.log_processing_detail(f"search_{search_index}_score", best_result.get('_score'))
                
                # NutritionMatch形式に変換
                return self._convert_to_nutrition_match(best_result, search_term)
            
            # 結果がない場合は直接データベース検索にフォールバック
            return await self._direct_database_search(search_term, search_index, input_data)
            
        except Exception as e:
            self.logger.error(f"Advanced local search failed for '{search_term}': {e}")
            # エラーの場合も直接データベース検索にフォールバック
            return await self._direct_database_search(search_term, search_index, input_data)
    
    async def _direct_database_search(self, search_term: str, search_index: int, input_data: NutritionQueryInput) -> Optional[NutritionMatch]:
        """
        ローカルデータベースファイルを直接検索
        
        Args:
            search_term: 検索語彙
            search_index: 検索インデックス（ログ用）
            input_data: 入力データ（検索タイプ判定用）
            
        Returns:
            NutritionMatch または None
        """
        try:
            self.log_processing_detail(f"search_{search_index}_method", "direct_database_search")
            
            search_term_lower = search_term.lower()
            best_match = None
            best_score = 0
            
            # unified_databaseから直接検索
            for item in self.unified_database:
                # search_nameフィールドで検索
                if 'search_name' not in item:
                    continue
                    
                item_name = item['search_name'].lower()
                score = 0
                
                # スコアリングアルゴリズム
                if search_term_lower == item_name:
                    score = 1.0  # 完全一致
                elif search_term_lower in item_name:
                    # 部分一致（語順考慮）
                    if item_name.startswith(search_term_lower):
                        score = 0.9  # 前方一致
                    elif item_name.endswith(search_term_lower):
                        score = 0.8  # 後方一致
                    else:
                        score = 0.7  # 中間一致
                elif item_name in search_term_lower:
                    score = 0.6  # 逆部分一致
                else:
                    # 単語レベルの一致をチェック
                    search_words = search_term_lower.split()
                    item_words = item_name.split()
                    
                    common_words = set(search_words) & set(item_words)
                    if common_words:
                        score = len(common_words) / max(len(search_words), len(item_words)) * 0.5
                
                # data_type優先度によるボーナス
                data_type = item.get('data_type', 'unknown')
                db_bonus = 1.0
                
                # dish_namesに含まれる場合は料理データを優先
                if search_term in input_data.dish_names and data_type == 'dish':
                    db_bonus = 1.2
                # ingredient_namesに含まれる場合は食材データを優先
                elif search_term in input_data.ingredient_names and data_type == 'ingredient':
                    db_bonus = 1.2
                
                final_score = score * db_bonus
                
                if final_score > best_score:
                    best_score = final_score
                    best_match = item.copy()
            
            if best_match and best_score > 0.1:  # 最低閾値
                # マッチスコア情報を追加
                best_match['_match_score'] = best_score
                
                self.log_reasoning(
                    f"match_selection_{search_index}",
                    f"Selected local item '{best_match['search_name']}' (ID: {best_match.get('id', 'N/A')}) for search term '{search_term}' using direct database search (score: {best_score:.3f})"
                )
                
                # 詳細なマッチ情報をログ
                self.log_processing_detail(f"search_{search_index}_selected_id", best_match.get('id', 'N/A'))
                self.log_processing_detail(f"search_{search_index}_selected_name", best_match['search_name'])
                self.log_processing_detail(f"search_{search_index}_data_type", best_match.get('data_type', 'unknown'))
                self.log_processing_detail(f"search_{search_index}_match_score", best_score)
                
                return self._convert_to_nutrition_match(best_match, search_term)
            
            return None
            
        except Exception as e:
            self.logger.error(f"Direct database search failed for '{search_term}': {e}")
            return None
    
    async def _simple_local_search(self, search_term: str, search_index: int, input_data: NutritionQueryInput) -> Optional[NutritionMatch]:
        """
        シンプルな文字列マッチングによるフォールバック検索（実際のデータベース使用）
        
        Args:
            search_term: 検索語彙
            search_index: 検索インデックス（ログ用）
            input_data: 入力データ（検索タイプ判定用）
            
        Returns:
            NutritionMatch または None
        """
        # 高度検索システムが利用できない場合は、直接データベース検索を使用
        return await self._direct_database_search(search_term, search_index, input_data)
    
    def _convert_to_nutrition_match(self, local_item: Dict[str, Any], search_term: str) -> NutritionMatch:
        """
        ローカルデータベースアイテムをNutritionMatch形式に変換（簡素化版）
        
        Args:
            local_item: ローカルデータベースのアイテム
            search_term: 元の検索語彙
            
        Returns:
            NutritionMatch: 変換されたマッチ結果（簡素化されたローカル形式）
        """
        # IDの取得
        item_id = local_item.get('id', 0)
        
        # 基本情報の取得
        search_name = local_item.get('search_name', search_term)
        description = local_item.get('description')  # brandedの場合のみ存在
        data_type = local_item.get('data_type', 'unknown')  # db_type → data_typeに変更
        
        # 栄養データ（100gあたり正規化済み）
        nutrition = local_item.get('nutrition', {})
        weight = local_item.get('weight')
        
        # マッチスコア
        score = local_item.get('_match_score') or local_item.get('_score') or 1.0
        
        # スコア計算の詳細分析
        search_term_lower = search_term.lower()
        item_name_lower = search_name.lower()
        
        # 基本マッチタイプの判定
        match_type = "unknown"
        base_score = 0.0
        if search_term_lower == item_name_lower:
            match_type = "exact_match"
            base_score = 1.0
        elif search_term_lower in item_name_lower:
            if item_name_lower.startswith(search_term_lower):
                match_type = "prefix_match"
                base_score = 0.9
            elif item_name_lower.endswith(search_term_lower):
                match_type = "suffix_match"
                base_score = 0.8
            else:
                match_type = "contains_match"
                base_score = 0.7
        elif item_name_lower in search_term_lower:
            match_type = "reverse_contains"
            base_score = 0.6
        else:
            # 単語レベルの一致
            search_words = set(search_term_lower.split())
            item_words = set(item_name_lower.split())
            common_words = search_words & item_words
            if common_words:
                match_type = "word_match"
                base_score = len(common_words) / max(len(search_words), len(item_words)) * 0.5
        
        # データタイプボーナスの計算
        type_bonus = 1.0
        if hasattr(self, '_current_input_data'):
            input_data = self._current_input_data
            if search_term in input_data.dish_names and data_type == 'dish':
                type_bonus = 1.2
            elif search_term in input_data.ingredient_names and data_type == 'ingredient':
                type_bonus = 1.2
        
        # 検索メタデータ（詳細な計算情報を含む）
        search_metadata = {
            "search_term": search_term,
            "match_score": score,
            "score_breakdown": {
                "match_type": match_type,
                "base_score": round(base_score, 3),
                "type_bonus": round(type_bonus, 3),
                "final_score": round(base_score * type_bonus, 3)
            },
            "calculation": f"{base_score:.3f} × {type_bonus:.3f} = {score:.3f}"
        }
        
        # NutritionMatchオブジェクトの作成（簡素化版）
        return NutritionMatch(
            id=item_id,
            search_name=search_name,
            description=description,
            data_type=data_type,  # db_type → data_typeに変更
            nutrition=nutrition,
            weight=weight,
            score=score,
            search_metadata=search_metadata
        ) 
```

============================================================

📁 データモデル層
============================================================

📄 FILE: app_v2/models/__init__.py
--------------------------------------------------
ファイルサイズ: 680 bytes
最終更新: 2025-06-09 12:06:09
存在: ✅

CONTENT:
```python
from .phase1_models import *
from .usda_models import *
from .phase2_models import *
from .nutrition_models import *
from .nutrition_search_models import *

__all__ = [
    # Phase1 models
    "Phase1Input", "Phase1Output", "Ingredient", "Dish",
    
    # USDA models
    "USDAQueryInput", "USDAQueryOutput", "USDAMatch", "USDANutrient",
    
    # Phase2 models
    "Phase2Input", "Phase2Output", "RefinedDish", "RefinedIngredient",
    
    # Nutrition models
    "NutritionInput", "NutritionOutput", "CalculatedNutrients", "TotalNutrients",
    
    # Nutrition Search models (純粋なローカル形式)
    "NutritionQueryInput", "NutritionQueryOutput", "NutritionMatch"
] 
```

============================================================

📄 FILE: app_v2/models/nutrition_search_models.py
--------------------------------------------------
ファイルサイズ: 4,037 bytes
最終更新: 2025-06-10 13:45:41
存在: ✅

CONTENT:
```python
#!/usr/bin/env python3
"""
Nutrition Search Models

ローカル栄養データベース検索で使用する純粋なローカル形式のモデル
"""

from typing import List, Dict, Optional, Any, Union
from pydantic import BaseModel, Field


class NutritionMatch(BaseModel):
    """栄養データベース照合結果モデル（純粋なローカル形式）"""
    id: Union[int, str] = Field(..., description="食品ID（ローカルID）")
    search_name: str = Field(..., description="検索名（簡潔な名称）")
    description: Optional[str] = Field(None, description="詳細説明")
    data_type: str = Field(..., description="データタイプ (dish, ingredient, branded)")
    source: str = Field(default="local_database", description="データソース（'local_database'）")
    
    # ローカルDBの生の栄養データ（100gあたり正規化済み）
    nutrition: Dict[str, float] = Field(default_factory=dict, description="ローカルDBの栄養データ（100gあたり）")
    weight: Optional[float] = Field(None, description="元データの重量（g）")
    
    # 検索スコア
    score: Optional[float] = Field(None, description="検索結果の関連度スコア")
    
    # 検索に関するメタデータ
    search_metadata: Optional[Dict[str, Any]] = Field(None, description="検索に関するメタデータ")


class NutritionQueryInput(BaseModel):
    """栄養データベース検索入力モデル（純粋なローカル形式）"""
    ingredient_names: List[str] = Field(default_factory=list, description="食材名のリスト")
    dish_names: List[str] = Field(default_factory=list, description="料理名のリスト")
    search_options: Optional[Dict[str, Any]] = Field(None, description="検索オプション")
    preferred_source: str = Field(default="local_database", description="優先データソース")

    def get_all_search_terms(self) -> List[str]:
        """全ての検索語彙を取得"""
        return list(set(self.ingredient_names + self.dish_names))


class NutritionQueryOutput(BaseModel):
    """栄養データベース検索結果モデル（純粋なローカル形式）"""
    # マルチデータベース検索対応：単一結果またはリスト結果を受け入れる
    matches: Dict[str, Union[NutritionMatch, List[NutritionMatch]]] = Field(
        default_factory=dict, 
        description="検索語彙と対応する照合結果のマッピング（単一結果またはマルチDB結果リスト）"
    )
    search_summary: Dict[str, Any] = Field(
        default_factory=dict, 
        description="検索結果のサマリー情報（柔軟な型対応）"
    )
    warnings: Optional[List[str]] = Field(None, description="警告メッセージのリスト")
    errors: Optional[List[str]] = Field(None, description="エラーメッセージのリスト")

    def get_match_rate(self) -> float:
        """照合成功率を計算"""
        total_searches = self.search_summary.get("total_searches", 0)
        successful_matches = self.search_summary.get("successful_matches", 0)
        if total_searches == 0:
            return 0.0
        return successful_matches / total_searches

    def get_total_matches(self) -> int:
        """総照合件数を取得（マルチDB検索対応）"""
        total = 0
        for match_result in self.matches.values():
            if isinstance(match_result, list):
                total += len(match_result)
            else:
                total += 1
        return total
    
    def get_total_individual_results(self) -> int:
        """個別結果の総数を取得（マルチDB検索用）"""
        return self.get_total_matches()
    
    def has_errors(self) -> bool:
        """エラーが存在するかチェック"""
        return self.errors is not None and len(self.errors) > 0
    
    def has_warnings(self) -> bool:
        """警告が存在するかチェック"""
        return self.warnings is not None and len(self.warnings) > 0 
```

============================================================

📄 FILE: app_v2/models/phase1_models.py
--------------------------------------------------
ファイルサイズ: 1,764 bytes
最終更新: 2025-06-09 11:27:28
存在: ✅

CONTENT:
```python
from typing import List, Optional
from pydantic import BaseModel, Field


class Ingredient(BaseModel):
    """食材情報モデル（USDA検索用）"""
    ingredient_name: str = Field(..., description="食材の名称（USDA検索で使用）")


class Dish(BaseModel):
    """料理情報モデル（USDA検索用）"""
    dish_name: str = Field(..., description="特定された料理の名称（USDA検索で使用）")
    ingredients: List[Ingredient] = Field(..., description="その料理に含まれる食材のリスト")


class Phase1Input(BaseModel):
    """Phase1コンポーネントの入力モデル"""
    image_bytes: bytes = Field(..., description="画像データ（バイト形式）")
    image_mime_type: str = Field(..., description="画像のMIMEタイプ")
    optional_text: Optional[str] = Field(None, description="オプションのテキスト情報")

    class Config:
        arbitrary_types_allowed = True


class Phase1Output(BaseModel):
    """Phase1コンポーネントの出力モデル（USDA検索特化）"""
    dishes: List[Dish] = Field(..., description="画像から特定された料理のリスト")
    warnings: Optional[List[str]] = Field(None, description="処理中の警告メッセージ")

    def get_all_ingredient_names(self) -> List[str]:
        """全ての食材名のリストを取得（USDA検索用）"""
        ingredient_names = []
        for dish in self.dishes:
            for ingredient in dish.ingredients:
                ingredient_names.append(ingredient.ingredient_name)
        return ingredient_names

    def get_all_dish_names(self) -> List[str]:
        """全ての料理名のリストを取得（USDA検索用）"""
        return [dish.dish_name for dish in self.dishes] 
```

============================================================

📁 設定管理
============================================================

📄 FILE: app_v2/config/__init__.py
--------------------------------------------------
ファイルサイズ: 85 bytes
最終更新: 2025-06-05 12:46:54
存在: ✅

CONTENT:
```python
from .settings import Settings, get_settings

__all__ = ["Settings", "get_settings"] 
```

============================================================

📁 Elasticsearch インデックス管理
============================================================

📄 FILE: create_elasticsearch_index.py
--------------------------------------------------
ファイルサイズ: 8,637 bytes
最終更新: 2025-06-10 13:04:18
存在: ✅

CONTENT:
```python
#!/usr/bin/env python3
"""
Elasticsearch Index Creation Script

現状のJSONデータベースからElasticsearchインデックスを作成する
"""

import json
import os
from elasticsearch import Elasticsearch
from typing import Dict, List, Any
import time


def create_index_mapping() -> Dict[str, Any]:
    """Elasticsearchインデックスのマッピングを定義"""
    return {
        "mappings": {
            "properties": {
                "id": {
                    "type": "keyword"
                },
                "search_name": {
                    "type": "text",
                    "analyzer": "standard",
                    "fields": {
                        "exact": {
                            "type": "keyword"
                        },
                        "suggest": {
                            "type": "completion"
                        }
                    }
                },
                "description": {
                    "type": "text",
                    "analyzer": "standard"
                },
                "data_type": {
                    "type": "keyword"
                },
                "nutrition": {
                    "type": "object",
                    "properties": {
                        "calories": {"type": "float"},
                        "protein": {"type": "float"},
                        "fat": {"type": "float"},
                        "carbs": {"type": "float"},
                        "carbohydrates": {"type": "float"},
                        "fiber": {"type": "float"},
                        "sugar": {"type": "float"},
                        "sodium": {"type": "float"}
                    }
                },
                "weight": {
                    "type": "float"
                },
                "source_db": {
                    "type": "keyword"
                }
            }
        },
        "settings": {
            "number_of_shards": 1,
            "number_of_replicas": 0,
            "analysis": {
                "analyzer": {
                    "food_analyzer": {
                        "type": "standard",
                        "stopwords": "_none_"
                    }
                }
            }
        }
    }


def load_json_databases() -> Dict[str, List[Dict[str, Any]]]:
    """JSONデータベースファイルを読み込み"""
    databases = {}
    
    db_configs = {
        "yazio": "db/yazio_db.json",
        "mynetdiary": "db/mynetdiary_db.json", 
        "eatthismuch": "db/eatthismuch_db.json"
    }
    
    for db_name, file_path in db_configs.items():
        try:
            if os.path.exists(file_path):
                print(f"Loading {db_name} from {file_path}...")
                with open(file_path, 'r', encoding='utf-8') as f:
                    database = json.load(f)
                    databases[db_name] = database
                    print(f"✅ Loaded {db_name}: {len(database)} items")
            else:
                print(f"⚠️  File not found: {file_path}")
                databases[db_name] = []
        except Exception as e:
            print(f"❌ Error loading {db_name}: {e}")
            databases[db_name] = []
    
    return databases


def prepare_document(item: Dict[str, Any], source_db: str) -> Dict[str, Any]:
    """ドキュメントをElasticsearch用に準備"""
    doc = {
        "id": item.get("id", 0),
        "search_name": item.get("search_name", ""),
        "description": item.get("description"),
        "data_type": item.get("data_type", "unknown"),
        "nutrition": item.get("nutrition", {}),
        "weight": item.get("weight"),
        "source_db": source_db
    }
    
    # 空の値を除去
    return {k: v for k, v in doc.items() if v is not None}


def bulk_index_documents(es_client: Elasticsearch, index_name: str, documents: List[Dict[str, Any]], batch_size: int = 1000):
    """バルクインデックスでドキュメントを追加"""
    total_docs = len(documents)
    indexed_count = 0
    
    print(f"📥 Indexing {total_docs} documents in batches of {batch_size}...")
    
    for i in range(0, total_docs, batch_size):
        batch = documents[i:i + batch_size]
        
        # バルクリクエストの構築
        bulk_body = []
        for doc in batch:
            bulk_body.append({
                "index": {
                    "_index": index_name,
                    "_id": f"{doc['source_db']}_{doc['id']}"
                }
            })
            bulk_body.append(doc)
        
        try:
            response = es_client.bulk(body=bulk_body)
            
            # エラーチェック
            if response.get("errors"):
                error_count = sum(1 for item in response["items"] if "error" in item.get("index", {}))
                print(f"⚠️  Batch {i//batch_size + 1}: {error_count} errors in batch")
            
            indexed_count += len(batch)
            print(f"   Progress: {indexed_count}/{total_docs} ({indexed_count/total_docs*100:.1f}%)")
            
        except Exception as e:
            print(f"❌ Error indexing batch {i//batch_size + 1}: {e}")
    
    print(f"✅ Indexing completed: {indexed_count} documents")


def main():
    """メイン処理"""
    print("=== Elasticsearch Index Creation ===")
    
    # Elasticsearchクライアントの初期化
    print("\n1. Connecting to Elasticsearch...")
    es_client = Elasticsearch(["http://localhost:9200"])
    
    if not es_client.ping():
        print("❌ Cannot connect to Elasticsearch. Make sure it's running on localhost:9200")
        return False
    
    print("✅ Connected to Elasticsearch")
    
    # インデックス名
    index_name = "nutrition_db"
    
    # 既存インデックスの削除（必要に応じて）
    print(f"\n2. Checking existing index '{index_name}'...")
    if es_client.indices.exists(index=index_name):
        print(f"   Index '{index_name}' already exists. Deleting...")
        es_client.indices.delete(index=index_name)
        print("   ✅ Deleted existing index")
    
    # インデックスの作成
    print(f"\n3. Creating index '{index_name}'...")
    mapping = create_index_mapping()
    es_client.indices.create(index=index_name, body=mapping)
    print("✅ Index created with mapping")
    
    # JSONデータベースの読み込み
    print("\n4. Loading JSON databases...")
    databases = load_json_databases()
    
    # ドキュメントの準備
    print("\n5. Preparing documents for indexing...")
    all_documents = []
    
    for db_name, items in databases.items():
        print(f"   Processing {db_name}: {len(items)} items")
        for item in items:
            if "search_name" in item:  # 有効なアイテムのみ
                doc = prepare_document(item, db_name)
                all_documents.append(doc)
    
    print(f"✅ Prepared {len(all_documents)} documents for indexing")
    
    # バルクインデックス
    print("\n6. Bulk indexing documents...")
    start_time = time.time()
    bulk_index_documents(es_client, index_name, all_documents)
    end_time = time.time()
    
    print(f"✅ Indexing completed in {end_time - start_time:.2f} seconds")
    
    # インデックス統計の表示
    print("\n7. Index statistics...")
    stats = es_client.indices.stats(index=index_name)
    doc_count = stats["indices"][index_name]["total"]["docs"]["count"]
    index_size = stats["indices"][index_name]["total"]["store"]["size_in_bytes"]
    
    print(f"   Total documents: {doc_count}")
    print(f"   Index size: {index_size / 1024 / 1024:.2f} MB")
    
    # サンプル検索テスト
    print("\n8. Testing sample search...")
    test_query = {
        "query": {
            "multi_match": {
                "query": "chicken",
                "fields": ["search_name", "search_name.exact"]
            }
        },
        "size": 3
    }
    
    response = es_client.search(index=index_name, body=test_query)
    hits = response["hits"]["hits"]
    
    print(f"   Sample search for 'chicken': {len(hits)} results")
    for hit in hits:
        source = hit["_source"]
        print(f"   - {source['search_name']} ({source['source_db']}) score: {hit['_score']:.2f}")
    
    print(f"\n🎉 Elasticsearch index '{index_name}' successfully created!")
    print(f"   Ready for high-speed nutrition search")
    
    return True


if __name__ == "__main__":
    success = main()
    if success:
        print("\n✅ Index creation completed successfully!")
    else:
        print("\n❌ Index creation failed!") 
```

============================================================

📁 栄養データベース
============================================================

📄 FILE: db/yazio_db.json
--------------------------------------------------
ファイルサイズ: 504,128 bytes
最終更新: 2025-06-10 11:55:48
存在: ✅

CONTENT (最初の50行):
```json
[
  {
    "data_type": "unified",
    "id": 1000000000,
    "search_name": "Cheese Coffeecake",
    "description": "Cakes & Pies",
    "nutrition": {
      "calories": 339.0,
      "protein": 7.0,
      "fat": 15.2,
      "carbs": 44.3
    },
    "source": "YAZIO"
  },
  {
    "data_type": "unified",
    "id": 1000000001,
    "search_name": "Fruit Fried Pie",
    "description": "Cakes & Pies",
    "nutrition": {
      "calories": 316.0,
      "protein": 3.0,
      "fat": 16.1,
      "carbs": 42.6
    },
    "source": "YAZIO"
  },
  {
    "data_type": "unified",
    "id": 1000000002,
    "search_name": "Blueberry Pie",
    "description": "Cakes & Pies",
    "nutrition": {
      "calories": 245.0,
      "protein": 2.7,
      "fat": 11.9,
      "carbs": 33.5
    },
    "source": "YAZIO"
  },
  {
    "data_type": "unified",
    "id": 1000000003,
    "search_name": "Apple Pie",
    "description": "Cakes & Pies",
    "nutrition": {
      "calories": 265.0,
      "protein": 2.4,
      "fat": 12.5,
      "carbs": 37.1

... (23677 more lines)
```

============================================================

📄 FILE: db/mynetdiary_db.json
--------------------------------------------------
ファイルサイズ: 349,780 bytes
最終更新: 2025-06-10 11:55:05
存在: ✅

CONTENT (最初の50行):
```json
[
  {
    "data_type": "unified",
    "id": 10000000000,
    "search_name": "Beans baked canned plain or vegetarian",
    "description": null,
    "nutrition": {
      "calories": 94.09448818897638,
      "protein": 4.724409448818898,
      "fat": 0.35433070866141736,
      "carbs": 21.25984251968504
    },
    "source": "MyNetDiary"
  },
  {
    "data_type": "unified",
    "id": 10000000001,
    "search_name": "Black beans boiled without salt",
    "description": null,
    "nutrition": {
      "calories": 131.97674418604652,
      "protein": 8.72093023255814,
      "fat": 0.5232558139534884,
      "carbs": 23.837209302325583
    },
    "source": "MyNetDiary"
  },
  {
    "data_type": "unified",
    "id": 10000000002,
    "search_name": "Black beans canned low sodium",
    "description": null,
    "nutrition": {
      "calories": 90.83333333333334,
      "protein": 5.833333333333334,
      "fat": 0.2916666666666667,
      "carbs": 16.666666666666668
    },
    "source": "MyNetDiary"
  },
  {
    "data_type": "unified",
    "id": 10000000003,
    "search_name": "Black beans canned no salt added",
    "description": null,
    "nutrition": {
      "calories": 84.61538461538461,
      "protein": 5.384615384615385,
      "fat": 0.0,
      "carbs": 16.153846153846153

... (14798 more lines)
```

============================================================

📄 FILE: db/eatthismuch_db.json
--------------------------------------------------
ファイルサイズ: 2,809,842 bytes
最終更新: 2025-06-10 11:50:01
存在: ✅

CONTENT (最初の50行):
```json
[
  {
    "data_type": "dish",
    "id": 907072,
    "search_name": "Garlic and Cream Cheese Cauliflower \"Mashed Potatoes\"",
    "description": null,
    "nutrition": {
      "calories": 43.63999999999999,
      "protein": 2.5545171339563866,
      "fat": 1.6926272066458983,
      "carbs": 5.7632398753894085
    },
    "source": "EatThisMuch"
  },
  {
    "data_type": "dish",
    "id": 905725,
    "search_name": "Poached Eggs on Toast",
    "description": null,
    "nutrition": {
      "calories": 211.81,
      "protein": 12.653061224489797,
      "fat": 6.530612244897958,
      "carbs": 24.89795918367347
    },
    "source": "EatThisMuch"
  },
  {
    "data_type": "dish",
    "id": 3267515,
    "search_name": "Caprese Salad",
    "description": null,
    "nutrition": {
      "calories": 174.96289228159455,
      "protein": 6.530958439355386,
      "fat": 15.436810856658182,
      "carbs": 3.307888040712468
    },
    "source": "EatThisMuch"
  },
  {
    "data_type": "dish",
    "id": 906392,
    "search_name": "Spinach and Pear Omelet",
    "description": null,
    "nutrition": {
      "calories": 105.17,
      "protein": 5.143651529193697,
      "fat": 6.580166821130676,
      "carbs": 7.298424467099165

... (115366 more lines)
```

============================================================

📁 Elasticsearch設定
============================================================

📄 FILE: elasticsearch-8.10.4/config/elasticsearch.yml
--------------------------------------------------
ファイルサイズ: 3,205 bytes
最終更新: 2025-06-06 16:30:26
存在: ✅

CONTENT (設定ファイル):
```yaml
# ======================== Elasticsearch Configuration =========================
#
# NOTE: Elasticsearch comes with reasonable defaults for most settings.
#       Before you set out to tweak and tune the configuration, make sure you
#       understand what are you trying to accomplish and the consequences.
#
# The primary way of configuring a node is via this file. This template lists
# the most important settings you may want to configure for a production cluster.
#
# Please consult the documentation for further information on configuration options:
# https://www.elastic.co/guide/en/elasticsearch/reference/index.html
#
# ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster:
#
cluster.name: meal-analysis-dev
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
node.name: node-1
#
# Add custom attributes to the node:
#
#node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
#path.data: /path/to/data
#
# Path to log files:
#
#path.logs: /path/to/logs
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
#bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# By default Elasticsearch is only accessible on localhost. Set a different
# address here to expose this node on the network:
#
network.host: 127.0.0.1
#
# By default Elasticsearch listens for HTTP traffic on the first free port it
# finds starting at 9200. Set a specific HTTP port here:
#
http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when this node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
discovery.type: single-node
#
# Bootstrap the cluster using an initial set of master-eligible nodes:
# single-nodeモードでは cluster.initial_master_nodes は不要（競合する）
#
# cluster.initial_master_nodes: ["node-1"]
#
# For more information, consult the discovery and cluster formation module documentation.
#
# ---------------------------------- Various -----------------------------------
#
# Allow wildcard deletion of indices:
#
action.destructive_requires_name: false

# ================================ Security ===================================
#
# 開発環境用: セキュリティを無効化
#
xpack.security.enabled: false
xpack.security.http.ssl.enabled: false
xpack.security.transport.ssl.enabled: false

# ================================ Machine Learning ============================
#
# 開発環境用: MLを無効化（リソース節約）
#
xpack.ml.enabled: false
```

============================================================

📁 依存関係・設定ファイル
============================================================

📄 FILE: requirements.txt
--------------------------------------------------
ファイルサイズ: 274 bytes
最終更新: 2025-06-10 13:01:13
存在: ✅

CONTENT:
```python
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0
google-cloud-aiplatform==1.94.0
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
httpx
pytest==7.4.3
pytest-asyncio==0.21.1
python-dotenv==1.0.0
Pillow==11.2.1
elasticsearch==8.15.1 
```

============================================================

📄 FILE: README.md
--------------------------------------------------
ファイルサイズ: 15,369 bytes
最終更新: 2025-06-10 14:55:33
存在: ✅

CONTENT:
```python
# 食事分析 API (Meal Analysis API) v2.0

## 概要

この API は、**Google Gemini AI** と **Elasticsearch ベースマルチデータベース栄養検索システム**を使用した高度な食事画像分析システムです。**動的栄養計算機能**により、料理の特性に応じて最適な栄養計算戦略を自動選択し、正確な栄養価情報を提供します。

## 🌟 主な機能

### **🔥 新機能: Elasticsearch マルチデータベース栄養検索 v2.0**

- **⚡ Elasticsearch 高速検索**: 高性能な Elasticsearch インデックスによる大規模栄養データベース検索
- **📊 3 つのデータベース統合検索**: 1 つのクエリで複数のデータベースから包括的な栄養情報を取得
  - **YAZIO**: 1,825 項目 - バランスの取れた食品カテゴリ
  - **MyNetDiary**: 1,142 項目 - 科学的/栄養学的アプローチ
  - **EatThisMuch**: 8,878 項目 - 最大かつ最も包括的なデータベース
- **🔍 マルチ DB 検索モード**: 各データベースから最大 5 件ずつ、総合的な検索結果を提供
- **🎯 高精度マッチング**: 90.9%の成功率、各 DB から均等な結果分散
- **💾 詳細結果保存**: JSON・マークダウン・テキスト形式での検索結果自動保存

### **従来機能: 動的栄養計算システム**

- **🧠 AI 駆動の計算戦略決定**: Gemini AI が各料理に対して最適な栄養計算方法を自動選択
- **🎯 高精度栄養計算**: 食材重量 × 100g あたり栄養価で正確な実栄養価を算出
- **📊 3 層集計システム**: 食材 → 料理 → 食事全体の自動栄養集計

### **コア機能**

- **フェーズ 1**: Gemini AI による食事画像の分析（料理識別、食材抽出、重量推定）
- **マルチ DB 検索**: 3 つのデータベースからの包括的栄養情報取得
- **複数料理対応**: 1 枚の画像で複数の料理を同時分析
- **英語・日本語対応**: 多言語での食材・料理認識
- **OpenAPI 3.0 準拠**: 完全な API 文書化とタイプ安全性

## 🏗 プロジェクト構造

```
meal_analysis_api_2/
├── db/                                   # マルチデータベース（新機能）
│   ├── yazio_db.json                     # YAZIO栄養データベース（1,825項目）
│   ├── mynetdiary_db.json                # MyNetDiary栄養データベース（1,142項目）
│   └── eatthismuch_db.json               # EatThisMuch栄養データベース（8,878項目）
├── app_v2/                               # 新アーキテクチャ版
│   ├── components/                       # コンポーネントベース設計
│   │   ├── local_nutrition_search_component.py  # マルチDB検索コンポーネント
│   │   ├── phase1_component.py           # 画像分析コンポーネント
│   │   └── base.py                       # ベースコンポーネント
│   ├── pipeline/                         # パイプライン管理
│   │   ├── orchestrator.py               # メイン処理オーケストレーター
│   │   └── result_manager.py             # 結果管理システム
│   ├── models/                           # データモデル
│   │   ├── nutrition_search_models.py    # 栄養検索モデル
│   │   └── phase1_models.py              # Phase1モデル
│   ├── main/
│   │   └── app.py                        # FastAPIアプリケーション
│   └── config/                           # 設定管理
├── test_multi_db_nutrition_search.py     # マルチDB検索テストスクリプト（新機能）
├── test_local_nutrition_search_v2.py     # ローカル検索テストスクリプト
├── test_images/                          # テスト用画像
└── requirements.txt                      # Python依存関係
```

## 🚀 セットアップ

### 1. 依存関係のインストール

```bash
# 仮想環境の作成
python -m venv venv

# 仮想環境のアクティベート
source venv/bin/activate  # macOS/Linux
# または
venv\Scripts\activate     # Windows

# 依存関係のインストール
pip install -r requirements.txt
```

### 2. Google Cloud 設定

#### Google Cloud SDK のインストール

まだインストールしていない場合は、以下からインストールしてください：
https://cloud.google.com/sdk/docs/install

#### Google Cloud 認証の設定

開発環境では以下のコマンドで認証を設定：

```bash
# Google Cloudにログイン
gcloud auth login

# アプリケーションのデフォルト認証情報を設定
gcloud auth application-default login

# プロジェクトIDを設定
gcloud config set project YOUR_PROJECT_ID
```

本番環境ではサービスアカウントキーを使用：

```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your-service-account-key.json"
```

#### Vertex AI API の有効化

```bash
# Vertex AI APIを有効化
gcloud services enable aiplatform.googleapis.com
```

### 3. 環境変数の設定

以下の環境変数を設定してください：

```bash
# USDA API設定
export USDA_API_KEY="your-usda-api-key"

# Vertex AI設定
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account-key.json"
export GEMINI_PROJECT_ID="your-gcp-project-id"
export GEMINI_LOCATION="us-central1"
export GEMINI_MODEL_NAME="gemini-2.5-flash-preview-05-20"
```

## 🖥 サーバー起動

### app_v2 サーバーの起動（マルチ DB 対応）

```bash
# app_v2サーバーの起動
python -m app_v2.main.app
```

**⚠️ 注意**: 相対インポートエラーを回避するため、必ずモジュール形式で実行してください。

サーバーが起動すると、以下の URL でアクセス可能になります：

- **API**: http://localhost:8000
- **ドキュメント**: http://localhost:8000/docs
- **ヘルスチェック**: http://localhost:8000/health

## 🧪 テストの実行

### 🔥 マルチデータベース栄養検索テスト（最新機能）

**重要**: サーバーが起動している状態で実行してください。

```bash
# 別のターミナルで実行
python test_multi_db_nutrition_search.py
```

**期待される結果**:

- **検索速度**: 11 クエリを 0.10 秒で処理
- **マッチ率**: 各 DB90.9%のクエリで結果発見
- **総マッチ数**: 87 件（平均 7.9 件/クエリ）
- **データベース統計**:
  - YAZIO: 1,825 項目
  - MyNetDiary: 1,142 項目
  - EatThisMuch: 8,878 項目

**テスト結果例**:

```
📈 Multi-Database Search Results Summary:
- Total queries: 11
- Total matches found: 87
- Average matches per query: 7.9
- Search time: 0.10s

🔍 Detailed Query Results:
1. 'Roasted Potatoes' (dish)
   EatThisMuch: 3 matches
     Best: 'Roasted Potatoes' (score: 1.000)
     Nutrition: 91.0 kcal, 1.9g protein
```

### ローカル栄養検索テスト

```bash
# ローカル栄養データベース検索の統合テスト
python test_local_nutrition_search_v2.py
```

### 基本テスト（フェーズ 1 のみ）

```bash
python test_phase1_only.py
```

## 🚀 ローカル栄養データベース検索システム v2.0

### **新機能: ローカルデータベース統合**

システムが USDA API 依存からローカル栄養データベース検索に対応しました：

- **🔍 BM25F + マルチシグナルブースティング検索**: 高精度な食材マッチング
- **📊 8,878 項目のローカルデータベース**: オフライン栄養計算対応
- **⚡ 90.9%マッチ率**: 実測値による高い成功率
- **🔄 USDA 互換性**: 既存システムとの完全互換性維持

### サーバー起動（v2.0 対応）

```bash
# app_v2サーバーの起動
python -m app_v2.main.app
```

### ローカル栄養検索テスト

**重要**: サーバーが起動している状態で実行してください。

```bash
# ローカル栄養データベース検索の統合テスト
python test_local_nutrition_search_v2.py
```

**期待される結果**:

- **マッチ率**: 90.9% (10/11 検索成功)
- **レスポンス時間**: ~11 秒
- **データベース**: ローカル栄養データ (8,878 項目)
- **検索方法**: BM25F + マルチシグナルブースティング

**テスト結果例**:

```
🔍 Local Nutrition Search Results:
- Matches found: 10
- Match rate: 90.9%
- Search method: local_nutrition_database
- Total searches: 11
- Successful matches: 10

🍽 Final Meal Nutrition:
- Calories: 400.00 kcal
- Protein: 60.00 g
- Carbohydrates: 220.00 g
- Fat: 120.00 g
```

### データベース詳細

**ローカル栄養データベース構成**:

- `dish_db.json`: 4,583 料理データ
- `ingredient_db.json`: 1,473 食材データ
- `branded_db.json`: 2,822 ブランド食品
- `unified_nutrition_db.json`: 8,878 統合データ

## 📡 API 使用方法

### 🔥 完全分析 (推奨): 全フェーズ統合

**1 つのリクエストで全ての分析を実行**

```bash
curl -X POST "http://localhost:8000/api/v1/meal-analyses/complete" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg"
```

このエンドポイントは以下を自動実行します：

- フェーズ 1: 画像分析
- USDA 照合: 食材データベース検索
- フェーズ 2: 計算戦略決定
- 栄養計算: 最終栄養価算出
- 結果保存: 自動的にファイル保存

**保存された結果の取得**

```bash
# 全結果一覧
curl "http://localhost:8000/api/v1/meal-analyses/results"

# 特定の結果取得
curl "http://localhost:8000/api/v1/meal-analyses/results/{analysis_id}"
```

### フェーズ 1: 基本分析

```bash
curl -X POST "http://localhost:8000/api/v1/meal-analyses" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg"
```

### フェーズ 2: 動的栄養計算

```bash
# 最初にフェーズ1の結果を取得
initial_result=$(curl -X POST "http://localhost:8000/api/v1/meal-analyses" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg")

# フェーズ2で動的栄養計算
curl -X POST "http://localhost:8000/api/v1/meal-analyses/refine" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg" \
  -F "initial_analysis_data=$initial_result"
```

## 📋 レスポンス例

### フェーズ 1 レスポンス

```json
{
  "dishes": [
    {
      "dish_name": "Fried Fish with Spaghetti and Tomato Sauce",
      "type": "Main Dish",
      "quantity_on_plate": "2 pieces of fish, 1 small serving of spaghetti",
      "ingredients": [
        {
          "ingredient_name": "White Fish Fillet",
          "weight_g": 150.0
        },
        {
          "ingredient_name": "Spaghetti (cooked)",
          "weight_g": 80.0
        }
      ]
    }
  ]
}
```

### フェーズ 2 レスポンス（動的栄養計算）

```json
{
  "dishes": [
    {
      "dish_name": "Spinach and Daikon Radish Aemono",
      "type": "Side Dish",
      "calculation_strategy": "ingredient_level",
      "fdc_id": null,
      "ingredients": [
        {
          "ingredient_name": "Spinach",
          "weight_g": 80.0,
          "fdc_id": 1905313,
          "usda_source_description": "SPINACH",
          "key_nutrients_per_100g": {
            "calories_kcal": 24.0,
            "protein_g": 3.53,
            "carbohydrates_g": 3.53,
            "fat_g": 0.0
          },
          "actual_nutrients": {
            "calories_kcal": 19.2,
            "protein_g": 2.82,
            "carbohydrates_g": 2.82,
            "fat_g": 0.0
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 57.45,
        "protein_g": 3.85,
        "carbohydrates_g": 4.57,
        "fat_g": 3.31
      }
    },
    {
      "dish_name": "Green Tea",
      "type": "Drink",
      "calculation_strategy": "dish_level",
      "fdc_id": 1810668,
      "usda_source_description": "GREEN TEA",
      "key_nutrients_per_100g": {
        "calories_kcal": 0.0,
        "protein_g": 0.0,
        "carbohydrates_g": 0.0,
        "fat_g": 0.0
      },
      "dish_total_actual_nutrients": {
        "calories_kcal": 0.0,
        "protein_g": 0.0,
        "carbohydrates_g": 0.0,
        "fat_g": 0.0
      }
    }
  ],
  "total_meal_nutrients": {
    "calories_kcal": 337.95,
    "protein_g": 13.32,
    "carbohydrates_g": 56.19,
    "fat_g": 6.67
  },
  "warnings": null,
  "errors": null
}
```

## 🔧 技術仕様

### 動的計算戦略の決定ロジック

**Dish Level (`dish_level`)**:

- シンプルな単品食品（果物、飲み物、基本食材）
- 標準化された既製品で適切な USDA ID が存在する場合
- 例: 緑茶、りんご、白米

**Ingredient Level (`ingredient_level`)**:

- 複雑な調理済み料理（炒め物、サラダ、スープ）
- 複数食材の組み合わせで料理全体の USDA ID が不適切な場合
- 例: 野菜炒め、手作りサラダ、味噌汁

### 栄養計算式

```
実栄養価 = (100gあたり栄養価 ÷ 100) × 推定重量(g)
```

### 集計階層

1. **食材レベル**: 個別食材の重量 × 100g 栄養価
2. **料理レベル**: 食材レベルの合計 または 料理全体計算
3. **食事レベル**: 全料理の栄養価合計

## ⚠️ エラーハンドリング

API は以下の HTTP ステータスコードを返します：

- `200 OK`: 正常な分析完了
- `400 Bad Request`: 不正なリクエスト（画像形式エラーなど）
- `422 Unprocessable Entity`: バリデーションエラー
- `503 Service Unavailable`: 外部サービス（USDA/Gemini）エラー
- `500 Internal Server Error`: サーバー内部エラー

## 🔍 トラブルシューティング

### 認証エラーが発生する場合

```bash
# 現在の認証状態を確認
gcloud auth list

# 現在のプロジェクト設定を確認
gcloud config list

# 必要に応じて再度認証
gcloud auth application-default login
```

### Vertex AI API が有効になっていない場合

```bash
# APIの有効状況を確認
gcloud services list --enabled | grep aiplatform

# 有効でない場合は有効化
gcloud services enable aiplatform.googleapis.com
```

### USDA API エラーが発生する場合

- API キーが正しく設定されているか確認
- レートリミット（3,600 件/時）に達していないか確認
- ネットワーク接続を確認

## 💻 開発情報

- **フレームワーク**: FastAPI 0.104+
- **AI サービス**: Google Vertex AI (Gemini 2.5 Flash)
- **栄養データベース**: USDA FoodData Central API
- **認証**: Google Cloud サービスアカウント
- **Python バージョン**: 3.9+
- **主要ライブラリ**:
  - `google-cloud-aiplatform` (Vertex AI)
  - `httpx` (非同期 HTTP)
  - `pydantic` (データバリデーション)
  - `pillow` (画像処理)

## 📄 ライセンス

このプロジェクトは MIT ライセンスの下で公開されています。

## 注意事項

**セキュリティ**: API キーやサービスアカウントキーは絶対にリポジトリにコミットしないでください。環境変数として安全に管理してください。

```

============================================================

🎯 STRATEGIC MULTI-DB SEARCH ANALYSIS SUMMARY
--------------------------------------------------
総ファイル数: 22
存在ファイル数: 22
分析完了時刻: 2025-06-10 17:11:57

このファイルには、test_multi_db_nutrition_search.py実行時に
関わる戦略的マルチDB Elasticsearch検索システムの全アプリケーション
ファイルの完全な内容が含まれています。

🔥 STRATEGIC SEARCH SYSTEM HIGHLIGHTS:
- 🍽️  Dish戦略: EatThisMuch dish → branded fallback
- 🥕 Ingredient戦略: EatThisMuch ingredient → Multi-DB fallback
- ⚡ 44%高速化: 677ms → 381ms
- 📊 結果最適化: 144件 → 50件 (関連性重視)
- 🎯 戦略的分散: EatThisMuch中心型 (72%)
- 🔍 スコア閾値: 動的フォールバック (20.0)
- 💾 詳細追跡: 戦略フェーズ・メタデータ記録
- 🚀 Component化: 拡張可能なアーキテクチャ
