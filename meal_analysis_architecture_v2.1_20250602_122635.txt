================================================================================
MEAL ANALYSIS API v2.1 - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ§‹é€ ã¨ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
================================================================================
ç”Ÿæˆæ—¥æ™‚: 2025-06-02 12:26:35
åˆ†æå¯¾è±¡: test_english_phase1_v2.py & test_english_phase2_v2.py å®Ÿè¡Œæ™‚ã«å‘¼ã³å‡ºã•ã‚Œã‚‹å…¨Pythonãƒ•ã‚¡ã‚¤ãƒ«
================================================================================

ğŸ“Š ARCHITECTURE OVERVIEW v2.1
----------------------------------------

ğŸ”„ EXECUTION FLOW (Advanced 2-Phase Approach):
Phase 1: ç”»åƒ â†’ Gemini AI â†’ æ–™ç†ãƒ»é£Ÿæè­˜åˆ¥ + USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆ
Phase 2: Phase1çµæœ â†’ ä¸¦åˆ—USDAæ¤œç´¢ â†’ æˆ¦ç•¥æ±ºå®šAI â†’ FDC IDé¸æŠ â†’ å‹•çš„æ „é¤Šè¨ˆç®—

ğŸ—ï¸ LAYER STRUCTURE v2.1:
â”œâ”€â”€ APIå±¤ (FastAPI)
â”‚   â”œâ”€â”€ meal_analyses.py (Phase 1 v2.1: USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆ)
â”‚   â””â”€â”€ meal_analyses_refine.py (Phase 2 v2.1: é«˜åº¦æˆ¦ç•¥æ±ºå®š + æ „é¤Šè¨ˆç®—)
â”œâ”€â”€ ã‚µãƒ¼ãƒ“ã‚¹å±¤ (Enhanced)
â”‚   â”œâ”€â”€ gemini_service.py (2ãƒ•ã‚§ãƒ¼ã‚ºãƒ¡ã‚½ãƒƒãƒ‰: analyze_image_phase1, refine_analysis_phase2)
â”‚   â”œâ”€â”€ usda_service.py (Rich search + æ „é¤Šè©³ç´°å–å¾—)
â”‚   â”œâ”€â”€ nutrition_calculation_service.py (å‹•çš„è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³)
â”‚   â””â”€â”€ logging_service.py (ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† + è©³ç´°ãƒ­ã‚°è¨˜éŒ²)
â”œâ”€â”€ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤ (v2.1 Schemas)
â”‚   â””â”€â”€ meal.py (Phase1AnalysisResponse, Phase2GeminiResponse, MealAnalysisRefinementResponse)
â””â”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†å±¤ (2-Phase Templates)
    â”œâ”€â”€ prompt_loader.py (ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†)
    â””â”€â”€ prompt templates (phase1_*, phase2_*)

ğŸ”§ TECHNICAL FEATURES v2.1:
- âœ¨ é«˜åº¦æˆ¦ç•¥æ±ºå®šã‚·ã‚¹ãƒ†ãƒ  (dish_level vs ingredient_level)
- ğŸ” ä¸¦åˆ—USDAæ¤œç´¢ (25+å€™è£œã®åŒæ™‚å‡¦ç†)
- ğŸ“Š å‹•çš„æ „é¤Šè¨ˆç®— (æˆ¦ç•¥ãƒ™ãƒ¼ã‚¹è¨ˆç®—)
- ğŸ“ˆ åŒ…æ‹¬çš„ãƒ­ã‚°æ©Ÿèƒ½ (ã‚»ãƒƒã‚·ãƒ§ãƒ³è¿½è·¡ + ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ)
- ğŸ¯ FDC IDé¸æŠã¨ã‚½ãƒ¼ã‚¹èª¬æ˜
- ğŸ”„ 3å±¤æ „é¤Šé›†è¨ˆ (é£Ÿæ â†’ æ–™ç† â†’ é£Ÿäº‹)
- âš¡ éåŒæœŸå‡¦ç†æœ€é©åŒ–
- ğŸ“‹ æ§‹é€ åŒ–JSONå‡ºåŠ› (Gemini response_schema)

ğŸ†• NEW FEATURES v2.1:
- USDAã‚¯ã‚¨ãƒªå€™è£œã®è‡ªå‹•ç”Ÿæˆ
- æˆ¦ç•¥ç†ç”±ã¨é¸æŠç†ç”±ã®è©³ç´°è¨˜éŒ²
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°åˆ†æ
- CSV/JSONLãƒ­ã‚°ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã¨ã‚¨ãƒ©ãƒ¼åˆ†æ

================================================================================

ğŸ“ v2.1ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
============================================================

ğŸ“„ FILE: test_english_phase1_v2.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 10100 bytes
æœ€çµ‚æ›´æ–°: 2025-05-30 16:11:18
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
Phase 1 Analysis Test Script (v2.1) - USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å«ã‚€æ–°ã—ã„å‡ºåŠ›ã‚’ãƒ†ã‚¹ãƒˆ

Usage:
    python test_english_phase1_v2.py [image_path]
    
Examples:
    python test_english_phase1_v2.py test_images/food1.jpg
    python test_english_phase1_v2.py  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒã‚’ä½¿ç”¨
"""

import requests
import json
import sys
import time
import argparse
from pathlib import Path
from datetime import datetime

# APIè¨­å®š
BASE_URL = "http://localhost:8000"
MEAL_ANALYSES_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/"

def get_default_image_paths():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç”»åƒãƒ‘ã‚¹ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    return [
        "test_images/food1.jpg",  # å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªæ¸ˆã¿
        "test_images/food2.jpg",
        "test_images/food3.jpg",
        "tests/assets/test_meal.jpg",
        "test_meal.jpg", 
        "sample_meal.jpg",
        # ä»–ã®ä¸€èˆ¬çš„ãªå ´æ‰€ã‚‚è©¦ã™
        Path.home() / "Downloads" / "meal.jpg",
        Path.cwd() / "meal.jpg"
    ]

def find_test_image(specified_path=None):
    """ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹"""
    if specified_path:
        path = Path(specified_path)
        if path.exists():
            return path
        else:
            print(f"âŒ Specified image not found: {specified_path}")
            return None
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç”»åƒã‚’æ¢ã™
    for path in get_default_image_paths():
        if Path(path).exists():
            return Path(path)
    
    return None

def test_phase1_analysis_v2(image_path):
    """Phase 1ã®æ–°ã—ã„ä»•æ§˜ï¼ˆv2.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print(f"ğŸ“· Using test image: {image_path}")
    
    # API ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    try:
        print("ğŸš€ Sending Phase 1 analysis request...")
        start_time = time.time()
        
        with open(image_path, 'rb') as image_file:
            files = {
                'image': ('test_meal.jpg', image_file, 'image/jpeg')
            }
            data = {
                'optional_text': 'This is a test meal for Phase 1 analysis with USDA query candidates.'
            }
            
            response = requests.post(
                MEAL_ANALYSES_ENDPOINT,
                files=files,
                data=data,
                timeout=60
            )
        
        elapsed_time = time.time() - start_time
        print(f"â±ï¸  Request completed in {elapsed_time:.2f} seconds")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
        print(f"ğŸ“Š Response status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ Error response: {response.text}")
            return False, None
        
        # JSON ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # çµæœã®è¡¨ç¤ºã¨æ¤œè¨¼
        print("\n" + "="*80)
        print("ğŸ“‹ PHASE 1 ANALYSIS RESULTS (v2.1)")
        print("="*80)
        
        # åŸºæœ¬æ§‹é€ ã®ç¢ºèª
        if 'dishes' not in result:
            print("âŒ Missing 'dishes' field in response")
            return False, None
        
        dishes = result['dishes']
        print(f"ğŸ½ï¸  Found {len(dishes)} dishes")
        
        # å„æ–™ç†ã®è©³ç´°è¡¨ç¤º
        for i, dish in enumerate(dishes, 1):
            print(f"\nğŸ“Œ DISH {i}: {dish.get('dish_name', 'Unknown')}")
            print(f"   Type: {dish.get('type', 'N/A')}")
            print(f"   Quantity: {dish.get('quantity_on_plate', 'N/A')}")
            
            # ææ–™ãƒªã‚¹ãƒˆ
            ingredients = dish.get('ingredients', [])
            print(f"   ğŸ¥— Ingredients ({len(ingredients)}):")
            for ing in ingredients:
                print(f"      - {ing.get('ingredient_name', 'Unknown')}: {ing.get('weight_g', 0)}g")
            
            # NEW: USDAã‚¯ã‚¨ãƒªå€™è£œã®ç¢ºèª (v2.1ã®é‡è¦ãªæ–°æ©Ÿèƒ½)
            usda_candidates = dish.get('usda_query_candidates', [])
            print(f"   ğŸ” USDA Query Candidates ({len(usda_candidates)}):")
            
            if not usda_candidates:
                print("      âŒ No USDA query candidates found - this is a problem for v2.1!")
                return False, None
            
            for j, candidate in enumerate(usda_candidates, 1):
                print(f"      {j}. Query: '{candidate.get('query_term', 'N/A')}'")
                print(f"         Granularity: {candidate.get('granularity_level', 'N/A')}")
                print(f"         Original: {candidate.get('original_term', 'N/A')}")
                print(f"         Reason: {candidate.get('reason_for_query', 'N/A')}")
        
        # v2.1 ä»•æ§˜ã®æ¤œè¨¼
        print(f"\nğŸ” V2.1 SPECIFICATION VALIDATION:")
        
        validation_passed = True
        
        # 1. å…¨ã¦ã®æ–™ç†ã«USDAã‚¯ã‚¨ãƒªå€™è£œãŒã‚ã‚‹ã‹
        for dish in dishes:
            if not dish.get('usda_query_candidates'):
                print(f"   âŒ Dish '{dish.get('dish_name')}' has no USDA query candidates")
                validation_passed = False
            else:
                print(f"   âœ… Dish '{dish.get('dish_name')}' has {len(dish.get('usda_query_candidates'))} USDA query candidates")
        
        # 2. ã‚¯ã‚¨ãƒªå€™è£œã®ç²’åº¦ãƒ¬ãƒ™ãƒ«ãŒé©åˆ‡ã‹
        granularity_levels = set()
        for dish in dishes:
            for candidate in dish.get('usda_query_candidates', []):
                level = candidate.get('granularity_level')
                if level in ['dish', 'ingredient', 'branded_product']:
                    granularity_levels.add(level)
                else:
                    print(f"   âŒ Invalid granularity level: {level}")
                    validation_passed = False
        
        print(f"   ğŸ“Š Granularity levels found: {list(granularity_levels)}")
        
        # 3. ç†ç”±ä»˜ã‘ãŒã‚ã‚‹ã‹
        reasoning_count = 0
        total_candidates = 0
        for dish in dishes:
            for candidate in dish.get('usda_query_candidates', []):
                total_candidates += 1
                if candidate.get('reason_for_query'):
                    reasoning_count += 1
        
        reasoning_percentage = (reasoning_count / total_candidates * 100) if total_candidates > 0 else 0
        print(f"   ğŸ“ Query reasoning coverage: {reasoning_percentage:.1f}% ({reasoning_count}/{total_candidates})")
        
        if reasoning_percentage < 80:
            print(f"   âš ï¸  Low reasoning coverage - should be > 80%")
            validation_passed = False
        
        # æœ€çµ‚åˆ¤å®š
        if validation_passed:
            print(f"\nâœ… Phase 1 v2.1 test PASSED!")
            print("   - All dishes have USDA query candidates")
            print("   - Granularity levels are valid") 
            print("   - Reasoning coverage is sufficient")
        else:
            print(f"\nâŒ Phase 1 v2.1 test FAILED!")
            print("   Please check the validation errors above.")
        
        return validation_passed, result
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Request error: {e}")
        return False, None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON decode error: {e}")
        print(f"Raw response: {response.text}")
        return False, None
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False, None

def save_result(result, image_path):
    """çµæœã‚’test_resultsãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜"""
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_dir = Path("test_results")
    output_dir.mkdir(exist_ok=True)
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    image_name = Path(image_path).stem
    output_file = output_dir / f"phase1_result_{image_name}_{timestamp}.json"
    
    # çµæœã‚’ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Full result saved to: {output_file}")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚‚ã‚³ãƒ”ãƒ¼ä¿å­˜ï¼ˆPhase 2ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
    default_file = "phase1_analysis_result_v2.json"
    with open(default_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Also saved as: {default_file} (for Phase 2 test)")
    
    return output_file

def main():
    parser = argparse.ArgumentParser(
        description="Phase 1 Analysis Test (v2.1) - USDA Query Candidates",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python test_english_phase1_v2.py test_images/food1.jpg
  python test_english_phase1_v2.py ~/Downloads/meal.jpg
  python test_english_phase1_v2.py  # Use default image
        """
    )
    parser.add_argument(
        'image_path', 
        nargs='?', 
        help='Path to the meal image file (optional, will search for default images if not provided)'
    )
    
    args = parser.parse_args()
    
    print("ğŸ§ª Phase 1 Analysis Test (v2.1) - USDA Query Candidates")
    print("-" * 60)
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    try:
        health_response = requests.get(f"{BASE_URL}/health", timeout=5)
        if health_response.status_code == 200:
            print("âœ… Server is healthy")
        else:
            print("âŒ Server health check failed")
            return 1
    except requests.exceptions.RequestException:
        print("âŒ Server is not reachable")
        return 1
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    image_path = find_test_image(args.image_path)
    
    if not image_path:
        print("âŒ No test image found. Please specify an image path or place a meal image in one of these locations:")
        for path in get_default_image_paths():
            print(f"   - {path}")
        print(f"\nUsage: python {sys.argv[0]} [image_path]")
        return 1
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    success, result = test_phase1_analysis_v2(image_path)
    
    # çµæœã‚’ä¿å­˜
    if result:
        save_result(result, image_path)
    
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ“„ FILE: test_english_phase2_v2.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 13855 bytes
æœ€çµ‚æ›´æ–°: 2025-06-01 11:29:05
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
Phase 2 Analysis Test Script (v2.1) - calculation_strategyã¨FDC IDé¸æŠã‚’ãƒ†ã‚¹ãƒˆ

Usage:
    python test_english_phase2_v2.py [image_path] [phase1_result_file]
    
Examples:
    python test_english_phase2_v2.py test_images/food1.jpg
    python test_english_phase2_v2.py test_images/food1.jpg test_results/phase1_result_food1_20240530_120000.json
    python test_english_phase2_v2.py  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒã¨Phase1çµæœã‚’ä½¿ç”¨
"""

import requests
import json
import sys
import time
import argparse
from pathlib import Path
from datetime import datetime

# APIè¨­å®š
BASE_URL = "http://localhost:8000"
PHASE1_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/"
PHASE2_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/refine"

def get_default_image_paths():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç”»åƒãƒ‘ã‚¹ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    return [
        "test_images/food1.jpg",
        "test_images/food2.jpg",
        "test_images/food3.jpg",
        "tests/assets/test_meal.jpg",
        "test_meal.jpg", 
        "sample_meal.jpg",
        Path.home() / "Downloads" / "meal.jpg",
        Path.cwd() / "meal.jpg"
    ]

def find_test_image(specified_path=None):
    """ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹"""
    if specified_path:
        path = Path(specified_path)
        if path.exists():
            return path
        else:
            print(f"âŒ Specified image not found: {specified_path}")
            return None
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç”»åƒã‚’æ¢ã™
    for path in get_default_image_paths():
        if Path(path).exists():
            return Path(path)
    
    return None

def find_phase1_result(specified_path=None):
    """Phase1çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹"""
    if specified_path:
        path = Path(specified_path)
        if path.exists():
            return path
        else:
            print(f"âŒ Specified Phase 1 result file not found: {specified_path}")
            return None
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    default_paths = [
        "phase1_analysis_result_v2.json",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
    ]
    
    # test_resultsãƒ•ã‚©ãƒ«ãƒ€å†…ã®æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèª
    test_results_dir = Path("test_results")
    if test_results_dir.exists():
        phase1_files = list(test_results_dir.glob("phase1_result_*.json"))
        # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ˆé ­ã«
        phase1_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        default_paths.extend(phase1_files)
    
    for path in default_paths:
        if Path(path).exists():
            return Path(path)
    
    return None

def test_phase2_analysis_v2(image_path, phase1_result_file):
    """Phase 2ã®æ–°ã—ã„ä»•æ§˜ï¼ˆv2.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print(f"ğŸ“· Using test image: {image_path}")
    print(f"ğŸ“„ Using Phase 1 result: {phase1_result_file}")
    
    # Phase 1çµæœã‚’èª­ã¿è¾¼ã¿
    try:
        with open(phase1_result_file, 'r', encoding='utf-8') as f:
            phase1_result = json.load(f)
        print(f"âœ… Phase 1 result loaded from {phase1_result_file}")
    except Exception as e:
        print(f"âŒ Error loading Phase 1 result: {e}")
        return False, None
    
    # Phase 2 API ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    try:
        print("ğŸš€ Sending Phase 2 analysis request...")
        start_time = time.time()
        
        with open(image_path, 'rb') as image_file:
            files = {
                'image': ('test_meal.jpg', image_file, 'image/jpeg')
            }
            data = {
                'phase1_analysis_json': json.dumps(phase1_result, ensure_ascii=False)
            }
            
            response = requests.post(
                PHASE2_ENDPOINT,
                files=files,
                data=data,
                timeout=120  # Phase 2ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§
            )
        
        elapsed_time = time.time() - start_time
        print(f"â±ï¸  Request completed in {elapsed_time:.2f} seconds")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
        print(f"ğŸ“Š Response status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ Error response: {response.text}")
            return False, None
        
        # JSON ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # çµæœã®è¡¨ç¤ºã¨æ¤œè¨¼
        print("\n" + "="*80)
        print("ğŸ“‹ PHASE 2 ANALYSIS RESULTS (v2.1)")
        print("="*80)
        
        # åŸºæœ¬æ§‹é€ ã®ç¢ºèª
        if 'dishes' not in result:
            print("âŒ Missing 'dishes' field in response")
            return False, None
        
        dishes = result['dishes']
        print(f"ğŸ½ï¸  Found {len(dishes)} dishes")
        
        # å„æ–™ç†ã®è©³ç´°è¡¨ç¤ºã¨æ¤œè¨¼
        validation_passed = True
        strategy_counts = {"dish_level": 0, "ingredient_level": 0}
        total_fdc_ids_selected = 0
        
        for i, dish in enumerate(dishes, 1):
            print(f"\nğŸ“Œ DISH {i}: {dish.get('dish_name', 'Unknown')}")
            print(f"   Type: {dish.get('type', 'N/A')}")
            
            # NEW v2.1: calculation_strategy ã®ç¢ºèª
            strategy = dish.get('calculation_strategy')
            print(f"   ğŸ¯ Calculation Strategy: {strategy}")
            
            if strategy not in ['dish_level', 'ingredient_level']:
                print(f"      âŒ Invalid calculation strategy: {strategy}")
                validation_passed = False
            else:
                strategy_counts[strategy] += 1
                print(f"   ğŸ“ Strategy Reason: {dish.get('reason_for_strategy', 'N/A')}")
            
            # FDC IDæƒ…å ±ã®ç¢ºèª
            dish_fdc_id = dish.get('fdc_id')
            if strategy == 'dish_level':
                if dish_fdc_id:
                    print(f"   ğŸ·ï¸  Dish FDC ID: {dish_fdc_id}")
                    print(f"   ğŸ“„ USDA Source: {dish.get('usda_source_description', 'N/A')}")
                    print(f"   ğŸ’­ Choice Reason: {dish.get('reason_for_choice', 'N/A')}")
                    total_fdc_ids_selected += 1
                else:
                    print(f"      âš ï¸  No FDC ID for dish-level strategy")
            
            # ææ–™ã®è©³ç´°
            ingredients = dish.get('ingredients', [])
            print(f"   ğŸ¥— Ingredients ({len(ingredients)}):")
            
            for ing in ingredients:
                ing_name = ing.get('ingredient_name', 'Unknown')
                weight = ing.get('weight_g', 0)
                ing_fdc_id = ing.get('fdc_id')
                
                print(f"      - {ing_name}: {weight}g", end="")
                if ing_fdc_id:
                    print(f" [FDC ID: {ing_fdc_id}]")
                    total_fdc_ids_selected += 1
                    if ing.get('reason_for_choice'):
                        print(f"        Reason: {ing.get('reason_for_choice')}")
                else:
                    print(f" [No FDC ID]")
            
            # æ „é¤Šç´ æƒ…å ±ã®ç¢ºèª
            nutrients = dish.get('dish_total_actual_nutrients')
            if nutrients:
                print(f"   ğŸ§® Nutrition (Total): {nutrients.get('calories_kcal', 0):.1f} kcal, "
                      f"{nutrients.get('protein_g', 0):.1f}g protein, "
                      f"{nutrients.get('carbohydrates_g', 0):.1f}g carbs, "
                      f"{nutrients.get('fat_g', 0):.1f}g fat")
            else:
                print(f"   âš ï¸  No nutritional data calculated")
        
        # é£Ÿäº‹å…¨ä½“ã®æ „é¤Š
        total_nutrients = result.get('total_meal_nutrients')
        if total_nutrients:
            print(f"\nğŸ½ï¸  MEAL TOTAL NUTRITION:")
            print(f"   Energy: {total_nutrients.get('calories_kcal', 0):.1f} kcal")
            print(f"   Protein: {total_nutrients.get('protein_g', 0):.1f}g")
            print(f"   Carbohydrates: {total_nutrients.get('carbohydrates_g', 0):.1f}g")
            print(f"   Fat: {total_nutrients.get('fat_g', 0):.1f}g")
            if total_nutrients.get('fiber_g'):
                print(f"   Fiber: {total_nutrients.get('fiber_g', 0):.1f}g")
            if total_nutrients.get('sodium_mg'):
                print(f"   Sodium: {total_nutrients.get('sodium_mg', 0):.1f}mg")
        else:
            print(f"\nâš ï¸  No total meal nutrition calculated")
            validation_passed = False
        
        # v2.1 ä»•æ§˜ã®æ¤œè¨¼
        print(f"\nğŸ” V2.1 SPECIFICATION VALIDATION:")
        print(f"   ğŸ“Š Strategy Distribution:")
        print(f"      - Dish Level: {strategy_counts['dish_level']} dishes")
        print(f"      - Ingredient Level: {strategy_counts['ingredient_level']} dishes") 
        print(f"   ğŸ·ï¸  Total FDC IDs Selected: {total_fdc_ids_selected}")
        
        # è­¦å‘Šã¨ã‚¨ãƒ©ãƒ¼ã®ç¢ºèª
        warnings = result.get('warnings', [])
        errors = result.get('errors', [])
        
        if warnings:
            print(f"   âš ï¸  Warnings ({len(warnings)}):")
            for warning in warnings:
                print(f"      - {warning}")
        
        if errors:
            print(f"   âŒ Errors ({len(errors)}):")
            for error in errors:
                print(f"      - {error}")
            validation_passed = False
        
        # æœ€çµ‚åˆ¤å®š
        if validation_passed:
            print(f"\nâœ… Phase 2 v2.1 test PASSED!")
            print("   - All calculation strategies are valid")
            print("   - FDC IDs are properly selected")
            print("   - Total meal nutrition is calculated")
        else:
            print(f"\nâŒ Phase 2 v2.1 test FAILED!")
            print("   Please check the validation errors above.")
        
        return validation_passed, result
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Request error: {e}")
        return False, None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON decode error: {e}")
        print(f"Raw response: {response.text}")
        return False, None
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False, None

def save_result(result, image_path, phase1_result_file):
    """çµæœã‚’test_resultsãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜"""
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_dir = Path("test_results")
    output_dir.mkdir(exist_ok=True)
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    image_name = Path(image_path).stem
    output_file = output_dir / f"phase2_result_{image_name}_{timestamp}.json"
    
    # çµæœã‚’ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Full result saved to: {output_file}")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚‚ã‚³ãƒ”ãƒ¼ä¿å­˜ï¼ˆå¾Œç¶šå‡¦ç†ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
    default_file = "phase2_analysis_result_v2.json"
    with open(default_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Also saved as: {default_file}")
    
    return output_file

def main():
    parser = argparse.ArgumentParser(
        description="Phase 2 Analysis Test (v2.1) - Calculation Strategy & FDC ID Selection",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python test_english_phase2_v2.py test_images/food1.jpg
  python test_english_phase2_v2.py test_images/food1.jpg test_results/phase1_result_food1_20240530_120000.json
  python test_english_phase2_v2.py  # Use default image and latest Phase 1 result
        """
    )
    parser.add_argument(
        'image_path', 
        nargs='?', 
        help='Path to the meal image file (optional, will search for default images if not provided)'
    )
    parser.add_argument(
        'phase1_result_file', 
        nargs='?', 
        help='Path to Phase 1 result JSON file (optional, will use latest if not provided)'
    )
    
    args = parser.parse_args()
    
    print("ğŸ§ª Phase 2 Analysis Test (v2.1) - Calculation Strategy & FDC ID Selection")
    print("-" * 80)
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    try:
        health_response = requests.get(f"{BASE_URL}/health", timeout=5)
        if health_response.status_code == 200:
            print("âœ… Server is healthy")
        else:
            print("âŒ Server health check failed")
            return 1
    except requests.exceptions.RequestException:
        print("âŒ Server is not reachable")
        return 1
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    image_path = find_test_image(args.image_path)
    
    if not image_path:
        print("âŒ No test image found. Please specify an image path or place a meal image in one of these locations:")
        for path in get_default_image_paths():
            print(f"   - {path}")
        print(f"\nUsage: python {sys.argv[0]} [image_path] [phase1_result_file]")
        return 1
    
    # Phase 1çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    phase1_result_file = find_phase1_result(args.phase1_result_file)
    
    if not phase1_result_file:
        print("âŒ No Phase 1 result file found. Please run Phase 1 test first or specify a result file:")
        print("   python test_english_phase1_v2.py")
        print(f"   OR: python {sys.argv[0]} {image_path} <phase1_result_file>")
        return 1
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    success, result = test_phase2_analysis_v2(image_path, phase1_result_file)
    
    # çµæœã‚’ä¿å­˜ (å¸¸ã«å®Ÿè¡Œ)
    if result:
        save_result(result, image_path, phase1_result_file)
    
    if success:
        print("\nğŸ‰ Phase 2 test completed successfully!")
        return 0
    else:
        print("\nğŸ’¥ Phase 2 test failed! Please check the implementation.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ“ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå±¤ (v2.1)
============================================================

ğŸ“„ FILE: app/main.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 3235 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import logging

from .api.v1.endpoints import meal_analyses, meal_analyses_refine
from .core.config import get_settings

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,  # ä¸€æ™‚çš„ã«DEBUGãƒ¬ãƒ™ãƒ«ã«å¤‰æ›´
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
    ]
)
logger = logging.getLogger(__name__)

# è¨­å®šã®å–å¾—
settings = get_settings()

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ
app = FastAPI(
    title="é£Ÿäº‹åˆ†æAPI (Meal Analysis API)",
    description="é£Ÿäº‹ã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€æ–™ç†ã¨ææ–™ã‚’ç‰¹å®šã™ã‚‹APIã€‚USDAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æºã«ã‚ˆã‚Šæ „é¤Šä¾¡è¨ˆç®—ã®ç²¾åº¦ã‚’å‘ä¸Šã€‚",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®è¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒç”¨ï¼‰
if settings.FASTAPI_ENV == "development":
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ã«åˆ¶é™ã™ã‚‹
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    """APIã®ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "é£Ÿäº‹åˆ†æAPI (Meal Analysis API)",
        "version": "2.0.0",
        "docs": "/docs",
        "health": "/health"
    }

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/health")
async def health_check():
    """APIã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "service": "meal-analysis-api"
    }

# v1 APIãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç™»éŒ²
app.include_router(
    meal_analyses.router,
    prefix=f"/api/{settings.API_VERSION}/meal-analyses",
    tags=["Meal Analysis"]
)

# v1 API ãƒ•ã‚§ãƒ¼ã‚º2ãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç™»éŒ²ï¼ˆ/refineã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
app.include_router(
    meal_analyses_refine.router,
    prefix=f"/api/{settings.API_VERSION}/meal-analyses",
    tags=["Meal Analysis"]
)

# ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆ
@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®å‡¦ç†"""
    logger.info("Meal Analysis API starting up...")
    logger.info(f"Environment: {settings.FASTAPI_ENV}")
    logger.info(f"API Version: {settings.API_VERSION}")
    logger.info(f"Gemini Model: {settings.GEMINI_MODEL_NAME}")
    logger.info("Phase 2 features with USDA integration enabled")

# ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆ
@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®å‡¦ç†"""
    logger.info("Meal Analysis API shutting down...")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": "INTERNAL_SERVER_ERROR",
                "message": "å†…éƒ¨ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
            }
        }
    ) 
```

============================================================

ğŸ“„ FILE: app/api/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/meal_analyses.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 7582 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:57:41
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import APIRouter, File, Form, UploadFile, HTTPException, Depends
from typing import Annotated, Optional
import logging
import time  # å®Ÿè¡Œæ™‚é–“æ¸¬å®šã®ãŸã‚

from ....services.gemini_service import GeminiMealAnalyzer
from ..schemas.meal import Phase1AnalysisResponse, MealAnalysisResponse, ErrorResponse
from ....services.logging_service import get_meal_analysis_logger, ProcessingPhase, LogLevel
from ....core.config import Settings, get_settings

logger = logging.getLogger(__name__)

router = APIRouter()

# Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_gemini_analyzer = None


async def get_gemini_analyzer(settings: Annotated[Settings, Depends(get_settings)]) -> GeminiMealAnalyzer:
    """
    Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
    """
    global _gemini_analyzer
    if _gemini_analyzer is None:
        _gemini_analyzer = GeminiMealAnalyzer(
            project_id=settings.GEMINI_PROJECT_ID,
            location=settings.GEMINI_LOCATION,
            model_name=settings.GEMINI_MODEL_NAME
        )
    return _gemini_analyzer


@router.post(
    "",
    response_model=Phase1AnalysisResponse,
    summary="Analyze Meal Image (Phase 1 v2.1)",
    description="v2.1: é£Ÿäº‹ç”»åƒã‚’åˆ†æã—ã€æ–™ç†ãƒ»é£Ÿæè­˜åˆ¥ã¨USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚"
)
async def analyze_meal_v2_1(
    settings: Annotated[Settings, Depends(get_settings)],
    image: Annotated[UploadFile, File(description="Meal image file.")],
    optional_text: Annotated[Optional[str], None] = None
):
    """
    v2.1ä»•æ§˜ï¼šé£Ÿäº‹ç”»åƒã®åŸºæœ¬åˆ†æ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. ç”»åƒã®åŸºæœ¬ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    2. Gemini AI ã«ã‚ˆã‚‹é£Ÿäº‹åˆ†æï¼ˆPhase 1ï¼‰
    3. USDAã‚¯ã‚¨ãƒªå€™è£œã®ç”Ÿæˆ
    4. çµæœè¿”å´
    """
    # ãƒ­ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    meal_logger = get_meal_analysis_logger()
    session_id = meal_logger.start_session(
        endpoint="/api/v1/meal-analyses",
        image_filename=getattr(image, 'filename', None),
        image_size_bytes=None  # å¾Œã§è¨­å®š
    )
    
    start_time = time.time()
    
    try:
        # 1. Image validation
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message="Starting Phase 1 meal analysis"
        )
        
        if not image.content_type or not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Invalid image file format.")
        
        try:
            image_bytes = await image.read()
            # Update image size in session
            if session_id in meal_logger.active_sessions:
                meal_logger.active_sessions[session_id].image_size_bytes = len(image_bytes)
            
            # File size check (e.g., 10MB)
            if len(image_bytes) > 10 * 1024 * 1024:
                raise HTTPException(status_code=400, detail="Image file size too large (max 10MB).")
        except Exception as e:
            logger.error(f"Error reading image file: {e}")
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.REQUEST_RECEIVED,
                error_message="Failed to read image file",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail="Failed to read image file.")

        # 2. Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—
        gemini_service = await get_gemini_analyzer(settings)

        # 3. Call Gemini service (Phase 1)
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE1_START,
            message="Starting Gemini Phase 1 analysis"
        )
        
        phase1_start_time = time.time()
        try:
            result = await gemini_service.analyze_image_phase1(
                image_bytes=image_bytes,
                image_mime_type=image.content_type,
                optional_text=optional_text
            )
            phase1_duration = (time.time() - phase1_start_time) * 1000
            
            # Phase 1çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
            dishes_count = len(result.get('dishes', []))
            usda_queries_count = sum(
                len(dish.get('usda_query_candidates', [])) 
                for dish in result.get('dishes', [])
            )
            
            meal_logger.update_phase1_results(
                session_id=session_id,
                duration_ms=phase1_duration,
                dishes_count=dishes_count,
                usda_queries_count=usda_queries_count,
                phase1_output=result
            )
            
        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE1_START,
                error_message="Gemini Phase 1 analysis failed",
                error_details=str(e)
            )
            raise HTTPException(status_code=503, detail=f"Gemini API error: {e}")

        # 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
        response = Phase1AnalysisResponse(**result)
        
        meal_logger.end_session(
            session_id=session_id,
            warnings=None,
            errors=None
        )
        
        return response
        
    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
        meal_logger.log_error(
            session_id=session_id,
            phase=ProcessingPhase.ERROR_OCCURRED,
            error_message="Unexpected error during Phase 1 processing",
            error_details=str(e)
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        meal_logger.end_session(
            session_id=session_id,
            warnings=None,
            errors=[str(e)]
        )
        
        raise


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å¤ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚‚ç¶­æŒ
@router.post(
    "/legacy",
    response_model=MealAnalysisResponse,
    summary="Legacy Meal Analysis (v1.0 compatibility)",
    description="å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚æ–°ã—ã„æ©Ÿèƒ½ã«ã¯ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ `/` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
)
async def analyze_meal_legacy(
    image: Annotated[UploadFile, File(description="Meal image file to analyze.")],
    settings: Annotated[Settings, Depends(get_settings)],
    gemini_service: Annotated[GeminiMealAnalyzer, Depends(get_gemini_analyzer)],
    optional_text: Annotated[Optional[str], Form(description="Optional additional information about the meal.")] = None
):
    """
    å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    # åŒã˜æ¤œè¨¼ã‚’å®Ÿè¡Œ
    if not image.content_type or not image.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="Invalid image file format.")
    
    image_bytes = await image.read()
    if len(image_bytes) > 10 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="File too large.")
    
    try:
        # æ—§ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        analysis_result = await gemini_service.analyze_image_and_text(
            image_bytes=image_bytes,
            image_mime_type=image.content_type,
            optional_text=optional_text
        )
        
        response = MealAnalysisResponse(**analysis_result)
        return response
        
    except Exception as e:
        logger.error(f"Legacy analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e)) 
```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/meal_analyses_refine.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 52329 bytes
æœ€çµ‚æ›´æ–°: 2025-06-02 12:18:34
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import APIRouter, File, Form, UploadFile, HTTPException, Depends
from typing import Annotated, List, Optional, Dict
import json
import logging
import asyncio  # éåŒæœŸå‡¦ç†ã®ãŸã‚
import time  # å®Ÿè¡Œæ™‚é–“æ¸¬å®šã®ãŸã‚

# æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«
from ..schemas.meal import (
    Phase1AnalysisResponse,  # Phase 1 å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«ä½¿ç”¨
    Phase2GeminiResponse,    # Phase 2 Geminiå‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«ä½¿ç”¨
    MealAnalysisRefinementResponse,
    USDASearchResultItem,
    RefinedDishResponse,
    RefinedIngredientResponse,
    CalculatedNutrients
)

# ã‚µãƒ¼ãƒ“ã‚¹
from ....services.usda_service import USDAService, get_usda_service
from ....services.gemini_service import GeminiMealAnalyzer
from ....services.nutrition_calculation_service import NutritionCalculationService, get_nutrition_calculation_service, WeightCalculationResult
from ....services.logging_service import get_meal_analysis_logger, ProcessingPhase, LogLevel
from ....core.config import Settings, get_settings

logger = logging.getLogger(__name__)

router = APIRouter()

# Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_gemini_analyzer = None

async def get_gemini_analyzer(settings: Annotated[Settings, Depends(get_settings)]) -> GeminiMealAnalyzer:
    """
    Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
    """
    global _gemini_analyzer
    if _gemini_analyzer is None:
        _gemini_analyzer = GeminiMealAnalyzer(
            project_id=settings.GEMINI_PROJECT_ID,
            location=settings.GEMINI_LOCATION,
            model_name=settings.GEMINI_MODEL_NAME
        )
    return _gemini_analyzer


@router.post(
    "/refine",
    response_model=MealAnalysisRefinementResponse,
    summary="Refine Meal Analysis with USDA Data & Enhanced Gemini Strategy (v2.1)",
    description="v2.1: Phase 1ã‹ã‚‰USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å—ä¿¡ã—ã€å…¨å€™è£œã§æ¤œç´¢ã‚’å®Ÿè¡Œã€‚Phase 2 GeminiãŒcalculation_strategyã‚’æ±ºå®šã—ã€FDC IDã‚’é¸æŠã€‚æ±ºå®šè«–çš„ã§ç²¾åº¦ã®é«˜ã„æ „é¤Šè¨ˆç®—ã‚’æä¾›ã€‚"
)
async def refine_meal_analysis(
    settings: Annotated[Settings, Depends(get_settings)],
    image: Annotated[UploadFile, File(description="Meal image file.")],
    # NEW: Phase 1 å‡ºåŠ›ã¯ JSON æ–‡å­—åˆ—ã¨ã—ã¦å—ã‘å–ã‚‹
    phase1_analysis_json: Annotated[str, Form(description="JSON response string from Phase 1 API.")],
    usda_service: Annotated[USDAService, Depends(get_usda_service)],
    gemini_service: Annotated[GeminiMealAnalyzer, Depends(get_gemini_analyzer)]
):
    """
    v2.1ä»•æ§˜ï¼šé£Ÿäº‹åˆ†æç²¾ç·»åŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. Phase 1åˆ†æçµæœã¨USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å—ä¿¡
    2. å…¨USDAã‚¯ã‚¨ãƒªå€™è£œã§ä¸¦åˆ—æ¤œç´¢ã‚’å®Ÿè¡Œ
    3. Phase 2 Geminiã§ calculation_strategy æ±ºå®šã¨FDC IDé¸æŠ
    4. calculation_strategyã«åŸºã¥ãæ „é¤Šè¨ˆç®—
    5. ç²¾ç·»åŒ–ã•ã‚ŒãŸçµæœã‚’è¿”ã™
    """
    # ãƒ­ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    meal_logger = get_meal_analysis_logger()
    session_id = meal_logger.start_session(
        endpoint="/api/v1/meal-analyses/refine",
        image_filename=getattr(image, 'filename', None),
        image_size_bytes=None  # å¾Œã§è¨­å®š
    )
    
    start_time = time.time()
    warnings = []
    errors = []

    try:
        # 1. Image validation (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯)
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message="Validating image file"
        )
        
        if not image.content_type or not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Invalid image file format.")
        
        try:
            image_bytes = await image.read()
            # Update image size in session
            if session_id in meal_logger.active_sessions:
                meal_logger.active_sessions[session_id].image_size_bytes = len(image_bytes)
            
            # File size check (e.g., 10MB)
            if len(image_bytes) > 10 * 1024 * 1024:
                raise HTTPException(status_code=400, detail="Image file size too large (max 10MB).")
        except Exception as e:
            logger.error(f"Error reading image file: {e}")
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.REQUEST_RECEIVED,
                error_message="Failed to read image file",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail="Failed to read image file.")

        # 2. Parse Phase 1 analysis_data
        try:
            phase1_dict = json.loads(phase1_analysis_json)
            phase1_analysis = Phase1AnalysisResponse(**phase1_dict)
            
            # ãƒ­ã‚°ã«Phase 1æƒ…å ±ã‚’è¨˜éŒ²
            dishes_count = len(phase1_analysis.dishes)
            usda_queries_count = sum(len(dish.usda_query_candidates) for dish in phase1_analysis.dishes)
            
            meal_logger.log_entry(
                session_id=session_id,
                level=LogLevel.INFO,
                phase=ProcessingPhase.PHASE1_COMPLETE,
                message=f"Phase 1 data received: {dishes_count} dishes, {usda_queries_count} USDA queries",
                data={
                    "dishes_count": dishes_count,
                    "usda_queries_count": usda_queries_count,
                    "phase1_output": phase1_dict
                }
            )
            
        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE1_COMPLETE,
                error_message="Failed to parse Phase 1 JSON",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail=f"Invalid Phase 1 JSON: {e}")

        # 3. Enhanced USDA Search with Tiered Strategy
        usda_search_start_time = time.time()
        
        # query_map ã¯ Phase 1 ã® query_term ã¨ original_term (è¡¨ç¤ºç”¨) ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¼•ãç¶šãä½¿ç”¨
        query_map = {}
        for dish in phase1_analysis.dishes:
            for candidate in dish.usda_query_candidates:
                query_map[candidate.query_term] = candidate.original_term or dish.dish_name

        # Enhanced USDA search with tiered approach
        all_usda_search_results_map: Dict[int, USDASearchResultItem] = {}
        search_details_for_log = []
        
        # Detect brand context from image or Phase 1 analysis
        brand_context = None
        brand_indicators = ["la madeleine", "madeleine"]
        for dish in phase1_analysis.dishes:
            for candidate in dish.usda_query_candidates:
                query_lower = candidate.query_term.lower()
                for brand in brand_indicators:
                    if brand in query_lower:
                        brand_context = "La Madeleine"
                        break
                if brand_context:
                    break

        logger.info(f"Starting enhanced tiered USDA search for {len(phase1_analysis.dishes)} dishes, brand_context: {brand_context}")

        # Execute tiered search for each unique query candidate
        processed_query_terms = set()
        
        for dish in phase1_analysis.dishes:
            for candidate in dish.usda_query_candidates:
                if candidate.query_term in processed_query_terms:
                    continue
                
                processed_query_terms.add(candidate.query_term)
                
                try:
                    # Use new tiered search strategy
                    tiered_results = await usda_service.execute_tiered_usda_search(
                        phase1_candidate=candidate,
                        brand_context=brand_context,
                        max_results_cap=15
                    )
                    
                    # Add results to global map for deduplication
                    for result in tiered_results:
                        if result.fdc_id not in all_usda_search_results_map:
                            all_usda_search_results_map[result.fdc_id] = result
                    
                    search_details_for_log.append({
                        "phase1_query_term": candidate.query_term,
                        "original_term": query_map.get(candidate.query_term, candidate.original_term),
                        "granularity": candidate.granularity_level,
                        "search_strategy": "tiered_search",
                        "results_count": len(tiered_results),
                        "status": "success" if tiered_results else "no_results"
                    })
                    
                    logger.info(f"Tiered search for '{candidate.query_term}': {len(tiered_results)} results")
                    
                except Exception as e:
                    logger.error(f"Tiered search failed for '{candidate.query_term}': {str(e)}")
                    search_details_for_log.append({
                        "phase1_query_term": candidate.query_term,
                        "original_term": query_map.get(candidate.query_term, candidate.original_term),
                        "granularity": candidate.granularity_level,
                        "search_strategy": "tiered_search",
                        "results_count": 0,
                        "status": "error",
                        "error_message": str(e)
                    })

        usda_search_duration = (time.time() - usda_search_start_time) * 1000
        logger.info(f"Enhanced tiered USDA searches completed in {usda_search_duration:.2f} ms. Total unique results: {len(all_usda_search_results_map)}")

        # Log comprehensive search summary
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.USDA_SEARCH_COMPLETE,
            message=f"Tiered USDA search completed: {len(search_details_for_log)} queries processed, {len(all_usda_search_results_map)} unique FDC IDs found",
            data={
                "total_queries": len(search_details_for_log),
                "unique_fdc_ids": len(all_usda_search_results_map),
                "brand_context": brand_context,
                "search_duration_ms": usda_search_duration,
                "search_details": search_details_for_log
            }
        )

        # 4. Format USDA results for Gemini prompt using enhanced results
        usda_candidates_prompt_segments = []
        
        # Create a mapping from query_term to results for Gemini prompt generation
        query_to_results_map = {}
        for dish in phase1_analysis.dishes:
            for candidate in dish.usda_query_candidates:
                query_to_results_map[candidate.query_term] = []
        
        # Populate the mapping with relevant results based on query similarity
        for fdc_id, result in all_usda_search_results_map.items():
            # Check which query this result best matches
            best_match_query = None
            best_match_score = 0
            
            for query_term in query_to_results_map.keys():
                # Simple keyword-based matching
                query_keywords = set(query_term.lower().replace(',', ' ').split())
                result_keywords = set(result.description.lower().replace(',', ' ').split())
                match_score = len(query_keywords.intersection(result_keywords))
                
                if match_score > best_match_score:
                    best_match_score = match_score
                    best_match_query = query_term
            
            # Add result to the best matching query (or first query if no good match)
            if best_match_query and best_match_score > 0:
                query_to_results_map[best_match_query].append(result)
            else:
                # Fallback: add to first query if no good match found
                first_query = next(iter(query_to_results_map.keys()), None)
                if first_query:
                    query_to_results_map[first_query].append(result)
        
        for dish in phase1_analysis.dishes:
            for candidate in dish.usda_query_candidates:
                phase1_query_term = candidate.query_term
                
                # Retrieve the results for this phase1_query_term
                results_for_this_query = query_to_results_map.get(phase1_query_term, [])
                
                prompt_segment_header = (
                    f"USDA candidates for Phase 1 query: '{phase1_query_term}' "
                    f"(Original term: '{query_map.get(phase1_query_term, candidate.original_term)}', "
                    f"Granularity: {candidate.granularity_level}, "
                    f"Reason from Phase 1: '{candidate.reason_for_query}'):\n"
                )
                
                segment_content = ""
                if not results_for_this_query:
                    segment_content = f"  No USDA candidates found for this query.\n"
                else:
                    for j, item in enumerate(results_for_this_query):                        
                        brand_part = f", Brand: {item.brand_owner}" if item.brand_owner else ""
                        score_part = f"{item.score:.2f}" if item.score is not None else "N/A"
                        tier_info = f" (Tier {getattr(item, 'search_tier', 'N/A')})" if hasattr(item, 'search_tier') else ""
                        
                        segment_content += (
                            f"  {j+1}. FDC ID: {item.fdc_id}, Name: {item.description} "
                            f"(Type: {item.data_type or 'N/A'}{brand_part}), "
                            f"Score: {score_part}{tier_info}\n"
                        )
                        if getattr(item, 'ingredients', None):
                            ingredients_preview = str(item.ingredients)[:100] if item.ingredients else ""
                            if ingredients_preview:
                                segment_content += f"     Ingredients (partial): {ingredients_preview}...\n"
                
                usda_candidates_prompt_segments.append(prompt_segment_header + segment_content)

        usda_candidates_prompt_text = "\n---\n".join(usda_candidates_prompt_segments)
        
        # 6. Call Gemini service (Phase 2) for strategy and FDC ID selection
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE2_START,
            message="Starting Phase 2 Gemini for strategy determination and FDC ID selection"
        )
        
        phase2_start_time = time.time()
        try:
            logger.info("Calling Gemini Phase 2 for strategy determination and FDC ID selection")
            # NEW: refine_analysis_phase2 ã‚’ä½¿ç”¨
            gemini_output_dict = await gemini_service.refine_analysis_phase2(
                image_bytes=image_bytes,
                image_mime_type=image.content_type,
                phase1_output_text=phase1_analysis_json,
                usda_results_text=usda_candidates_prompt_text
            )
            gemini_phase2_response = Phase2GeminiResponse(**gemini_output_dict)
            phase2_duration = (time.time() - phase2_start_time) * 1000
            
            # Phase 2çµæœã‚’è§£æã—ã¦ãƒ­ã‚°ã«è¨˜éŒ²
            strategy_decisions = {}
            fdc_selections = {}
            for dish in gemini_phase2_response.dishes:
                strategy_decisions[dish.dish_name] = {
                    "strategy": dish.calculation_strategy,
                    "reason": dish.reason_for_strategy
                }
                fdc_selections[dish.dish_name] = {
                    "dish_fdc_id": dish.fdc_id,
                    "dish_reason": dish.reason_for_choice,
                    "ingredients": [{
                        "name": ing.ingredient_name,
                        "fdc_id": ing.fdc_id,
                        "reason": ing.reason_for_choice
                    } for ing in dish.ingredients]
                }
            
            meal_logger.update_phase2_results(
                session_id=session_id,
                duration_ms=phase2_duration,
                strategy_decisions=strategy_decisions,
                fdc_selections=fdc_selections,
                phase2_output=gemini_output_dict
            )

        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE2_START,
                error_message="Gemini Phase 2 failed",
                error_details=str(e)
            )
            raise HTTPException(status_code=503, detail=f"Gemini Phase 2 error: {e}")

        # Check for skipped dishes - CRITICAL ERROR HANDLING
        phase1_dish_names = {dish.dish_name for dish in phase1_analysis.dishes}
        phase2_dish_names = {dish.dish_name for dish in gemini_phase2_response.dishes}
        skipped_dishes = phase1_dish_names - phase2_dish_names
        
        if skipped_dishes:
            error_message = f"Critical Error: Phase 2 skipped dishes that must be processed: {list(skipped_dishes)}"
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE2_START,
                error_message=error_message,
                error_details=f"Phase 1 identified {len(phase1_dish_names)} dishes, but Phase 2 only processed {len(phase2_dish_names)} dishes. Skipped: {skipped_dishes}"
            )
            raise HTTPException(
                status_code=422, 
                detail={
                    "error": "DISH_PROCESSING_INCOMPLETE",
                    "message": error_message,
                    "skipped_dishes": list(skipped_dishes),
                    "phase1_dishes": list(phase1_dish_names),
                    "phase2_dishes": list(phase2_dish_names),
                    "recommendation": "Image may contain dishes that cannot be analyzed with current USDA database. Please try with a different image or contact support."
                }
            )

        # Check for dishes with missing FDC IDs - ZERO TOLERANCE FOR UNPROCESSABLE DISHES
        unprocessable_dishes = []
        for dish in gemini_phase2_response.dishes:
            if dish.calculation_strategy == "dish_level":
                if not dish.fdc_id:
                    unprocessable_dishes.append({
                        "dish_name": dish.dish_name,
                        "strategy": dish.calculation_strategy,
                        "issue": "No FDC ID selected for dish-level calculation",
                        "reason": dish.reason_for_choice or "No reason provided"
                    })
            elif dish.calculation_strategy == "ingredient_level":
                # Check if all critical ingredients have FDC IDs
                ingredients_without_fdc = [
                    ing.ingredient_name for ing in dish.ingredients 
                    if not ing.fdc_id and ing.ingredient_name.lower() not in ["garnish", "seasoning", "salt", "pepper"]
                ]
                if len(ingredients_without_fdc) > len(dish.ingredients) * 0.5:  # More than 50% missing
                    unprocessable_dishes.append({
                        "dish_name": dish.dish_name,
                        "strategy": dish.calculation_strategy,
                        "issue": f"Too many ingredients without FDC IDs: {ingredients_without_fdc}",
                        "reason": "Insufficient USDA database coverage for ingredient-level calculation"
                    })

        if unprocessable_dishes:
            error_message = f"Critical Error: {len(unprocessable_dishes)} dishes cannot be processed due to missing USDA data"
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE2_START,
                error_message=error_message,
                error_details=f"Unprocessable dishes: {unprocessable_dishes}"
            )
            raise HTTPException(
                status_code=422,
                detail={
                    "error": "INSUFFICIENT_USDA_DATA",
                    "message": error_message,
                    "unprocessable_dishes": unprocessable_dishes,
                    "recommendation": "The meal contains dishes that cannot be accurately analyzed with the current USDA FoodData Central database. Please try with a simpler meal or contact support for assistance."
                }
            )

        # 7. Process Gemini output and perform Nutrition Calculation
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.NUTRITION_CALC_START,
            message="Starting nutrition calculation based on Phase 2 strategy"
        )
        
        nutrition_calc_start_time = time.time()
        refined_dishes_response: List[RefinedDishResponse] = []
        nutrition_service = get_nutrition_calculation_service()  # æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹

        for gemini_dish in gemini_phase2_response.dishes:
            # Phase 1 Dish ã‚’åå‰ã§æ¢ã™ (å³å¯†ã«ã¯IDãªã©ã§å¼•ãã¹ãã ãŒã€ä»Šå›ã¯åå‰ã§)
            p1_dish = next((d for d in phase1_analysis.dishes if d.dish_name == gemini_dish.dish_name), None)
            if not p1_dish:
                warnings.append(f"Could not match Phase 2 dish '{gemini_dish.dish_name}' to Phase 1.")
                continue

            # Phase1æ¨å¥¨æˆ¦ç•¥ã¨å®Ÿéš›ã®æˆ¦ç•¥ã®æ¯”è¼ƒã¯å»ƒæ­¢ï¼ˆPhase1ãŒstrategyæ¨å¥¨ã‚’ã—ãªããªã£ãŸãŸã‚ï¼‰
            # phase1_recommendation = p1_dish.calculation_strategy_recommendation  # å‰Šé™¤
            final_strategy = gemini_dish.calculation_strategy
            # strategy_changed = gemini_dish.strategy_changed_from_phase1 if hasattr(gemini_dish, 'strategy_changed_from_phase1') else (phase1_recommendation != final_strategy)  # å‰Šé™¤
            strategy_changed = False  # Phase1ã¯æˆ¦ç•¥æ¨å¥¨ã‚’ã—ãªã„ãŸã‚ã€å¸¸ã«Phase2ã§æ±ºå®š

            dish_total_nutrients = None
            refined_ingredients_list: List[RefinedIngredientResponse] = []
            dish_key_nutrients_100g = None
            weight_calculation_method = f"Phase2 image-based weight estimation (Strategy: {final_strategy}, Phase2 decision)"
            
            # Phase2ã§ã®é‡é‡æ¨å®šï¼šGeminiã‹ã‚‰ã®é‡é‡æ¨å®šã‚’å„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ 
            if gemini_dish.calculation_strategy == "dish_level" and gemini_dish.estimated_dish_weight_g:
                # Phase2 Geminiç”»åƒãƒ™ãƒ¼ã‚¹é‡é‡æ¨å®šã‚’ä½¿ç”¨
                actual_weight_used_g = gemini_dish.estimated_dish_weight_g
                weight_calculation_method = f"Phase2 Gemini visual estimation: {actual_weight_used_g}g (Strategy: {final_strategy}, Phase2 decision)"
            elif gemini_dish.calculation_strategy == "ingredient_level":
                # ingredient_levelã®å ´åˆã€å€‹åˆ¥ææ–™é‡é‡ã‚’ãƒã‚§ãƒƒã‚¯
                gemini_ingredient_weights = {
                    ing.ingredient_name: ing.estimated_weight_g 
                    for ing in gemini_dish.ingredients 
                    if hasattr(ing, 'estimated_weight_g') and ing.estimated_weight_g
                }
                
                if gemini_ingredient_weights:
                    actual_weight_used_g = sum(gemini_ingredient_weights.values())
                    weight_calculation_method = f"Phase2 Gemini ingredient weights: {actual_weight_used_g}g total (Strategy: {final_strategy}, Phase2 decision)"
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ—¢å­˜ã®æ¨å®šã‚·ã‚¹ãƒ†ãƒ 
                    actual_weight_used_g = 200.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡é‡
                    weight_calculation_method = f"Fallback default weight: {actual_weight_used_g}g (Strategy: {final_strategy}, Phase2 decision)"
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ—¢å­˜ã®æ¨å®šã‚·ã‚¹ãƒ†ãƒ 
                actual_weight_used_g = 200.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡é‡
                weight_calculation_method = f"Fallback default weight: {actual_weight_used_g}g (Strategy: {final_strategy}, Phase2 decision)"

            if gemini_dish.calculation_strategy == "dish_level":
                dish_fdc_id = gemini_dish.fdc_id
                
                if dish_fdc_id:
                    dish_key_nutrients_100g = await usda_service.get_food_details_for_nutrition(dish_fdc_id)
                    if dish_key_nutrients_100g and actual_weight_used_g > 0:
                        dish_total_nutrients = nutrition_service.calculate_actual_nutrients(dish_key_nutrients_100g, actual_weight_used_g)
                        
                        meal_logger.log_entry(
                            session_id=session_id,
                            level=LogLevel.INFO,
                            phase=ProcessingPhase.NUTRITION_CALC_START,
                            message=f"Dish-level nutrition calculated for '{gemini_dish.dish_name}': {actual_weight_used_g}g using FDC {dish_fdc_id}",
                            data={"dish_weight_g": actual_weight_used_g, "fdc_id": dish_fdc_id, "calculation_method": weight_calculation_method}
                        )
                    else:
                        warnings.append(f"Could not calculate dish-level nutrition for '{gemini_dish.dish_name}'. Switching to ingredient-level.")
                        gemini_dish.calculation_strategy = "ingredient_level"
                        weight_calculation_method = "Fallback to ingredient-level due to nutrition calculation failure"

                # Material information for dish_level (fallback FDC IDs for reference)
                if gemini_dish.calculation_strategy == "dish_level":
                    # Phase2ã§ã®å€‹åˆ¥ææ–™é‡é‡æ¨å®šï¼šGeminiã®é‡é‡ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’å„ªå…ˆ
                    ingredient_weights = {}
                    for gemini_ing in gemini_dish.ingredients:
                        if hasattr(gemini_ing, 'estimated_weight_g') and gemini_ing.estimated_weight_g:
                            # Geminiã‹ã‚‰ã®é‡é‡æ¨å®šã‚’ä½¿ç”¨
                            ingredient_weights[gemini_ing.ingredient_name] = gemini_ing.estimated_weight_g
                    
                    # Geminiã‹ã‚‰ã®é‡é‡ãŒãªã„ææ–™ã«ã¤ã„ã¦ã¯æ¨å®šã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
                    if len(ingredient_weights) < len(gemini_dish.ingredients):
                        fallback_weights = nutrition_service.estimate_ingredient_weights_from_dish(
                            total_dish_weight_g=actual_weight_used_g,
                            ingredients=p1_dish.ingredients
                        )
                        for gemini_ing in gemini_dish.ingredients:
                            if gemini_ing.ingredient_name not in ingredient_weights:
                                ingredient_weights[gemini_ing.ingredient_name] = fallback_weights.get(gemini_ing.ingredient_name, 0.0)
                    
                    for gemini_ing in gemini_dish.ingredients:
                        # Phase2ã§æ¨å®šã•ã‚ŒãŸé‡é‡ã‚’ä½¿ç”¨ï¼ˆGeminiå„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æ¨å®šã‚·ã‚¹ãƒ†ãƒ ï¼‰
                        estimated_weight = ingredient_weights.get(gemini_ing.ingredient_name, 0.0)
                        ing_nutrients_100g = await usda_service.get_food_details_for_nutrition(gemini_ing.fdc_id) if gemini_ing.fdc_id else None
                        refined_ingredients_list.append(RefinedIngredientResponse(
                            ingredient_name=gemini_ing.ingredient_name,
                            weight_g=estimated_weight,
                            fdc_id=gemini_ing.fdc_id,  # Fallback ID
                            usda_source_description=gemini_ing.usda_source_description,
                            reason_for_choice=gemini_ing.reason_for_choice,
                            key_nutrients_per_100g=ing_nutrients_100g,
                            actual_nutrients=None  # Not calculated here
                        ))

            # Handle ingredient_level (including fallback cases)
            if gemini_dish.calculation_strategy == "ingredient_level":
                ingredient_nutrients_list = []
                for gemini_ing in gemini_dish.ingredients:
                    # Phase2ã§æ¨å®šã•ã‚ŒãŸé‡é‡ã‚’ä½¿ç”¨ï¼šGeminiå„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æ¨å®šã‚·ã‚¹ãƒ†ãƒ 
                    if hasattr(gemini_ing, 'estimated_weight_g') and gemini_ing.estimated_weight_g:
                        # Geminiã‹ã‚‰ã®é‡é‡æ¨å®šã‚’ä½¿ç”¨
                        estimated_weight = gemini_ing.estimated_weight_g
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ¨å®šã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
                        ingredient_weights = nutrition_service.estimate_ingredient_weights_from_dish(
                            total_dish_weight_g=actual_weight_used_g,
                            ingredients=p1_dish.ingredients
                        )
                        estimated_weight = ingredient_weights.get(gemini_ing.ingredient_name, 0.0)
                    
                    ing_fdc_id = gemini_ing.fdc_id
                    ing_nutrients_100g = None
                    ing_actual_nutrients = None

                    # Enhanced ingredient-level fallback processing
                    if not ing_fdc_id and estimated_weight > 0:
                        # Try fallback searches for missing ingredients
                        fallback_attempted = False
                        
                        # Look for alternative query candidates from Phase 1 for this ingredient
                        for p1_dish_check in phase1_analysis.dishes:
                            if p1_dish_check.dish_name == gemini_dish.dish_name:
                                for candidate_query in p1_dish_check.usda_query_candidates:
                                    # Check if this query might be a broader alternative for the current ingredient
                                    if (candidate_query.granularity_level == "ingredient" and 
                                        gemini_ing.ingredient_name.lower() in candidate_query.query_term.lower()):
                                        
                                        # Try searching with the broader query term
                                        try:
                                            fallback_results = await usda_service.search_foods_rich(
                                                query=candidate_query.query_term,
                                                page_size=5,
                                                data_types=["Foundation", "SR Legacy", "Branded"],
                                                require_all_words=False  # More permissive for fallback
                                            )
                                            
                                            if fallback_results and len(fallback_results) > 0:
                                                # Use the first reasonable result as fallback
                                                fallback_fdc_id = fallback_results[0].fdc_id
                                                if fallback_fdc_id:
                                                    ing_fdc_id = fallback_fdc_id
                                                    gemini_ing.fdc_id = fallback_fdc_id
                                                    gemini_ing.reason_for_choice = f"Fallback search using broader query '{candidate_query.query_term}' after original search failed"
                                                    fallback_attempted = True
                                                    
                                                    meal_logger.log_entry(
                                                        session_id=session_id,
                                                        level=LogLevel.INFO,
                                                        phase=ProcessingPhase.NUTRITION_CALC_START,
                                                        message=f"Fallback successful for ingredient '{gemini_ing.ingredient_name}' using query '{candidate_query.query_term}'"
                                                    )
                                                    break
                                        except Exception as e:
                                            meal_logger.log_entry(
                                                session_id=session_id,
                                                level=LogLevel.WARNING,
                                                phase=ProcessingPhase.NUTRITION_CALC_START,
                                                message=f"Fallback search failed for ingredient '{gemini_ing.ingredient_name}': {str(e)}"
                                            )
                                            continue
                                            
                                if fallback_attempted and ing_fdc_id:
                                    break
                        
                        if not fallback_attempted or not ing_fdc_id:
                            warnings.append(f"Missing FDC ID for ingredient '{gemini_ing.ingredient_name}' - no suitable fallback found")

                    if ing_fdc_id and estimated_weight > 0:
                        ing_nutrients_100g = await usda_service.get_food_details_for_nutrition(ing_fdc_id)
                        if ing_nutrients_100g:
                            ing_actual_nutrients = nutrition_service.calculate_actual_nutrients(ing_nutrients_100g, estimated_weight)
                            ingredient_nutrients_list.append(ing_actual_nutrients)
                        else:
                            warnings.append(f"Could not get nutrition data for ingredient '{gemini_ing.ingredient_name}' (FDC ID: {ing_fdc_id})")
                    elif not ing_fdc_id:
                        warnings.append(f"Missing FDC ID for ingredient '{gemini_ing.ingredient_name}'")
                    elif estimated_weight <= 0:
                        warnings.append(f"Missing or invalid weight for ingredient '{gemini_ing.ingredient_name}'")

                    refined_ingredients_list.append(RefinedIngredientResponse(
                        ingredient_name=gemini_ing.ingredient_name,
                        weight_g=estimated_weight,
                        fdc_id=ing_fdc_id,
                        usda_source_description=gemini_ing.usda_source_description,
                        reason_for_choice=gemini_ing.reason_for_choice,
                        key_nutrients_per_100g=ing_nutrients_100g,
                        actual_nutrients=ing_actual_nutrients
                    ))
                
                # Aggregate nutrients from valid ingredients
                dish_total_nutrients = nutrition_service.aggregate_nutrients_for_dish_from_ingredients(
                    [ing for ing in refined_ingredients_list if ing.actual_nutrients]  # None ã‚’é™¤å¤–
                )

            # RefinedDishResponse ã‚’ä½œæˆ
            refined_dishes_response.append(RefinedDishResponse(
                dish_name=gemini_dish.dish_name,
                type=p1_dish.type,
                quantity_on_plate=p1_dish.quantity_on_plate,
                estimated_total_dish_weight_g=None,  # Phase1ã«é‡é‡æ¨å®šãªã—
                actual_weight_used_for_calculation_g=actual_weight_used_g,
                weight_calculation_method=weight_calculation_method,
                calculation_strategy=gemini_dish.calculation_strategy,
                reason_for_strategy=gemini_dish.reason_for_strategy,
                fdc_id=gemini_dish.fdc_id,
                usda_source_description=gemini_dish.usda_source_description,
                reason_for_choice=gemini_dish.reason_for_choice,
                key_nutrients_per_100g=dish_key_nutrients_100g,
                ingredients=refined_ingredients_list,
                dish_total_actual_nutrients=dish_total_nutrients
            ))

        # 8. Calculate total meal nutrients
        total_meal_nutrients = nutrition_service.aggregate_nutrients_for_meal(
            refined_dishes_response
        )
        
        nutrition_calc_duration = (time.time() - nutrition_calc_start_time) * 1000
        total_calories = total_meal_nutrients.calories_kcal if total_meal_nutrients else 0.0
        
        # æ „é¤Šè¨ˆç®—çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        meal_logger.update_nutrition_results(
            session_id=session_id,
            duration_ms=nutrition_calc_duration,
            total_calories=total_calories,
            final_nutrition={
                "total_meal_nutrients": total_meal_nutrients.dict() if total_meal_nutrients else None,
                "dishes_count": len(refined_dishes_response),
                "warnings_count": len(warnings),
                "errors_count": len(errors)
            }
        )

        # 9. Create final response
        response = MealAnalysisRefinementResponse(
            dishes=refined_dishes_response,
            total_meal_nutrients=total_meal_nutrients,
            warnings=warnings if warnings else None,
            errors=errors if errors else None
        )
        
        # 8. Enhanced Iterative Improvement Loop with Cooking State Validation
        MAX_RETRY_ATTEMPTS = 1  # Maximum retry attempts per problematic ingredient
        retry_summary = []
        needs_recalculation = False
        
        # Function to check cooking state mismatch
        def has_cooking_state_mismatch(ingredient_name: str, usda_description: str, phase1_state: str) -> bool:
            """Check if there's a cooking state mismatch between Phase1 and selected FDC ID"""
            if not usda_description or not phase1_state:
                return False
            
            usda_lower = usda_description.lower()
            state_lower = phase1_state.lower()
            
            # Define cooking state indicators
            cooked_indicators = ["cooked", "prepared", "grilled", "fried", "baked", "boiled", "steamed", "roasted"]
            raw_indicators = ["raw", "fresh", "uncooked"]
            dry_indicators = ["dry", "dried", "dehydrated", "uncooked"]
            
            # Check for mismatches
            if state_lower == "cooked":
                # Phase1 says cooked, but USDA suggests dry/raw
                if any(indicator in usda_lower for indicator in dry_indicators + raw_indicators):
                    return True
            elif state_lower == "raw":
                # Phase1 says raw, but USDA suggests cooked
                if any(indicator in usda_lower for indicator in cooked_indicators):
                    return True
            elif state_lower == "dry":
                # Phase1 says dry, but USDA suggests cooked
                if any(indicator in usda_lower for indicator in cooked_indicators):
                    return True
            
            return False
        
        for dish_idx, dish_response in enumerate(response.dishes):
            for ing_idx, ingredient_response in enumerate(dish_response.ingredients):
                # Find corresponding Phase1 ingredient for state comparison
                p1_ingredient_state = None
                for p1_dish in phase1_analysis.dishes:
                    if p1_dish.dish_name == dish_response.dish_name:
                        for p1_ing in p1_dish.ingredients:
                            if p1_ing.ingredient_name == ingredient_response.ingredient_name:
                                p1_ingredient_state = p1_ing.state
                                break
                    if p1_ingredient_state:
                        break
                
                # Identify problematic ingredients
                is_problematic = False
                problem_reason = ""
                
                # Case 1: Missing FDC ID
                if ingredient_response.fdc_id is None and ingredient_response.weight_g > 0:
                    is_problematic = True
                    problem_reason = "Missing FDC ID"
                
                # Case 2: Cooking state mismatch
                elif (ingredient_response.fdc_id and 
                      ingredient_response.usda_source_description and 
                      p1_ingredient_state and
                      has_cooking_state_mismatch(ingredient_response.ingredient_name, 
                                               ingredient_response.usda_source_description, 
                                               p1_ingredient_state)):
                    is_problematic = True
                    problem_reason = f"Cooking state mismatch: Phase1='{p1_ingredient_state}' vs USDA='{ingredient_response.usda_source_description}'"
                
                if is_problematic and ingredient_response.weight_g > 0:  # Only retry significant ingredients
                    meal_logger.log_entry(
                        session_id=session_id,
                        level=LogLevel.WARNING,
                        phase=ProcessingPhase.NUTRITION_CALC_START,
                        message=f"Problematic ingredient detected: {ingredient_response.ingredient_name} - {problem_reason}"
                    )
                    
                    for attempt in range(MAX_RETRY_ATTEMPTS):
                        meal_logger.log_entry(
                            session_id=session_id, 
                            level=LogLevel.INFO, 
                            phase=ProcessingPhase.PHASE1_START,
                            message=f"Retry attempt {attempt + 1} for problematic ingredient: {ingredient_response.ingredient_name} in dish {dish_response.dish_name}",
                            data={
                                "problematic_ingredient": ingredient_response.ingredient_name,
                                "dish_name": dish_response.dish_name,
                                "weight_g": ingredient_response.weight_g,
                                "problem_reason": problem_reason,
                                "attempt_number": attempt + 1
                            }
                        )
                        
                        try:
                            # Collect relevant USDA candidates from all_usda_search_results_map
                            relevant_candidates = []
                            
                            # Look for alternatives that better match the cooking state
                            for fdc_id_key, usda_item in all_usda_search_results_map.items():
                                if ingredient_response.ingredient_name.lower() in usda_item.description.lower():
                                    # Prioritize candidates that match cooking state
                                    if p1_ingredient_state:
                                        state_match = False
                                        if p1_ingredient_state.lower() == "cooked":
                                            state_match = any(term in usda_item.description.lower() 
                                                            for term in ["cooked", "prepared", "grilled", "fried", "baked", "boiled", "steamed"])
                                        elif p1_ingredient_state.lower() == "raw":
                                            state_match = any(term in usda_item.description.lower() 
                                                            for term in ["raw", "fresh", "uncooked"])
                                        elif p1_ingredient_state.lower() == "dry":
                                            state_match = any(term in usda_item.description.lower() 
                                                            for term in ["dry", "dried", "dehydrated"])
                                        
                                        if state_match:
                                            relevant_candidates.append((usda_item, "cooking_state_match"))
                                    
                                    relevant_candidates.append((usda_item, "name_match"))
                            
                            # Sort candidates: cooking state matches first, then by score
                            relevant_candidates.sort(key=lambda x: (0 if x[1] == "cooking_state_match" else 1, -(x[0].score or 0)))
                            
                            # Try top candidates
                            selected_fallback = None
                            best_fallback_reason = "No suitable fallback found after retry."
                            
                            for candidate_item, match_type in relevant_candidates[:3]:  # Try top 3
                                # Additional validation for cooking state
                                if p1_ingredient_state and match_type == "cooking_state_match":
                                    selected_fallback = candidate_item
                                    best_fallback_reason = f"Enhanced retry: Selected '{candidate_item.description}' for better cooking state match (Phase1: {p1_ingredient_state})"
                                    break
                                elif not selected_fallback and match_type == "name_match":
                                    # Fallback to name match if no cooking state match
                                    selected_fallback = candidate_item
                                    best_fallback_reason = f"Enhanced retry: Selected '{candidate_item.description}' as best available match"
                            
                            if selected_fallback:
                                # Update the ingredient with better FDC ID
                                old_fdc_id = ingredient_response.fdc_id
                                response.dishes[dish_idx].ingredients[ing_idx].fdc_id = selected_fallback.fdc_id
                                response.dishes[dish_idx].ingredients[ing_idx].usda_source_description = selected_fallback.description
                                response.dishes[dish_idx].ingredients[ing_idx].reason_for_choice = best_fallback_reason
                                
                                # Get new nutrition data
                                new_nutrition_100g = await usda_service.get_food_details_for_nutrition(selected_fallback.fdc_id)
                                if new_nutrition_100g:
                                    response.dishes[dish_idx].ingredients[ing_idx].key_nutrients_per_100g = new_nutrition_100g
                                    response.dishes[dish_idx].ingredients[ing_idx].actual_nutrients = nutrition_service.calculate_actual_nutrients(new_nutrition_100g, ingredient_response.weight_g)
                                    needs_recalculation = True
                                
                                retry_summary.append({
                                    "ingredient": ingredient_response.ingredient_name,
                                    "status": "success",
                                    "old_fdc_id": old_fdc_id,
                                    "new_fdc_id": selected_fallback.fdc_id,
                                    "problem_reason": problem_reason,
                                    "solution": best_fallback_reason
                                })
                                
                                meal_logger.log_entry(
                                    session_id=session_id,
                                    level=LogLevel.INFO,
                                    phase=ProcessingPhase.NUTRITION_CALC_START,
                                    message=f"Enhanced retry successful for {ingredient_response.ingredient_name}: {old_fdc_id} -> {selected_fallback.fdc_id}"
                                )
                                
                                break  # Success, exit retry loop for this ingredient
                            else:
                                retry_summary.append({
                                    "ingredient": ingredient_response.ingredient_name,
                                    "status": "failed - no suitable candidate",
                                    "problem_reason": problem_reason
                                })
                                
                        except Exception as retry_e:
                            meal_logger.log_entry(
                                session_id=session_id,
                                level=LogLevel.ERROR,
                                phase=ProcessingPhase.NUTRITION_CALC_START,
                                message=f"Error during enhanced retry for {ingredient_response.ingredient_name}: {retry_e}"
                            )
                            retry_summary.append({
                                "ingredient": ingredient_response.ingredient_name,
                                "status": "error",
                                "details": str(retry_e),
                                "problem_reason": problem_reason
                            })
                            break
                    
                    # Log final outcome for this ingredient
                    if not any(r["ingredient"] == ingredient_response.ingredient_name and r["status"] == "success" for r in retry_summary):
                        meal_logger.log_entry(
                            session_id=session_id,
                            level=LogLevel.WARNING,
                            phase=ProcessingPhase.NUTRITION_CALC_START,
                            message=f"All retry attempts failed for {ingredient_response.ingredient_name} - {problem_reason}"
                        )
        
        # Recalculate dish and meal totals if any ingredients were updated
        if needs_recalculation:
            meal_logger.log_entry(
                session_id=session_id,
                level=LogLevel.INFO,
                phase=ProcessingPhase.NUTRITION_CALC_START,
                message="Recalculating nutrition after enhanced iterative improvements..."
            )
            
            for dish_response in response.dishes:
                if dish_response.calculation_strategy == "ingredient_level":
                    # Recalculate dish total from updated ingredients
                    valid_ingredients = [ing for ing in dish_response.ingredients if ing.actual_nutrients]
                    dish_response.dish_total_actual_nutrients = nutrition_service.aggregate_nutrients_for_dish_from_ingredients(valid_ingredients)
            
            # Recalculate meal total
            response.total_meal_nutrients = nutrition_service.aggregate_nutrients_for_meal(response.dishes)
        
        # Log retry summary
        if retry_summary:
            meal_logger.log_entry(
                session_id=session_id,
                level=LogLevel.INFO,
                phase=ProcessingPhase.NUTRITION_CALC_START,
                message=f"Enhanced iterative improvement completed: {len(retry_summary)} ingredients processed",
                data={"retry_summary": retry_summary}
            )

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
        meal_logger.end_session(
            session_id=session_id,
            warnings=warnings,
            errors=errors
        )
        
        return response

    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
        meal_logger.log_error(
            session_id=session_id,
            phase=ProcessingPhase.ERROR_OCCURRED,
            error_message="Unexpected error during request processing",
            error_details=str(e)
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        meal_logger.end_session(
            session_id=session_id,
            warnings=warnings,
            errors=errors + [str(e)]
        )
        
        raise 
```

============================================================

ğŸ“ ã‚µãƒ¼ãƒ“ã‚¹å±¤ (v2.1å¯¾å¿œ)
============================================================

ğŸ“„ FILE: app/services/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/services/gemini_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 12578 bytes
æœ€çµ‚æ›´æ–°: 2025-06-02 12:05:56
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig, HarmCategory, HarmBlockThreshold
from typing import Dict, Optional
import json
import logging
from PIL import Image
import io

# æ–°ã—ã„ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..api.v1.schemas.meal import PHASE_1_GEMINI_SCHEMA, PHASE_2_GEMINI_SCHEMA, MEAL_ANALYSIS_GEMINI_SCHEMA, REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA
from ..prompts import PromptLoader

logger = logging.getLogger(__name__)

# Geminiã®æ§‹é€ åŒ–å‡ºåŠ›ã®ãŸã‚ã®JSONã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©
MEAL_ANALYSIS_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆã€‚",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°ã€‚"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—, ãƒ‡ã‚¶ãƒ¼ãƒˆï¼‰ã€‚"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°ï¼ˆä¾‹: '1æ¯', '2åˆ‡ã‚Œ', 'ç´„200g'ï¼‰ã€‚"},
                    "ingredients": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ã¨æ¨å®šã•ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§°ã€‚"},
                                "weight_g": {"type": "number", "description": "ãã®ææ–™ã®æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰ã€‚"}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients"]
            }
        }
    },
    "required": ["dishes"]
}


class GeminiMealAnalyzer:
    """Vertex AIçµŒç”±ã§Geminiã‚’ä½¿ç”¨ã—ã¦é£Ÿäº‹ç”»åƒã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹ (v2.1å¯¾å¿œ)"""
    
    def __init__(self, project_id: str, location: str, model_name: str = "gemini-2.5-flash-preview-05-20"):
        """
        åˆæœŸåŒ–
        
        Args:
            project_id: GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
            location: Vertex AIã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¾‹: us-central1ï¼‰
            model_name: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        """
        # Vertex AIã®åˆæœŸåŒ–
        vertexai.init(project=project_id, location=location)
        
        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.model = GenerativeModel(model_name=model_name)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–ï¼ˆå¿…é ˆï¼‰
        self.prompt_loader = PromptLoader()
        
        # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®š
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        }

    async def analyze_image_phase1(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        optional_text: Optional[str] = None
    ) -> Dict:
        """
        Phase 1: ç”»åƒã‚’åˆ†æã—ã€æ–™ç†ãƒ»é£Ÿæã¨USDAã‚¯ã‚¨ãƒªå€™è£œã‚’æŠ½å‡º (v2.1ä»•æ§˜)
        """
        try:
            system_prompt = self.prompt_loader.get_phase1_system_prompt()
            user_prompt = self.prompt_loader.get_phase1_user_prompt(optional_text)
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            contents = [Part.from_text(full_prompt), Part.from_data(data=image_bytes, mime_type=image_mime_type)]

            generation_config = GenerationConfig(
                temperature=0.3, # å€™è£œã‚’åºƒã’ã‚‹ãŸã‚ã«å°‘ã—ä¸Šã’ã‚‹ã“ã¨ã‚‚æ¤œè¨
                top_p=0.9,
                top_k=20,
                max_output_tokens=16384, # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å¢—ã‚„ã™
                response_mime_type="application/json",
                # NEW: Phase 1 ç”¨ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
                response_schema=PHASE_1_GEMINI_SCHEMA
            )

            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )

            if not response.text:
                raise ValueError("No response returned from Gemini (Phase 1).")

            result = json.loads(response.text)
            logger.info(f"Gemini Phase 1 analysis completed. Found {len(result.get('dishes', []))} dishes.")
            return result

        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error (Phase 1): {e}")
            raise RuntimeError(f"Vertex AI/Gemini (Phase 1) API request failed: {e}") from e

    async def refine_analysis_phase2(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        phase1_output_text: str, # Phase 1 ã®ç”Ÿ JSON å‡ºåŠ›
        usda_results_text: str # æ•´å½¢ã•ã‚ŒãŸå…¨ USDA æ¤œç´¢çµæœ
    ) -> Dict:
        """
        Phase 2: USDAå€™è£œã«åŸºã¥ãã€calculation_strategy ã‚’æ±ºå®šã—ã€FDC ID ã‚’é¸æŠ (v2.1ä»•æ§˜)
        """
        try:
            system_prompt = self.prompt_loader.get_phase2_system_prompt()
            user_prompt = self.prompt_loader.get_phase2_user_prompt(
                initial_ai_output=phase1_output_text,
                usda_candidates=usda_results_text
            )
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            contents = [Part.from_text(full_prompt), Part.from_data(data=image_bytes, mime_type=image_mime_type)]

            generation_config = GenerationConfig(
                temperature=0.1, # æ±ºå®šè«–çš„ãªå‡ºåŠ›ã‚’ç›®æŒ‡ã™ãŸã‚ä½ã‚ã«è¨­å®š
                top_p=0.8,
                top_k=10,
                max_output_tokens=16384, # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å¢—ã‚„ã™
                response_mime_type="application/json",
                # NEW: Phase 2 ç”¨ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
                response_schema=PHASE_2_GEMINI_SCHEMA
            )

            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )

            if not response.text:
                raise ValueError("No response returned from Gemini (Phase 2).")

            result = json.loads(response.text)
            logger.info(f"Gemini Phase 2 analysis completed. Processed {len(result.get('dishes', []))} dishes.")
            return result

        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error (Phase 2): {e}")
            raise RuntimeError(f"Vertex AI/Gemini (Phase 2) API request failed: {e}") from e

    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚ä¿æŒ
    async def analyze_image_and_text(
        self, 
        image_bytes: bytes, 
        image_mime_type: str, 
        optional_text: Optional[str] = None
    ) -> Dict:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆæ—¢å­˜ã®Phase 1ã¨ã—ã¦å‹•ä½œï¼‰
        """
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            system_prompt = self.prompt_loader.get_phase1_system_prompt()
            user_prompt = self.prompt_loader.get_phase1_user_prompt(optional_text)
            
            # å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—¢å­˜ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
            generation_config = GenerationConfig(
                temperature=0.2,
                top_p=0.9,
                top_k=20,
                max_output_tokens=8192,
                response_mime_type="application/json",
                response_schema=MEAL_ANALYSIS_GEMINI_SCHEMA
            )
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆéåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼‰
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if not response.text:
                raise ValueError("No response returned from Gemini.")
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)
            
            logger.info(f"Gemini analysis completed successfully. Found {len(result.get('dishes', []))} dishes.")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error: {e}")
            raise RuntimeError(f"Error processing response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error: {e}")
            raise RuntimeError(f"Vertex AI/Gemini API request failed: {e}") from e
    
    async def analyze_image_with_usda_context(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        usda_candidates_text: str,
        initial_ai_output_text: Optional[str] = None
    ) -> Dict:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆæ—¢å­˜ã®Phase 2ã¨ã—ã¦å‹•ä½œï¼‰
        """
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            system_prompt = self.prompt_loader.get_phase2_system_prompt()
            user_prompt = self.prompt_loader.get_phase2_user_prompt(
                initial_ai_output=initial_ai_output_text or "{}",
                usda_candidates=usda_candidates_text
            )
            
            # å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            # ãƒ•ã‚§ãƒ¼ã‚º2ç”¨ã®Generation Config
            phase2_generation_config = GenerationConfig(
                temperature=0.2,
                top_p=0.9,
                top_k=20,
                max_output_tokens=8192,
                response_mime_type="application/json",
                response_schema=REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA
            )
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=phase2_generation_config,
                safety_settings=self.safety_settings
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if not response.text:
                raise ValueError("No response returned from Gemini Phase 2.")
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)
            
            logger.info(f"Gemini Phase 2 refinement completed successfully. Processed {len(result.get('dishes', []))} dishes.")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error in Phase 2: {e}")
            raise RuntimeError(f"Error processing Phase 2 response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error in Phase 2: {e}")
            raise RuntimeError(f"Vertex AI/Gemini Phase 2 API request failed: {e}") from e


def get_gemini_analyzer(project_id: str, location: str, model_name: str) -> GeminiMealAnalyzer:
    """GeminiMealAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦è¿”ã™"""
    return GeminiMealAnalyzer(project_id=project_id, location=location, model_name=model_name) 
```

============================================================

ğŸ“„ FILE: app/services/usda_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 36339 bytes
æœ€çµ‚æ›´æ–°: 2025-06-02 12:17:22
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
# app/services/usda_service.py
import httpx
import json
import logging
import asyncio
import time
from typing import List, Optional, Dict, Any
from functools import lru_cache

from ..core.config import get_settings
from ..api.v1.schemas.meal import USDANutrient, USDASearchResultItem

logger = logging.getLogger(__name__)


class USDAService:
    """USDA FoodData Central APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        settings = get_settings()
        self.api_key = settings.USDA_API_KEY
        self.base_url = settings.USDA_API_BASE_URL
        self.timeout = settings.USDA_API_TIMEOUT
        self.max_retries = settings.USDA_API_MAX_RETRIES
        self.retry_delay = settings.USDA_API_RETRY_DELAY
        self.retry_backoff = settings.USDA_API_RETRY_BACKOFF
        self.key_nutrient_numbers = settings.USDA_KEY_NUTRIENT_NUMBERS
        
        if not self.api_key:
            logger.error("USDA_API_KEY is not configured.")
            raise ValueError("USDA API key not configured.")
        
        # httpx.AsyncClientã®è¨­å®š
        self.client = httpx.AsyncClient(
            timeout=self.timeout,
            headers={"X-Api-Key": self.api_key}
        )
    
    async def _make_request_with_retry(
        self, 
        method: str, 
        url: str, 
        params: Optional[Dict[str, Any]] = None,
        context: str = "API request"
    ) -> Optional[httpx.Response]:
        """
        ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ä»˜ãHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        
        Args:
            method: HTTPãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆ'GET', 'POST'ãªã©ï¼‰
            url: ãƒªã‚¯ã‚¨ã‚¹ãƒˆURL
            params: ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            context: ãƒ­ã‚°ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            
        Returns:
            httpx.Response or Noneï¼ˆå…¨ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆï¼‰
        """
        last_exception = None
        
        for attempt in range(self.max_retries + 1):  # åˆå› + ãƒªãƒˆãƒ©ã‚¤å›æ•°
            try:
                if attempt > 0:
                    # ãƒªãƒˆãƒ©ã‚¤ã®å ´åˆã¯å¾…æ©Ÿ
                    delay = self.retry_delay * (self.retry_backoff ** (attempt - 1))
                    logger.info(f"Retrying {context} (attempt {attempt + 1}/{self.max_retries + 1}) after {delay:.1f}s delay...")
                    await asyncio.sleep(delay)
                
                logger.debug(f"Making {method} request to {url} (attempt {attempt + 1}/{self.max_retries + 1})")
                start_time = time.time()
                
                response = await self.client.request(method, url, params=params)
                
                end_time = time.time()
                duration_ms = (end_time - start_time) * 1000
                
                if "X-RateLimit-Remaining" in response.headers:
                    logger.debug(f"USDA API Rate Limit Remaining: {response.headers.get('X-RateLimit-Remaining')}")
                
                response.raise_for_status()
                
                if attempt > 0:
                    logger.info(f"{context} succeeded on attempt {attempt + 1} after {duration_ms:.1f}ms")
                else:
                    logger.debug(f"{context} succeeded on first attempt in {duration_ms:.1f}ms")
                
                return response
                
            except httpx.TimeoutException as e:
                last_exception = e
                logger.warning(f"{context} timed out on attempt {attempt + 1}/{self.max_retries + 1}: {str(e)}")
                if attempt == self.max_retries:
                    logger.error(f"{context} failed after {self.max_retries + 1} attempts due to timeout")
                    break
                    
            except httpx.HTTPStatusError as e:
                # 404ã‚„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ï¼ˆ4xxï¼‰ã¯ãƒªãƒˆãƒ©ã‚¤ã—ãªã„
                if 400 <= e.response.status_code < 500:
                    logger.warning(f"{context} failed with client error {e.response.status_code}, not retrying")
                    last_exception = e
                    break
                # ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ï¼ˆ5xxï¼‰ã¯ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹
                elif e.response.status_code >= 500:
                    last_exception = e
                    logger.warning(f"{context} failed with server error {e.response.status_code} on attempt {attempt + 1}/{self.max_retries + 1}")
                    if attempt == self.max_retries:
                        logger.error(f"{context} failed after {self.max_retries + 1} attempts due to server errors")
                        break
                else:
                    # ãã®ä»–ã®HTTPã‚¨ãƒ©ãƒ¼
                    logger.error(f"{context} failed with HTTP error {e.response.status_code}: {e.response.text}")
                    last_exception = e
                    break
                    
            except Exception as e:
                last_exception = e
                logger.warning(f"{context} failed with exception on attempt {attempt + 1}/{self.max_retries + 1}: {str(e)}")
                if attempt == self.max_retries:
                    logger.error(f"{context} failed after {self.max_retries + 1} attempts due to: {str(e)}")
                    break
        
        # ã™ã¹ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆ
        logger.error(f"{context} ultimately failed after {self.max_retries + 1} attempts. Last error: {last_exception}")
        return None
    
    async def search_foods_rich(
        self,
        query: str,
        data_types: Optional[List[str]] = None,
        page_size: int = 10,
        page_number: int = 1,
        sort_by: str = "score",
        sort_order: str = "desc",
        require_all_words: bool = False,
        brand_owner_filter: Optional[str] = None,
        search_context: Optional[str] = None
    ) -> List[USDASearchResultItem]:
        """
        Enhanced USDA FoodData Central API food search with tiered search capabilities
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            data_types: æ¤œç´¢å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹ï¼š["Branded", "SR Legacy"]ï¼‰
            page_size: çµæœã®æœ€å¤§ä»¶æ•°
            page_number: ãƒšãƒ¼ã‚¸ç•ªå·  
            sort_by: ã‚½ãƒ¼ãƒˆåŸºæº–
            sort_order: ã‚½ãƒ¼ãƒˆé †åº
            require_all_words: å…¨ã¦ã®å˜èªã‚’å¿…é ˆã¨ã™ã‚‹ã‹
            brand_owner_filter: ãƒ–ãƒ©ãƒ³ãƒ‰ã‚ªãƒ¼ãƒŠãƒ¼ãƒ•ã‚£ãƒ«ã‚¿
            search_context: æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ"branded", "ingredient", "dish"ï¼‰
            
        Returns:
            List[USDASearchResultItem]: æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        """
        if not query.strip():
            return []

        try:
            # Build query parameters
            params = {
                "query": query,
                "pageSize": min(page_size, 200),  # API limit
                "pageNumber": page_number,
                "sortBy": sort_by,
                "sortOrder": sort_order,
                "requireAllWords": require_all_words
            }

            # Add data types if specified
            if data_types:
                # Convert list to comma-separated string as expected by USDA API
                params["dataType"] = ",".join(data_types)
            
            # Add brand owner filter if specified
            if brand_owner_filter:
                params["brandOwner"] = brand_owner_filter

            # Log the search attempt
            logger.info(f"USDA API search: query='{query}', data_types={data_types}, "
                       f"require_all_words={require_all_words}, brand_owner='{brand_owner_filter}', "
                       f"context='{search_context}'")

            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(
                    f"{self.base_url}/foods/search",
                    params=params,
                    headers={"X-Api-Key": self.api_key}
                )
                response.raise_for_status()
                
                data = response.json()
                foods = data.get("foods", [])
                
                # Process and enhance results
                results = []
                for food_item in foods:
                    result = USDASearchResultItem(
                        fdc_id=food_item.get("fdcId"),
                        description=food_item.get("description", ""),
                        data_type=food_item.get("dataType"),
                        publication_date=food_item.get("publishedDate"),
                        brand_owner=food_item.get("brandOwner"),
                        brand_name=food_item.get("brandName"),
                        subbrand_name=food_item.get("subbrandName"),
                        gtin_upc=food_item.get("gtinUpc"),
                        ndb_number=food_item.get("ndbNumber"),
                        food_code=food_item.get("foodCode"),
                        score=food_item.get("score", 0.0),
                        ingredients=food_item.get("ingredients")
                    )
                    
                    # Add search metadata for tracking
                    result.search_context = search_context
                    result.require_all_words_used = require_all_words
                    result.data_types_searched = data_types
                    
                    results.append(result)

                logger.info(f"USDA API response: {len(results)} results returned "
                           f"(query: '{query}', context: '{search_context}')")
                return results

        except httpx.HTTPStatusError as e:
            logger.error(f"USDA API HTTP error for query '{query}': {e.response.status_code} - {e.response.text}")
            return []
        except httpx.RequestError as e:
            logger.error(f"USDA API request error for query '{query}': {str(e)}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error in USDA search for query '{query}': {str(e)}")
            return []
    
    def _extract_key_nutrients(self, food_nutrients: List[Dict[str, Any]]) -> List[USDANutrient]:
        """
        foodNutrientsãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸»è¦æ „é¤Šç´ ã‚’æŠ½å‡º (æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ä½¿ç”¨)
        """
        # ä¸»è¦æ „é¤Šç´  (configã‹ã‚‰å–å¾—) ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹
        nutrients_extracted = []
        key_numbers = self.key_nutrient_numbers # Settings ã‹ã‚‰å–å¾—

        for nutrient_entry in food_nutrients:
            nutrient_detail = nutrient_entry.get("nutrient", {})
            amount = nutrient_entry.get("amount")

            if not nutrient_detail and "nutrientId" in nutrient_entry: # Branded abridged
                number = nutrient_entry.get("nutrientNumber")
                name = nutrient_entry.get("nutrientName")
                unit_name = nutrient_entry.get("unitName")
                amount = nutrient_entry.get("value")
                nutrient_id = nutrient_entry.get("nutrientId")
            else: # Standard
                number = nutrient_detail.get("number")
                name = nutrient_detail.get("name")
                unit_name = nutrient_detail.get("unitName")
                nutrient_id = nutrient_detail.get("id")

            if number and str(number) in key_numbers:
                if name and amount is not None and unit_name:
                    nutrients_extracted.append(USDANutrient(
                        name=name,
                        amount=float(amount),
                        unit_name=unit_name,
                        nutrient_id=int(nutrient_id) if nutrient_id else None,
                        nutrient_number=str(number) if number else None
                    ))
        return nutrients_extracted

    async def get_food_details(self, fdc_id: int) -> Optional[USDASearchResultItem]:
        """
        ç‰¹å®šã®FDC IDã®é£Ÿå“è©³ç´°æƒ…å ±ã‚’å–å¾— (æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ä½¿ç”¨)
        """
        params = {
            "api_key": self.api_key,
            "format": "full"  # ingredients ã‚‚ç¢ºå®Ÿã«å–å¾—ã™ã‚‹ãŸã‚ã« format="full" ã‚’ä½¿ç”¨
        }
        
        try:
            logger.info(f"Getting USDA food details for FDC ID: {fdc_id}")
            response = await self._make_request_with_retry(
                method="GET",
                url=f"{self.base_url}/food/{fdc_id}",
                params=params,
                context="Getting USDA food details"
            )
            
            if response:
                food_data = response.json()
                
                # _extract_key_nutrients ã‚’ä½¿ç”¨ã—ã¦æ „é¤Šç´ ã‚’ãƒ‘ãƒ¼ã‚¹
                nutrients_extracted = self._extract_key_nutrients(food_data.get("foodNutrients", []))
                
                return USDASearchResultItem(
                    fdc_id=food_data.get("fdcId"),
                    description=food_data.get("description"),
                    data_type=food_data.get("dataType"),
                    brand_owner=food_data.get("brandOwner"),
                    ingredients_text=food_data.get("ingredients"),
                    food_nutrients=nutrients_extracted,
                    score=None  # è©³ç´°å–å¾—æ™‚ã¯ã‚¹ã‚³ã‚¢ãªã—
                )
            
        except Exception as e:
            logger.error(f"Error getting food details for FDC ID {fdc_id}: {str(e)}")
            raise RuntimeError(f"Error getting food details: {str(e)}") from e

    async def get_food_details_for_nutrition(self, fdc_id: int) -> Optional[Dict[str, float]]:
        """
        æ „é¤Šè¨ˆç®—ç”¨ã®é£Ÿå“è©³ç´°æƒ…å ±ã‚’å–å¾— (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒãƒ»ç¢ºèª)
        """
        params = {
            "api_key": self.api_key,
            "format": "full"
            # Remove nutrient filter to get all nutrients including 957, 958
            # "nutrients": ",".join(self.key_nutrient_numbers)
        }
        
        try:
            logger.debug(f"Getting nutrition data for FDC ID: {fdc_id}")
            response = await self._make_request_with_retry(
                method="GET",
                url=f"{self.base_url}/food/{fdc_id}",
                params=params,
                context="Getting nutrition data"
            )
            
            if response:
                food_data = response.json()
                
                return self._parse_nutrients_for_calculation(food_data)
            
        except Exception as e:
            logger.error(f"Error getting nutrition data for FDC ID {fdc_id}: {str(e)}")
            return None

    def _parse_nutrients_for_calculation(self, food_data_raw: dict) -> Dict[str, float]:
        """
        USDA APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ „é¤Šè¨ˆç®—ç”¨ã®æ „é¤Šç´ è¾æ›¸ã‚’ä½œæˆ
        """
        nutrients_dict = {}
        food_nutrients = food_data_raw.get("foodNutrients", [])
        
        # æ „é¤Šç´ ç•ªå·ã¨æ¨™æº–åã®å¯¾å¿œè¡¨
        nutrient_map = {
            "208": "calories_kcal",      # Energy (older format)
            "957": "calories_kcal",      # Energy (Atwater General Factors) - Foundation data
            "958": "calories_kcal",      # Energy (Atwater Specific Factors) - Foundation data  
            "203": "protein_g",          # Protein  
            "205": "carbohydrates_g",    # Carbohydrate
            "204": "fat_g",              # Total lipid (fat)
            "291": "fiber_g",            # Fiber, total dietary
            "269": "sugars_g",           # Sugars, total
            "307": "sodium_mg"           # Sodium
        }
        
        for nutrient_entry in food_nutrients:
            nutrient_detail = nutrient_entry.get("nutrient", {})
            amount = nutrient_entry.get("amount")
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®é•ã„ã«å¯¾å¿œ
            if not nutrient_detail and "nutrientId" in nutrient_entry:
                # Branded Foods abridged format
                number = nutrient_entry.get("nutrientNumber")
                amount = nutrient_entry.get("value")
            else:
                # Standard format
                number = nutrient_detail.get("number")
            
            if number and str(number) in nutrient_map and amount is not None:
                standard_name = nutrient_map[str(number)]
                # For calories, prefer Atwater Specific Factors (958) over General Factors (957) over legacy (208)
                if standard_name == "calories_kcal":
                    if "calories_kcal" not in nutrients_dict or str(number) == "958":
                        nutrients_dict[standard_name] = float(amount)
                    elif str(number) == "957" and "calories_kcal" in nutrients_dict:
                        # Only replace if current value is from legacy 208
                        current_from_legacy = True  # We can't track source easily, so prefer 957 over existing
                        nutrients_dict[standard_name] = float(amount)
                else:
                    nutrients_dict[standard_name] = float(amount)
        
        logger.debug(f"Parsed nutrients for calculation: {nutrients_dict}")
        return nutrients_dict

    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚ä¿æŒ
    async def search_foods(
        self,
        query: str,
        data_types: Optional[List[str]] = None,
        page_size: int = 5,
        page_number: int = 1,
        sort_by: str = "score",
        sort_order: str = "desc"
    ) -> List:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜search_foodsãƒ¡ã‚½ãƒƒãƒ‰
        """
        # æ–°ã—ã„search_foods_richã‚’å‘¼ã³å‡ºã—ã¦ã€å¤ã„å½¢å¼ã«å¤‰æ›
        rich_results = await self.search_foods_rich(
            query=query,
            data_types=data_types,
            page_size=page_size,
            page_number=page_number,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«å¤ã„USDASearchResultItemã‚¯ãƒ©ã‚¹å½¢å¼ã«å¤‰æ›
        # ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€å¿…è¦ã«å¿œã˜ã¦ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä¿æŒã™ã‚‹ï¼‰
        return rich_results
    
    async def close_client(self):
        """HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.client:
            await self.client.aclose()

    async def search_foods_with_fallback(
        self,
        query_candidates: List[str],
        search_context: str = "ingredient",
        max_results: int = 5
    ) -> List[USDASearchResultItem]:
        """
        Multiple query candidates with intelligent fallback searching
        
        Args:
            query_candidates: List of query terms to try in order of preference
            search_context: Search context for optimization
            max_results: Maximum results to return
        """
        all_results = []
        
        for i, query in enumerate(query_candidates):
            try:
                results = await self.search_foods_rich(
                    query=query,
                    page_size=max_results,
                    search_context=search_context
                )
                
                if results:
                    logger.info(f"Fallback search #{i+1} successful with query '{query}': {len(results)} results")
                    # Add query source info to results
                    for result in results:
                        result.fallback_query_used = query
                        result.fallback_attempt = i + 1
                    all_results.extend(results)
                    
                    # Stop after first successful search unless we need more results
                    if len(all_results) >= max_results:
                        break
                else:
                    logger.info(f"Fallback search #{i+1} returned no results for query '{query}'")
                    
            except Exception as e:
                logger.warning(f"Fallback search #{i+1} failed for query '{query}': {str(e)}")
                continue
        
        # Remove duplicates and limit results
        unique_results = []
        seen_fdc_ids = set()
        
        for result in all_results:
            if result.fdc_id not in seen_fdc_ids:
                unique_results.append(result)
                seen_fdc_ids.add(result.fdc_id)
                if len(unique_results) >= max_results:
                    break
        
        logger.info(f"Fallback search completed: {len(unique_results)} unique results from {len(query_candidates)} queries")
        return unique_results

    async def execute_tiered_usda_search(
        self,
        phase1_candidate: 'USDACandidateQuery',
        brand_context: Optional[str] = None,
        max_results_cap: int = 15
    ) -> List[USDASearchResultItem]:
        """
        Execute tiered USDA search strategy with multiple fallback levels
        Each tier returns up to 5 results for structured Phase2 analysis
        
        Args:
            phase1_candidate: Query candidate from Phase 1 with metadata
            brand_context: Detected brand context (e.g., "La Madeleine")
            max_results_cap: Maximum total results to return
            
        Returns:
            List of deduplicated USDASearchResultItem results from all tiers
        """
        all_found_results_map: Dict[int, USDASearchResultItem] = {}  # FDC IDã§é‡è¤‡æ’é™¤
        attempted_queries = set()
        tier_results_count = {}  # Track results per tier
        RESULTS_PER_TIER = 5  # Fixed number per tier for structured analysis
        
        logger.info(f"Starting tiered USDA search for: {phase1_candidate.query_term} (granularity: {phase1_candidate.granularity_level})")
        
        # Tier 1: Specific/Branded Query
        query_term_t1 = phase1_candidate.query_term
        if query_term_t1 not in attempted_queries:
            # Use Phase1 preferred_data_types if available, otherwise fall back to enhanced dynamic selection
            if hasattr(phase1_candidate, 'preferred_data_types') and phase1_candidate.preferred_data_types:
                data_types_t1 = phase1_candidate.preferred_data_types
                search_context_t1 = phase1_candidate.granularity_level
                brand_owner_t1 = brand_context if "Branded" in data_types_t1 else None
                require_all_words_t1 = True
                logger.info(f"Tier 1 (Phase1 Guided): query='{query_term_t1}', data_types={data_types_t1}")
            else:
                # Enhanced dynamic dataType selection based on granularity and cooking state
                is_cooked_query = any(term in query_term_t1.lower() for term in ["cooked", "prepared", "grilled", "fried", "baked", "boiled", "steamed"])
                is_raw_query = "raw" in query_term_t1.lower()
                
                if phase1_candidate.granularity_level == "dish":
                    # For dish-level queries, prefer SR Legacy for prepared dishes, then Branded as backup
                    data_types_t1 = ["SR Legacy", "Branded"]
                    search_context_t1 = "dish"
                    brand_owner_t1 = brand_context
                    require_all_words_t1 = True
                    logger.info(f"Tier 1 (Dish Level): query='{query_term_t1}', data_types={data_types_t1}")
                elif phase1_candidate.granularity_level == "ingredient":
                    # Enhanced ingredient data type selection based on cooking state
                    if is_raw_query:
                        # Raw ingredients: Foundation preferred for detailed raw composition
                        data_types_t1 = ["Foundation", "SR Legacy"]
                        search_context_t1 = "raw_ingredient"
                        logger.info(f"Tier 1 (Raw Ingredient): query='{query_term_t1}', data_types={data_types_t1}")
                    elif is_cooked_query:
                        # Cooked ingredients: SR Legacy preferred for standard cooked preparations
                        data_types_t1 = ["SR Legacy", "Foundation"]
                        search_context_t1 = "cooked_ingredient"
                        logger.info(f"Tier 1 (Cooked Ingredient): query='{query_term_t1}', data_types={data_types_t1}")
                    else:
                        # Generic ingredient (cooking state unclear): try both
                        data_types_t1 = ["Foundation", "SR Legacy"]
                        search_context_t1 = "ingredient"
                        logger.info(f"Tier 1 (Generic Ingredient): query='{query_term_t1}', data_types={data_types_t1}")
                    
                    brand_owner_t1 = None
                    require_all_words_t1 = True
                elif phase1_candidate.granularity_level == "branded_product":
                    # For branded products, use Branded database
                    data_types_t1 = ["Branded"]
                    search_context_t1 = "branded_product"
                    brand_owner_t1 = brand_context
                    require_all_words_t1 = True
                    logger.info(f"Tier 1 (Branded Product): query='{query_term_t1}', data_types={data_types_t1}")
                else:
                    # Fallback for unknown granularity
                    data_types_t1 = ["SR Legacy", "Foundation", "Branded"]
                    search_context_t1 = "general"
                    brand_owner_t1 = brand_context
                    require_all_words_t1 = False
                    logger.info(f"Tier 1 (Fallback): query='{query_term_t1}', data_types={data_types_t1}")

            try:
                results_t1 = await self.search_foods_rich(
                    query=query_term_t1,
                    data_types=data_types_t1,
                    page_size=RESULTS_PER_TIER,  # Fixed to 5 per tier
                    require_all_words=require_all_words_t1,
                    brand_owner_filter=brand_owner_t1,
                    search_context=search_context_t1
                )
                
                tier_results_count[1] = len(results_t1)
                for res in results_t1:
                    if res.fdc_id not in all_found_results_map:
                        all_found_results_map[res.fdc_id] = res
                        # Mark tier for tracking
                        res.search_tier = 1
                        res.search_query_used = query_term_t1
                        
                attempted_queries.add(query_term_t1)
                logger.info(f"Tier 1 completed: {len(results_t1)} results found")
                    
            except Exception as e:
                logger.warning(f"Tier 1 search failed for '{query_term_t1}': {str(e)}")

        # Tier 2: Broader/Simplified Query - Always execute for comprehensive analysis
        query_term_t2 = self._simplify_query_term(query_term_t1)
        
        if query_term_t2 and query_term_t2 != query_term_t1 and query_term_t2 not in attempted_queries:
            # More permissive parameters for Tier 2
            data_types_t2 = ["SR Legacy", "Branded", "Foundation"]  # Fixed: Remove FNDDS
            require_all_words_t2 = False  # More permissive
            
            logger.info(f"Tier 2 (Broader): query='{query_term_t2}', require_all_words=False")
            
            try:
                results_t2 = await self.search_foods_rich(
                    query=query_term_t2,
                    data_types=data_types_t2,
                    page_size=RESULTS_PER_TIER,  # Fixed to 5 per tier
                    require_all_words=require_all_words_t2,
                    search_context="ingredient"  # Generally more permissive
                )
                
                tier_results_count[2] = len(results_t2)
                for res in results_t2:
                    if res.fdc_id not in all_found_results_map:
                        all_found_results_map[res.fdc_id] = res
                        res.search_tier = 2
                        res.search_query_used = query_term_t2
                        
                attempted_queries.add(query_term_t2)
                logger.info(f"Tier 2 completed: {len(results_t2)} new results found")
                
            except Exception as e:
                logger.warning(f"Tier 2 search failed for '{query_term_t2}': {str(e)}")

        # Tier 3: Generic/Fallback Query - Always execute for comprehensive analysis
        query_term_t3 = self._generalize_query_term(phase1_candidate)
        
        if query_term_t3 and query_term_t3 not in attempted_queries:
            # Most permissive parameters for Tier 3
            data_types_t3 = ["Foundation", "SR Legacy", "Branded"]  # Fixed: Remove FNDDS
            require_all_words_t3 = False
            
            logger.info(f"Tier 3 (Generic): query='{query_term_t3}', require_all_words=False")
            
            try:
                results_t3 = await self.search_foods_rich(
                    query=query_term_t3,
                    data_types=data_types_t3,
                    page_size=RESULTS_PER_TIER,  # Fixed to 5 per tier
                    require_all_words=require_all_words_t3,
                    search_context="ingredient"
                )
                
                tier_results_count[3] = len(results_t3)
                for res in results_t3:
                    if res.fdc_id not in all_found_results_map:
                        all_found_results_map[res.fdc_id] = res
                        res.search_tier = 3
                        res.search_query_used = query_term_t3
                        
                attempted_queries.add(query_term_t3)
                logger.info(f"Tier 3 completed: {len(results_t3)} new results found")
                
            except Exception as e:
                logger.warning(f"Tier 3 search failed for '{query_term_t3}': {str(e)}")

        final_results = list(all_found_results_map.values())
        final_results = self._sort_and_limit_results(final_results, max_results_cap)
        
        logger.info(f"Tiered search completed: {len(final_results)} total unique results from {len(attempted_queries)} queries")
        logger.info(f"Results per tier: {tier_results_count}")
        return final_results

    def _extract_brand_from_query(self, query_term: str) -> Optional[str]:
        """Extract potential brand name from query term"""
        known_brands = ["La Madeleine", "McDonald's", "Subway", "Panera", "Starbucks"]
        query_lower = query_term.lower()
        
        for brand in known_brands:
            if brand.lower() in query_lower:
                return brand
        
        # Generic brand extraction - first 1-2 words if they look like brand names
        words = query_term.split()
        if len(words) >= 2 and words[0][0].isupper():
            # Check if first word(s) might be brand name
            if len(words[0]) > 2 and not words[0].lower() in ["the", "a", "an"]:
                return words[0] if len(words) == 2 else f"{words[0]} {words[1]}"
        
        return None

    def _simplify_query_term(self, query_term: str) -> str:
        """
        Simplify query term by mechanically removing rightmost comma-separated component
        Simple hierarchical strategy: "A, B, C" â†’ "A, B" â†’ "A"
        """
        # Handle comma-separated format - simply remove rightmost component
        if ',' in query_term:
            parts = [part.strip() for part in query_term.split(',')]
            if len(parts) > 1:
                # Remove rightmost component: "Meatloaf, prepared, cooked" â†’ "Meatloaf, prepared"
                return ", ".join(parts[:-1])
            else:
                return query_term
        
        # Handle space-separated format (fallback) - remove last word
        words = query_term.split()
        if len(words) > 1:
            return " ".join(words[:-1])
        
        return query_term

    def _generalize_query_term(self, phase1_candidate: 'USDACandidateQuery') -> str:
        """
        Generate the most generic term by extracting leftmost comma-separated component
        Simple rule: "A, B, C" â†’ "A" (core food category)
        """
        query_term = phase1_candidate.query_term
        
        # Extract core category from comma-separated format
        if ',' in query_term:
            # Return the first part (core category) from "Category, Type, Method"
            core_category = query_term.split(',')[0].strip()
            return core_category
        
        # Handle space-separated format (fallback) - return first word
        words = query_term.split()
        if words:
            return words[0]
        
        return query_term

    def _sort_and_limit_results(self, results: List[USDASearchResultItem], max_results: int) -> List[USDASearchResultItem]:
        """Sort results by quality and limit to max_results"""
        def get_sort_key(item: USDASearchResultItem):
            # Primary sort: data type priority
            datatype_priority = self._get_datatype_priority(item.data_type)
            # Secondary sort: score (higher is better)
            score = item.score or 0
            # Tertiary sort: tier (lower tier = earlier, better)
            tier = getattr(item, 'search_tier', 999)
            
            return (-datatype_priority, -score, tier)
        
        results.sort(key=get_sort_key)
        return results[:max_results]

    def _get_datatype_priority(self, data_type: Optional[str]) -> int:
        """Get priority score for USDA data type"""
        if data_type == "SR Legacy": 
            return 4  # Highest priority for prepared dishes
        elif data_type == "Foundation": 
            return 3  # High priority for basic ingredients
        elif data_type == "Branded": 
            return 2  # Medium priority for commercial products
        else: 
            return 1  # Lowest priority for unknown types

    def organize_results_by_tier(self, results: List[USDASearchResultItem]) -> Dict[int, List[USDASearchResultItem]]:
        """
        Organize search results by tier for structured Phase2 analysis
        
        Args:
            results: List of search results from tiered search
            
        Returns:
            Dict mapping tier number to list of results for that tier
        """
        tier_organized = {}
        
        for result in results:
            tier = getattr(result, 'search_tier', 0)
            if tier not in tier_organized:
                tier_organized[tier] = []
            tier_organized[tier].append(result)
        
        return tier_organized

    def format_tier_results_for_prompt(self, results: List[USDASearchResultItem]) -> str:
        """
        Format tiered search results for Phase2 prompt inclusion
        
        Args:
            results: List of search results from tiered search
            
        Returns:
            Formatted string for prompt inclusion
        """
        if not results:
            return "No USDA search results available."
        
        tier_organized = self.organize_results_by_tier(results)
        formatted_sections = []
        
        for tier in sorted(tier_organized.keys()):
            tier_results = tier_organized[tier]
            if not tier_results:
                continue
                
            # Get query used for this tier
            query_used = getattr(tier_results[0], 'search_query_used', 'N/A')
            
            # Format tier header
            tier_section = f"**TIER {tier} RESULTS** (Query: '{query_used}'):\n"
            
            # Format each result in this tier
            for i, result in enumerate(tier_results, 1):
                combo_indicator = ""
                if any(combo in result.description.lower() for combo in ["with", "&", "and", "meal", "dinner", "plate", "combo"]):
                    combo_indicator = " [COMBO MEAL]"
                
                tier_section += (
                    f"{i}. FDC {result.fdc_id}: {result.description}{combo_indicator}\n"
                    f"   Type: {result.data_type}, Score: {result.score:.1f}\n"
                )
            
            formatted_sections.append(tier_section)
        
        return "\n".join(formatted_sections)


@lru_cache()
def get_usda_service():
    """USDAServiceã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return USDAService() 
```

============================================================

ğŸ“„ FILE: app/services/nutrition_calculation_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 17045 bytes
æœ€çµ‚æ›´æ–°: 2025-06-02 12:05:56
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
æ „é¤Šç´ è¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ (v2.1å¯¾å¿œ)

ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç´”ç²‹ãªè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ï¼š
1. 100gã‚ãŸã‚Šã®æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®æ „é¤Šç´ ã‚’è¨ˆç®—
2. é£Ÿæãƒªã‚¹ãƒˆã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ
3. æ–™ç†ãƒªã‚¹ãƒˆã‹ã‚‰é£Ÿäº‹å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ
4. Phase2ã§ã®é‡é‡å†è¨ˆç®—ã¨ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
"""

import logging
from typing import List, Optional, Dict, Tuple
from ..api.v1.schemas.meal import CalculatedNutrients, RefinedIngredientResponse, RefinedDishResponse, Phase1Ingredient

logger = logging.getLogger(__name__)


class WeightCalculationResult:
    """é‡é‡è¨ˆç®—çµæœã‚’æ ¼ç´ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, 
                 final_weight_g: float, 
                 calculation_method: str, 
                 original_phase1_weight_g: Optional[float] = None,
                 ingredient_weights: Optional[Dict[str, float]] = None):
        self.final_weight_g = final_weight_g
        self.calculation_method = calculation_method
        self.original_phase1_weight_g = original_phase1_weight_g
        self.ingredient_weights = ingredient_weights or {}


class NutritionCalculationService:
    """æ „é¤Šç´ è¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ (v2.1å¯¾å¿œ)"""
    
    @staticmethod
    def calculate_actual_nutrients(
        key_nutrients_per_100g: Dict[str, float], 
        estimated_weight_g: float
    ) -> CalculatedNutrients:
        """
        100gã‚ãŸã‚Šã®ä¸»è¦æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®æ „é¤Šç´ é‡ã‚’è¨ˆç®— (v2.1ä»•æ§˜)
        
        Args:
            key_nutrients_per_100g: 100gã‚ãŸã‚Šã®ä¸»è¦æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿
            estimated_weight_g: æ¨å®šã‚°ãƒ©ãƒ æ•°
            
        Returns:
            CalculatedNutrients: è¨ˆç®—æ¸ˆã¿æ „é¤Šç´ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        if not key_nutrients_per_100g or estimated_weight_g <= 0:
            logger.warning(f"Invalid input: key_nutrients_per_100g={key_nutrients_per_100g}, estimated_weight_g={estimated_weight_g}")
            return CalculatedNutrients()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆå…¨ã¦0.0ï¼‰ã‚’è¿”ã™
        
        try:
            # è¨ˆç®—å¼: (Nutrient_Value_per_100g / 100) Ã— estimated_weight_g
            multiplier = estimated_weight_g / 100.0
            
            # å„æ „é¤Šç´ ã‚’è¨ˆç®—ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„/Noneã®å ´åˆã¯0.0ã¨ã—ã¦æ‰±ã†ï¼‰
            calories_kcal = round((key_nutrients_per_100g.get('calories_kcal', 0.0) or 0.0) * multiplier, 2)
            protein_g = round((key_nutrients_per_100g.get('protein_g', 0.0) or 0.0) * multiplier, 2)
            carbohydrates_g = round((key_nutrients_per_100g.get('carbohydrates_g', 0.0) or 0.0) * multiplier, 2)
            fat_g = round((key_nutrients_per_100g.get('fat_g', 0.0) or 0.0) * multiplier, 2)
            
            # v2.1ã§è¿½åŠ ã•ã‚ŒãŸæ „é¤Šç´ ã‚‚è¨ˆç®—
            fiber_g = key_nutrients_per_100g.get('fiber_g')
            fiber_g = round(fiber_g * multiplier, 2) if fiber_g is not None else None
            
            sugars_g = key_nutrients_per_100g.get('sugars_g')
            sugars_g = round(sugars_g * multiplier, 2) if sugars_g is not None else None
            
            sodium_mg = key_nutrients_per_100g.get('sodium_mg')
            sodium_mg = round(sodium_mg * multiplier, 2) if sodium_mg is not None else None
            
            result = CalculatedNutrients(
                calories_kcal=calories_kcal,
                protein_g=protein_g,
                carbohydrates_g=carbohydrates_g,
                fat_g=fat_g,
                fiber_g=fiber_g,
                sugars_g=sugars_g,
                sodium_mg=sodium_mg
            )
            
            logger.debug(f"Calculated nutrients for {estimated_weight_g}g: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error calculating actual nutrients: {e}")
            return CalculatedNutrients()  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
    
    @staticmethod
    def aggregate_nutrients_for_dish_from_ingredients(
        ingredients: List[RefinedIngredientResponse]
    ) -> CalculatedNutrients:
        """
        ææ–™ãƒªã‚¹ãƒˆã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ (v2.1ä»•æ§˜)
        
        Args:
            ingredients: RefinedIngredientResponseã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¨ˆç®—æ¸ˆã¿ã®actual_nutrientsã‚’æŒã¤ï¼‰
            
        Returns:
            CalculatedNutrients: æ–™ç†ã®é›†è¨ˆæ „é¤Šç´ 
        """
        if not ingredients:
            logger.warning("No ingredients provided for aggregation")
            return CalculatedNutrients()
        
        try:
            total_calories = 0.0
            total_protein = 0.0
            total_carbohydrates = 0.0
            total_fat = 0.0
            total_fiber = 0.0
            total_sugars = 0.0
            total_sodium = 0.0
            
            # Optionalæ „é¤Šç´ ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            fiber_count = 0
            sugars_count = 0
            sodium_count = 0
            calculated_count = 0
            
            for ingredient in ingredients:
                if ingredient.actual_nutrients:
                    total_calories += ingredient.actual_nutrients.calories_kcal
                    total_protein += ingredient.actual_nutrients.protein_g
                    total_carbohydrates += ingredient.actual_nutrients.carbohydrates_g
                    total_fat += ingredient.actual_nutrients.fat_g
                    
                    # Optionalæ „é¤Šç´ ã®å‡¦ç†
                    if ingredient.actual_nutrients.fiber_g is not None:
                        total_fiber += ingredient.actual_nutrients.fiber_g
                        fiber_count += 1
                    
                    if ingredient.actual_nutrients.sugars_g is not None:
                        total_sugars += ingredient.actual_nutrients.sugars_g
                        sugars_count += 1
                    
                    if ingredient.actual_nutrients.sodium_mg is not None:
                        total_sodium += ingredient.actual_nutrients.sodium_mg
                        sodium_count += 1
                    
                    calculated_count += 1
                else:
                    logger.warning(f"Ingredient '{ingredient.ingredient_name}' has no actual_nutrients")
            
            # å°æ•°ç‚¹ä»¥ä¸‹2æ¡ã«ä¸¸ã‚ã‚‹
            result = CalculatedNutrients(
                calories_kcal=round(total_calories, 2),
                protein_g=round(total_protein, 2),
                carbohydrates_g=round(total_carbohydrates, 2),
                fat_g=round(total_fat, 2),
                fiber_g=round(total_fiber, 2) if fiber_count > 0 else None,
                sugars_g=round(total_sugars, 2) if sugars_count > 0 else None,
                sodium_mg=round(total_sodium, 2) if sodium_count > 0 else None
            )
            
            logger.info(f"Aggregated nutrients from {calculated_count}/{len(ingredients)} ingredients: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error aggregating nutrients for dish: {e}")
            return CalculatedNutrients()
    
    @staticmethod
    def aggregate_nutrients_for_meal(
        dishes: List[RefinedDishResponse]
    ) -> CalculatedNutrients:
        """
        æ–™ç†ãƒªã‚¹ãƒˆã‹ã‚‰é£Ÿäº‹å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ (v2.1ä»•æ§˜)
        
        Args:
            dishes: RefinedDishResponseã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¨ˆç®—æ¸ˆã¿ã®dish_total_actual_nutrientsã‚’æŒã¤ï¼‰
            
        Returns:
            CalculatedNutrients: é£Ÿäº‹å…¨ä½“ã®ç·æ „é¤Šç´ 
        """
        if not dishes:
            logger.warning("No dishes provided for meal aggregation")
            return CalculatedNutrients()
        
        try:
            total_calories = 0.0
            total_protein = 0.0
            total_carbohydrates = 0.0
            total_fat = 0.0
            total_fiber = 0.0
            total_sugars = 0.0
            total_sodium = 0.0
            
            # Optionalæ „é¤Šç´ ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            fiber_count = 0
            sugars_count = 0
            sodium_count = 0
            calculated_count = 0
            
            for dish in dishes:
                if dish.dish_total_actual_nutrients:
                    total_calories += dish.dish_total_actual_nutrients.calories_kcal
                    total_protein += dish.dish_total_actual_nutrients.protein_g
                    total_carbohydrates += dish.dish_total_actual_nutrients.carbohydrates_g
                    total_fat += dish.dish_total_actual_nutrients.fat_g
                    
                    # Optionalæ „é¤Šç´ ã®å‡¦ç†
                    if dish.dish_total_actual_nutrients.fiber_g is not None:
                        total_fiber += dish.dish_total_actual_nutrients.fiber_g
                        fiber_count += 1
                    
                    if dish.dish_total_actual_nutrients.sugars_g is not None:
                        total_sugars += dish.dish_total_actual_nutrients.sugars_g
                        sugars_count += 1
                    
                    if dish.dish_total_actual_nutrients.sodium_mg is not None:
                        total_sodium += dish.dish_total_actual_nutrients.sodium_mg
                        sodium_count += 1
                    
                    calculated_count += 1
                else:
                    logger.warning(f"Dish '{dish.dish_name}' has no dish_total_actual_nutrients")
            
            # å°æ•°ç‚¹ä»¥ä¸‹2æ¡ã«ä¸¸ã‚ã‚‹
            result = CalculatedNutrients(
                calories_kcal=round(total_calories, 2),
                protein_g=round(total_protein, 2),
                carbohydrates_g=round(total_carbohydrates, 2),
                fat_g=round(total_fat, 2),
                fiber_g=round(total_fiber, 2) if fiber_count > 0 else None,
                sugars_g=round(total_sugars, 2) if sugars_count > 0 else None,
                sodium_mg=round(total_sodium, 2) if sodium_count > 0 else None
            )
            
            logger.info(f"Aggregated meal nutrients from {calculated_count}/{len(dishes)} dishes: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error aggregating nutrients for meal: {e}")
            return CalculatedNutrients()
    
    @staticmethod
    def calculate_refined_dish_weight(
        phase1_total_dish_weight_g: Optional[float],
        phase1_ingredients: List[Phase1Ingredient],
        calculation_strategy: str,
        has_valid_fdc_id: bool = True
    ) -> WeightCalculationResult:
        """
        Phase2ã§ä½¿ç”¨ã™ã‚‹ç²¾å¯†ãªé‡é‡ã‚’è¨ˆç®—
        
        Args:
            phase1_total_dish_weight_g: Phase1ã§æ¨å®šã•ã‚ŒãŸæ–™ç†å…¨ä½“ã®é‡é‡
            phase1_ingredients: Phase1ã§èªè­˜ã•ã‚ŒãŸææ–™ãƒªã‚¹ãƒˆ
            calculation_strategy: è¨ˆç®—æˆ¦ç•¥ ("dish_level" or "ingredient_level")
            has_valid_fdc_id: æœ‰åŠ¹ãªFDC IDãŒå–å¾—ã§ãã¦ã„ã‚‹ã‹
            
        Returns:
            WeightCalculationResult: è¨ˆç®—çµæœ
        """
        # Phase1ã«ã¯é‡é‡æƒ…å ±ãŒãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡é‡æ¨å®šã‚’ä½¿ç”¨
        if not phase1_ingredients:
            return WeightCalculationResult(
                final_weight_g=100.0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡é‡
                calculation_method="No ingredients found - using default weight",
                original_phase1_weight_g=phase1_total_dish_weight_g,
                ingredient_weights={}
            )
        
        # ç°¡å˜ãªç”»åƒãƒ™ãƒ¼ã‚¹é‡é‡æ¨å®šï¼ˆææ–™æ•°ã«åŸºã¥ãï¼‰
        ingredient_count = len(phase1_ingredients)
        
        # åŸºæœ¬çš„ãªé‡é‡æ¨å®šãƒ­ã‚¸ãƒƒã‚¯
        if ingredient_count == 1:
            estimated_weight = 150.0  # å˜ä¸€ææ–™æ–™ç†
        elif ingredient_count <= 3:
            estimated_weight = 200.0  # ã‚·ãƒ³ãƒ—ãƒ«ãªæ–™ç†
        elif ingredient_count <= 5:
            estimated_weight = 250.0  # æ¨™æº–çš„ãªæ–™ç†
        else:
            estimated_weight = 300.0  # è¤‡é›‘ãªæ–™ç†
        
        # æ–™ç†ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãèª¿æ•´
        dish_weight_adjustments = {
            'salad': 0.8,
            'soup': 1.2,
            'pasta': 1.1,
            'rice': 1.0,
            'meat': 1.3,
            'sandwich': 1.1,
            'dessert': 0.7
        }
        
        # ææ–™åã‹ã‚‰æ–™ç†ã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
        for ingredient in phase1_ingredients:
            name = ingredient.ingredient_name.lower()
            for dish_type, adjustment in dish_weight_adjustments.items():
                if dish_type in name:
                    estimated_weight *= adjustment
                    break
        
        estimated_weight = round(estimated_weight, 1)
        
        # ææ–™é‡é‡ã®è¾æ›¸ã‚’ä½œæˆï¼ˆPhase2ã§æ¨å®šï¼‰
        ingredient_weights = {}
        if phase1_ingredients:
            # estimate_ingredient_weights_from_dishã‚’ä½¿ç”¨ã—ã¦ææ–™é‡é‡ã‚’é…åˆ†
            ingredient_weights = NutritionCalculationService.estimate_ingredient_weights_from_dish(
                estimated_weight, phase1_ingredients
            )
        
        method = f"Phase2 image-based weight estimation: {estimated_weight}g ({ingredient_count} ingredients)"
        
        return WeightCalculationResult(
            final_weight_g=estimated_weight,
            calculation_method=method,
            original_phase1_weight_g=phase1_total_dish_weight_g,
            ingredient_weights=ingredient_weights
        )

    @staticmethod
    def estimate_ingredient_weights_from_dish(
        total_dish_weight_g: float,
        ingredients: List[Phase1Ingredient]
    ) -> Dict[str, float]:
        """
        æ–™ç†å…¨ä½“é‡é‡ã‹ã‚‰å„ææ–™ã®é‡é‡ã‚’æ¨å®šï¼ˆPhase2é‡é‡è¨ˆç®—ç”¨ï¼‰
        
        Args:
            total_dish_weight_g: æ–™ç†å…¨ä½“ã®é‡é‡
            ingredients: Phase1ã§èªè­˜ã•ã‚ŒãŸææ–™ãƒªã‚¹ãƒˆ
            
        Returns:
            Dict[str, float]: ææ–™å -> æ¨å®šé‡é‡ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        """
        if not ingredients or total_dish_weight_g <= 0:
            return {}
        
        # Phase1ã§é‡é‡æƒ…å ±ãŒãªã„ãŸã‚ã€åŸºæœ¬çš„ãªæ¨å®šãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        # ç°¡å˜ãªå‰²åˆãƒ™ãƒ¼ã‚¹ã®æ¨å®šï¼ˆå°†æ¥çš„ã«ã¯ã‚ˆã‚Šé«˜åº¦ãªæ¨å®šã«ç½®æ›å¯èƒ½ï¼‰
        ingredient_count = len(ingredients)
        
        if ingredient_count == 1:
            # ææ–™ãŒ1ã¤ã®å ´åˆã€å…¨é‡é‡ã‚’å‰²ã‚Šå½“ã¦
            return {ingredients[0].ingredient_name: total_dish_weight_g}
        
        # åŸºæœ¬é‡é‡é…åˆ†ï¼ˆå‡ç­‰åˆ†å‰²ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆï¼‰
        base_weight = total_dish_weight_g / ingredient_count
        
        # ææ–™ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãèª¿æ•´ä¿‚æ•°
        type_weights = {}
        for ingredient in ingredients:
            name = ingredient.ingredient_name.lower()
            
            # è‚‰é¡ï¼ˆé«˜é‡é‡ï¼‰
            if any(meat in name for meat in ['beef', 'chicken', 'pork', 'fish', 'meat', 'ground']):
                type_weights[ingredient.ingredient_name] = 1.5
            # ä¸»é£Ÿé¡ï¼ˆé«˜é‡é‡ï¼‰
            elif any(staple in name for staple in ['rice', 'pasta', 'noodle', 'bread', 'potato']):
                type_weights[ingredient.ingredient_name] = 1.3
            # ãƒãƒ¼ã‚ºãƒ»ä¹³è£½å“ï¼ˆä¸­é‡é‡ï¼‰
            elif any(dairy in name for dairy in ['cheese', 'milk', 'cream', 'butter']):
                type_weights[ingredient.ingredient_name] = 1.1
            # é‡èœé¡ï¼ˆæ¨™æº–é‡é‡ï¼‰
            elif any(veg in name for veg in ['lettuce', 'tomato', 'onion', 'pepper', 'carrot', 'bean', 'pea', 'corn']):
                type_weights[ingredient.ingredient_name] = 1.0
            # èª¿å‘³æ–™ãƒ»ã‚½ãƒ¼ã‚¹é¡ï¼ˆä½é‡é‡ï¼‰
            elif any(sauce in name for sauce in ['sauce', 'dressing', 'oil', 'seasoning', 'ketchup']):
                type_weights[ingredient.ingredient_name] = 0.3
            # ãã®ä»–ï¼ˆæ¨™æº–é‡é‡ï¼‰
            else:
                type_weights[ingredient.ingredient_name] = 1.0
        
        # é‡é‡ä¿‚æ•°ã®åˆè¨ˆ
        total_weight_factor = sum(type_weights.values())
        
        # èª¿æ•´ã•ã‚ŒãŸé‡é‡é…åˆ†
        estimated_weights = {}
        for ingredient in ingredients:
            weight_ratio = type_weights[ingredient.ingredient_name] / total_weight_factor
            estimated_weights[ingredient.ingredient_name] = round(total_dish_weight_g * weight_ratio, 1)
        
        logger.info(f"Estimated ingredient weights for dish ({total_dish_weight_g}g): {estimated_weights}")
        return estimated_weights


# ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
def get_nutrition_calculation_service() -> NutritionCalculationService:
    """
    æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
    
    Returns:
        NutritionCalculationService: æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return NutritionCalculationService() 
```

============================================================

ğŸ“„ FILE: app/services/logging_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 13198 bytes
æœ€çµ‚æ›´æ–°: 2025-06-01 14:51:32
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import json
import logging
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)

class LogLevel(str, Enum):
    """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«å®šç¾©"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class ProcessingPhase(str, Enum):
    """å‡¦ç†ãƒ•ã‚§ãƒ¼ã‚ºå®šç¾©"""
    REQUEST_RECEIVED = "REQUEST_RECEIVED"
    PHASE1_START = "PHASE1_START"
    PHASE1_COMPLETE = "PHASE1_COMPLETE"
    USDA_SEARCH_START = "USDA_SEARCH_START"
    USDA_SEARCH_COMPLETE = "USDA_SEARCH_COMPLETE"
    PHASE2_START = "PHASE2_START"
    PHASE2_COMPLETE = "PHASE2_COMPLETE"
    NUTRITION_CALC_START = "NUTRITION_CALC_START"
    NUTRITION_CALC_COMPLETE = "NUTRITION_CALC_COMPLETE"
    RESPONSE_SENT = "RESPONSE_SENT"
    ERROR_OCCURRED = "ERROR_OCCURRED"

@dataclass
class LogEntry:
    """ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®æ¨™æº–æ§‹é€ """
    timestamp: str
    request_id: str
    log_level: LogLevel
    phase: ProcessingPhase
    message: str
    data: Optional[Dict[str, Any]] = None
    execution_time_ms: Optional[float] = None
    error_details: Optional[str] = None

@dataclass
class MealAnalysisSession:
    """é£Ÿäº‹åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®ãƒ­ã‚°"""
    session_id: str
    start_time: str
    end_time: Optional[str] = None
    endpoint: str = ""
    image_filename: Optional[str] = None
    image_size_bytes: Optional[int] = None
    
    # ãƒ•ã‚§ãƒ¼ã‚º1çµæœ
    phase1_duration_ms: Optional[float] = None
    phase1_dishes_count: Optional[int] = None
    phase1_usda_queries_count: Optional[int] = None
    phase1_output: Optional[Dict[str, Any]] = None
    
    # USDAæ¤œç´¢çµæœ
    usda_search_duration_ms: Optional[float] = None
    usda_queries_executed: Optional[int] = None
    usda_results_found: Optional[int] = None
    usda_search_details: Optional[List[Dict[str, Any]]] = None
    
    # ãƒ•ã‚§ãƒ¼ã‚º2çµæœ
    phase2_duration_ms: Optional[float] = None
    phase2_strategy_decisions: Optional[Dict[str, Any]] = None
    phase2_fdc_selections: Optional[Dict[str, Any]] = None
    phase2_output: Optional[Dict[str, Any]] = None
    
    # æ „é¤Šè¨ˆç®—çµæœ
    nutrition_calc_duration_ms: Optional[float] = None
    total_calories: Optional[float] = None
    final_nutrition: Optional[Dict[str, Any]] = None
    
    # ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Š
    warnings: Optional[List[str]] = None
    errors: Optional[List[str]] = None
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    total_duration_ms: Optional[float] = None
    gemini_api_calls: Optional[int] = None
    usda_api_calls: Optional[int] = None

class MealAnalysisLogger:
    """é£Ÿäº‹åˆ†æå°‚ç”¨ãƒ­ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        self.active_sessions: Dict[str, MealAnalysisSession] = {}
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
        self.setup_file_logging()
    
    def setup_file_logging(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚°ã®è¨­å®š"""
        # è©³ç´°ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        detailed_log_file = self.log_dir / "meal_analysis_detailed.jsonl"
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        session_log_file = self.log_dir / "meal_analysis_sessions.jsonl"
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        error_log_file = self.log_dir / "meal_analysis_errors.log"
        
        self.detailed_log_file = detailed_log_file
        self.session_log_file = session_log_file
        self.error_log_file = error_log_file
    
    def start_session(
        self, 
        endpoint: str,
        image_filename: Optional[str] = None,
        image_size_bytes: Optional[int] = None
    ) -> str:
        """æ–°ã—ã„åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        session_id = str(uuid.uuid4())
        
        session = MealAnalysisSession(
            session_id=session_id,
            start_time=datetime.now(timezone.utc).isoformat(),
            endpoint=endpoint,
            image_filename=image_filename,
            image_size_bytes=image_size_bytes
        )
        
        self.active_sessions[session_id] = session
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message=f"Started meal analysis session for endpoint: {endpoint}",
            data={
                "endpoint": endpoint,
                "image_filename": image_filename,
                "image_size_bytes": image_size_bytes
            }
        )
        
        return session_id
    
    def log_entry(
        self,
        session_id: str,
        level: LogLevel,
        phase: ProcessingPhase,
        message: str,
        data: Optional[Dict[str, Any]] = None,
        execution_time_ms: Optional[float] = None,
        error_details: Optional[str] = None
    ):
        """å€‹åˆ¥ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’è¨˜éŒ²"""
        entry = LogEntry(
            timestamp=datetime.now(timezone.utc).isoformat(),
            request_id=session_id,
            log_level=level,
            phase=phase,
            message=message,
            data=data,
            execution_time_ms=execution_time_ms,
            error_details=error_details
        )
        
        # JSONLãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
        try:
            with open(self.detailed_log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(entry), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write detailed log: {e}")
        
        # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã®å ´åˆã¯å°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚è¨˜éŒ²
        if level in [LogLevel.ERROR, LogLevel.CRITICAL]:
            try:
                with open(self.error_log_file, "a", encoding="utf-8") as f:
                    f.write(f"[{entry.timestamp}] {session_id} - {message}\n")
                    if error_details:
                        f.write(f"  Error Details: {error_details}\n")
                    if data:
                        f.write(f"  Data: {json.dumps(data, ensure_ascii=False)}\n")
                    f.write("\n")
            except Exception as e:
                logger.error(f"Failed to write error log: {e}")
    
    def update_phase1_results(
        self,
        session_id: str,
        duration_ms: float,
        dishes_count: int,
        usda_queries_count: int,
        phase1_output: Dict[str, Any]
    ):
        """ãƒ•ã‚§ãƒ¼ã‚º1çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.phase1_duration_ms = duration_ms
            session.phase1_dishes_count = dishes_count
            session.phase1_usda_queries_count = usda_queries_count
            session.phase1_output = phase1_output
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE1_COMPLETE,
            message=f"Phase 1 completed: {dishes_count} dishes, {usda_queries_count} USDA queries",
            data={
                "duration_ms": duration_ms,
                "dishes_count": dishes_count,
                "usda_queries_count": usda_queries_count,
                "phase1_output": phase1_output
            },
            execution_time_ms=duration_ms
        )
    
    def update_usda_search_results(
        self,
        session_id: str,
        duration_ms: float,
        queries_executed: int,
        results_found: int,
        search_details: List[Dict[str, Any]]
    ):
        """USDAæ¤œç´¢çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.usda_search_duration_ms = duration_ms
            session.usda_queries_executed = queries_executed
            session.usda_results_found = results_found
            session.usda_search_details = search_details
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.USDA_SEARCH_COMPLETE,
            message=f"USDA search completed: {queries_executed} queries, {results_found} results",
            data={
                "duration_ms": duration_ms,
                "queries_executed": queries_executed,
                "results_found": results_found,
                "search_summary": search_details
            },
            execution_time_ms=duration_ms
        )
    
    def update_phase2_results(
        self,
        session_id: str,
        duration_ms: float,
        strategy_decisions: Dict[str, Any],
        fdc_selections: Dict[str, Any],
        phase2_output: Dict[str, Any]
    ):
        """ãƒ•ã‚§ãƒ¼ã‚º2çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.phase2_duration_ms = duration_ms
            session.phase2_strategy_decisions = strategy_decisions
            session.phase2_fdc_selections = fdc_selections
            session.phase2_output = phase2_output
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE2_COMPLETE,
            message="Phase 2 completed: Strategy decisions and FDC ID selections made",
            data={
                "duration_ms": duration_ms,
                "strategy_decisions": strategy_decisions,
                "fdc_selections": fdc_selections,
                "phase2_output": phase2_output
            },
            execution_time_ms=duration_ms
        )
    
    def update_nutrition_results(
        self,
        session_id: str,
        duration_ms: float,
        total_calories: float,
        final_nutrition: Dict[str, Any]
    ):
        """æ „é¤Šè¨ˆç®—çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.nutrition_calc_duration_ms = duration_ms
            session.total_calories = total_calories
            session.final_nutrition = final_nutrition
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.NUTRITION_CALC_COMPLETE,
            message=f"Nutrition calculation completed: {total_calories:.1f} kcal total",
            data={
                "duration_ms": duration_ms,
                "total_calories": total_calories,
                "final_nutrition": final_nutrition
            },
            execution_time_ms=duration_ms
        )
    
    def end_session(
        self,
        session_id: str,
        warnings: Optional[List[str]] = None,
        errors: Optional[List[str]] = None
    ):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã€å®Œå…¨ãªãƒ­ã‚°ã‚’ä¿å­˜"""
        if session_id not in self.active_sessions:
            return
        
        session = self.active_sessions[session_id]
        session.end_time = datetime.now(timezone.utc).isoformat()
        session.warnings = warnings
        session.errors = errors
        
        # ç·å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
        if session.start_time and session.end_time:
            start = datetime.fromisoformat(session.start_time.replace('Z', '+00:00'))
            end = datetime.fromisoformat(session.end_time.replace('Z', '+00:00'))
            session.total_duration_ms = (end - start).total_seconds() * 1000
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        try:
            with open(self.session_log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(session), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write session log: {e}")
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.RESPONSE_SENT,
            message=f"Session completed in {session.total_duration_ms:.1f}ms",
            data={
                "total_duration_ms": session.total_duration_ms,
                "warnings_count": len(warnings) if warnings else 0,
                "errors_count": len(errors) if errors else 0
            },
            execution_time_ms=session.total_duration_ms
        )
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å‰Šé™¤
        del self.active_sessions[session_id]
    
    def log_error(
        self,
        session_id: str,
        phase: ProcessingPhase,
        error_message: str,
        error_details: str,
        data: Optional[Dict[str, Any]] = None
    ):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        self.log_entry(
            session_id=session_id,
            level=LogLevel.ERROR,
            phase=phase,
            message=error_message,
            data=data,
            error_details=error_details
        )

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
meal_analysis_logger = MealAnalysisLogger()

def get_meal_analysis_logger() -> MealAnalysisLogger:
    """ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return meal_analysis_logger 
```

============================================================

ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤ (v2.1ã‚¹ã‚­ãƒ¼ãƒ)
============================================================

ğŸ“„ FILE: app/api/v1/schemas/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/schemas/meal.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 21391 bytes
æœ€çµ‚æ›´æ–°: 2025-06-02 12:18:53
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from typing import List, Optional, Dict, Literal, Union
from pydantic import BaseModel, Field, field_validator

# --- å…±é€šãƒ¢ãƒ‡ãƒ« ---

class CalculatedNutrients(BaseModel):
    """è¨ˆç®—æ¸ˆã¿æ „é¤Šç´ ãƒ¢ãƒ‡ãƒ«"""
    calories_kcal: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ã‚«ãƒ­ãƒªãƒ¼ (kcal)")
    protein_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ã‚¿ãƒ³ãƒ‘ã‚¯è³ª (g)")
    carbohydrates_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ç‚­æ°´åŒ–ç‰© (g)")
    fat_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·è„‚è³ª (g)")
    fiber_g: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·é£Ÿç‰©ç¹Šç¶­ (g)")
    sugars_g: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·ç³–è³ª (g)")
    sodium_mg: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·ãƒŠãƒˆãƒªã‚¦ãƒ  (mg)")

class USDANutrient(BaseModel):
    """USDAæ „é¤Šç´ æƒ…å ±ãƒ¢ãƒ‡ãƒ« (USDA ServiceãŒè¿”ã™)"""
    name: str = Field(..., description="æ „é¤Šç´ å")
    amount: float = Field(..., description="100gã¾ãŸã¯100mlã‚ãŸã‚Šã®é‡")
    unit_name: str = Field(..., description="å˜ä½å (ä¾‹: g, mg, kcal)")
    nutrient_id: Optional[int] = Field(None, description="USDAæ „é¤Šç´ ID")
    nutrient_number: Optional[str] = Field(None, description="USDAæ „é¤Šç´ ç•ªå·")

class USDASearchResultItem(BaseModel):
    """USDAæ¤œç´¢çµæœã‚¢ã‚¤ãƒ†ãƒ ãƒ¢ãƒ‡ãƒ« (USDA ServiceãŒè¿”ã™)"""
    fdc_id: int = Field(..., description="USDA FoodData Central ID")
    description: str = Field(..., description="é£Ÿå“ã®å…¬å¼åç§°")
    data_type: Optional[str] = Field(None, description="USDAãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— (ä¾‹: SR Legacy, Branded)")
    publication_date: Optional[str] = Field(None, description="å…¬é–‹æ—¥")
    brand_owner: Optional[str] = Field(None, description="ãƒ–ãƒ©ãƒ³ãƒ‰æ‰€æœ‰è€… (Branded Foodsã®å ´åˆ)")
    brand_name: Optional[str] = Field(None, description="ãƒ–ãƒ©ãƒ³ãƒ‰å")
    subbrand_name: Optional[str] = Field(None, description="ã‚µãƒ–ãƒ–ãƒ©ãƒ³ãƒ‰å")
    gtin_upc: Optional[str] = Field(None, description="GTIN/UPCã‚³ãƒ¼ãƒ‰")
    ndb_number: Optional[Union[str, int]] = Field(None, description="NDBç•ªå· (æ–‡å­—åˆ—ã¾ãŸã¯æ•´æ•°)")
    food_code: Optional[str] = Field(None, description="é£Ÿå“ã‚³ãƒ¼ãƒ‰")
    score: Optional[float] = Field(None, description="æ¤œç´¢çµæœã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢")
    ingredients: Optional[str] = Field(None, description="åŸææ–™ãƒªã‚¹ãƒˆæ–‡å­—åˆ— (Brandedé£Ÿå“ã®å ´åˆ)")
    ingredients_text: Optional[str] = Field(None, description="åŸææ–™ãƒªã‚¹ãƒˆæ–‡å­—åˆ— (Brandedé£Ÿå“ã®å ´åˆ, **Assumption: String**)")
    food_nutrients: List[USDANutrient] = Field(default_factory=list, description="ä¸»è¦ãªæ „é¤Šç´ æƒ…å ±ã®ãƒªã‚¹ãƒˆ")
    
    # Enhanced search tracking attributes
    search_tier: Optional[int] = Field(None, description="æ¤œç´¢éšå±¤ (1=specific, 2=broader, 3=generic)")
    search_query_used: Optional[str] = Field(None, description="å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª")
    search_context: Optional[str] = Field(None, description="æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ (branded, ingredient, dish)")
    require_all_words_used: Optional[bool] = Field(None, description="requireAllWordsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä½¿ç”¨ã•ã‚ŒãŸã‹")
    data_types_searched: Optional[List[str]] = Field(None, description="æ¤œç´¢å¯¾è±¡ã¨ãªã£ãŸãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ")
    
    # Legacy fallback search tracking attributes (for backward compatibility)
    fallback_query_used: Optional[str] = Field(None, description="ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã§ä½¿ç”¨ã•ã‚ŒãŸã‚¯ã‚¨ãƒªï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰")
    fallback_attempt: Optional[int] = Field(None, description="ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã®è©¦è¡Œå›æ•°ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰")

    @field_validator('ndb_number')
    @classmethod
    def validate_ndb_number(cls, v):
        """ndb_numberã‚’æ–‡å­—åˆ—ã«æ­£è¦åŒ–"""
        if v is not None:
            return str(v)
        return v

# --- Phase 1 Gemini å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« ---

class USDACandidateQuery(BaseModel):
    """Phase 1ã§GeminiãŒå‡ºåŠ›ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œ"""
    query_term: str = Field(..., description="USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)")
    granularity_level: Literal["dish", "ingredient", "branded_product"] = Field(..., description="ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«")
    preferred_data_types: Optional[List[Literal["Foundation", "SR Legacy", "Branded"]]] = Field(None, description="æ¨å¥¨USDAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆå„ªå…ˆé †ï¼‰")
    original_term: str = Field("", description="ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå")
    reason_for_query: str = Field("", description="ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±")

class Phase1Ingredient(BaseModel):
    """Phase 1 ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§° (è‹±èª)")
    state: Optional[Literal["raw", "cooked", "fried", "baked", "processed", "dry", "unknown"]] = Field("unknown", description="ææ–™ã®èª¿ç†ãƒ»åŠ å·¥çŠ¶æ…‹")

class Phase1Dish(BaseModel):
    """Phase 1 æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str = Field(..., description="ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§° (è‹±èª)")
    type: str = Field(..., description="æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: Main course, Side dishï¼‰")
    quantity_on_plate: str = Field(..., description="çš¿ã®ä¸Šã®é‡ã‚„å€‹æ•°")
    ingredients: List[Phase1Ingredient] = Field(..., description="å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ")
    # NEW: Phase 1ã§ã‚¯ã‚¨ãƒªå€™è£œã‚’å‡ºåŠ›
    usda_query_candidates: List[USDACandidateQuery] = Field(..., description="ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆ")

class Phase1AnalysisResponse(BaseModel):
    """Phase 1 é£Ÿäº‹åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[Phase1Dish] = Field(..., description="ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ")

# --- Phase 2 Gemini å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« (Geminiå‘ã‘ã‚¹ã‚­ãƒ¼ãƒ) ---

class RefinedIngredientGeminiOutput(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚")
    estimated_weight_g: Optional[float] = Field(None, description="ç”»åƒã‹ã‚‰æ¨å®šã•ã‚ŒãŸææ–™ã®é‡é‡ (g)ã€‚ingredient_levelè¨ˆç®—ã®å ´åˆã«è¨­å®šã€‚")
    fdc_id: Optional[int] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã€‚ingredient_levelã®å ´åˆã€ã¾ãŸã¯dish_levelã®Fallbackæ™‚ã«è¨­å®šã€‚")
    usda_source_description: Optional[str] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°ã€‚")
    reason_for_choice: Optional[str] = Field(None, description="ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€ã¾ãŸã¯é¸æŠã—ãªã‹ã£ãŸç†ç”±ã€‚")

class RefinedDishGeminiOutput(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str = Field(..., description="æ–™ç†ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚")
    calculation_strategy: Literal["dish_level", "ingredient_level"] = Field(..., description="å†™çœŸã¨æ¤œç´¢çµæœã«åŸºã¥ã„ã¦æ±ºå®šã•ã‚ŒãŸæœ€çµ‚è¨ˆç®—æˆ¦ç•¥")
    reason_for_strategy: str = Field(..., description="ã“ã®è¨ˆç®—æˆ¦ç•¥ã‚’é¸æŠã—ãŸç†ç”±ã€‚å†™çœŸã®è¤‡é›‘ã•ã¨æ¤œç´¢çµæœã®è³ªã‚’è€ƒæ…®ã€‚")
    estimated_dish_weight_g: Optional[float] = Field(None, description="ç”»åƒã‹ã‚‰æ¨å®šã•ã‚ŒãŸæ–™ç†å…¨ä½“ã®é‡é‡ (g)ã€‚dish_levelè¨ˆç®—ã®å ´åˆã«è¨­å®šã€‚")
    fdc_id: Optional[int] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã€‚dish_levelã®å ´åˆã«è¨­å®šã€‚")
    usda_source_description: Optional[str] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°ã€‚")
    reason_for_choice: Optional[str] = Field(None, description="ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€ã¾ãŸã¯é¸æŠã—ãªã‹ã£ãŸç†ç”±ã€‚")
    ingredients: List[RefinedIngredientGeminiOutput] = Field(..., description="ææ–™ãƒªã‚¹ãƒˆ")

class Phase2GeminiResponse(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - å…¨ä½“ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[RefinedDishGeminiOutput] = Field(..., description="ç²¾ç·»åŒ–ã•ã‚ŒãŸæ–™ç†ãƒªã‚¹ãƒˆã€‚")

# --- Phase 2 API å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« (æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹) ---

class RefinedIngredientResponse(BaseModel):
    """Phase 2 APIå‡ºåŠ›ç”¨ - ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str
    weight_g: float
    fdc_id: Optional[int]
    usda_source_description: Optional[str]
    reason_for_choice: Optional[str] # From Gemini
    key_nutrients_per_100g: Optional[Dict[str, float]] # From USDA Service
    actual_nutrients: Optional[CalculatedNutrients] # From Nutrition Calculation

class RefinedDishResponse(BaseModel):
    """Phase 2 APIå‡ºåŠ›ç”¨ - æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str
    type: str # From Phase 1
    quantity_on_plate: str # From Phase 1
    estimated_total_dish_weight_g: Optional[float] = Field(None, description="Phase1ã§æ¨å®šã•ã‚ŒãŸæ–™ç†å…¨ä½“ã®é‡é‡ï¼ˆã‚°ãƒ©ãƒ ï¼‰")
    actual_weight_used_for_calculation_g: Optional[float] = Field(None, description="æ „é¤Šè¨ˆç®—ã§å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸé‡é‡ï¼ˆã‚°ãƒ©ãƒ ï¼‰")
    weight_calculation_method: Optional[str] = Field(None, description="é‡é‡è¨ˆç®—æ–¹æ³•ã®èª¬æ˜")
    calculation_strategy: Literal["dish_level", "ingredient_level"] # From Gemini
    reason_for_strategy: Optional[str] # From Gemini
    fdc_id: Optional[int] # From Gemini (dish_level)
    usda_source_description: Optional[str] # From Gemini (dish_level)
    reason_for_choice: Optional[str] # From Gemini (dish_level)
    key_nutrients_per_100g: Optional[Dict[str, float]] # From USDA Service (dish_level)
    ingredients: List[RefinedIngredientResponse]
    dish_total_actual_nutrients: Optional[CalculatedNutrients] # From Nutrition Calculation

class MealAnalysisRefinementResponse(BaseModel):
    """Phase 2 é£Ÿäº‹åˆ†æç²¾ç·»åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[RefinedDishResponse]
    total_meal_nutrients: Optional[CalculatedNutrients]
    warnings: Optional[List[str]] = Field(None, description="å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸè­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚")
    errors: Optional[List[str]] = Field(None, description="å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚")

# --- å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚‚ä¿æŒ ---

class Ingredient(BaseModel):
    """ææ–™æƒ…å ±ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§°")
    weight_g: float = Field(..., description="æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰", ge=0.1)

class Dish(BaseModel):
    """æ–™ç†æƒ…å ±ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    dish_name: str = Field(..., description="ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°")
    type: str = Field(..., description="æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—ï¼‰")
    quantity_on_plate: str = Field(..., description="çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°")
    ingredients: List[Ingredient] = Field(..., description="ãã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ")

class MealAnalysisResponse(BaseModel):
    """é£Ÿäº‹åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    dishes: List[Dish] = Field(..., description="ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ")

class ErrorResponse(BaseModel):
    """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    error: dict = Field(..., description="ã‚¨ãƒ©ãƒ¼æƒ…å ±")
    
    class Config:
        json_schema_extra = {
            "example": {
                "error": {
                    "code": "INVALID_INPUT", 
                    "message": "æä¾›ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                }
            }
        }

# --- å¾Œæ–¹äº’æ›æ€§ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ ---
InitialAnalysisIngredient = Ingredient  
InitialAnalysisDish = Dish  
InitialAnalysisData = MealAnalysisResponse  

# --- RefinedIngredient/RefinedDish ã¯ RefinedIngredientResponse/RefinedDishResponse ã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ ---
RefinedIngredient = RefinedIngredientResponse
RefinedDish = RefinedDishResponse

# --- Geminiå‘ã‘JSONã‚¹ã‚­ãƒ¼ãƒå®šç¾© (æ‰‹å‹•ã§ä¿®æ­£) ---

# Phase 1 Schema - æ‰‹å‹•ã§å®šç¾©ã—ã¦Gemini APIäº’æ›ã«ã™ã‚‹
PHASE_1_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§° (è‹±èª)"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: Main course, Side dishï¼‰"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã®é‡ã‚„å€‹æ•°"},
                    "ingredients": {
                        "type": "array",
                        "description": "å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§° (è‹±èª)"},
                                "state": {
                                    "type": "string",
                                    "enum": ["raw", "cooked", "fried", "baked", "processed", "dry", "unknown"],
                                    "description": "ææ–™ã®èª¿ç†ãƒ»åŠ å·¥çŠ¶æ…‹"
                                }
                            },
                            "required": ["ingredient_name", "state"]
                        }
                    },
                    "usda_query_candidates": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆ",
                        "items": {
                            "type": "object",
                            "properties": {
                                "query_term": {"type": "string", "description": "USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)"},
                                "granularity_level": {
                                    "type": "string",
                                    "enum": ["dish", "ingredient", "branded_product"],
                                    "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«"
                                },
                                "preferred_data_types": {
                                    "type": "array",
                                    "items": {
                                        "type": "string",
                                        "enum": ["Foundation", "SR Legacy", "Branded"]
                                    },
                                    "description": "æ¨å¥¨USDAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆå„ªå…ˆé †ï¼‰"
                                },
                                "original_term": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå"},
                                "reason_for_query": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±"}
                            },
                            "required": ["query_term", "granularity_level", "original_term", "reason_for_query"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients", "usda_query_candidates"]
            }
        }
    },
    "required": ["dishes"]
}

# Phase 2 Schema - æ‰‹å‹•ã§å®šç¾©ã—ã¦Gemini APIäº’æ›ã«ã™ã‚‹
PHASE_2_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç²¾ç·»åŒ–ã•ã‚ŒãŸæ–™ç†ãƒªã‚¹ãƒˆ",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "æ–™ç†ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚"},
                    "calculation_strategy": {
                        "type": "string",
                        "enum": ["dish_level", "ingredient_level"],
                        "description": "å†™çœŸã¨æ¤œç´¢çµæœã«åŸºã¥ã„ã¦æ±ºå®šã•ã‚ŒãŸæœ€çµ‚è¨ˆç®—æˆ¦ç•¥"
                    },
                    "reason_for_strategy": {"type": "string", "description": "ã“ã®è¨ˆç®—æˆ¦ç•¥ã‚’é¸æŠã—ãŸç†ç”±ã€‚å†™çœŸã®è¤‡é›‘ã•ã¨æ¤œç´¢çµæœã®è³ªã‚’è€ƒæ…®ã€‚"},
                    "estimated_dish_weight_g": {"type": "number", "description": "ç”»åƒã‹ã‚‰æ¨å®šã•ã‚ŒãŸæ–™ç†å…¨ä½“ã®é‡é‡ (g)ã€‚dish_levelè¨ˆç®—ã®å ´åˆã«è¨­å®šã€‚"},
                    "fdc_id": {"type": "integer", "description": "dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC ID"},
                    "usda_source_description": {"type": "string", "description": "dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°"},
                    "reason_for_choice": {"type": "string", "description": "dish_levelã®å ´åˆã€ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±"},
                    "ingredients": {
                        "type": "array",
                        "description": "ææ–™ãƒªã‚¹ãƒˆã€‚å„ææ–™ã«ã¤ã„ã¦FDC IDã¨é¸æŠç†ç”±ã‚’è¨˜è¿°",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£"},
                                "estimated_weight_g": {"type": "number", "description": "ç”»åƒã‹ã‚‰æ¨å®šã•ã‚ŒãŸææ–™ã®é‡é‡ (g)ã€‚ingredient_levelè¨ˆç®—ã®å ´åˆã«è¨­å®šã€‚"},
                                "fdc_id": {"type": "integer", "description": "é¸æŠã•ã‚ŒãŸFDC IDã€‚ingredient_levelã®å ´åˆã€ã¾ãŸã¯dish_levelã®Fallbackæ™‚ã«è¨­å®š"},
                                "usda_source_description": {"type": "string", "description": "é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°"},
                                "reason_for_choice": {"type": "string", "description": "ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€ã¾ãŸã¯é¸æŠã—ãªã‹ã£ãŸç†ç”±"}
                            },
                            "required": ["ingredient_name"]
                        }
                    }
                },
                "required": ["dish_name", "calculation_strategy", "reason_for_strategy", "ingredients"]
            }
        }
    },
    "required": ["dishes"]
}

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ã‚¹ã‚­ãƒ¼ãƒã‚‚ä¿æŒ
MEAL_ANALYSIS_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆã€‚",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°ã€‚"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—, ãƒ‡ã‚¶ãƒ¼ãƒˆï¼‰ã€‚"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°ï¼ˆä¾‹: '1æ¯', '2åˆ‡ã‚Œ', 'ç´„200g'ï¼‰ã€‚"},
                    "ingredients": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ã¨æ¨å®šã•ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§°ã€‚"},
                                "weight_g": {"type": "number", "description": "ãã®ææ–™ã®æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰ã€‚"}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    },
                    "usda_query_candidates": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "query_term": {"type": "string", "description": "USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)"},
                                "granularity_level": {
                                    "type": "string", 
                                    "enum": ["dish", "ingredient", "branded_product"],
                                    "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«"
                                },
                                "original_term": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå"},
                                "reason_for_query": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±"}
                            },
                            "required": ["query_term", "granularity_level"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients", "usda_query_candidates"]
            }
        }
    },
    "required": ["dishes"]
}

REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA = PHASE_2_GEMINI_SCHEMA 
```

============================================================

ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†å±¤ (v2.1)
============================================================

ğŸ“„ FILE: app/prompts/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 114 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

from .prompt_loader import PromptLoader

__all__ = ['PromptLoader'] 
```

============================================================

ğŸ“„ FILE: app/prompts/prompt_loader.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 4029 bytes
æœ€çµ‚æ›´æ–°: 2025-06-01 16:12:20
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import os
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class PromptLoader:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, prompts_dir: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            prompts_dir: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
                        Noneã®å ´åˆã¯ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
        """
        if prompts_dir is None:
            self.prompts_dir = Path(__file__).parent
        else:
            self.prompts_dir = Path(prompts_dir)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._prompt_cache = {}
    
    def _load_prompt_file(self, filename: str) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            filename: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
            IOError: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
        """
        if filename in self._prompt_cache:
            return self._prompt_cache[filename]
        
        file_path = self.prompts_dir / filename
        
        if not file_path.exists():
            raise FileNotFoundError(f"Prompt file not found: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            self._prompt_cache[filename] = content
            logger.debug(f"Loaded prompt file: {filename}")
            return content
        
        except Exception as e:
            logger.error(f"Error loading prompt file {filename}: {e}")
            raise IOError(f"Failed to load prompt file {filename}: {e}") from e
    
    def get_phase1_system_prompt(self) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
        return self._load_prompt_file("phase1_system_prompt.txt")
    
    def get_phase1_user_prompt(self, optional_text: Optional[str] = None) -> str:
        """
        ãƒ•ã‚§ãƒ¼ã‚º1ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        
        Args:
            optional_text: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        template = self._load_prompt_file("phase1_user_prompt_template.txt")
        
        if optional_text and optional_text.strip():
            optional_text_section = f" Additional information from user: {optional_text}"
        else:
            optional_text_section = ""
        
        return template.format(optional_text_section=optional_text_section)
    
    def get_phase2_system_prompt(self) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
        return self._load_prompt_file("phase2_system_prompt.txt")
    
    def get_phase2_user_prompt(
        self, 
        initial_ai_output: str,
        usda_candidates: str
    ) -> str:
        """
        ãƒ•ã‚§ãƒ¼ã‚º2ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        
        Args:
            initial_ai_output: ãƒ•ã‚§ãƒ¼ã‚º1ã®AIå‡ºåŠ›ï¼ˆJSONæ–‡å­—åˆ—ï¼‰
            usda_candidates: USDAå€™è£œæƒ…å ±
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        template = self._load_prompt_file("phase2_user_prompt_template.txt")
        
        return template.format(
            initial_ai_output=initial_ai_output,
            usda_candidates=usda_candidates
        )
    
    def reload_prompts(self):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦å†èª­ã¿è¾¼ã¿ã‚’ä¿ƒã™"""
        self._prompt_cache.clear()
        logger.info("Prompt cache cleared. Prompts will be reloaded on next access.") 
```

============================================================

ğŸ¯ SUMMARY v2.1
----------------------------------------
ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 17
å­˜åœ¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 17
åˆ†æå®Œäº†æ™‚åˆ»: 2025-06-02 12:26:35

ğŸ“‹ v2.1ã®ä¸»è¦æ”¹å–„ç‚¹:
âœ… USDAã‚¯ã‚¨ãƒªå€™è£œã®è‡ªå‹•ç”Ÿæˆ
âœ… é«˜åº¦ãªæˆ¦ç•¥æ±ºå®šã‚·ã‚¹ãƒ†ãƒ 
âœ… å‹•çš„æ „é¤Šè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
âœ… åŒ…æ‹¬çš„ãƒ­ã‚°æ©Ÿèƒ½
âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ„ãƒ¼ãƒ«

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€test_english_phase1_v2.py ãŠã‚ˆã³
test_english_phase2_v2.pyå®Ÿè¡Œæ™‚ã«é–¢ã‚ã‚‹å…¨ã¦ã®
Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãªå†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
