"""
È´òÂ∫¶È£üÂìÅÊ§úÁ¥¢„Çµ„Éº„Éì„Çπ
‰ªïÊßòÊõ∏„Å´Âü∫„Å•„ÅèElasticsearchÊ§úÁ¥¢Ê©üËÉΩ„ÅÆÂÆüË£Ö
"""
import logging
import math
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass

from .client import es_client
from .config import es_config

logger = logging.getLogger(__name__)


@dataclass
class NutritionTarget:
    """Ê†ÑÈ§ä„Éó„É≠„Éï„Ç°„Ç§„É´ÁõÆÊ®ôÂÄ§"""
    calories: float
    protein_g: float
    fat_total_g: float
    carbohydrate_by_difference_g: float
    # ËøΩÂä†Ê†ÑÈ§äÁ¥†ÔºàÂøÖË¶Å„Å´Âøú„Åò„Å¶Ôºâ
    fiber_total_dietary_g: Optional[float] = None
    sodium_mg: Optional[float] = None
    
    def to_dict(self) -> Dict[str, float]:
        """ËæûÊõ∏ÂΩ¢Âºè„Å´Â§âÊèõ"""
        result = {
            "calories": self.calories,
            "protein_g": self.protein_g,
            "fat_total_g": self.fat_total_g,
            "carbohydrate_by_difference_g": self.carbohydrate_by_difference_g
        }
        
        if self.fiber_total_dietary_g is not None:
            result["fiber_total_dietary_g"] = self.fiber_total_dietary_g
        if self.sodium_mg is not None:
            result["sodium_mg"] = self.sodium_mg
            
        return result


@dataclass
class SearchQuery:
    """Ê§úÁ¥¢„ÇØ„Ç®„É™ÊÉÖÂ†±"""
    elasticsearch_query_terms: str
    exact_phrase: Optional[str] = None
    target_nutrition_vector: Optional[NutritionTarget] = None
    semantic_embedding: Optional[List[float]] = None


@dataclass
class SearchResult:
    """Ê§úÁ¥¢ÁµêÊûú„Ç¢„Ç§„ÉÜ„É†"""
    food_id: str
    fdc_id: Optional[int]
    food_name: str
    description: Optional[str]
    brand_name: Optional[str]
    category: Optional[str]
    data_type: Optional[str]  # ËøΩÂä†ÔºöÂÖÉ„ÅÆ„Éá„Éº„Çø„Çø„Ç§„Éó„Çí‰øùÊåÅ
    num_favorites: Optional[int]  # üéØ ‰∫∫Ê∞óÂ∫¶ÊåáÊ®ô„ÇíËøΩÂä†
    nutrition: Dict[str, float]
    score: float
    explanation: Dict[str, Any]


class FoodSearchService:
    """È£üÂìÅÊ§úÁ¥¢„Çµ„Éº„Éì„Çπ"""
    
    def __init__(self):
        """ÂàùÊúüÂåñ"""
        # üéØ config„Åã„ÇâË®≠ÂÆö„ÇíË™≠„ÅøËæº„ÅøÔºà„Éè„Éº„Éâ„Ç≥„Éº„ÉâÂÄ§„ÇíÊéíÈô§Ôºâ
        self.nutrition_normalization = es_config.get_nutrition_normalization_factors()
        self.nutrition_weights = es_config.get_nutrition_weights()
        self.field_boosts = es_config.get_field_boosts()
    
    async def search_foods(
        self, 
        query: SearchQuery, 
        size: int = 10,
        enable_nutritional_similarity: bool = True,
        enable_semantic_similarity: bool = False,
        data_type_filter: Optional[List[str]] = None
    ) -> List[SearchResult]:
        """
        È´òÂ∫¶È£üÂìÅÊ§úÁ¥¢„ÇíÂÆüË°å
        
        Args:
            query: Ê§úÁ¥¢„ÇØ„Ç®„É™ÊÉÖÂ†±
            size: ÁµêÊûú‰ª∂Êï∞
            enable_nutritional_similarity: Ê†ÑÈ§ä„Éó„É≠„Éï„Ç°„Ç§„É´È°û‰ººÊÄß„ÇíÊúâÂäπ„Å´„Åô„Çã„Åã
            enable_semantic_similarity: „Çª„Éû„É≥„ÉÜ„Ç£„ÉÉ„ÇØÈ°û‰ººÊÄß„ÇíÊúâÂäπ„Å´„Åô„Çã„Åã
            data_type_filter: Ê§úÁ¥¢ÂØæË±°„ÅÆ„Éá„Éº„Çø„Çø„Ç§„Éó (‰æã: ["ingredient", "branded"])
        
        Returns:
            Ê§úÁ¥¢ÁµêÊûú„É™„Çπ„Éà
        """
        try:
            # Elasticsearch„ÇØ„Ç®„É™„ÇíÊßãÁØâ
            es_query = self._build_elasticsearch_query(
                query, 
                enable_nutritional_similarity,
                enable_semantic_similarity,
                data_type_filter
            )
            
            # „É≠„Ç∞Âá∫Âäõ„ÇíÊîπÂñÑ
            query_desc = f"'{query.elasticsearch_query_terms}'"
            if data_type_filter:
                query_desc += f" (filtered to: {', '.join(data_type_filter)})"
            
            logger.info(f"Executing advanced food search for: {query_desc}")
            logger.debug(f"Elasticsearch query: {es_query}")
            
            # Ê§úÁ¥¢ÂÆüË°å
            response = await es_client.search(
                index_name=es_config.food_nutrition_index,
                query=es_query,
                size=size
            )
            
            if not response:
                logger.warning("Search response is empty")
                return []
            
            # ÁµêÊûú„ÇíËß£Êûê
            results = self._parse_search_results(response)
            
            logger.info(f"Search completed: {len(results)} results found")
            return results
            
        except Exception as e:
            logger.error(f"Food search failed: {e}")
            return []
    
    def _build_elasticsearch_query(
        self, 
        query: SearchQuery,
        enable_nutritional_similarity: bool,
        enable_semantic_similarity: bool,
        data_type_filter: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ‰ªïÊßòÊõ∏„Å´Âü∫„Å•„ÅèElasticsearch„ÇØ„Ç®„É™„ÇíÊßãÁØâ
        """
        # „Éô„Éº„ÇπË™ûÂΩôÁöÑÊ§úÁ¥¢„ÇØ„Ç®„É™
        base_query = {
            "bool": {
                "must": [
                    {
                        "multi_match": {
                            "query": query.elasticsearch_query_terms,
                            "fields": [
                                f"food_name^{self.field_boosts['food_name']}",
                                f"description^{self.field_boosts['description']}",
                                f"brand_name^{self.field_boosts['brand_name']}",
                                f"ingredients_text^{self.field_boosts['ingredients_text']}",
                                f"food_name.phonetic^{self.field_boosts['food_name.phonetic']}"
                            ],
                            "type": "most_fields",
                            "fuzziness": "AUTO"  # typoË®±ÂÆπ
                        }
                    }
                ],
                "should": [],  # Âä†ÁÇπË¶ÅÁ¥†
                "filter": []   # „Éï„Ç£„É´„ÇøÊù°‰ª∂
            }
        }
        
        # „Éá„Éº„Çø„Çø„Ç§„Éó„Éï„Ç£„É´„Çø„ÇíËøΩÂä†
        if data_type_filter:
            base_query["bool"]["filter"].append({
                "terms": {
                    "data_type": data_type_filter
                }
            })
        
        # „Éï„É¨„Éº„Ç∫‰∏ÄËá¥„Éñ„Éº„Çπ„Éà„ÇíËøΩÂä†
        if query.exact_phrase:
            base_query["bool"]["should"].append({
                "match_phrase": {
                    "food_name": {
                        "query": query.exact_phrase,
                        "boost": es_config.phrase_match_boost
                    }
                }
            })
        
        # üéØ config„Éô„Éº„Çπ„Åßfunction_score„ÇíÂà∂Âæ°
        functions = []
        
        # ‰∫∫Ê∞óÂ∫¶„Éñ„Éº„Çπ„ÉàÔºàconfig„ÅßÂà∂Âæ°Ôºâ
        if es_config.enable_popularity_boost:
            popularity_function = self._build_popularity_boost_function()
            functions.append(popularity_function)
            logger.info("üéØ Popularity boost enabled via config")
        
        # Ê†ÑÈ§ä„Éó„É≠„Éï„Ç°„Ç§„É´È°û‰ººÊÄßÔºàconfig„ÅßÂà∂Âæ°Ôºâ
        if (es_config.enable_nutritional_similarity and 
            enable_nutritional_similarity and 
            query.target_nutrition_vector):
            nutrition_function = self._build_nutrition_similarity_function(query.target_nutrition_vector)
            functions.append(nutrition_function)
            logger.info("üéØ Nutritional similarity scoring enabled via config")
        
        # function_score„ÇíÈÅ©Áî®„Åô„Çã„Åã„Éô„Éº„Çπ„ÇØ„Ç®„É™„ÅÆ„Åø„Å´„Åô„Çã„ÅãÊ±∫ÂÆö
        if functions:
            function_score_query = {
                "function_score": {
                    "query": base_query,
                    "functions": functions,
                    "score_mode": "sum",     # ÂêÑ„Çπ„Ç≥„Ç¢„ÇíÂêàË®à
                    "boost_mode": "multiply" # ÂÖÉ„ÅÆ„ÇØ„Ç®„É™„Çπ„Ç≥„Ç¢„Å´Èñ¢Êï∞„Çπ„Ç≥„Ç¢„Çí‰πóÁÆó
                }
            }
            return {"query": function_score_query}
        else:
            # function_score„ÅåÁÑ°Âäπ„ÅÆÂ†¥Âêà„ÅØ„Éô„Éº„Çπ„ÇØ„Ç®„É™„ÅÆ„Åø
            logger.info("üéØ Using pure lexical search (no function_score)")
            return {"query": base_query}
    
    def _build_nutrition_similarity_function(self, target: NutritionTarget) -> Dict[str, Any]:
        """
        Ê†ÑÈ§ä„Éó„É≠„Éï„Ç°„Ç§„É´È°û‰ººÊÄß„Çπ„Ç≥„Ç¢„É™„É≥„Ç∞Èñ¢Êï∞„ÇíÊßãÁØâ
        """
        target_dict = target.to_dict()
        
        # ÂøÖÈ†àÊ†ÑÈ§äÁ¥†„Éï„Ç£„Éº„É´„Éâ„ÅÆÂ≠òÂú®„ÉÅ„Çß„ÉÉ„ÇØÁî®„Éï„Ç£„É´„Çø
        nutrition_filter = {
            "bool": {
                "must": [
                    {"exists": {"field": "nutrition.calories"}},
                    {"exists": {"field": "nutrition.protein_g"}},
                    {"exists": {"field": "nutrition.fat_total_g"}},
                    {"exists": {"field": "nutrition.carbohydrate_by_difference_g"}}
                ]
            }
        }
        
        # Painless„Çπ„ÇØ„É™„Éó„ÉàÔºöÊ≠£Ë¶èÂåñÈáç„Åø‰ªò„ÅëÈÄÜ„É¶„Éº„ÇØ„É™„ÉÉ„ÉâË∑ùÈõ¢
        nutrition_script = """
            // Target values from Gemini Phase 1
            double target_cal = params.target_nutrition_vector.calories;
            double target_pro = params.target_nutrition_vector.protein_g;
            double target_fat = params.target_nutrition_vector.fat_total_g;
            double target_carb = params.target_nutrition_vector.carbohydrate_by_difference_g;
            
            // Normalization factors
            double norm_cal = params.normalization_factors.calories;
            double norm_pro = params.normalization_factors.protein_g;
            double norm_fat = params.normalization_factors.fat_total_g;
            double norm_carb = params.normalization_factors.carbohydrate_by_difference_g;
            
            // Weights
            double w_cal = params.weights.calories;
            double w_pro = params.weights.protein_g;
            double w_fat = params.weights.fat_total_g;
            double w_carb = params.weights.carbohydrate_by_difference_g;
            
            // Calculate normalized differences
            double cal_diff = (doc['nutrition.calories'].value - target_cal) / norm_cal;
            double pro_diff = (doc['nutrition.protein_g'].value - target_pro) / norm_pro;
            double fat_diff = (doc['nutrition.fat_total_g'].value - target_fat) / norm_fat;
            double carb_diff = (doc['nutrition.carbohydrate_by_difference_g'].value - target_carb) / norm_carb;
            
            // Calculate weighted squared distance
            double dist_sq = w_cal * cal_diff * cal_diff +
                             w_pro * pro_diff * pro_diff +
                             w_fat * fat_diff * fat_diff +
                             w_carb * carb_diff * carb_diff;
            
            // Return inverse similarity score
            return 1.0 / (1.0 + Math.sqrt(dist_sq));
        """
        
        return {
            "filter": nutrition_filter,
            "script_score": {
                "script": {
                    "source": nutrition_script,
                    "params": {
                        "target_nutrition_vector": target_dict,
                        "normalization_factors": self.nutrition_normalization,
                        "weights": self.nutrition_weights
                    }
                }
            },
            "weight": es_config.nutritional_similarity_weight
        }
    
    def _build_popularity_boost_function(self) -> Dict[str, Any]:
        """
        ‰∫∫Ê∞óÂ∫¶Ôºànum_favoritesÔºâ„Å´„Çà„Çã„Éñ„Éº„Çπ„ÉàÈñ¢Êï∞„ÇíÊßãÁØâ
        
        Returns:
            ‰∫∫Ê∞óÂ∫¶„Éñ„Éº„Çπ„ÉàÈñ¢Êï∞
        """
        # üéØ „Çà„ÇäÂÆâÂÖ®„Åß„Ç∑„É≥„Éó„É´„Å™‰∫∫Ê∞óÂ∫¶„Éñ„Éº„Çπ„Éà
        popularity_script = """
            // num_favorites„Éï„Ç£„Éº„É´„Éâ„ÅÆÂ≠òÂú®Á¢∫Ë™ç„Å®ÂÆâÂÖ®„Å™„Ç¢„ÇØ„Çª„Çπ
            if (!doc.containsKey('num_favorites') || doc['num_favorites'].empty) {
                return 1.0; // „Éá„Éï„Ç©„É´„ÉàÔºà„Éñ„Éº„Çπ„Éà„Å™„ÅóÔºâ
            }
            
            // ÂÆâÂÖ®„Å´ÂÄ§„ÇíÂèñÂæó
            long favorites = doc['num_favorites'].value;
            
            // „Ç∑„É≥„Éó„É´„Å™ÊÆµÈöéÁöÑ„Éñ„Éº„Çπ„Éà
            if (favorites >= 1000) {
                return 1.2; // È´ò‰∫∫Ê∞ó
            } else if (favorites >= 100) {
                return 1.1; // ‰∏≠‰∫∫Ê∞ó  
            } else if (favorites >= 10) {
                return 1.05; // ‰Ωé‰∫∫Ê∞ó
            } else {
                return 1.0; // „Éñ„Éº„Çπ„Éà„Å™„Åó
            }
        """
        
        return {
            "script_score": {
                "script": {
                    "source": popularity_script
                }
            },
            "weight": es_config.popularity_boost_weight
        }
    
    def _parse_search_results(self, response: Dict[str, Any]) -> List[SearchResult]:
        """
        ElasticsearchÊ§úÁ¥¢ÁµêÊûú„ÇíËß£Êûê„Åó„Å¶SearchResult„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Å´Â§âÊèõ
        """
        results = []
        
        for hit in response.get("hits", {}).get("hits", []):
            source = hit.get("_source", {})
            
            # Ê†ÑÈ§äÊÉÖÂ†±„ÇíÂèñÂæó
            nutrition = source.get("nutrition", {})
            
            # Ê§úÁ¥¢ÁµêÊûú„ÇíÊßãÁØâ
            result = SearchResult(
                food_id=source.get("food_id", ""),
                fdc_id=source.get("fdc_id"),
                food_name=source.get("food_name", ""),
                description=source.get("description"),
                brand_name=source.get("brand_name"),
                category=source.get("category"),
                data_type=source.get("data_type"),
                num_favorites=source.get("num_favorites"),
                nutrition=nutrition,
                score=hit.get("_score", 0.0),
                explanation={
                    "total_score": hit.get("_score", 0.0),
                    "elasticsearch_score": hit.get("_score", 0.0)
                }
            )
            
            results.append(result)
        
        return results
    
    async def analyze_query_terms(self, query_text: str) -> List[str]:
        """
        È£üÂìÅÂêç„ÇØ„Ç®„É™„Çí„Ç´„Çπ„Çø„É†„Ç¢„Éä„É©„Ç§„Ç∂„Éº„ÅßÂàÜÊûê
        """
        try:
            tokens = await es_client.analyze_text(
                index_name=es_config.food_nutrition_index,
                analyzer="food_item_analyzer", 
                text=query_text
            )
            
            logger.debug(f"Query analysis: '{query_text}' -> {tokens}")
            return tokens or []
            
        except Exception as e:
            logger.error(f"Query analysis failed: {e}")
            return []


# „Ç∞„É≠„Éº„Éê„É´Ê§úÁ¥¢„Çµ„Éº„Éì„Çπ„Ç§„É≥„Çπ„Çø„É≥„Çπ
food_search_service = FoodSearchService() 