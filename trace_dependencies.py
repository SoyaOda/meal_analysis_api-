#!/usr/bin/env python3
"""
ä¾å­˜é–¢ä¿‚è¿½è·¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (æ”¹è‰¯ç‰ˆ)

test_local_nutrition_search_v2.pyãŒå®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¶²ç¾…çš„ã«ç‰¹å®šã—ã¾ã™ï¼š
1. é™çš„è§£æï¼šimportæ–‡ã®è§£æ
2. å‹•çš„è¿½è·¡ï¼šå®Ÿè¡Œæ™‚ã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
3. APIãƒ†ã‚¹ãƒˆå ´åˆï¼šå¯¾å¿œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼å´ä¾å­˜é–¢ä¿‚ã‚‚è¿½è·¡
"""

import ast
import os
import sys
import json
import importlib.util
from pathlib import Path
from typing import Set, List, Dict, Any

class DependencyTracer:
    def __init__(self, root_file: str, project_root: str = "."):
        self.root_file = root_file
        self.project_root = Path(project_root).resolve()
        self.traced_files: Set[Path] = set()
        self.data_files: Set[Path] = set()
        self.config_files: Set[Path] = set()
        self.import_errors: List[str] = []
        self.server_files: Set[Path] = set()  # ã‚µãƒ¼ãƒãƒ¼å´ãƒ•ã‚¡ã‚¤ãƒ«
        
    def trace_all_dependencies(self) -> Dict[str, List[str]]:
        """å…¨ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’è¿½è·¡"""
        print(f"ğŸ” Tracing dependencies for: {self.root_file}")
        print(f"ğŸ“ Project root: {self.project_root}")
        print("-" * 60)
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–‹å§‹
        root_path = Path(self.root_file).resolve()
        self._trace_python_file(root_path)
        
        # APIãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€ã‚µãƒ¼ãƒãƒ¼å´ã®ä¾å­˜é–¢ä¿‚ã‚‚è¿½è·¡
        if self._is_api_test_file(root_path):
            print("ğŸŒ Detected API test file - tracing server dependencies...")
            self._trace_server_dependencies()
        
        # çµæœã‚’åˆ†é¡
        project_files = []
        server_files = []
        external_files = []
        missing_files = []
        
        for file_path in self.traced_files:
            if file_path.exists():
                if self._is_in_project(file_path):
                    project_files.append(str(file_path.relative_to(self.project_root)))
                else:
                    external_files.append(str(file_path))
            else:
                missing_files.append(str(file_path))
        
        # ã‚µãƒ¼ãƒãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
        for file_path in self.server_files:
            if file_path.exists():
                server_files.append(str(file_path.relative_to(self.project_root)))
            else:
                missing_files.append(str(file_path))
        
        return {
            "project_python_files": sorted(project_files),
            "server_files": sorted(server_files),
            "data_files": sorted([str(f.relative_to(self.project_root)) for f in self.data_files if f.exists()]),
            "config_files": sorted([str(f.relative_to(self.project_root)) for f in self.config_files if f.exists()]),
            "external_files": sorted(external_files),
            "missing_files": sorted(missing_files),
            "import_errors": self.import_errors
        }
    
    def _is_api_test_file(self, file_path: Path) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãŒAPIãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            # APIãƒ†ã‚¹ãƒˆã®ç‰¹å¾´ã‚’æ¤œå‡º
            return ('requests.' in content and 
                    'BASE_URL' in content and 
                    ('localhost' in content or 'api/v1' in content))
        except:
            return False
    
    def _trace_server_dependencies(self):
        """ã‚µãƒ¼ãƒãƒ¼å´ã®ä¾å­˜é–¢ä¿‚ã‚’è¿½è·¡"""
        # app_v2ã®ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½è·¡
        app_paths = [
            self.project_root / "app_v2" / "main" / "app.py",
            self.project_root / "app_v2" / "api" / "routes.py", 
            self.project_root / "app_v2" / "api" / "meal_analysis.py",
            self.project_root / "app_v2" / "pipeline" / "orchestrator.py",
            self.project_root / "app_v2" / "components" / "local_nutrition_search.py",
            self.project_root / "app_v2" / "config" / "settings.py"
        ]
        
        # å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è¿½è·¡
        for app_file in app_paths:
            if app_file.exists():
                self._trace_server_file(app_file)
        
        # app_v2ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã‚’èµ°æŸ»
        app_v2_dir = self.project_root / "app_v2"
        if app_v2_dir.exists():
            for py_file in app_v2_dir.rglob("*.py"):
                if py_file.name != "__pycache__":
                    self._trace_server_file(py_file)
        
        # nutrition_db_experimentã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½è·¡
        self._trace_nutrition_db_data()
    
    def _trace_nutrition_db_data(self):
        """nutrition_db_experimentã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½è·¡"""
        nutrition_db_dir = self.project_root / "nutrition_db_experiment"
        if nutrition_db_dir.exists():
            print("ğŸ—ƒï¸ Tracing nutrition_db_experiment files...")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã¯è†¨å¤§ãªã®ã§é™¤å¤–
            # db_files = [
            #     "nutrition_db/dish_db.json",
            #     "nutrition_db/ingredient_db.json",
            #     "nutrition_db/branded_db.json",
            #     "nutrition_db/unified_nutrition_db.json"
            # ]
            # 
            # for db_file in db_files:
            #     db_path = nutrition_db_dir / db_file
            #     if db_path.exists():
            #         self.data_files.add(db_path)
            #         print(f"ğŸ—‚ï¸ Data file: {db_path.relative_to(self.project_root)}")
            
            # Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ï¼‰
            search_service_dir = nutrition_db_dir / "search_service"
            if search_service_dir.exists():
                for py_file in search_service_dir.rglob("*.py"):
                    if py_file.name != "__pycache__":
                        self._trace_server_file(py_file)
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            config_files = [
                "config.py",
                "settings.json",
                "nutrition_database_specification.md"
            ]
            
            for config_file in config_files:
                config_path = nutrition_db_dir / config_file
                if config_path.exists():
                    self.config_files.add(config_path)
                    print(f"âš™ï¸ Config file: {config_path.relative_to(self.project_root)}")
    
    def _trace_server_file(self, file_path: Path):
        """ã‚µãƒ¼ãƒãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½è·¡ã—ã€ãã®ä¾å­˜é–¢ä¿‚ã‚‚è§£æ"""
        if file_path in self.server_files or file_path in self.traced_files:
            return
            
        self.server_files.add(file_path)
        print(f"ğŸŒ Server file: {file_path.relative_to(self.project_root)}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ASTè§£æã§importæ–‡ã‚’æŠ½å‡º
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        self._resolve_server_import(alias.name, file_path)
                        
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        self._resolve_server_import(node.module, file_path, node.level)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ“ä½œã‚’æ¤œå‡º
                elif isinstance(node, ast.Call):
                    self._detect_file_operations(node, file_path)
                    
        except Exception as e:
            error_msg = f"Error parsing server file {file_path}: {str(e)}"
            print(f"âŒ {error_msg}")
            self.import_errors.append(error_msg)
    
    def _resolve_server_import(self, module_name: str, current_file: Path, level: int = 0):
        """ã‚µãƒ¼ãƒãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®importæ–‡ã‚’è§£æ±º"""
        try:
            if level > 0:  # ç›¸å¯¾import
                current_dir = current_file.parent
                for _ in range(level - 1):
                    current_dir = current_dir.parent
                
                if module_name:
                    module_path = current_dir / module_name.replace('.', '/')
                else:
                    module_path = current_dir
            else:  # çµ¶å¯¾import
                # app_v2å†…ã®importã‚’å„ªå…ˆ
                if module_name.startswith('app_v2.'):
                    module_path = self.project_root / module_name.replace('.', '/')
                else:
                    module_path = self.project_root / module_name.replace('.', '/')
                
                # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if not self._is_project_module(module_path):
                    return
            
            # Pythonãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è§£æ±ºã‚’è©¦è¡Œ
            possible_files = [
                module_path.with_suffix('.py'),
                module_path / '__init__.py'
            ]
            
            for py_file in possible_files:
                if py_file.exists() and self._is_in_project(py_file):
                    self._trace_server_file(py_file)
                    break
                    
        except Exception as e:
            error_msg = f"Error resolving server import '{module_name}': {str(e)}"
            self.import_errors.append(error_msg)
    
    def _trace_python_file(self, file_path: Path) -> None:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾å­˜é–¢ä¿‚ã‚’è¿½è·¡"""
        if file_path in self.traced_files:
            return
            
        if not file_path.exists():
            print(f"âŒ Missing: {file_path}")
            return
            
        self.traced_files.add(file_path)
        print(f"ğŸ“„ Tracing: {file_path.relative_to(self.project_root) if self._is_in_project(file_path) else file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ASTè§£æã§importæ–‡ã‚’æŠ½å‡º
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        self._resolve_import(alias.name, file_path)
                        
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        self._resolve_import(node.module, file_path, node.level)
                    
                # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ“ä½œã‚’æ¤œå‡º
                elif isinstance(node, ast.Call):
                    self._detect_file_operations(node, file_path)
                    
        except Exception as e:
            error_msg = f"Error parsing {file_path}: {str(e)}"
            print(f"âŒ {error_msg}")
            self.import_errors.append(error_msg)
    
    def _resolve_import(self, module_name: str, current_file: Path, level: int = 0) -> None:
        """importæ–‡ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è§£æ±º"""
        try:
            if level > 0:  # ç›¸å¯¾import
                # ç›¸å¯¾importã®è§£æ±º
                current_dir = current_file.parent
                for _ in range(level - 1):
                    current_dir = current_dir.parent
                
                if module_name:
                    module_path = current_dir / module_name.replace('.', '/')
                else:
                    module_path = current_dir
            else:  # çµ¶å¯¾import
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å„ªå…ˆ
                module_path = self.project_root / module_name.replace('.', '/')
                
                # æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ã®å ´åˆ
                if not self._is_project_module(module_path):
                    try:
                        spec = importlib.util.find_spec(module_name)
                        if spec and spec.origin and spec.origin != 'built-in':
                            external_path = Path(spec.origin)
                            if external_path.exists():
                                self.traced_files.add(external_path)
                    except (ImportError, ModuleNotFoundError):
                        pass
                    return
            
            # Pythonãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è§£æ±ºã‚’è©¦è¡Œ
            possible_files = [
                module_path.with_suffix('.py'),
                module_path / '__init__.py'
            ]
            
            for py_file in possible_files:
                if py_file.exists() and self._is_in_project(py_file):
                    self._trace_python_file(py_file)
                    break
                    
        except Exception as e:
            error_msg = f"Error resolving import '{module_name}': {str(e)}"
            self.import_errors.append(error_msg)
    
    def _detect_file_operations(self, node: ast.Call, current_file: Path) -> None:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œï¼ˆopen, json.loadç­‰ï¼‰ã‚’æ¤œå‡º"""
        try:
            # open() å‘¼ã³å‡ºã—
            if (isinstance(node.func, ast.Name) and node.func.id == 'open') or \
               (isinstance(node.func, ast.Attribute) and node.func.attr == 'open'):
                if node.args and isinstance(node.args[0], ast.Constant):
                    file_path = self._resolve_file_path(node.args[0].value, current_file)
                    if file_path:
                        self.data_files.add(file_path)
            
            # json.load, yaml.loadç­‰ã®æ¤œå‡º
            elif isinstance(node.func, ast.Attribute):
                if node.func.attr in ['load', 'loads', 'read_text', 'read_bytes']:
                    # å‰ã®å¼•æ•°ã‚’ç¢ºèªï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å¯èƒ½æ€§ï¼‰
                    for arg in node.args:
                        if isinstance(arg, ast.Constant) and isinstance(arg.value, str):
                            file_path = self._resolve_file_path(arg.value, current_file)
                            if file_path:
                                self.data_files.add(file_path)
                                
        except Exception:
            pass  # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã®æ¤œå‡ºã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
    
    def _resolve_file_path(self, path_str: str, current_file: Path) -> Path:
        """æ–‡å­—åˆ—ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«è§£æ±º"""
        path = Path(path_str)
        
        if path.is_absolute():
            return path
        else:
            # ç›¸å¯¾ãƒ‘ã‚¹ - ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ç›¸å¯¾ã¾ãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾
            candidates = [
                current_file.parent / path,
                self.project_root / path
            ]
            
            for candidate in candidates:
                if candidate.exists():
                    return candidate.resolve()
                    
            # å­˜åœ¨ã—ãªãã¦ã‚‚è¿½è·¡å¯¾è±¡ã¨ã—ã¦è¿”ã™
            return (current_file.parent / path).resolve()
    
    def _is_in_project(self, file_path: Path) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            file_path.relative_to(self.project_root)
            return True
        except ValueError:
            return False
    
    def _is_project_module(self, module_path: Path) -> bool:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ãƒã‚§ãƒƒã‚¯"""
        return module_path.exists() or (module_path.parent.exists() and 
                                        any(module_path.parent.glob(f"{module_path.name}.*")))

def create_enhanced_architecture_analyzer(dependencies: Dict[str, List[str]]) -> str:
    """ä¾å­˜é–¢ä¿‚è¿½è·¡çµæœã‚’åŸºã«æ”¹è‰¯ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ"""
    
    script_content = '''#!/usr/bin/env python3
"""
ãƒ­ãƒ¼ã‚«ãƒ«æ „é¤Šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æ (ä¾å­˜é–¢ä¿‚è¿½è·¡ç‰ˆ)

å®Ÿéš›ã«test_local_nutrition_search_v2.pyã‹ã‚‰è¿½è·¡ã•ã‚ŒãŸä¾å­˜é–¢ä¿‚ã«åŸºã¥ã„ã¦
æ­£ç¢ºãªãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import os
import datetime
from pathlib import Path
from typing import Dict, List

def get_file_content(file_path: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å®‰å…¨ã«èª­ã¿å–ã‚‹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"ERROR: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {str(e)}"

def analyze_traced_dependencies():
    """è¿½è·¡ã•ã‚ŒãŸä¾å­˜é–¢ä¿‚ã«åŸºã¥ãã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æ"""
    
    # å®Ÿéš›ã«è¿½è·¡ã•ã‚ŒãŸä¾å­˜é–¢ä¿‚
    traced_dependencies = ''' + repr(dependencies) + '''
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ©Ÿèƒ½åˆ¥ã«åˆ†é¡
    files_to_analyze = {
        "ğŸ¯ å®Ÿè¡Œèµ·ç‚¹ãƒ•ã‚¡ã‚¤ãƒ«": [
            "test_local_nutrition_search_v2.py"
        ],
        "ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…Pythonãƒ•ã‚¡ã‚¤ãƒ«": traced_dependencies["project_python_files"],
        "ğŸŒ ã‚µãƒ¼ãƒãƒ¼å´ãƒ•ã‚¡ã‚¤ãƒ«": traced_dependencies["server_files"],
        "âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«": traced_dependencies["config_files"]
    }
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"traced_nutrition_architecture_{timestamp}.txt"
    
    with open(output_file, 'w', encoding='utf-8') as out_f:
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        out_f.write("=" * 80 + "\\n")
        out_f.write("MEAL ANALYSIS API v2.0 - ä¾å­˜é–¢ä¿‚è¿½è·¡ç‰ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æ\\n")
        out_f.write("=" * 80 + "\\n")
        out_f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n")
        out_f.write(f"è¿½è·¡èµ·ç‚¹: test_local_nutrition_search_v2.py\\n")
        out_f.write(f"ç·è¿½è·¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(traced_dependencies['project_python_files']) + len(traced_dependencies['server_files']) + len(traced_dependencies['config_files'])}\\n")
        out_f.write("=" * 80 + "\\n\\n")
        
        # ä¾å­˜é–¢ä¿‚æ¦‚è¦
        out_f.write("ğŸ“Š DEPENDENCY TRACE SUMMARY\\n")
        out_f.write("-" * 40 + "\\n")
        out_f.write(f"âœ… Project Python Files: {len(traced_dependencies['project_python_files'])}\\n")
        out_f.write(f"ğŸŒ Server Files: {len(traced_dependencies['server_files'])}\\n")
        out_f.write(f"âš™ï¸ Config Files: {len(traced_dependencies['config_files'])}\\n")
        out_f.write(f"ğŸ—ƒï¸ Data Files (excluded): {len(traced_dependencies['data_files'])}\\n")
        out_f.write(f"ğŸŒ External Files: {len(traced_dependencies['external_files'])}\\n")
        out_f.write(f"âŒ Missing Files: {len(traced_dependencies['missing_files'])}\\n")
        if traced_dependencies['import_errors']:
            out_f.write(f"âš ï¸ Import Errors: {len(traced_dependencies['import_errors'])}\\n")
        out_f.write("\\n")
        
        # ã‚¨ãƒ©ãƒ¼ã¨æ¬ æãƒ•ã‚¡ã‚¤ãƒ«ã®å ±å‘Š
        if traced_dependencies['missing_files']:
            out_f.write("âŒ MISSING FILES\\n")
            out_f.write("-" * 20 + "\\n")
            for missing in traced_dependencies['missing_files']:
                out_f.write(f"- {missing}\\n")
            out_f.write("\\n")
        
        if traced_dependencies['import_errors']:
            out_f.write("âš ï¸ IMPORT ERRORS\\n")
            out_f.write("-" * 20 + "\\n")
            for error in traced_dependencies['import_errors']:
                out_f.write(f"- {error}\\n")
            out_f.write("\\n")
        
        # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        for category, file_list in files_to_analyze.items():
            if not file_list:
                continue
                
            out_f.write(f"{category}\\n")
            out_f.write("=" * 60 + "\\n\\n")
            
            for file_path in file_list:
                out_f.write(f"ğŸ“„ FILE: {file_path}\\n")
                out_f.write("-" * 50 + "\\n")
                
                if os.path.exists(file_path):
                    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
                    file_stat = os.stat(file_path)
                    file_size = file_stat.st_size
                    mod_time = datetime.datetime.fromtimestamp(file_stat.st_mtime)
                    
                    out_f.write(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes\\n")
                    out_f.write(f"æœ€çµ‚æ›´æ–°: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}\\n")
                    out_f.write(f"å­˜åœ¨: âœ…\\n\\n")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯åˆ¶é™ï¼‰
                    if file_path.endswith('.json') and file_size > 1024*1024:  # 1MBä»¥ä¸Šã®JSONã¯æ¦‚è¦ã®ã¿
                        out_f.write("CONTENT: (Large JSON file - showing structure only)\\n")
                        try:
                            import json
                            with open(file_path, 'r') as f:
                                data = json.load(f)
                            if isinstance(data, list):
                                out_f.write(f"Array with {len(data)} items\\n")
                                if data:
                                    out_f.write(f"Sample item keys: {list(data[0].keys()) if isinstance(data[0], dict) else 'Non-dict items'}\\n")
                            elif isinstance(data, dict):
                                out_f.write(f"Object with keys: {list(data.keys())}\\n")
                        except:
                            out_f.write("Could not parse JSON structure\\n")
                    else:
                        out_f.write("CONTENT:\\n")
                        out_f.write("```\\n")
                        content = get_file_content(file_path)
                        out_f.write(content)
                        out_f.write("\\n```\\n")
                    out_f.write("\\n")
                else:
                    out_f.write("å­˜åœ¨: âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\\n\\n")
                
                out_f.write("=" * 60 + "\\n\\n")
        
        # çµ±è¨ˆæƒ…å ±
        out_f.write("ğŸ“Š ANALYSIS STATISTICS\\n")
        out_f.write("-" * 40 + "\\n")
        total_files = sum(len(files) for files in files_to_analyze.values() if files)
        existing_files = sum(1 for files in files_to_analyze.values() if files for f in files if os.path.exists(f))
        
        out_f.write(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}\\n")
        out_f.write(f"å­˜åœ¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {existing_files}\\n")
        out_f.write(f"åˆ†æå®Œäº†æ™‚åˆ»: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n")
        out_f.write("\\nã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€test_local_nutrition_search_v2.pyå®Ÿè¡Œæ™‚ã«\\n")
        out_f.write("å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã‚‹å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\\n")
        
    return output_file, total_files, existing_files

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” ä¾å­˜é–¢ä¿‚è¿½è·¡ç‰ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æé–‹å§‹...")
    print("-" * 60)
    
    try:
        output_file, total_files, existing_files = analyze_traced_dependencies()
        
        print(f"âœ… åˆ†æå®Œäº†!")
        print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
        print(f"ğŸ“Š ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
        print(f"âœ… å­˜åœ¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {existing_files}")
        
        if existing_files < total_files:
            missing = total_files - existing_files
            print(f"âš ï¸  è¦‹ã¤ã‹ã‚‰ãªã„ãƒ•ã‚¡ã‚¤ãƒ«: {missing}å€‹")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
        if os.path.exists(output_file):
            file_size = os.path.getsize(output_file)
            print(f"ğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes")
        
        print("\\nğŸ‰ ä¾å­˜é–¢ä¿‚è¿½è·¡ç‰ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ!")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
'''
    
    return script_content

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    if len(sys.argv) < 2:
        print("Usage: python trace_dependencies.py <target_file>")
        print("Example: python trace_dependencies.py test_local_nutrition_search_v2.py")
        sys.exit(1)
    
    target_file = sys.argv[1]
    
    if not os.path.exists(target_file):
        print(f"âŒ Target file not found: {target_file}")
        sys.exit(1)
    
    # ä¾å­˜é–¢ä¿‚ã‚’è¿½è·¡
    tracer = DependencyTracer(target_file)
    dependencies = tracer.trace_all_dependencies()
    
    # çµæœã‚’è¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ“Š DEPENDENCY TRACE RESULTS")
    print("="*60)
    
    for category, files in dependencies.items():
        if files:
            print(f"\n{category.upper()} ({len(files)}):")
            for file in files[:10]:  # æœ€åˆã®10å€‹ã®ã¿è¡¨ç¤º
                print(f"  - {file}")
            if len(files) > 10:
                print(f"  ... and {len(files) - 10} more")
    
    # æ”¹è‰¯ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ
    script_content = create_enhanced_architecture_analyzer(dependencies)
    
    output_script = "analyze_traced_architecture.py"
    with open(output_script, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"\nâœ… Enhanced architecture analyzer created: {output_script}")
    print(f"ğŸš€ Run it with: python {output_script}")

if __name__ == "__main__":
    main() 