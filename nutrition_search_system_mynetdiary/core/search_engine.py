"""
æ „é¤Šæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ - 7æ®µéšŽæ¤œç´¢æˆ¦ç•¥ã¨è¦‹å‡ºã—èªžåŒ–æ©Ÿèƒ½
"""

import logging
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional

from .models import SearchQuery, SearchResponse, SearchResult, NutritionInfo, BatchSearchQuery, BatchSearchResponse
from utils.lemmatization import lemmatize_term, create_lemmatized_query_variations
from utils.elasticsearch_client import get_elasticsearch_client

logger = logging.getLogger(__name__)


class NutritionSearchEngine:
    """æ „é¤Šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.es_client = get_elasticsearch_client()
        
        # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.lemmatized_exact_match_boost = 2.0
        self.compound_word_penalty = 0.8
        self.enable_lemmatization = True
        
        # çµ±è¨ˆ
        self.total_searches = 0
        self.total_response_time = 0
        
        logger.info("ðŸ” NutritionSearchEngine initialized")
    
    async def search(self, query: SearchQuery) -> SearchResponse:
        """å˜ä¸€æ¤œç´¢å®Ÿè¡Œ"""
        start_time = datetime.now()
        
        if not self.es_client.is_connected():
            return SearchResponse(
                query=query.query,
                results=[],
                total_found=0,
                search_time_ms=0,
                lemmatized_query=None
            )
        
        # è¦‹å‡ºã—èªžåŒ–å‡¦ç†
        lemmatized_query = lemmatize_term(query.query) if self.enable_lemmatization else query.query
        
        # 7æ®µéšŽæ¤œç´¢ã‚¯ã‚¨ãƒªæ§‹ç¯‰
        es_query = self._build_advanced_search_query(query.query, lemmatized_query, query.max_results)
        
        # Elasticsearchæ¤œç´¢å®Ÿè¡Œ
        response = await self.es_client.search(es_query)
        
        # çµæžœå¤‰æ›
        results = []
        if response and response.get('hits', {}).get('hits'):
            results = self._convert_es_results(response['hits']['hits'], query.query, lemmatized_query)
            
            # ã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            results = [r for r in results if r.score >= query.min_score]
            
            # ã‚½ãƒ¼ã‚¹DBãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if query.source_db_filter:
                results = [r for r in results if r.source_db in query.source_db_filter]
        
        # çµ±è¨ˆæ›´æ–°
        end_time = datetime.now()
        search_time_ms = int((end_time - start_time).total_seconds() * 1000)
        self.total_searches += 1
        self.total_response_time += search_time_ms
        
        return SearchResponse(
            query=query.query,
            results=results,
            total_found=len(results),
            search_time_ms=search_time_ms,
            lemmatized_query=lemmatized_query if lemmatized_query != query.query else None
        )
    
    async def batch_search(self, batch_query: BatchSearchQuery) -> BatchSearchResponse:
        """ãƒãƒƒãƒæ¤œç´¢å®Ÿè¡Œ"""
        start_time = datetime.now()
        
        # ä¸¦åˆ—æ¤œç´¢å®Ÿè¡Œ
        search_tasks = []
        for query_text in batch_query.queries:
            search_query = SearchQuery(
                query=query_text,
                max_results=batch_query.max_results
            )
            search_tasks.append(self.search(search_query))
        
        responses = await asyncio.gather(*search_tasks)
        
        # çµ±è¨ˆæƒ…å ±ä½œæˆ
        end_time = datetime.now()
        total_search_time_ms = int((end_time - start_time).total_seconds() * 1000)
        
        total_results = sum(len(r.results) for r in responses)
        successful_searches = sum(1 for r in responses if len(r.results) > 0)
        
        summary = {
            "total_queries": len(batch_query.queries),
            "successful_searches": successful_searches,
            "total_results": total_results,
            "average_results_per_query": total_results / len(batch_query.queries) if batch_query.queries else 0,
            "match_rate_percent": (successful_searches / len(batch_query.queries) * 100) if batch_query.queries else 0
        }
        
        return BatchSearchResponse(
            queries=batch_query.queries,
            responses=responses,
            total_search_time_ms=total_search_time_ms,
            summary=summary
        )
    
    def _build_advanced_search_query(self, original_term: str, lemmatized_term: str, max_results: int) -> Dict[str, Any]:
        """7æ®µéšŽæ¤œç´¢æˆ¦ç•¥ã®Elasticsearchã‚¯ã‚¨ãƒªæ§‹ç¯‰"""
        
        bool_query = {
            "bool": {
                "should": [
                    # 1. è¦‹å‡ºã—èªžåŒ–å®Œå…¨ä¸€è‡´ï¼ˆæœ€é«˜ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰
                    {
                        "match": {
                            "search_name_lemmatized.exact": {
                                "query": lemmatized_term,
                                "boost": self.lemmatized_exact_match_boost * 3.0
                            }
                        }
                    },
                    # 2. è¦‹å‡ºã—èªžåŒ–ä¸€è‡´ï¼ˆé«˜ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰
                    {
                        "match": {
                            "search_name_lemmatized": {
                                "query": lemmatized_term,
                                "boost": self.lemmatized_exact_match_boost * 2.0
                            }
                        }
                    },
                    # 3. å…ƒã®èªžã§ã®å®Œå…¨ä¸€è‡´
                    {
                        "match": {
                            "search_name.exact": {
                                "query": original_term,
                                "boost": 1.8
                            }
                        }
                    },
                    # 4. å…ƒã®èªžã§ã®ä¸€è‡´
                    {
                        "match": {
                            "search_name": {
                                "query": original_term,
                                "boost": 1.5
                            }
                        }
                    },
                    # 5. è¦‹å‡ºã—èªžåŒ–éƒ¨åˆ†ä¸€è‡´
                    {
                        "match_phrase": {
                            "search_name_lemmatized": {
                                "query": lemmatized_term,
                                "boost": self.lemmatized_exact_match_boost
                            }
                        }
                    },
                    # 6. å…ƒã®èªžã§ã®éƒ¨åˆ†ä¸€è‡´
                    {
                        "match_phrase": {
                            "search_name": {
                                "query": original_term,
                                "boost": 1.0
                            }
                        }
                    },
                    # 7. ã‚ã„ã¾ã„æ¤œç´¢ï¼ˆtypoå¯¾å¿œï¼‰
                    {
                        "fuzzy": {
                            "search_name_lemmatized": {
                                "value": lemmatized_term,
                                "fuzziness": "AUTO",
                                "boost": 0.5
                            }
                        }
                    }
                ],
                "minimum_should_match": 1
            }
        }
        
        return {
            "query": bool_query,
            "size": max_results * 2,  # ã‚¹ã‚³ã‚¢èª¿æ•´å¾Œã«çµžã‚Šè¾¼ã‚€ãŸã‚å¤šã‚ã«å–å¾—
            "_source": ["id", "search_name", "description", "data_type", "nutrition", "source_db"]
        }
    
    def _convert_es_results(self, es_hits: List[Dict[str, Any]], original_term: str, lemmatized_term: str) -> List[SearchResult]:
        """Elasticsearchçµæžœã‚’SearchResultã«å¤‰æ›"""
        results = []
        
        for hit in es_hits:
            source = hit['_source']
            
            # æ „é¤Šæƒ…å ±å¤‰æ›
            nutrition_data = source.get('nutrition', {})
            nutrition = NutritionInfo(**nutrition_data)
            
            # ãƒžãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¤å®š
            match_type = self._determine_match_type(
                source.get('search_name', ''),
                source.get('search_name_lemmatized', ''),
                original_term,
                lemmatized_term
            )
            
            # ã‚¹ã‚³ã‚¢èª¿æ•´
            adjusted_score = self._calculate_adjusted_score(
                hit['_score'],
                original_term,
                lemmatized_term,
                source.get('search_name', ''),
                source.get('search_name_lemmatized', ''),
                match_type
            )
            
            result = SearchResult(
                id=str(source.get('id', '')),
                name=source.get('search_name', ''),
                description=source.get('description', ''),
                nutrition=nutrition,
                source_db=source.get('source_db', ''),
                score=adjusted_score,
                match_type=match_type
            )
            
            results.append(result)
        
        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x.score, reverse=True)
        
        return results
    
    def _determine_match_type(self, db_name: str, db_name_lemmatized: str, original_term: str, lemmatized_term: str) -> str:
        """ãƒžãƒƒãƒã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        db_name_lower = db_name.lower()
        db_lemmatized_lower = db_name_lemmatized.lower()
        original_lower = original_term.lower()
        lemmatized_lower = lemmatized_term.lower()
        
        if db_name_lower == original_lower or db_lemmatized_lower == lemmatized_lower:
            return "exact"
        elif db_lemmatized_lower == lemmatized_lower:
            return "lemmatized"
        elif original_lower in db_name_lower or lemmatized_lower in db_lemmatized_lower:
            return "partial"
        else:
            return "fuzzy"
    
    def _calculate_adjusted_score(
        self, 
        base_score: float, 
        original_term: str, 
        lemmatized_term: str, 
        db_name: str, 
        db_name_lemmatized: str, 
        match_type: str
    ) -> float:
        """ã‚¹ã‚³ã‚¢èª¿æ•´è¨ˆç®—"""
        
        # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢èª¿æ•´
        if match_type == "exact":
            adjustment = self.lemmatized_exact_match_boost
        elif match_type == "lemmatized":
            adjustment = self.lemmatized_exact_match_boost * 0.9
        elif match_type == "partial":
            adjustment = 0.8
        else:  # fuzzy
            adjustment = 0.5
        
        # è¤‡åˆèªžãƒšãƒŠãƒ«ãƒ†ã‚£
        if len(original_term.split()) > 1:
            adjustment *= self.compound_word_penalty
        
        return base_score * adjustment
    
    def get_stats(self) -> Dict[str, Any]:
        """æ¤œç´¢çµ±è¨ˆå–å¾—"""
        avg_response_time = (self.total_response_time / self.total_searches) if self.total_searches > 0 else 0
        
        return {
            "total_searches": self.total_searches,
            "average_response_time_ms": avg_response_time,
            "total_documents": self.es_client.get_total_documents(),
            "elasticsearch_health": self.es_client.get_index_stats()
        } 