"""
Ê†ÑÈ§äÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥ - 7ÊÆµÈöéÊ§úÁ¥¢Êà¶Áï•„Å®Ë¶ãÂá∫„ÅóË™ûÂåñÊ©üËÉΩ
"""

import logging
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional

from .models import SearchQuery, SearchResponse, SearchResult, NutritionInfo, BatchSearchQuery, BatchSearchResponse
from utils.lemmatization import lemmatize_term, create_lemmatized_query_variations
from utils.elasticsearch_client import get_elasticsearch_client

logger = logging.getLogger(__name__)


class NutritionSearchEngine:
    """Ê†ÑÈ§ä„Éá„Éº„Çø„Éô„Éº„ÇπÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥"""
    
    def __init__(self):
        self.es_client = get_elasticsearch_client()
        
        # Ê§úÁ¥¢„Éë„É©„É°„Éº„Çø
        self.lemmatized_exact_match_boost = 2.0
        self.compound_word_penalty = 0.8
        self.enable_lemmatization = True
        
        # Áµ±Ë®à
        self.total_searches = 0
        self.total_response_time = 0
        
        logger.info("üîç NutritionSearchEngine initialized")
    
    async def search(self, query: SearchQuery) -> SearchResponse:
        """Âçò‰∏ÄÊ§úÁ¥¢ÂÆüË°å"""
        start_time = datetime.now()
        
        if not self.es_client.is_connected():
            return SearchResponse(
                query=query.query,
                results=[],
                total_found=0,
                search_time_ms=0,
                lemmatized_query=None
            )
        
        # Ë¶ãÂá∫„ÅóË™ûÂåñÂá¶ÁêÜ
        lemmatized_query = lemmatize_term(query.query) if self.enable_lemmatization else query.query
        
        # 7ÊÆµÈöéÊ§úÁ¥¢„ÇØ„Ç®„É™ÊßãÁØâ
        es_query = self._build_advanced_search_query(query.query, lemmatized_query, query.max_results)
        
        # ElasticsearchÊ§úÁ¥¢ÂÆüË°å
        response = await self.es_client.search(es_query)
        
        # ÁµêÊûúÂ§âÊèõ
        results = []
        if response and response.get('hits', {}).get('hits'):
            results = self._convert_es_results(response['hits']['hits'], query.query, lemmatized_query)
            
            # „Çπ„Ç≥„Ç¢„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
            results = [r for r in results if r.score >= query.min_score]
            
            # „ÇΩ„Éº„ÇπDB„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
            if query.source_db_filter:
                results = [r for r in results if r.source_db in query.source_db_filter]
        
        # Áµ±Ë®àÊõ¥Êñ∞
        end_time = datetime.now()
        search_time_ms = int((end_time - start_time).total_seconds() * 1000)
        self.total_searches += 1
        self.total_response_time += search_time_ms
        
        return SearchResponse(
            query=query.query,
            results=results,
            total_found=len(results),
            search_time_ms=search_time_ms,
            lemmatized_query=lemmatized_query if lemmatized_query != query.query else None
        )
    
    async def batch_search(self, batch_query: BatchSearchQuery) -> BatchSearchResponse:
        """„Éê„ÉÉ„ÉÅÊ§úÁ¥¢ÂÆüË°å"""
        start_time = datetime.now()
        
        # ‰∏¶ÂàóÊ§úÁ¥¢ÂÆüË°å
        search_tasks = []
        for query_text in batch_query.queries:
            search_query = SearchQuery(
                query=query_text,
                max_results=batch_query.max_results
            )
            search_tasks.append(self.search(search_query))
        
        responses = await asyncio.gather(*search_tasks)
        
        # Áµ±Ë®àÊÉÖÂ†±‰ΩúÊàê
        end_time = datetime.now()
        total_search_time_ms = int((end_time - start_time).total_seconds() * 1000)
        
        total_results = sum(len(r.results) for r in responses)
        successful_searches = sum(1 for r in responses if len(r.results) > 0)
        
        summary = {
            "total_queries": len(batch_query.queries),
            "successful_searches": successful_searches,
            "total_results": total_results,
            "average_results_per_query": total_results / len(batch_query.queries) if batch_query.queries else 0,
            "match_rate_percent": (successful_searches / len(batch_query.queries) * 100) if batch_query.queries else 0
        }
        
        return BatchSearchResponse(
            queries=batch_query.queries,
            responses=responses,
            total_search_time_ms=total_search_time_ms,
            summary=summary
        )
    
    def _build_advanced_search_query(self, original_term: str, lemmatized_term: str, max_results: int) -> Dict[str, Any]:
        """7ÊÆµÈöéÊ§úÁ¥¢Êà¶Áï•„ÅÆElasticsearch„ÇØ„Ç®„É™ÊßãÁØâ"""
        
        bool_query = {
            "bool": {
                "should": [
                    # 1. Ë¶ãÂá∫„ÅóË™ûÂåñÂÆåÂÖ®‰∏ÄËá¥ÔºàÊúÄÈ´ò„Éñ„Éº„Çπ„ÉàÔºâ
                    {
                        "match": {
                            "search_name_lemmatized.exact": {
                                "query": lemmatized_term,
                                "boost": self.lemmatized_exact_match_boost * 3.0
                            }
                        }
                    },
                    # 2. Ë¶ãÂá∫„ÅóË™ûÂåñ‰∏ÄËá¥ÔºàÈ´ò„Éñ„Éº„Çπ„ÉàÔºâ
                    {
                        "match": {
                            "search_name_lemmatized": {
                                "query": lemmatized_term,
                                "boost": self.lemmatized_exact_match_boost * 2.0
                            }
                        }
                    },
                    # 3. ÂÖÉ„ÅÆË™û„Åß„ÅÆÂÆåÂÖ®‰∏ÄËá¥
                    {
                        "match": {
                            "search_name.exact": {
                                "query": original_term,
                                "boost": 1.8
                            }
                        }
                    },
                    # 4. ÂÖÉ„ÅÆË™û„Åß„ÅÆ‰∏ÄËá¥
                    {
                        "match": {
                            "search_name": {
                                "query": original_term,
                                "boost": 1.5
                            }
                        }
                    },
                    # 5. Ë¶ãÂá∫„ÅóË™ûÂåñÈÉ®ÂàÜ‰∏ÄËá¥
                    {
                        "match_phrase": {
                            "search_name_lemmatized": {
                                "query": lemmatized_term,
                                "boost": self.lemmatized_exact_match_boost
                            }
                        }
                    },
                    # 6. ÂÖÉ„ÅÆË™û„Åß„ÅÆÈÉ®ÂàÜ‰∏ÄËá¥
                    {
                        "match_phrase": {
                            "search_name": {
                                "query": original_term,
                                "boost": 1.0
                            }
                        }
                    },
                    # 7. „ÅÇ„ÅÑ„Åæ„ÅÑÊ§úÁ¥¢ÔºàtypoÂØæÂøúÔºâ
                    {
                        "fuzzy": {
                            "search_name_lemmatized": {
                                "value": lemmatized_term,
                                "fuzziness": "AUTO",
                                "boost": 0.5
                            }
                        }
                    }
                ],
                "minimum_should_match": 1
            }
        }
        
        return {
            "query": bool_query,
            "size": max_results * 2,  # „Çπ„Ç≥„Ç¢Ë™øÊï¥Âæå„Å´Áµû„ÇäËæº„ÇÄ„Åü„ÇÅÂ§ö„ÇÅ„Å´ÂèñÂæó
            "_source": ["id", "search_name", "description", "data_type", "nutrition", "source_db"]
        }
    
    def _convert_es_results(self, es_hits: List[Dict[str, Any]], original_term: str, lemmatized_term: str) -> List[SearchResult]:
        """ElasticsearchÁµêÊûú„ÇíSearchResult„Å´Â§âÊèõ"""
        results = []
        
        for hit in es_hits:
            source = hit['_source']
            
            # Ê†ÑÈ§äÊÉÖÂ†±Â§âÊèõ
            nutrition_data = source.get('nutrition', {})
            nutrition = NutritionInfo(**nutrition_data)
            
            # „Éû„ÉÉ„ÉÅ„Çø„Ç§„ÉóÂà§ÂÆö
            match_type = self._determine_match_type(
                source.get('search_name', ''),
                source.get('search_name_lemmatized', ''),
                original_term,
                lemmatized_term
            )
            
            # „Çπ„Ç≥„Ç¢Ë™øÊï¥
            adjusted_score = self._calculate_adjusted_score(
                hit['_score'],
                original_term,
                lemmatized_term,
                source.get('search_name', ''),
                source.get('search_name_lemmatized', ''),
                match_type
            )
            
            result = SearchResult(
                id=str(source.get('id', '')),
                name=source.get('search_name', ''),
                description=source.get('description', ''),
                nutrition=nutrition,
                source_db=source.get('source_db', ''),
                score=adjusted_score,
                match_type=match_type
            )
            
            results.append(result)
        
        # „Çπ„Ç≥„Ç¢È†Ü„Åß„ÇΩ„Éº„Éà
        results.sort(key=lambda x: x.score, reverse=True)
        
        return results
    
    def _determine_match_type(self, db_name: str, db_name_lemmatized: str, original_term: str, lemmatized_term: str) -> str:
        """„Éû„ÉÉ„ÉÅ„Çø„Ç§„Éó„ÇíÂà§ÂÆö"""
        db_name_lower = db_name.lower()
        db_lemmatized_lower = db_name_lemmatized.lower()
        original_lower = original_term.lower()
        lemmatized_lower = lemmatized_term.lower()
        
        if db_name_lower == original_lower or db_lemmatized_lower == lemmatized_lower:
            return "exact"
        elif db_lemmatized_lower == lemmatized_lower:
            return "lemmatized"
        elif original_lower in db_name_lower or lemmatized_lower in db_lemmatized_lower:
            return "partial"
        else:
            return "fuzzy"
    
    def _calculate_adjusted_score(
        self, 
        base_score: float, 
        original_term: str, 
        lemmatized_term: str, 
        db_name: str, 
        db_name_lemmatized: str, 
        match_type: str
    ) -> float:
        """„Çπ„Ç≥„Ç¢Ë™øÊï¥Ë®àÁÆó"""
        
        # „Éô„Éº„Çπ„Çπ„Ç≥„Ç¢Ë™øÊï¥
        if match_type == "exact":
            adjustment = self.lemmatized_exact_match_boost
        elif match_type == "lemmatized":
            adjustment = self.lemmatized_exact_match_boost * 0.9
        elif match_type == "partial":
            adjustment = 0.8
        else:  # fuzzy
            adjustment = 0.5
        
        # Ë§áÂêàË™û„Éö„Éä„É´„ÉÜ„Ç£
        if len(original_term.split()) > 1:
            adjustment *= self.compound_word_penalty
        
        return base_score * adjustment
    
    def get_stats(self) -> Dict[str, Any]:
        """Ê§úÁ¥¢Áµ±Ë®àÂèñÂæó"""
        avg_response_time = (self.total_response_time / self.total_searches) if self.total_searches > 0 else 0
        
        return {
            "total_searches": self.total_searches,
            "average_response_time_ms": avg_response_time,
            "total_documents": self.es_client.get_total_documents(),
            "elasticsearch_health": self.es_client.get_index_stats()
        } 