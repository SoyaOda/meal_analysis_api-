#!/usr/bin/env python3
"""
Comprehensive Nutrition Search Systems Test Script

READMEã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ä¸¡æ–¹ã®æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ†ã‚¹ãƒˆ:
1. MyNetDiary System (mynetdiary_list_support_db & mynetdiary_tool_calls_db)
2. Multi-Database System (usda_food_db)

test_mynetdiary_tool_calls_db.py ã¨åŒæ§˜ã®è©³ç´°ãªãƒ†ã‚¹ãƒˆå‡ºåŠ›ã‚’æä¾›
"""

import requests
import json
import os
import sys
from datetime import datetime
from typing import List, Dict, Any, Optional

# Elasticsearchç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ç”¨
ELASTICSEARCH_URL = "http://localhost:9200"

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆREADMEã‹ã‚‰ï¼‰
INDICES = {
    "mynetdiary_list_support": "mynetdiary_list_support_db",
    "mynetdiary_tool_calls": "mynetdiary_tool_calls_db",
    "usda_food": "usda_food_db",
    "mynetdiary_fixed": "mynetdiary_fixed_db"
}

def check_elasticsearch_connection() -> bool:
    """Elasticsearchã®æ¥ç¶šã‚’ç¢ºèª"""
    try:
        response = requests.get(ELASTICSEARCH_URL)
        return response.status_code == 200
    except Exception as e:
        print(f"âŒ Elasticsearchæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return False

def get_available_indices() -> List[str]:
    """ä½¿ç”¨å¯èƒ½ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
    try:
        response = requests.get(f"{ELASTICSEARCH_URL}/_cat/indices?format=json")
        if response.status_code == 200:
            indices_data = response.json()
            return [idx["index"] for idx in indices_data if not idx["index"].startswith(".")]
        return []
    except Exception as e:
        print(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def elasticsearch_search(index_name: str, query: str, size: int = 10) -> Dict[str, Any]:
    """Elasticsearchã«ç›´æ¥ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ"""

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã”ã¨ã«æœ€é©åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªæ§‹æˆ
    if "mynetdiary" in index_name:
        # MyNetDiaryã‚·ã‚¹ãƒ†ãƒ ç”¨ï¼ˆREADMEã®7æ®µéšæ¤œç´¢æˆ¦ç•¥ + search_name_listé…åˆ—å¯¾å¿œï¼‰
        search_body = {
            "query": {
                "bool": {
                    "should": [
                        # 1. Exact Match (search_name_listé…åˆ—è¦ç´ ) - Score: 15+
                        {"match_phrase": {"search_name_list": {"query": query, "boost": 15}}},
                        # 1b. Exact Match (search_nameæ–‡å­—åˆ—) - Score: 15+ (fallback)
                        {"match_phrase": {"search_name": {"query": query, "boost": 15}}},

                        # 2. Exact Match (description) - Score: 12+
                        {"match_phrase": {"description": {"query": query, "boost": 12}}},

                        # 3. Phrase Match (search_name_listé…åˆ—è¦ç´ ) - Score: 10+
                        {"match": {"search_name_list": {"query": query, "boost": 10}}},
                        # 3b. Phrase Match (search_nameæ–‡å­—åˆ—) - Score: 10+ (fallback)
                        {"match": {"search_name": {"query": query, "boost": 10}}},

                        # 4. Phrase Match (description) - Score: 8+
                        {"match": {"description": {"query": query, "boost": 8}}},

                        # 5. Term Match (search_name_listè¦ç´ ã®å®Œå…¨ä¸€è‡´) - Score: 6+
                        {"term": {"search_name_list.keyword": {"value": query.lower(), "boost": 6}}},
                        # 5b. Term Match (search_nameæ–‡å­—åˆ—ã®å®Œå…¨ä¸€è‡´) - Score: 6+ (fallback)
                        {"term": {"search_name.keyword": {"value": query.lower(), "boost": 6}}},

                        # 6. Multi-field match (é…åˆ—ã¨æ–‡å­—åˆ—ä¸¡å¯¾å¿œ) - Score: 4+
                        {"multi_match": {
                            "query": query,
                            "fields": ["search_name_list^3", "search_name^3", "description^2", "original_name"],
                            "boost": 4
                        }},

                        # 7. Fuzzy Match (search_name_listé…åˆ—è¦ç´ ) - Score: 2+
                        {"fuzzy": {"search_name_list": {"value": query, "boost": 2}}},
                        # 7b. Fuzzy Match (search_nameæ–‡å­—åˆ—) - Score: 2+ (fallback)
                        {"fuzzy": {"search_name": {"value": query, "boost": 2}}}
                    ]
                }
            },
            "size": size
        }
    else:
        # åŸºæœ¬çš„ãªãƒãƒ«ãƒãƒãƒƒãƒã‚¯ã‚¨ãƒªï¼ˆMulti-DBã‚·ã‚¹ãƒ†ãƒ ç”¨ï¼‰
        search_body = {
            "query": {
                "multi_match": {
                    "query": query,
                    "fields": ["name^3", "description^2", "category", "ingredients"]
                }
            },
            "size": size
        }

    try:
        response = requests.post(
            f"{ELASTICSEARCH_URL}/{index_name}/_search",
            headers={"Content-Type": "application/json"},
            data=json.dumps(search_body)
        )
        return response.json()
    except Exception as e:
        return {"error": str(e)}

def format_nutrition_info(nutrition: Dict[str, Any]) -> str:
    """æ „é¤Šæƒ…å ±ã‚’è¦‹ã‚„ã™ã„å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if not nutrition:
        return "æ „é¤Šæƒ…å ±ãªã—"

    # MyNetDiaryå½¢å¼
    if "calories" in nutrition:
        return f"ğŸ½ {nutrition.get('calories', 0):.1f}kcal | ğŸ¥© {nutrition.get('protein', 0):.1f}g | ğŸ {nutrition.get('carbs', 0):.1f}g | ğŸ§ˆ {nutrition.get('fat', 0):.1f}g"

    # USDAå½¢å¼ï¼ˆç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®å¯èƒ½æ€§ï¼‰
    elif "energy" in nutrition:
        return f"ğŸ½ {nutrition.get('energy', 0):.1f}kcal | ğŸ¥© {nutrition.get('protein', 0):.1f}g | ğŸ {nutrition.get('carbohydrate', 0):.1f}g | ğŸ§ˆ {nutrition.get('fat', 0):.1f}g"

    # ãã®ä»–ã®å½¢å¼
    else:
        key_nutrients = ["calories", "energy", "protein", "carbs", "carbohydrate", "fat", "fiber", "sodium"]
        found_nutrients = [f"{k}: {v}" for k, v in nutrition.items() if k in key_nutrients and v]
        return " | ".join(found_nutrients) if found_nutrients else "æ „é¤Šæƒ…å ±å½¢å¼ä¸æ˜"

def get_index_stats(index_name: str) -> Dict[str, Any]:
    """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        stats_response = requests.get(f"{ELASTICSEARCH_URL}/{index_name}/_stats")
        if stats_response.status_code == 200:
            stats = stats_response.json()
            doc_count = stats.get("_all", {}).get("total", {}).get("docs", {}).get("count", 0)
            index_size = stats.get("_all", {}).get("total", {}).get("store", {}).get("size_in_bytes", 0)
            return {
                "doc_count": doc_count,
                "size_mb": round(index_size / (1024*1024), 2),
                "exists": True
            }
        else:
            return {"exists": False, "error": f"HTTP {stats_response.status_code}"}
    except Exception as e:
        return {"exists": False, "error": str(e)}

def test_single_query_on_index(index_name: str, query: str, expected_description: str = "") -> Dict[str, Any]:
    """å˜ä¸€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§å˜ä¸€ã‚¯ã‚¨ãƒªã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print(f"\n{'â”€'*60}")
    print(f"ğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {index_name} | ã‚¯ã‚¨ãƒª: '{query}'")
    if expected_description:
        print(f"ğŸ“ æœŸå¾…ã™ã‚‹çµæœ: {expected_description}")

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    stats = get_index_stats(index_name)
    if not stats["exists"]:
        print(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {stats.get('error', 'Unknown error')}")
        return {
            "index": index_name,
            "query": query,
            "exists": False,
            "error": stats.get("error", "Index not found"),
            "results": []
        }

    print(f"ğŸ“Š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆ: {stats['doc_count']:,} documents, {stats['size_mb']} MB")

    # Elasticsearchæ¤œç´¢ã‚’å®Ÿè¡Œ
    result = elasticsearch_search(index_name, query, size=10)

    if "error" in result:
        print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {result['error']}")
        return {
            "index": index_name,
            "query": query,
            "exists": True,
            "error": result["error"],
            "results": []
        }

    hits = result.get("hits", {}).get("hits", [])
    total_hits = result.get("hits", {}).get("total", {}).get("value", 0)

    print(f"ğŸ“‹ æ¤œç´¢çµæœ: {total_hits} ä»¶ä¸­ {len(hits)} ä»¶è¡¨ç¤º")

    processed_results = []

    for i, hit in enumerate(hits, 1):
        source = hit["_source"]
        score = hit["_score"]

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å‹•çš„ã«å–å¾—
        if "mynetdiary" in index_name:
            name = source.get("search_name", source.get("name", "Unknown"))
            description = source.get("description", "No description")
            original_name = source.get("original_name", "")
            nutrition = source.get("nutrition", {})
            processing_method = source.get("processing_method", "Unknown")

            print(f"   ğŸ† #{i} (ã‚¹ã‚³ã‚¢: {score:.2f})")
            print(f"      ğŸ”¸ æ¤œç´¢å: '{name}'")
            print(f"      ğŸ”¸ èª¬æ˜: '{description}'")
            if original_name:
                print(f"      ğŸ”¸ å…ƒã®åå‰: '{original_name}'")
            print(f"      ğŸ”¸ æ „é¤Šæƒ…å ±: {format_nutrition_info(nutrition)}")
            print(f"      ğŸ”¸ å‡¦ç†æ–¹æ³•: {processing_method}")

        else:
            # Multi-DBã‚·ã‚¹ãƒ†ãƒ ç”¨
            name = source.get("name", source.get("food_name", "Unknown"))
            description = source.get("description", source.get("category", "No description"))
            nutrition = source.get("nutrition", source.get("nutrients", {}))
            category = source.get("category", "")

            print(f"   ğŸ† #{i} (ã‚¹ã‚³ã‚¢: {score:.2f})")
            print(f"      ğŸ”¸ åå‰: '{name}'")
            print(f"      ğŸ”¸ èª¬æ˜: '{description}'")
            if category:
                print(f"      ğŸ”¸ ã‚«ãƒ†ã‚´ãƒª: '{category}'")
            print(f"      ğŸ”¸ æ „é¤Šæƒ…å ±: {format_nutrition_info(nutrition)}")

        processed_results.append({
            "rank": i,
            "score": score,
            "name": name,
            "description": description,
            "source": source  # å®Œå…¨ãªã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
        })

    return {
        "index": index_name,
        "query": query,
        "exists": True,
        "total_hits": total_hits,
        "displayed_results": len(hits),
        "results": processed_results
    }

def run_comprehensive_test() -> Dict[str, Any]:
    """ã™ã¹ã¦ã®ã‚·ã‚¹ãƒ†ãƒ ã§åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("ğŸš€ åŒ…æ‹¬çš„ãªæ „é¤Šæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

    # Elasticsearchæ¥ç¶šãƒã‚§ãƒƒã‚¯
    if not check_elasticsearch_connection():
        return {"error": "Elasticsearch connection failed"}

    # ä½¿ç”¨å¯èƒ½ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç¢ºèª
    available_indices = get_available_indices()
    print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {', '.join(available_indices)}")

    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    test_indices = {}
    for name, index_name in INDICES.items():
        if index_name in available_indices:
            test_indices[name] = index_name
            print(f"âœ… ãƒ†ã‚¹ãƒˆå¯¾è±¡: {name} ({index_name})")
        else:
            print(f"âŒ åˆ©ç”¨ä¸å¯: {name} ({index_name})")

    if not test_indices:
        print("âŒ ãƒ†ã‚¹ãƒˆå¯èƒ½ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")
        return {"error": "No testable indices found"}

    # READMEã«åŸºã¥ã„ãŸãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    test_queries = [
        # åŸºæœ¬çš„ãªé£Ÿæï¼ˆREADMEã®ä¾‹ã‹ã‚‰ï¼‰
        ("tomato", "ãƒˆãƒãƒˆé–¢é€£ - READMEã®ä¸»è¦ä¾‹"),
        ("chicken", "ãƒã‚­ãƒ³é–¢é€£ - READMEã®ä¸»è¦ä¾‹"),
        ("rice", "ç±³é–¢é€£ - READMEã®ä¸»è¦ä¾‹"),
        ("beans", "è±†é¡é–¢é€£ - READMEã®ä¸»è¦ä¾‹"),

        # å…·ä½“çš„ãªè£½å“ï¼ˆREADMEã®ä¾‹ã‹ã‚‰ï¼‰
        ("tomato powder", "ãƒˆãƒãƒˆãƒ‘ã‚¦ãƒ€ãƒ¼ - å…·ä½“çš„æ¤œç´¢ä¾‹"),
        ("chicken breast", "ãƒã‚­ãƒ³ãƒ–ãƒ¬ã‚¹ãƒˆ - å…·ä½“çš„æ¤œç´¢ä¾‹"),
        ("brown rice", "ç„ç±³ - å…·ä½“çš„æ¤œç´¢ä¾‹"),

        # ä»£æ›¿åã®ãƒ†ã‚¹ãƒˆï¼ˆREADMEã§è¨€åŠï¼‰
        ("chickpeas", "ã²ã‚ˆã“è±† - ä»£æ›¿åãƒ†ã‚¹ãƒˆç”¨"),
        ("garbanzo beans", "ã‚¬ãƒ«ãƒãƒ³ã‚¾è±† - chickpeasã®ä»£æ›¿å"),

        # è¤‡é›‘ãªã‚¯ã‚¨ãƒªï¼ˆREADMEã§è¨€åŠï¼‰
        ("stewed tomatoes", "ç…®è¾¼ã¿ãƒˆãƒãƒˆ - è¤‡é›‘ã‚¯ã‚¨ãƒªä¾‹"),
        ("lean ground beef", "èµ¤èº«ã²ãè‚‰ - è¤‡é›‘ã‚¯ã‚¨ãƒªä¾‹"),

        # ä¸€èˆ¬çš„ãªæ¤œç´¢ï¼ˆREADMEã®æ¤œç´¢æˆ¦ç•¥ãƒ†ã‚¹ãƒˆç”¨ï¼‰
        ("soup", "ã‚¹ãƒ¼ãƒ— - ä¸€èˆ¬çš„ã‚«ãƒ†ã‚´ãƒª"),
        ("salad", "ã‚µãƒ©ãƒ€ - ä¸€èˆ¬çš„ã‚«ãƒ†ã‚´ãƒª"),
        ("pasta", "ãƒ‘ã‚¹ã‚¿ - ä¸€èˆ¬çš„ã‚«ãƒ†ã‚´ãƒª"),

        # å¤§æ–‡å­—å°æ–‡å­—ãƒ»éƒ¨åˆ†ä¸€è‡´ãƒ†ã‚¹ãƒˆ
        ("TOMATO", "å¤§æ–‡å­—ã§ã®ãƒˆãƒãƒˆæ¤œç´¢"),
        ("chick", "éƒ¨åˆ†ä¸€è‡´ãƒ†ã‚¹ãƒˆ")
    ]

    all_results = {}

    # å„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    for index_type, index_name in test_indices.items():
        print(f"\n{'='*80}")
        print(f"ğŸ—„ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ: {index_type} ({index_name})")
        print(f"{'='*80}")

        index_results = []

        for query, description in test_queries:
            result = test_single_query_on_index(index_name, query, description)
            index_results.append(result)

        all_results[index_type] = {
            "index_name": index_name,
            "total_queries": len(test_queries),
            "queries_with_results": len([r for r in index_results if r.get("total_hits", 0) > 0]),
            "avg_results_per_query": sum(r.get("total_hits", 0) for r in index_results) / len(test_queries),
            "detailed_results": index_results
        }

    # æ¯”è¼ƒã‚µãƒãƒªãƒ¼
    print(f"\n{'='*80}")
    print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ é–“æ¯”è¼ƒã‚µãƒãƒªãƒ¼")
    print(f"{'='*80}")

    for index_type, stats in all_results.items():
        if "error" not in stats:
            print(f"\nğŸ” {index_type} ({stats['index_name']}):")
            print(f"   âœ… çµæœã‚ã‚Šã‚¯ã‚¨ãƒª: {stats['queries_with_results']}/{stats['total_queries']}")
            print(f"   ğŸ“ˆ å¹³å‡çµæœæ•°: {stats['avg_results_per_query']:.1f}")

            # ä¸Šä½çµæœã®å“è³ªãƒã‚§ãƒƒã‚¯
            top_results_with_good_scores = 0
            for result in stats['detailed_results']:
                if result.get('results') and len(result['results']) > 0:
                    if result['results'][0].get('score', 0) >= 5.0:  # é«˜ã‚¹ã‚³ã‚¢é–¾å€¤
                        top_results_with_good_scores += 1

            print(f"   ğŸ¯ é«˜å“è³ªçµæœã‚¯ã‚¨ãƒª: {top_results_with_good_scores}/{stats['total_queries']}")

    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"nutrition_search_systems_test_results_{timestamp}.json"

    test_summary = {
        "timestamp": timestamp,
        "tested_indices": test_indices,
        "total_queries_per_index": len(test_queries),
        "systems_comparison": all_results
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(test_summary, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {output_file}")

    return test_summary

def check_all_indices_stats():
    """å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’ç¢ºèª"""
    print(f"\nğŸ—„ï¸ å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆæƒ…å ±")
    print("="*80)

    available_indices = get_available_indices()

    for index_name in available_indices:
        if any(target in index_name for target in ["mynetdiary", "usda", "food"]):
            stats = get_index_stats(index_name)
            if stats["exists"]:
                print(f"ğŸ“Š {index_name}: {stats['doc_count']:,} docs, {stats['size_mb']} MB")
            else:
                print(f"âŒ {index_name}: {stats.get('error', 'Error')}")

if __name__ == "__main__":
    print("ğŸ” åŒ…æ‹¬çš„æ „é¤Šæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("="*80)
    print("ğŸ“– READMEã«åŸºã¥ã„ãŸ MyNetDiary & Multi-Database ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("ğŸ¯ test_mynetdiary_tool_calls_db.py ã¨åŒæ§˜ã®è©³ç´°å‡ºåŠ›")
    print("="*80)

    # å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆæƒ…å ±
    check_all_indices_stats()

    # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = run_comprehensive_test()

    if "error" not in results:
        successful_systems = len([s for s in results["systems_comparison"].values() if "error" not in s])
        total_systems = len(results["systems_comparison"])
        print(f"\nğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†!")
        print(f"ğŸ“Š {successful_systems}/{total_systems} ã‚·ã‚¹ãƒ†ãƒ ã§ãƒ†ã‚¹ãƒˆæˆåŠŸ")

        # æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å®šï¼ˆREADMEã«åŸºã¥ãï¼‰
        if "mynetdiary_list_support" in results["systems_comparison"]:
            mynet_stats = results["systems_comparison"]["mynetdiary_list_support"]
            if "error" not in mynet_stats:
                print(f"ğŸ¥‡ æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ  (MyNetDiary): {mynet_stats['queries_with_results']}/{mynet_stats['total_queries']} ã‚¯ã‚¨ãƒªã§çµæœ")
    else:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {results['error']}")