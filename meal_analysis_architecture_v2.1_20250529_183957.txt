================================================================================
MEAL ANALYSIS API v2.1 - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ§‹é€ ã¨ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
================================================================================
ç”Ÿæˆæ—¥æ™‚: 2025-05-29 18:39:57
åˆ†æå¯¾è±¡: test_english_phase1_v2.py & test_english_phase2_v2.py å®Ÿè¡Œæ™‚ã«å‘¼ã³å‡ºã•ã‚Œã‚‹å…¨Pythonãƒ•ã‚¡ã‚¤ãƒ«
================================================================================

ğŸ“Š ARCHITECTURE OVERVIEW v2.1
----------------------------------------

ğŸ”„ EXECUTION FLOW (Advanced 2-Phase Approach):
Phase 1: ç”»åƒ â†’ Gemini AI â†’ æ–™ç†ãƒ»é£Ÿæè­˜åˆ¥ + USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆ
Phase 2: Phase1çµæœ â†’ ä¸¦åˆ—USDAæ¤œç´¢ â†’ æˆ¦ç•¥æ±ºå®šAI â†’ FDC IDé¸æŠ â†’ å‹•çš„æ „é¤Šè¨ˆç®—

ğŸ—ï¸ LAYER STRUCTURE v2.1:
â”œâ”€â”€ APIå±¤ (FastAPI)
â”‚   â”œâ”€â”€ meal_analyses.py (Phase 1 v2.1: USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆ)
â”‚   â””â”€â”€ meal_analyses_refine.py (Phase 2 v2.1: é«˜åº¦æˆ¦ç•¥æ±ºå®š + æ „é¤Šè¨ˆç®—)
â”œâ”€â”€ ã‚µãƒ¼ãƒ“ã‚¹å±¤ (Enhanced)
â”‚   â”œâ”€â”€ gemini_service.py (2ãƒ•ã‚§ãƒ¼ã‚ºãƒ¡ã‚½ãƒƒãƒ‰: analyze_image_phase1, refine_analysis_phase2)
â”‚   â”œâ”€â”€ usda_service.py (Rich search + æ „é¤Šè©³ç´°å–å¾—)
â”‚   â”œâ”€â”€ nutrition_calculation_service.py (å‹•çš„è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³)
â”‚   â””â”€â”€ logging_service.py (ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† + è©³ç´°ãƒ­ã‚°è¨˜éŒ²)
â”œâ”€â”€ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤ (v2.1 Schemas)
â”‚   â””â”€â”€ meal.py (Phase1AnalysisResponse, Phase2GeminiResponse, MealAnalysisRefinementResponse)
â”œâ”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†å±¤ (2-Phase Templates)
â”‚   â”œâ”€â”€ prompt_loader.py (ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†)
â”‚   â””â”€â”€ prompt templates (phase1_*, phase2_*)
â”œâ”€â”€ ãƒ­ã‚°åˆ†æå±¤ (New)
â”‚   â”œâ”€â”€ log_analyzer.py (çµ±è¨ˆåˆ†æ + ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ)
â”‚   â””â”€â”€ analyze_logs.py (CLIåˆ†æãƒ„ãƒ¼ãƒ«)
â””â”€â”€ è¨­å®šå±¤
    â””â”€â”€ config.py (Environment configuration)

ğŸ”§ TECHNICAL FEATURES v2.1:
- âœ¨ é«˜åº¦æˆ¦ç•¥æ±ºå®šã‚·ã‚¹ãƒ†ãƒ  (dish_level vs ingredient_level)
- ğŸ” ä¸¦åˆ—USDAæ¤œç´¢ (25+å€™è£œã®åŒæ™‚å‡¦ç†)
- ğŸ“Š å‹•çš„æ „é¤Šè¨ˆç®— (æˆ¦ç•¥ãƒ™ãƒ¼ã‚¹è¨ˆç®—)
- ğŸ“ˆ åŒ…æ‹¬çš„ãƒ­ã‚°æ©Ÿèƒ½ (ã‚»ãƒƒã‚·ãƒ§ãƒ³è¿½è·¡ + ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ)
- ğŸ¯ FDC IDé¸æŠã¨ã‚½ãƒ¼ã‚¹èª¬æ˜
- ğŸ”„ 3å±¤æ „é¤Šé›†è¨ˆ (é£Ÿæ â†’ æ–™ç† â†’ é£Ÿäº‹)
- âš¡ éåŒæœŸå‡¦ç†æœ€é©åŒ–
- ğŸ“‹ æ§‹é€ åŒ–JSONå‡ºåŠ› (Gemini response_schema)

ğŸ†• NEW FEATURES v2.1:
- USDAã‚¯ã‚¨ãƒªå€™è£œã®è‡ªå‹•ç”Ÿæˆ
- æˆ¦ç•¥ç†ç”±ã¨é¸æŠç†ç”±ã®è©³ç´°è¨˜éŒ²
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°åˆ†æ
- CSV/JSONLãƒ­ã‚°ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã¨ã‚¨ãƒ©ãƒ¼åˆ†æ

================================================================================

ğŸ“ v2.1ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
============================================================

ğŸ“„ FILE: test_english_phase1_v2.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 7992 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:27:12
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
Phase 1 Analysis Test Script (v2.1) - USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å«ã‚€æ–°ã—ã„å‡ºåŠ›ã‚’ãƒ†ã‚¹ãƒˆ
"""

import requests
import json
import sys
import time
from pathlib import Path

# APIè¨­å®š
BASE_URL = "http://localhost:8000"
MEAL_ANALYSES_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/"

def test_phase1_analysis_v2():
    """Phase 1ã®æ–°ã—ã„ä»•æ§˜ï¼ˆv2.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    # ãƒ†ã‚¹ãƒˆç”»åƒã‚’æ¢ã™
    test_image_paths = [
        "test_images/food1.jpg",  # å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªæ¸ˆã¿
        "test_images/food2.jpg",
        "test_images/food3.jpg",
        "tests/assets/test_meal.jpg",
        "test_meal.jpg", 
        "sample_meal.jpg",
        # ä»–ã®ä¸€èˆ¬çš„ãªå ´æ‰€ã‚‚è©¦ã™
        Path.home() / "Downloads" / "meal.jpg",
        Path.cwd() / "meal.jpg"
    ]
    
    test_image_path = None
    for path in test_image_paths:
        if Path(path).exists():
            test_image_path = Path(path)
            break
    
    if not test_image_path:
        print("âŒ Test image not found. Please place a meal image in one of these locations:")
        for path in test_image_paths:
            print(f"   - {path}")
        return False
    
    print(f"ğŸ“· Using test image: {test_image_path}")
    
    # API ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    try:
        print("ğŸš€ Sending Phase 1 analysis request...")
        start_time = time.time()
        
        with open(test_image_path, 'rb') as image_file:
            files = {
                'image': ('test_meal.jpg', image_file, 'image/jpeg')
            }
            data = {
                'optional_text': 'This is a test meal for Phase 1 analysis with USDA query candidates.'
            }
            
            response = requests.post(
                MEAL_ANALYSES_ENDPOINT,
                files=files,
                data=data,
                timeout=60
            )
        
        elapsed_time = time.time() - start_time
        print(f"â±ï¸  Request completed in {elapsed_time:.2f} seconds")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
        print(f"ğŸ“Š Response status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ Error response: {response.text}")
            return False
        
        # JSON ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # çµæœã®è¡¨ç¤ºã¨æ¤œè¨¼
        print("\n" + "="*80)
        print("ğŸ“‹ PHASE 1 ANALYSIS RESULTS (v2.1)")
        print("="*80)
        
        # åŸºæœ¬æ§‹é€ ã®ç¢ºèª
        if 'dishes' not in result:
            print("âŒ Missing 'dishes' field in response")
            return False
        
        dishes = result['dishes']
        print(f"ğŸ½ï¸  Found {len(dishes)} dishes")
        
        # å„æ–™ç†ã®è©³ç´°è¡¨ç¤º
        for i, dish in enumerate(dishes, 1):
            print(f"\nğŸ“Œ DISH {i}: {dish.get('dish_name', 'Unknown')}")
            print(f"   Type: {dish.get('type', 'N/A')}")
            print(f"   Quantity: {dish.get('quantity_on_plate', 'N/A')}")
            
            # ææ–™ãƒªã‚¹ãƒˆ
            ingredients = dish.get('ingredients', [])
            print(f"   ğŸ¥— Ingredients ({len(ingredients)}):")
            for ing in ingredients:
                print(f"      - {ing.get('ingredient_name', 'Unknown')}: {ing.get('weight_g', 0)}g")
            
            # NEW: USDAã‚¯ã‚¨ãƒªå€™è£œã®ç¢ºèª (v2.1ã®é‡è¦ãªæ–°æ©Ÿèƒ½)
            usda_candidates = dish.get('usda_query_candidates', [])
            print(f"   ğŸ” USDA Query Candidates ({len(usda_candidates)}):")
            
            if not usda_candidates:
                print("      âŒ No USDA query candidates found - this is a problem for v2.1!")
                return False
            
            for j, candidate in enumerate(usda_candidates, 1):
                print(f"      {j}. Query: '{candidate.get('query_term', 'N/A')}'")
                print(f"         Granularity: {candidate.get('granularity_level', 'N/A')}")
                print(f"         Original: {candidate.get('original_term', 'N/A')}")
                print(f"         Reason: {candidate.get('reason_for_query', 'N/A')}")
        
        # v2.1 ä»•æ§˜ã®æ¤œè¨¼
        print(f"\nğŸ” V2.1 SPECIFICATION VALIDATION:")
        
        validation_passed = True
        
        # 1. å…¨ã¦ã®æ–™ç†ã«USDAã‚¯ã‚¨ãƒªå€™è£œãŒã‚ã‚‹ã‹
        for dish in dishes:
            if not dish.get('usda_query_candidates'):
                print(f"   âŒ Dish '{dish.get('dish_name')}' has no USDA query candidates")
                validation_passed = False
            else:
                print(f"   âœ… Dish '{dish.get('dish_name')}' has {len(dish.get('usda_query_candidates'))} USDA query candidates")
        
        # 2. ã‚¯ã‚¨ãƒªå€™è£œã®ç²’åº¦ãƒ¬ãƒ™ãƒ«ãŒé©åˆ‡ã‹
        granularity_levels = set()
        for dish in dishes:
            for candidate in dish.get('usda_query_candidates', []):
                level = candidate.get('granularity_level')
                if level in ['dish', 'ingredient', 'branded_product']:
                    granularity_levels.add(level)
                else:
                    print(f"   âŒ Invalid granularity level: {level}")
                    validation_passed = False
        
        print(f"   ğŸ“Š Granularity levels found: {list(granularity_levels)}")
        
        # 3. ç†ç”±ä»˜ã‘ãŒã‚ã‚‹ã‹
        reasoning_count = 0
        total_candidates = 0
        for dish in dishes:
            for candidate in dish.get('usda_query_candidates', []):
                total_candidates += 1
                if candidate.get('reason_for_query'):
                    reasoning_count += 1
        
        reasoning_percentage = (reasoning_count / total_candidates * 100) if total_candidates > 0 else 0
        print(f"   ğŸ“ Query reasoning coverage: {reasoning_percentage:.1f}% ({reasoning_count}/{total_candidates})")
        
        if reasoning_percentage < 80:
            print(f"   âš ï¸  Low reasoning coverage - should be > 80%")
            validation_passed = False
        
        # çµæœä¿å­˜
        output_file = "phase1_analysis_result_v2.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ Full result saved to: {output_file}")
        
        # æœ€çµ‚åˆ¤å®š
        if validation_passed:
            print(f"\nâœ… Phase 1 v2.1 test PASSED!")
            print("   - All dishes have USDA query candidates")
            print("   - Granularity levels are valid") 
            print("   - Reasoning coverage is sufficient")
            return True
        else:
            print(f"\nâŒ Phase 1 v2.1 test FAILED!")
            print("   Please check the validation errors above.")
            return False
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Request error: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON decode error: {e}")
        print(f"Raw response: {response.text}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False

def main():
    print("ğŸ§ª Phase 1 Analysis Test (v2.1) - USDA Query Candidates")
    print("-" * 60)
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    try:
        health_response = requests.get(f"{BASE_URL}/health", timeout=5)
        if health_response.status_code == 200:
            print("âœ… Server is healthy")
        else:
            print("âŒ Server health check failed")
            return 1
    except:
        print("âŒ Cannot connect to server. Is it running on http://localhost:8000?")
        return 1
    
    # Phase 1ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if test_phase1_analysis_v2():
        print("\nğŸ‰ All tests passed! Ready for Phase 2 integration.")
        return 0
    else:
        print("\nğŸ’¥ Tests failed! Please check the implementation.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ“„ FILE: test_english_phase2_v2.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 9883 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:36:43
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
Phase 2 Analysis Test Script (v2.1) - calculation_strategyã¨FDC IDé¸æŠã‚’ãƒ†ã‚¹ãƒˆ
"""

import requests
import json
import sys
import time
from pathlib import Path

# APIè¨­å®š
BASE_URL = "http://localhost:8000"
PHASE1_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/"
PHASE2_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/refine"

def test_phase2_analysis_v2():
    """Phase 2ã®æ–°ã—ã„ä»•æ§˜ï¼ˆv2.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    # 1. Phase 1çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    phase1_result_file = "phase1_analysis_result_v2.json"
    if not Path(phase1_result_file).exists():
        print(f"âŒ Phase 1 result file not found: {phase1_result_file}")
        print("   Please run test_english_phase1_v2.py first")
        return False
    
    # Phase 1çµæœã‚’èª­ã¿è¾¼ã¿
    try:
        with open(phase1_result_file, 'r', encoding='utf-8') as f:
            phase1_result = json.load(f)
        print(f"âœ… Phase 1 result loaded from {phase1_result_file}")
    except Exception as e:
        print(f"âŒ Error loading Phase 1 result: {e}")
        return False
    
    # 2. ãƒ†ã‚¹ãƒˆç”»åƒã®ç¢ºèª
    test_image_paths = [
        "test_images/food1.jpg",
        "test_images/food2.jpg",
        "test_images/food3.jpg",
    ]
    
    test_image_path = None
    for path in test_image_paths:
        if Path(path).exists():
            test_image_path = Path(path)
            break
    
    if not test_image_path:
        print("âŒ Test image not found")
        return False
    
    print(f"ğŸ“· Using test image: {test_image_path}")
    
    # 3. Phase 2 API ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    try:
        print("ğŸš€ Sending Phase 2 analysis request...")
        start_time = time.time()
        
        with open(test_image_path, 'rb') as image_file:
            files = {
                'image': ('test_meal.jpg', image_file, 'image/jpeg')
            }
            data = {
                'phase1_analysis_json': json.dumps(phase1_result, ensure_ascii=False)
            }
            
            response = requests.post(
                PHASE2_ENDPOINT,
                files=files,
                data=data,
                timeout=120  # Phase 2ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§
            )
        
        elapsed_time = time.time() - start_time
        print(f"â±ï¸  Request completed in {elapsed_time:.2f} seconds")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
        print(f"ğŸ“Š Response status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ Error response: {response.text}")
            return False
        
        # JSON ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # çµæœã®è¡¨ç¤ºã¨æ¤œè¨¼
        print("\n" + "="*80)
        print("ğŸ“‹ PHASE 2 ANALYSIS RESULTS (v2.1)")
        print("="*80)
        
        # åŸºæœ¬æ§‹é€ ã®ç¢ºèª
        if 'dishes' not in result:
            print("âŒ Missing 'dishes' field in response")
            return False
        
        dishes = result['dishes']
        print(f"ğŸ½ï¸  Found {len(dishes)} dishes")
        
        # å„æ–™ç†ã®è©³ç´°è¡¨ç¤ºã¨æ¤œè¨¼
        validation_passed = True
        strategy_counts = {"dish_level": 0, "ingredient_level": 0}
        total_fdc_ids_selected = 0
        
        for i, dish in enumerate(dishes, 1):
            print(f"\nğŸ“Œ DISH {i}: {dish.get('dish_name', 'Unknown')}")
            print(f"   Type: {dish.get('type', 'N/A')}")
            
            # NEW v2.1: calculation_strategy ã®ç¢ºèª
            strategy = dish.get('calculation_strategy')
            print(f"   ğŸ¯ Calculation Strategy: {strategy}")
            
            if strategy not in ['dish_level', 'ingredient_level']:
                print(f"      âŒ Invalid calculation strategy: {strategy}")
                validation_passed = False
            else:
                strategy_counts[strategy] += 1
                print(f"   ğŸ“ Strategy Reason: {dish.get('reason_for_strategy', 'N/A')}")
            
            # FDC IDæƒ…å ±ã®ç¢ºèª
            dish_fdc_id = dish.get('fdc_id')
            if strategy == 'dish_level':
                if dish_fdc_id:
                    print(f"   ğŸ·ï¸  Dish FDC ID: {dish_fdc_id}")
                    print(f"   ğŸ“„ USDA Source: {dish.get('usda_source_description', 'N/A')}")
                    print(f"   ğŸ’­ Choice Reason: {dish.get('reason_for_choice', 'N/A')}")
                    total_fdc_ids_selected += 1
                else:
                    print(f"      âš ï¸  No FDC ID for dish-level strategy")
            
            # ææ–™ã®è©³ç´°
            ingredients = dish.get('ingredients', [])
            print(f"   ğŸ¥— Ingredients ({len(ingredients)}):")
            
            for ing in ingredients:
                ing_name = ing.get('ingredient_name', 'Unknown')
                weight = ing.get('weight_g', 0)
                ing_fdc_id = ing.get('fdc_id')
                
                print(f"      - {ing_name}: {weight}g", end="")
                if ing_fdc_id:
                    print(f" [FDC ID: {ing_fdc_id}]")
                    total_fdc_ids_selected += 1
                    if ing.get('reason_for_choice'):
                        print(f"        Reason: {ing.get('reason_for_choice')}")
                else:
                    print(f" [No FDC ID]")
            
            # æ „é¤Šç´ æƒ…å ±ã®ç¢ºèª
            nutrients = dish.get('dish_total_actual_nutrients')
            if nutrients:
                print(f"   ğŸ§® Nutrition (Total): {nutrients.get('calories_kcal', 0):.1f} kcal, "
                      f"{nutrients.get('protein_g', 0):.1f}g protein, "
                      f"{nutrients.get('carbohydrates_g', 0):.1f}g carbs, "
                      f"{nutrients.get('fat_g', 0):.1f}g fat")
            else:
                print(f"   âš ï¸  No nutritional data calculated")
        
        # é£Ÿäº‹å…¨ä½“ã®æ „é¤Š
        total_nutrients = result.get('total_meal_nutrients')
        if total_nutrients:
            print(f"\nğŸ½ï¸  MEAL TOTAL NUTRITION:")
            print(f"   Energy: {total_nutrients.get('calories_kcal', 0):.1f} kcal")
            print(f"   Protein: {total_nutrients.get('protein_g', 0):.1f}g")
            print(f"   Carbohydrates: {total_nutrients.get('carbohydrates_g', 0):.1f}g")
            print(f"   Fat: {total_nutrients.get('fat_g', 0):.1f}g")
            if total_nutrients.get('fiber_g'):
                print(f"   Fiber: {total_nutrients.get('fiber_g', 0):.1f}g")
            if total_nutrients.get('sodium_mg'):
                print(f"   Sodium: {total_nutrients.get('sodium_mg', 0):.1f}mg")
        
        # v2.1 ä»•æ§˜ã®æ¤œè¨¼
        print(f"\nğŸ” V2.1 SPECIFICATION VALIDATION:")
        print(f"   ğŸ“Š Strategy Distribution:")
        print(f"      - Dish Level: {strategy_counts['dish_level']} dishes")
        print(f"      - Ingredient Level: {strategy_counts['ingredient_level']} dishes") 
        print(f"   ğŸ·ï¸  Total FDC IDs Selected: {total_fdc_ids_selected}")
        
        # è­¦å‘Šã¨ã‚¨ãƒ©ãƒ¼ã®ç¢ºèª
        warnings = result.get('warnings', [])
        errors = result.get('errors', [])
        
        if warnings:
            print(f"   âš ï¸  Warnings ({len(warnings)}):")
            for warning in warnings:
                print(f"      - {warning}")
        
        if errors:
            print(f"   âŒ Errors ({len(errors)}):")
            for error in errors:
                print(f"      - {error}")
            validation_passed = False
        
        # çµæœä¿å­˜
        output_file = "phase2_analysis_result_v2.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ Full result saved to: {output_file}")
        
        # æœ€çµ‚åˆ¤å®š
        success_criteria = [
            len(dishes) > 0,
            all(d.get('calculation_strategy') in ['dish_level', 'ingredient_level'] for d in dishes),
            total_fdc_ids_selected > 0,
            total_nutrients is not None,
            not errors  # ã‚¨ãƒ©ãƒ¼ãŒãªã„ã“ã¨
        ]
        
        if all(success_criteria) and validation_passed:
            print(f"\nâœ… Phase 2 v2.1 test PASSED!")
            print("   - All dishes have valid calculation strategies")
            print("   - FDC IDs were successfully selected")
            print("   - Nutritional calculations completed")
            print("   - No critical errors")
            return True
        else:
            print(f"\nâŒ Phase 2 v2.1 test FAILED!")
            print("   Please check the validation errors above.")
            return False
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Request error: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON decode error: {e}")
        print(f"Raw response: {response.text}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False

def main():
    print("ğŸ§ª Phase 2 Analysis Test (v2.1) - Strategy & FDC ID Selection")
    print("-" * 70)
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    try:
        health_response = requests.get(f"{BASE_URL}/health", timeout=5)
        if health_response.status_code == 200:
            print("âœ… Server is healthy")
        else:
            print("âŒ Server health check failed")
            return 1
    except:
        print("âŒ Cannot connect to server. Is it running on http://localhost:8000?")
        return 1
    
    # Phase 2ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if test_phase2_analysis_v2():
        print("\nğŸ‰ Phase 2 test passed! v2.1 implementation is working correctly.")
        return 0
    else:
        print("\nğŸ’¥ Phase 2 test failed! Please check the implementation.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ“ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå±¤ (v2.1)
============================================================

ğŸ“„ FILE: app/main.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 3235 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import logging

from .api.v1.endpoints import meal_analyses, meal_analyses_refine
from .core.config import get_settings

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,  # ä¸€æ™‚çš„ã«DEBUGãƒ¬ãƒ™ãƒ«ã«å¤‰æ›´
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
    ]
)
logger = logging.getLogger(__name__)

# è¨­å®šã®å–å¾—
settings = get_settings()

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ
app = FastAPI(
    title="é£Ÿäº‹åˆ†æAPI (Meal Analysis API)",
    description="é£Ÿäº‹ã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€æ–™ç†ã¨ææ–™ã‚’ç‰¹å®šã™ã‚‹APIã€‚USDAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æºã«ã‚ˆã‚Šæ „é¤Šä¾¡è¨ˆç®—ã®ç²¾åº¦ã‚’å‘ä¸Šã€‚",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®è¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒç”¨ï¼‰
if settings.FASTAPI_ENV == "development":
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ã«åˆ¶é™ã™ã‚‹
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    """APIã®ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "é£Ÿäº‹åˆ†æAPI (Meal Analysis API)",
        "version": "2.0.0",
        "docs": "/docs",
        "health": "/health"
    }

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/health")
async def health_check():
    """APIã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "service": "meal-analysis-api"
    }

# v1 APIãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç™»éŒ²
app.include_router(
    meal_analyses.router,
    prefix=f"/api/{settings.API_VERSION}/meal-analyses",
    tags=["Meal Analysis"]
)

# v1 API ãƒ•ã‚§ãƒ¼ã‚º2ãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç™»éŒ²ï¼ˆ/refineã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
app.include_router(
    meal_analyses_refine.router,
    prefix=f"/api/{settings.API_VERSION}/meal-analyses",
    tags=["Meal Analysis"]
)

# ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆ
@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®å‡¦ç†"""
    logger.info("Meal Analysis API starting up...")
    logger.info(f"Environment: {settings.FASTAPI_ENV}")
    logger.info(f"API Version: {settings.API_VERSION}")
    logger.info(f"Gemini Model: {settings.GEMINI_MODEL_NAME}")
    logger.info("Phase 2 features with USDA integration enabled")

# ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆ
@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®å‡¦ç†"""
    logger.info("Meal Analysis API shutting down...")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": "INTERNAL_SERVER_ERROR",
                "message": "å†…éƒ¨ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
            }
        }
    ) 
```

============================================================

ğŸ“„ FILE: app/api/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/meal_analyses.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 7582 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:57:41
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import APIRouter, File, Form, UploadFile, HTTPException, Depends
from typing import Annotated, Optional
import logging
import time  # å®Ÿè¡Œæ™‚é–“æ¸¬å®šã®ãŸã‚

from ....services.gemini_service import GeminiMealAnalyzer
from ..schemas.meal import Phase1AnalysisResponse, MealAnalysisResponse, ErrorResponse
from ....services.logging_service import get_meal_analysis_logger, ProcessingPhase, LogLevel
from ....core.config import Settings, get_settings

logger = logging.getLogger(__name__)

router = APIRouter()

# Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_gemini_analyzer = None


async def get_gemini_analyzer(settings: Annotated[Settings, Depends(get_settings)]) -> GeminiMealAnalyzer:
    """
    Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
    """
    global _gemini_analyzer
    if _gemini_analyzer is None:
        _gemini_analyzer = GeminiMealAnalyzer(
            project_id=settings.GEMINI_PROJECT_ID,
            location=settings.GEMINI_LOCATION,
            model_name=settings.GEMINI_MODEL_NAME
        )
    return _gemini_analyzer


@router.post(
    "",
    response_model=Phase1AnalysisResponse,
    summary="Analyze Meal Image (Phase 1 v2.1)",
    description="v2.1: é£Ÿäº‹ç”»åƒã‚’åˆ†æã—ã€æ–™ç†ãƒ»é£Ÿæè­˜åˆ¥ã¨USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚"
)
async def analyze_meal_v2_1(
    settings: Annotated[Settings, Depends(get_settings)],
    image: Annotated[UploadFile, File(description="Meal image file.")],
    optional_text: Annotated[Optional[str], None] = None
):
    """
    v2.1ä»•æ§˜ï¼šé£Ÿäº‹ç”»åƒã®åŸºæœ¬åˆ†æ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. ç”»åƒã®åŸºæœ¬ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    2. Gemini AI ã«ã‚ˆã‚‹é£Ÿäº‹åˆ†æï¼ˆPhase 1ï¼‰
    3. USDAã‚¯ã‚¨ãƒªå€™è£œã®ç”Ÿæˆ
    4. çµæœè¿”å´
    """
    # ãƒ­ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    meal_logger = get_meal_analysis_logger()
    session_id = meal_logger.start_session(
        endpoint="/api/v1/meal-analyses",
        image_filename=getattr(image, 'filename', None),
        image_size_bytes=None  # å¾Œã§è¨­å®š
    )
    
    start_time = time.time()
    
    try:
        # 1. Image validation
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message="Starting Phase 1 meal analysis"
        )
        
        if not image.content_type or not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Invalid image file format.")
        
        try:
            image_bytes = await image.read()
            # Update image size in session
            if session_id in meal_logger.active_sessions:
                meal_logger.active_sessions[session_id].image_size_bytes = len(image_bytes)
            
            # File size check (e.g., 10MB)
            if len(image_bytes) > 10 * 1024 * 1024:
                raise HTTPException(status_code=400, detail="Image file size too large (max 10MB).")
        except Exception as e:
            logger.error(f"Error reading image file: {e}")
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.REQUEST_RECEIVED,
                error_message="Failed to read image file",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail="Failed to read image file.")

        # 2. Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—
        gemini_service = await get_gemini_analyzer(settings)

        # 3. Call Gemini service (Phase 1)
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE1_START,
            message="Starting Gemini Phase 1 analysis"
        )
        
        phase1_start_time = time.time()
        try:
            result = await gemini_service.analyze_image_phase1(
                image_bytes=image_bytes,
                image_mime_type=image.content_type,
                optional_text=optional_text
            )
            phase1_duration = (time.time() - phase1_start_time) * 1000
            
            # Phase 1çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
            dishes_count = len(result.get('dishes', []))
            usda_queries_count = sum(
                len(dish.get('usda_query_candidates', [])) 
                for dish in result.get('dishes', [])
            )
            
            meal_logger.update_phase1_results(
                session_id=session_id,
                duration_ms=phase1_duration,
                dishes_count=dishes_count,
                usda_queries_count=usda_queries_count,
                phase1_output=result
            )
            
        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE1_START,
                error_message="Gemini Phase 1 analysis failed",
                error_details=str(e)
            )
            raise HTTPException(status_code=503, detail=f"Gemini API error: {e}")

        # 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
        response = Phase1AnalysisResponse(**result)
        
        meal_logger.end_session(
            session_id=session_id,
            warnings=None,
            errors=None
        )
        
        return response
        
    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
        meal_logger.log_error(
            session_id=session_id,
            phase=ProcessingPhase.ERROR_OCCURRED,
            error_message="Unexpected error during Phase 1 processing",
            error_details=str(e)
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        meal_logger.end_session(
            session_id=session_id,
            warnings=None,
            errors=[str(e)]
        )
        
        raise


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å¤ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚‚ç¶­æŒ
@router.post(
    "/legacy",
    response_model=MealAnalysisResponse,
    summary="Legacy Meal Analysis (v1.0 compatibility)",
    description="å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚æ–°ã—ã„æ©Ÿèƒ½ã«ã¯ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ `/` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
)
async def analyze_meal_legacy(
    image: Annotated[UploadFile, File(description="Meal image file to analyze.")],
    settings: Annotated[Settings, Depends(get_settings)],
    gemini_service: Annotated[GeminiMealAnalyzer, Depends(get_gemini_analyzer)],
    optional_text: Annotated[Optional[str], Form(description="Optional additional information about the meal.")] = None
):
    """
    å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    # åŒã˜æ¤œè¨¼ã‚’å®Ÿè¡Œ
    if not image.content_type or not image.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="Invalid image file format.")
    
    image_bytes = await image.read()
    if len(image_bytes) > 10 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="File too large.")
    
    try:
        # æ—§ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        analysis_result = await gemini_service.analyze_image_and_text(
            image_bytes=image_bytes,
            image_mime_type=image.content_type,
            optional_text=optional_text
        )
        
        response = MealAnalysisResponse(**analysis_result)
        return response
        
    except Exception as e:
        logger.error(f"Legacy analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e)) 
```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/meal_analyses_refine.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 21048 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:57:01
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import APIRouter, File, Form, UploadFile, HTTPException, Depends
from typing import Annotated, List, Optional, Dict
import json
import logging
import asyncio  # éåŒæœŸå‡¦ç†ã®ãŸã‚
import time  # å®Ÿè¡Œæ™‚é–“æ¸¬å®šã®ãŸã‚

# æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«
from ..schemas.meal import (
    Phase1AnalysisResponse,  # Phase 1 å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«ä½¿ç”¨
    Phase2GeminiResponse,    # Phase 2 Geminiå‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«ä½¿ç”¨
    MealAnalysisRefinementResponse,
    USDASearchResultItem,
    RefinedDishResponse,
    RefinedIngredientResponse,
    CalculatedNutrients
)

# ã‚µãƒ¼ãƒ“ã‚¹
from ....services.usda_service import USDAService, get_usda_service
from ....services.gemini_service import GeminiMealAnalyzer
from ....services.nutrition_calculation_service import NutritionCalculationService, get_nutrition_calculation_service
from ....services.logging_service import get_meal_analysis_logger, ProcessingPhase, LogLevel
from ....core.config import Settings, get_settings

logger = logging.getLogger(__name__)

router = APIRouter()

# Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_gemini_analyzer = None

async def get_gemini_analyzer(settings: Annotated[Settings, Depends(get_settings)]) -> GeminiMealAnalyzer:
    """
    Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
    """
    global _gemini_analyzer
    if _gemini_analyzer is None:
        _gemini_analyzer = GeminiMealAnalyzer(
            project_id=settings.GEMINI_PROJECT_ID,
            location=settings.GEMINI_LOCATION,
            model_name=settings.GEMINI_MODEL_NAME
        )
    return _gemini_analyzer


@router.post(
    "/refine",
    response_model=MealAnalysisRefinementResponse,
    summary="Refine Meal Analysis with USDA Data & Enhanced Gemini Strategy (v2.1)",
    description="v2.1: Phase 1ã‹ã‚‰USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å—ä¿¡ã—ã€å…¨å€™è£œã§æ¤œç´¢ã‚’å®Ÿè¡Œã€‚Phase 2 GeminiãŒcalculation_strategyã‚’æ±ºå®šã—ã€FDC IDã‚’é¸æŠã€‚æ±ºå®šè«–çš„ã§ç²¾åº¦ã®é«˜ã„æ „é¤Šè¨ˆç®—ã‚’æä¾›ã€‚"
)
async def refine_meal_analysis(
    settings: Annotated[Settings, Depends(get_settings)],
    image: Annotated[UploadFile, File(description="Meal image file.")],
    # NEW: Phase 1 å‡ºåŠ›ã¯ JSON æ–‡å­—åˆ—ã¨ã—ã¦å—ã‘å–ã‚‹
    phase1_analysis_json: Annotated[str, Form(description="JSON response string from Phase 1 API.")],
    usda_service: Annotated[USDAService, Depends(get_usda_service)],
    gemini_service: Annotated[GeminiMealAnalyzer, Depends(get_gemini_analyzer)]
):
    """
    v2.1ä»•æ§˜ï¼šé£Ÿäº‹åˆ†æç²¾ç·»åŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. Phase 1åˆ†æçµæœã¨USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å—ä¿¡
    2. å…¨USDAã‚¯ã‚¨ãƒªå€™è£œã§ä¸¦åˆ—æ¤œç´¢ã‚’å®Ÿè¡Œ
    3. Phase 2 Geminiã§ calculation_strategy æ±ºå®šã¨FDC IDé¸æŠ
    4. calculation_strategyã«åŸºã¥ãæ „é¤Šè¨ˆç®—
    5. ç²¾ç·»åŒ–ã•ã‚ŒãŸçµæœã‚’è¿”ã™
    """
    # ãƒ­ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    meal_logger = get_meal_analysis_logger()
    session_id = meal_logger.start_session(
        endpoint="/api/v1/meal-analyses/refine",
        image_filename=getattr(image, 'filename', None),
        image_size_bytes=None  # å¾Œã§è¨­å®š
    )
    
    start_time = time.time()
    warnings = []
    errors = []

    try:
        # 1. Image validation (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯)
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message="Validating image file"
        )
        
        if not image.content_type or not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Invalid image file format.")
        
        try:
            image_bytes = await image.read()
            # Update image size in session
            if session_id in meal_logger.active_sessions:
                meal_logger.active_sessions[session_id].image_size_bytes = len(image_bytes)
            
            # File size check (e.g., 10MB)
            if len(image_bytes) > 10 * 1024 * 1024:
                raise HTTPException(status_code=400, detail="Image file size too large (max 10MB).")
        except Exception as e:
            logger.error(f"Error reading image file: {e}")
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.REQUEST_RECEIVED,
                error_message="Failed to read image file",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail="Failed to read image file.")

        # 2. Parse Phase 1 analysis_data
        try:
            phase1_dict = json.loads(phase1_analysis_json)
            phase1_analysis = Phase1AnalysisResponse(**phase1_dict)
            
            # ãƒ­ã‚°ã«Phase 1æƒ…å ±ã‚’è¨˜éŒ²
            dishes_count = len(phase1_analysis.dishes)
            usda_queries_count = sum(len(dish.usda_query_candidates) for dish in phase1_analysis.dishes)
            
            meal_logger.log_entry(
                session_id=session_id,
                level=LogLevel.INFO,
                phase=ProcessingPhase.PHASE1_COMPLETE,
                message=f"Phase 1 data received: {dishes_count} dishes, {usda_queries_count} USDA queries",
                data={
                    "dishes_count": dishes_count,
                    "usda_queries_count": usda_queries_count,
                    "phase1_output": phase1_dict
                }
            )
            
        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE1_COMPLETE,
                error_message="Failed to parse Phase 1 JSON",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail=f"Invalid Phase 1 JSON: {e}")

        # 3. Execute ALL USDA searches based on Phase 1 candidates
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.USDA_SEARCH_START,
            message="Starting USDA searches for all query candidates"
        )
        
        usda_search_start_time = time.time()
        usda_search_tasks = []
        query_map = {}  # ã‚¯ã‚¨ãƒªã¨å…ƒã®æ–™ç†/é£Ÿæåã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
        unique_queries = set()

        for dish in phase1_analysis.dishes:
            for candidate in dish.usda_query_candidates:
                if candidate.query_term not in unique_queries:
                    # NEW: search_foods_rich ã‚’ä½¿ç”¨
                    usda_search_tasks.append(usda_service.search_foods_rich(candidate.query_term))
                    query_map[candidate.query_term] = candidate.original_term or dish.dish_name
                    unique_queries.add(candidate.query_term)

        # éåŒæœŸã§USDAæ¤œç´¢ã‚’å®Ÿè¡Œ
        logger.info(f"Starting {len(usda_search_tasks)} USDA searches")
        usda_search_results_list = await asyncio.gather(*usda_search_tasks, return_exceptions=True)
        usda_search_duration = (time.time() - usda_search_start_time) * 1000

        # 4. Format USDA results for Gemini prompt
        usda_candidates_prompt_segments = []
        all_usda_search_results_map: Dict[int, USDASearchResultItem] = {}  # FDC ID ã§å¼•ã‘ã‚‹ã‚ˆã†ã«
        search_term_to_results: Dict[str, List[USDASearchResultItem]] = {}  # ã‚¯ã‚¨ãƒª -> çµæœ
        total_results_found = 0
        search_details = []

        for query, results_or_exc in zip(unique_queries, usda_search_results_list):
            original_term = query_map.get(query, query)
            if isinstance(results_or_exc, Exception):
                segment = f"Error searching USDA for '{query}' (related to '{original_term}'): {results_or_exc}\n"
                errors.append(f"USDA Search failed for {query}: {results_or_exc}")
                search_details.append({
                    "query": query,
                    "original_term": original_term,
                    "status": "error",
                    "error": str(results_or_exc)
                })
            elif not results_or_exc:
                segment = f"No USDA candidates found for '{query}' (related to '{original_term}').\n"
                search_details.append({
                    "query": query,
                    "original_term": original_term,
                    "status": "no_results"
                })
            else:
                search_term_to_results[query] = results_or_exc
                total_results_found += len(results_or_exc)
                segment = f"USDA candidates for '{query}' (related to '{original_term}'):\n"
                
                result_summaries = []
                for i, item in enumerate(results_or_exc):
                    all_usda_search_results_map[item.fdc_id] = item
                    # NEW: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã¨ãƒ–ãƒ©ãƒ³ãƒ‰æƒ…å ±ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
                    segment += (
                        f"  {i+1}. FDC ID: {item.fdc_id}, Name: {item.description} "
                        f"(Type: {item.data_type or 'N/A'}"
                        f"{f', Brand: {item.brand_owner}' if item.brand_owner else ''}), "
                        f"Score: {item.score:.2f}\n"
                        # å¿…è¦ã§ã‚ã‚Œã° ingredientsText ã‚„ nutrients ã‚‚ä¸€éƒ¨å«ã‚ã‚‹
                    )
                    if item.ingredients_text:
                        segment += f"    Ingredients: {item.ingredients_text[:150]}...\n"
                    
                    result_summaries.append({
                        "fdc_id": item.fdc_id,
                        "description": item.description,
                        "data_type": item.data_type,
                        "score": item.score
                    })
                
                search_details.append({
                    "query": query,
                    "original_term": original_term,
                    "status": "success",
                    "results_count": len(results_or_exc),
                    "results": result_summaries
                })
            
            usda_candidates_prompt_segments.append(segment)

        usda_candidates_prompt_text = "\n---\n".join(usda_candidates_prompt_segments)
        
        # USDAæ¤œç´¢çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        meal_logger.update_usda_search_results(
            session_id=session_id,
            duration_ms=usda_search_duration,
            queries_executed=len(unique_queries),
            results_found=total_results_found,
            search_details=search_details
        )

        # 5. Call Gemini service (Phase 2) for strategy and FDC ID selection
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE2_START,
            message="Starting Phase 2 Gemini for strategy determination and FDC ID selection"
        )
        
        phase2_start_time = time.time()
        try:
            logger.info("Calling Gemini Phase 2 for strategy determination and FDC ID selection")
            # NEW: refine_analysis_phase2 ã‚’ä½¿ç”¨
            gemini_output_dict = await gemini_service.refine_analysis_phase2(
                image_bytes=image_bytes,
                image_mime_type=image.content_type,
                phase1_output_text=phase1_analysis_json,
                usda_results_text=usda_candidates_prompt_text
            )
            gemini_phase2_response = Phase2GeminiResponse(**gemini_output_dict)
            phase2_duration = (time.time() - phase2_start_time) * 1000
            
            # Phase 2çµæœã‚’è§£æã—ã¦ãƒ­ã‚°ã«è¨˜éŒ²
            strategy_decisions = {}
            fdc_selections = {}
            for dish in gemini_phase2_response.dishes:
                strategy_decisions[dish.dish_name] = {
                    "strategy": dish.calculation_strategy,
                    "reason": dish.reason_for_strategy
                }
                fdc_selections[dish.dish_name] = {
                    "dish_fdc_id": dish.fdc_id,
                    "dish_reason": dish.reason_for_choice,
                    "ingredients": [{
                        "name": ing.ingredient_name,
                        "fdc_id": ing.fdc_id,
                        "reason": ing.reason_for_choice
                    } for ing in dish.ingredients]
                }
            
            meal_logger.update_phase2_results(
                session_id=session_id,
                duration_ms=phase2_duration,
                strategy_decisions=strategy_decisions,
                fdc_selections=fdc_selections,
                phase2_output=gemini_output_dict
            )

        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE2_START,
                error_message="Gemini Phase 2 failed",
                error_details=str(e)
            )
            raise HTTPException(status_code=503, detail=f"Gemini Phase 2 error: {e}")

        # 6. Process Gemini output and perform Nutrition Calculation
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.NUTRITION_CALC_START,
            message="Starting nutrition calculation based on Phase 2 strategy"
        )
        
        nutrition_calc_start_time = time.time()
        refined_dishes_response: List[RefinedDishResponse] = []
        nutrition_service = get_nutrition_calculation_service()  # æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹

        # Phase 1 ã®é‡é‡æƒ…å ±ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã‚„ã™ãã™ã‚‹
        phase1_weights_map = {
            (d.dish_name, i.ingredient_name): i.weight_g
            for d in phase1_analysis.dishes
            for i in d.ingredients
        }

        for gemini_dish in gemini_phase2_response.dishes:
            # Phase 1 Dish ã‚’åå‰ã§æ¢ã™ (å³å¯†ã«ã¯IDãªã©ã§å¼•ãã¹ãã ãŒã€ä»Šå›ã¯åå‰ã§)
            p1_dish = next((d for d in phase1_analysis.dishes if d.dish_name == gemini_dish.dish_name), None)
            if not p1_dish:
                warnings.append(f"Could not match Phase 2 dish '{gemini_dish.dish_name}' to Phase 1.")
                continue

            dish_total_nutrients = None
            refined_ingredients_list: List[RefinedIngredientResponse] = []
            dish_key_nutrients_100g = None

            if gemini_dish.calculation_strategy == "dish_level":
                dish_fdc_id = gemini_dish.fdc_id
                if dish_fdc_id:
                    dish_weight_g = sum(ing.weight_g for ing in p1_dish.ingredients)
                    dish_key_nutrients_100g = await usda_service.get_food_details_for_nutrition(dish_fdc_id)
                    if dish_key_nutrients_100g and dish_weight_g > 0:
                        dish_total_nutrients = nutrition_service.calculate_actual_nutrients(dish_key_nutrients_100g, dish_weight_g)
                    else:
                        warnings.append(f"Could not calculate dish-level nutrition for '{gemini_dish.dish_name}'")
                else:
                    warnings.append(f"Dish-level strategy selected for '{gemini_dish.dish_name}' but no FDC ID provided.")

                # ææ–™æƒ…å ±ã¯èª¬æ˜çš„ã«æ®‹ã™ãŒã€æ „é¤Šè¨ˆç®—ã¯ã—ãªã„ (Fallback FDC ID ã¯å–å¾—ãƒ»è¡¨ç¤º)
                for gemini_ing in gemini_dish.ingredients:
                    weight = phase1_weights_map.get((gemini_dish.dish_name, gemini_ing.ingredient_name), 0.0)
                    ing_nutrients_100g = await usda_service.get_food_details_for_nutrition(gemini_ing.fdc_id) if gemini_ing.fdc_id else None
                    refined_ingredients_list.append(RefinedIngredientResponse(
                        ingredient_name=gemini_ing.ingredient_name,
                        weight_g=weight,
                        fdc_id=gemini_ing.fdc_id,  # Fallback ID
                        usda_source_description=gemini_ing.usda_source_description,
                        reason_for_choice=gemini_ing.reason_for_choice,
                        key_nutrients_per_100g=ing_nutrients_100g,
                        actual_nutrients=None  # Not calculated here
                    ))

            elif gemini_dish.calculation_strategy == "ingredient_level":
                ingredient_nutrients_list = []
                for gemini_ing in gemini_dish.ingredients:
                    weight = phase1_weights_map.get((gemini_dish.dish_name, gemini_ing.ingredient_name), 0.0)
                    ing_fdc_id = gemini_ing.fdc_id
                    ing_nutrients_100g = None
                    ing_actual_nutrients = None

                    if ing_fdc_id and weight > 0:
                        ing_nutrients_100g = await usda_service.get_food_details_for_nutrition(ing_fdc_id)
                        if ing_nutrients_100g:
                            ing_actual_nutrients = nutrition_service.calculate_actual_nutrients(ing_nutrients_100g, weight)
                            ingredient_nutrients_list.append(ing_actual_nutrients)
                        else:
                            warnings.append(f"Could not get nutrition for ingredient '{gemini_ing.ingredient_name}' (FDC ID: {ing_fdc_id})")
                    else:
                        warnings.append(f"Missing FDC ID or weight for ingredient '{gemini_ing.ingredient_name}'")

                    refined_ingredients_list.append(RefinedIngredientResponse(
                        ingredient_name=gemini_ing.ingredient_name,
                        weight_g=weight,
                        fdc_id=ing_fdc_id,
                        usda_source_description=gemini_ing.usda_source_description,
                        reason_for_choice=gemini_ing.reason_for_choice,
                        key_nutrients_per_100g=ing_nutrients_100g,
                        actual_nutrients=ing_actual_nutrients
                    ))
                # ææ–™ã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šã‚’åˆè¨ˆ
                dish_total_nutrients = nutrition_service.aggregate_nutrients_for_dish_from_ingredients(
                    [ing for ing in refined_ingredients_list if ing.actual_nutrients]  # None ã‚’é™¤å¤–
                )

            # RefinedDishResponse ã‚’ä½œæˆ
            refined_dishes_response.append(RefinedDishResponse(
                dish_name=gemini_dish.dish_name,
                type=p1_dish.type,
                quantity_on_plate=p1_dish.quantity_on_plate,
                calculation_strategy=gemini_dish.calculation_strategy,
                reason_for_strategy=gemini_dish.reason_for_strategy,
                fdc_id=gemini_dish.fdc_id,
                usda_source_description=gemini_dish.usda_source_description,
                reason_for_choice=gemini_dish.reason_for_choice,
                key_nutrients_per_100g=dish_key_nutrients_100g,
                ingredients=refined_ingredients_list,
                dish_total_actual_nutrients=dish_total_nutrients
            ))

        # 7. Calculate total meal nutrients
        total_meal_nutrients = nutrition_service.aggregate_nutrients_for_meal(
            [dish.dish_total_actual_nutrients for dish in refined_dishes_response if dish.dish_total_actual_nutrients]
        )
        
        nutrition_calc_duration = (time.time() - nutrition_calc_start_time) * 1000
        total_calories = total_meal_nutrients.calories_kcal if total_meal_nutrients else 0.0
        
        # æ „é¤Šè¨ˆç®—çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        meal_logger.update_nutrition_results(
            session_id=session_id,
            duration_ms=nutrition_calc_duration,
            total_calories=total_calories,
            final_nutrition={
                "total_meal_nutrients": total_meal_nutrients.dict() if total_meal_nutrients else None,
                "dishes_count": len(refined_dishes_response),
                "warnings_count": len(warnings),
                "errors_count": len(errors)
            }
        )

        # 8. Create final response
        response = MealAnalysisRefinementResponse(
            dishes=refined_dishes_response,
            total_meal_nutrients=total_meal_nutrients,
            warnings=warnings if warnings else None,
            errors=errors if errors else None
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
        meal_logger.end_session(
            session_id=session_id,
            warnings=warnings,
            errors=errors
        )
        
        return response

    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
        meal_logger.log_error(
            session_id=session_id,
            phase=ProcessingPhase.ERROR_OCCURRED,
            error_message="Unexpected error during request processing",
            error_details=str(e)
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        meal_logger.end_session(
            session_id=session_id,
            warnings=warnings,
            errors=errors + [str(e)]
        )
        
        raise 
```

============================================================

ğŸ“ ã‚µãƒ¼ãƒ“ã‚¹å±¤ (v2.1å¯¾å¿œ)
============================================================

ğŸ“„ FILE: app/services/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/services/gemini_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 12578 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:41:52
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig, HarmCategory, HarmBlockThreshold
from typing import Dict, Optional
import json
import logging
from PIL import Image
import io

# æ–°ã—ã„ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..api.v1.schemas.meal import PHASE_1_GEMINI_SCHEMA, PHASE_2_GEMINI_SCHEMA, MEAL_ANALYSIS_GEMINI_SCHEMA, REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA
from ..prompts import PromptLoader

logger = logging.getLogger(__name__)

# Geminiã®æ§‹é€ åŒ–å‡ºåŠ›ã®ãŸã‚ã®JSONã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©
MEAL_ANALYSIS_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆã€‚",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°ã€‚"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—, ãƒ‡ã‚¶ãƒ¼ãƒˆï¼‰ã€‚"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°ï¼ˆä¾‹: '1æ¯', '2åˆ‡ã‚Œ', 'ç´„200g'ï¼‰ã€‚"},
                    "ingredients": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ã¨æ¨å®šã•ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§°ã€‚"},
                                "weight_g": {"type": "number", "description": "ãã®ææ–™ã®æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰ã€‚"}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients"]
            }
        }
    },
    "required": ["dishes"]
}


class GeminiMealAnalyzer:
    """Vertex AIçµŒç”±ã§Geminiã‚’ä½¿ç”¨ã—ã¦é£Ÿäº‹ç”»åƒã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹ (v2.1å¯¾å¿œ)"""
    
    def __init__(self, project_id: str, location: str, model_name: str = "gemini-2.5-flash-preview-05-20"):
        """
        åˆæœŸåŒ–
        
        Args:
            project_id: GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
            location: Vertex AIã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¾‹: us-central1ï¼‰
            model_name: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        """
        # Vertex AIã®åˆæœŸåŒ–
        vertexai.init(project=project_id, location=location)
        
        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.model = GenerativeModel(model_name=model_name)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–ï¼ˆå¿…é ˆï¼‰
        self.prompt_loader = PromptLoader()
        
        # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®š
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        }

    async def analyze_image_phase1(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        optional_text: Optional[str] = None
    ) -> Dict:
        """
        Phase 1: ç”»åƒã‚’åˆ†æã—ã€æ–™ç†ãƒ»é£Ÿæã¨USDAã‚¯ã‚¨ãƒªå€™è£œã‚’æŠ½å‡º (v2.1ä»•æ§˜)
        """
        try:
            system_prompt = self.prompt_loader.get_phase1_system_prompt()
            user_prompt = self.prompt_loader.get_phase1_user_prompt(optional_text)
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            contents = [Part.from_text(full_prompt), Part.from_data(data=image_bytes, mime_type=image_mime_type)]

            generation_config = GenerationConfig(
                temperature=0.3, # å€™è£œã‚’åºƒã’ã‚‹ãŸã‚ã«å°‘ã—ä¸Šã’ã‚‹ã“ã¨ã‚‚æ¤œè¨
                top_p=0.9,
                top_k=20,
                max_output_tokens=16384, # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å¢—ã‚„ã™
                response_mime_type="application/json",
                # NEW: Phase 1 ç”¨ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
                response_schema=PHASE_1_GEMINI_SCHEMA
            )

            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )

            if not response.text:
                raise ValueError("No response returned from Gemini (Phase 1).")

            result = json.loads(response.text)
            logger.info(f"Gemini Phase 1 analysis completed. Found {len(result.get('dishes', []))} dishes.")
            return result

        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error (Phase 1): {e}")
            raise RuntimeError(f"Vertex AI/Gemini (Phase 1) API request failed: {e}") from e

    async def refine_analysis_phase2(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        phase1_output_text: str, # Phase 1 ã®ç”Ÿ JSON å‡ºåŠ›
        usda_results_text: str # æ•´å½¢ã•ã‚ŒãŸå…¨ USDA æ¤œç´¢çµæœ
    ) -> Dict:
        """
        Phase 2: USDAå€™è£œã«åŸºã¥ãã€calculation_strategy ã‚’æ±ºå®šã—ã€FDC ID ã‚’é¸æŠ (v2.1ä»•æ§˜)
        """
        try:
            system_prompt = self.prompt_loader.get_phase2_system_prompt()
            user_prompt = self.prompt_loader.get_phase2_user_prompt(
                initial_ai_output=phase1_output_text,
                usda_candidates=usda_results_text
            )
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            contents = [Part.from_text(full_prompt), Part.from_data(data=image_bytes, mime_type=image_mime_type)]

            generation_config = GenerationConfig(
                temperature=0.1, # æ±ºå®šè«–çš„ãªå‡ºåŠ›ã‚’ç›®æŒ‡ã™ãŸã‚ä½ã‚ã«è¨­å®š
                top_p=0.8,
                top_k=10,
                max_output_tokens=16384, # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å¢—ã‚„ã™
                response_mime_type="application/json",
                # NEW: Phase 2 ç”¨ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
                response_schema=PHASE_2_GEMINI_SCHEMA
            )

            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )

            if not response.text:
                raise ValueError("No response returned from Gemini (Phase 2).")

            result = json.loads(response.text)
            logger.info(f"Gemini Phase 2 analysis completed. Processed {len(result.get('dishes', []))} dishes.")
            return result

        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error (Phase 2): {e}")
            raise RuntimeError(f"Vertex AI/Gemini (Phase 2) API request failed: {e}") from e

    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚ä¿æŒ
    async def analyze_image_and_text(
        self, 
        image_bytes: bytes, 
        image_mime_type: str, 
        optional_text: Optional[str] = None
    ) -> Dict:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆæ—¢å­˜ã®Phase 1ã¨ã—ã¦å‹•ä½œï¼‰
        """
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            system_prompt = self.prompt_loader.get_phase1_system_prompt()
            user_prompt = self.prompt_loader.get_phase1_user_prompt(optional_text)
            
            # å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—¢å­˜ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
            generation_config = GenerationConfig(
                temperature=0.2,
                top_p=0.9,
                top_k=20,
                max_output_tokens=8192,
                response_mime_type="application/json",
                response_schema=MEAL_ANALYSIS_GEMINI_SCHEMA
            )
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆéåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼‰
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if not response.text:
                raise ValueError("No response returned from Gemini.")
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)
            
            logger.info(f"Gemini analysis completed successfully. Found {len(result.get('dishes', []))} dishes.")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error: {e}")
            raise RuntimeError(f"Error processing response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error: {e}")
            raise RuntimeError(f"Vertex AI/Gemini API request failed: {e}") from e
    
    async def analyze_image_with_usda_context(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        usda_candidates_text: str,
        initial_ai_output_text: Optional[str] = None
    ) -> Dict:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆæ—¢å­˜ã®Phase 2ã¨ã—ã¦å‹•ä½œï¼‰
        """
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            system_prompt = self.prompt_loader.get_phase2_system_prompt()
            user_prompt = self.prompt_loader.get_phase2_user_prompt(
                initial_ai_output=initial_ai_output_text or "{}",
                usda_candidates=usda_candidates_text
            )
            
            # å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            # ãƒ•ã‚§ãƒ¼ã‚º2ç”¨ã®Generation Config
            phase2_generation_config = GenerationConfig(
                temperature=0.2,
                top_p=0.9,
                top_k=20,
                max_output_tokens=8192,
                response_mime_type="application/json",
                response_schema=REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA
            )
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=phase2_generation_config,
                safety_settings=self.safety_settings
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if not response.text:
                raise ValueError("No response returned from Gemini Phase 2.")
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)
            
            logger.info(f"Gemini Phase 2 refinement completed successfully. Processed {len(result.get('dishes', []))} dishes.")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error in Phase 2: {e}")
            raise RuntimeError(f"Error processing Phase 2 response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error in Phase 2: {e}")
            raise RuntimeError(f"Vertex AI/Gemini Phase 2 API request failed: {e}") from e


def get_gemini_analyzer(project_id: str, location: str, model_name: str) -> GeminiMealAnalyzer:
    """GeminiMealAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦è¿”ã™"""
    return GeminiMealAnalyzer(project_id=project_id, location=location, model_name=model_name) 
```

============================================================

ğŸ“„ FILE: app/services/usda_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 13467 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:39:14
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
# app/services/usda_service.py
import httpx
import json
import logging
from typing import List, Optional, Dict, Any
from functools import lru_cache

from ..core.config import get_settings
from ..api.v1.schemas.meal import USDANutrient, USDASearchResultItem

logger = logging.getLogger(__name__)


class USDAService:
    """USDA FoodData Central APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        settings = get_settings()
        self.api_key = settings.USDA_API_KEY
        self.base_url = settings.USDA_API_BASE_URL
        self.timeout = settings.USDA_API_TIMEOUT
        self.key_nutrient_numbers = settings.USDA_KEY_NUTRIENT_NUMBERS
        
        if not self.api_key:
            logger.error("USDA_API_KEY is not configured.")
            raise ValueError("USDA API key not configured.")
        
        # httpx.AsyncClientã®è¨­å®š
        self.client = httpx.AsyncClient(
            timeout=self.timeout,
            headers={"X-Api-Key": self.api_key}
        )
    
    async def search_foods_rich(
        self,
        query: str,
        data_types: Optional[List[str]] = None,
        page_size: int = 10, # å€™è£œæ•°ã‚’å¢—ã‚„ã™ (è¨­å®šå¯èƒ½ã«)
        page_number: int = 1,
        sort_by: str = "score",
        sort_order: str = "desc"
    ) -> List[USDASearchResultItem]:
        """
        USDA FoodData Central APIã§é£Ÿå“ã‚’æ¤œç´¢ã—ã€è©³ç´°ãªæƒ…å ±ã‚’è¿”ã™ (v2.1ä»•æ§˜)
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—
            data_types: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["Foundation", "SR Legacy", "Branded"]ï¼‰
            page_size: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®çµæœæ•°
            page_number: å–å¾—ã™ã‚‹ãƒšãƒ¼ã‚¸ç•ªå·
            sort_by: ã‚½ãƒ¼ãƒˆã‚­ãƒ¼
            sort_order: ã‚½ãƒ¼ãƒˆé †ï¼ˆ"asc" ã¾ãŸã¯ "desc"ï¼‰
            
        Returns:
            USDASearchResultItemã®ãƒªã‚¹ãƒˆï¼ˆæ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ï¼‰
        """
        params = {
            "query": query,
            "api_key": self.api_key,
            "pageSize": page_size,
            "pageNumber": page_number,
            "sortBy": sort_by,
            "sortOrder": sort_order
        }
        
        if data_types:
            # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã¨ã—ã¦æ¸¡ã™
            params["dataType"] = ",".join(data_types)
        
        # NEW: requireAllWords ã‚’ True ã«è¨­å®šã—ã¦ç²¾åº¦ã‚’ä¸Šã’ã‚‹ã“ã¨ã‚‚æ¤œè¨ (ãŸã ã—ãƒ’ãƒƒãƒˆæ•°ãŒæ¸›ã‚‹)
        # params["requireAllWords"] = "true"
        
        try:
            logger.info(f"USDA API rich search: query='{query}', page_size={page_size}")
            response = await self.client.get(f"{self.base_url}/foods/search", params=params)
            
            # ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆæƒ…å ±ã®ãƒ­ã‚°
            if "X-RateLimit-Remaining" in response.headers:
                logger.info(f"USDA API Rate Limit Remaining: {response.headers.get('X-RateLimit-Remaining')}")
            
            response.raise_for_status()
            data = response.json()
            
            results = []
            for food_data in data.get("foods", [])[:page_size]:
                # NEW: foodNutrients ã‚’è©³ç´°ã«å–å¾—ãƒ»ãƒ‘ãƒ¼ã‚¹
                # NOTE: æ¤œç´¢çµæœã® foodNutrients ã¯é™å®šçš„ãªã“ã¨ãŒå¤šã„ã€‚
                # è©³ç´°ãªæ „é¤Šç´ ã¯ get_food_details_for_nutrition ã§å–å¾—ã™ã‚‹ã€‚
                # ã“ã“ã§ã¯ä¸»ã« FDC ID, description, dataType, brandOwner, ingredients ã‚’é‡è¦–ã€‚
                nutrients_extracted = self._extract_key_nutrients(food_data.get("foodNutrients", []))
                
                results.append(USDASearchResultItem(
                    fdc_id=food_data.get("fdcId"),
                    description=food_data.get("description"),
                    data_type=food_data.get("dataType"),
                    brand_owner=food_data.get("brandOwner"),
                    # NEW: ingredientsText ã‚’å–å¾—
                    ingredients_text=food_data.get("ingredients"),
                    food_nutrients=nutrients_extracted,
                    score=food_data.get("score")
                ))
            
            logger.info(f"USDA API rich search returned {len(results)} results for query '{query}'")
            return results
            
        except httpx.HTTPStatusError as e:
            logger.error(f"USDA API HTTP error: {e.response.status_code} - {e.response.text}")
            if e.response.status_code == 429:
                raise RuntimeError(f"USDA API rate limit exceeded. Detail: {e.response.text}") from e
            raise RuntimeError(f"USDA API error: {e.response.status_code} - {e.response.text}") from e
        except httpx.RequestError as e:
            logger.error(f"USDA API request failed: {str(e)}")
            raise RuntimeError(f"USDA API request failed: {str(e)}") from e
        except (json.JSONDecodeError, TypeError, KeyError) as e:
            logger.error(f"USDA API response parsing error: {str(e)}")
            raise RuntimeError(f"USDA API response parsing error: {str(e)}") from e
        except Exception as e:
            logger.error(f"Unexpected error in USDAService.search_foods_rich: {str(e)}")
            raise RuntimeError(f"Unexpected error in USDA service: {str(e)}") from e
    
    def _extract_key_nutrients(self, food_nutrients: List[Dict[str, Any]]) -> List[USDANutrient]:
        """
        foodNutrientsãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸»è¦æ „é¤Šç´ ã‚’æŠ½å‡º (æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ä½¿ç”¨)
        """
        # ä¸»è¦æ „é¤Šç´  (configã‹ã‚‰å–å¾—) ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹
        nutrients_extracted = []
        key_numbers = self.key_nutrient_numbers # Settings ã‹ã‚‰å–å¾—

        for nutrient_entry in food_nutrients:
            nutrient_detail = nutrient_entry.get("nutrient", {})
            amount = nutrient_entry.get("amount")

            if not nutrient_detail and "nutrientId" in nutrient_entry: # Branded abridged
                number = nutrient_entry.get("nutrientNumber")
                name = nutrient_entry.get("nutrientName")
                unit_name = nutrient_entry.get("unitName")
                amount = nutrient_entry.get("value")
                nutrient_id = nutrient_entry.get("nutrientId")
            else: # Standard
                number = nutrient_detail.get("number")
                name = nutrient_detail.get("name")
                unit_name = nutrient_detail.get("unitName")
                nutrient_id = nutrient_detail.get("id")

            if number and str(number) in key_numbers:
                if name and amount is not None and unit_name:
                    nutrients_extracted.append(USDANutrient(
                        name=name,
                        amount=float(amount),
                        unit_name=unit_name,
                        nutrient_id=int(nutrient_id) if nutrient_id else None,
                        nutrient_number=str(number) if number else None
                    ))
        return nutrients_extracted

    async def get_food_details(self, fdc_id: int) -> Optional[USDASearchResultItem]:
        """
        ç‰¹å®šã®FDC IDã®é£Ÿå“è©³ç´°æƒ…å ±ã‚’å–å¾— (æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ä½¿ç”¨)
        """
        params = {
            "api_key": self.api_key,
            "format": "full"  # ingredients ã‚‚ç¢ºå®Ÿã«å–å¾—ã™ã‚‹ãŸã‚ã« format="full" ã‚’ä½¿ç”¨
        }
        
        try:
            logger.info(f"Getting USDA food details for FDC ID: {fdc_id}")
            response = await self.client.get(f"{self.base_url}/food/{fdc_id}", params=params)
            
            if "X-RateLimit-Remaining" in response.headers:
                logger.debug(f"USDA API Rate Limit Remaining: {response.headers.get('X-RateLimit-Remaining')}")
            
            response.raise_for_status()
            food_data = response.json()
            
            # _extract_key_nutrients ã‚’ä½¿ç”¨ã—ã¦æ „é¤Šç´ ã‚’ãƒ‘ãƒ¼ã‚¹
            nutrients_extracted = self._extract_key_nutrients(food_data.get("foodNutrients", []))
            
            return USDASearchResultItem(
                fdc_id=food_data.get("fdcId"),
                description=food_data.get("description"),
                data_type=food_data.get("dataType"),
                brand_owner=food_data.get("brandOwner"),
                ingredients_text=food_data.get("ingredients"),
                food_nutrients=nutrients_extracted,
                score=None  # è©³ç´°å–å¾—æ™‚ã¯ã‚¹ã‚³ã‚¢ãªã—
            )
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                logger.warning(f"Food with FDC ID {fdc_id} not found")
                return None
            logger.error(f"USDA API error getting food details: {e.response.status_code} - {e.response.text}")
            raise RuntimeError(f"USDA API error: {e.response.status_code}") from e
        except Exception as e:
            logger.error(f"Error getting food details for FDC ID {fdc_id}: {str(e)}")
            raise RuntimeError(f"Error getting food details: {str(e)}") from e

    async def get_food_details_for_nutrition(self, fdc_id: int) -> Optional[Dict[str, float]]:
        """
        æ „é¤Šè¨ˆç®—ç”¨ã®é£Ÿå“è©³ç´°æƒ…å ±ã‚’å–å¾— (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒãƒ»ç¢ºèª)
        """
        params = {
            "api_key": self.api_key,
            "format": "full",
            # ä¸»è¦æ „é¤Šç´ ã®ã¿å–å¾—
            "nutrients": ",".join(self.key_nutrient_numbers)
        }
        
        try:
            logger.debug(f"Getting nutrition data for FDC ID: {fdc_id}")
            response = await self.client.get(f"{self.base_url}/food/{fdc_id}", params=params)
            
            if "X-RateLimit-Remaining" in response.headers:
                logger.debug(f"USDA API Rate Limit Remaining: {response.headers.get('X-RateLimit-Remaining')}")
            
            response.raise_for_status()
            food_data = response.json()
            
            return self._parse_nutrients_for_calculation(food_data)
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                logger.warning(f"Food with FDC ID {fdc_id} not found for nutrition calculation")
                return None
            logger.error(f"USDA API error getting nutrition data: {e.response.status_code} - {e.response.text}")
            return None
        except Exception as e:
            logger.error(f"Error getting nutrition data for FDC ID {fdc_id}: {str(e)}")
            return None

    def _parse_nutrients_for_calculation(self, food_data_raw: dict) -> Dict[str, float]:
        """
        USDA APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ „é¤Šè¨ˆç®—ç”¨ã®æ „é¤Šç´ è¾æ›¸ã‚’ä½œæˆ
        """
        nutrients_dict = {}
        food_nutrients = food_data_raw.get("foodNutrients", [])
        
        # æ „é¤Šç´ ç•ªå·ã¨æ¨™æº–åã®å¯¾å¿œè¡¨
        nutrient_map = {
            "208": "calories_kcal",      # Energy
            "203": "protein_g",          # Protein  
            "205": "carbohydrates_g",    # Carbohydrate
            "204": "fat_g",              # Total lipid (fat)
            "291": "fiber_g",            # Fiber, total dietary
            "269": "sugars_g",           # Sugars, total
            "307": "sodium_mg"           # Sodium
        }
        
        for nutrient_entry in food_nutrients:
            nutrient_detail = nutrient_entry.get("nutrient", {})
            amount = nutrient_entry.get("amount")
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®é•ã„ã«å¯¾å¿œ
            if not nutrient_detail and "nutrientId" in nutrient_entry:
                # Branded Foods abridged format
                number = nutrient_entry.get("nutrientNumber")
                amount = nutrient_entry.get("value")
            else:
                # Standard format
                number = nutrient_detail.get("number")
            
            if number and str(number) in nutrient_map and amount is not None:
                standard_name = nutrient_map[str(number)]
                nutrients_dict[standard_name] = float(amount)
        
        logger.debug(f"Parsed nutrients for calculation: {nutrients_dict}")
        return nutrients_dict

    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚ä¿æŒ
    async def search_foods(
        self,
        query: str,
        data_types: Optional[List[str]] = None,
        page_size: int = 5,
        page_number: int = 1,
        sort_by: str = "score",
        sort_order: str = "desc"
    ) -> List:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜search_foodsãƒ¡ã‚½ãƒƒãƒ‰
        """
        # æ–°ã—ã„search_foods_richã‚’å‘¼ã³å‡ºã—ã¦ã€å¤ã„å½¢å¼ã«å¤‰æ›
        rich_results = await self.search_foods_rich(
            query=query,
            data_types=data_types,
            page_size=page_size,
            page_number=page_number,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«å¤ã„USDASearchResultItemã‚¯ãƒ©ã‚¹å½¢å¼ã«å¤‰æ›
        # ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€å¿…è¦ã«å¿œã˜ã¦ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä¿æŒã™ã‚‹ï¼‰
        return rich_results
    
    async def close_client(self):
        """HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.client:
            await self.client.aclose()


@lru_cache()
def get_usda_service():
    """USDAServiceã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return USDAService() 
```

============================================================

ğŸ“„ FILE: app/services/nutrition_calculation_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 10114 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:21:23
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
æ „é¤Šç´ è¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ (v2.1å¯¾å¿œ)

ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç´”ç²‹ãªè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ï¼š
1. 100gã‚ãŸã‚Šã®æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®æ „é¤Šç´ ã‚’è¨ˆç®—
2. é£Ÿæãƒªã‚¹ãƒˆã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ
3. æ–™ç†ãƒªã‚¹ãƒˆã‹ã‚‰é£Ÿäº‹å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ
"""

import logging
from typing import List, Optional, Dict
from ..api.v1.schemas.meal import CalculatedNutrients, RefinedIngredientResponse, RefinedDishResponse

logger = logging.getLogger(__name__)


class NutritionCalculationService:
    """æ „é¤Šç´ è¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ (v2.1å¯¾å¿œ)"""
    
    @staticmethod
    def calculate_actual_nutrients(
        key_nutrients_per_100g: Dict[str, float], 
        estimated_weight_g: float
    ) -> CalculatedNutrients:
        """
        100gã‚ãŸã‚Šã®ä¸»è¦æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®æ „é¤Šç´ é‡ã‚’è¨ˆç®— (v2.1ä»•æ§˜)
        
        Args:
            key_nutrients_per_100g: 100gã‚ãŸã‚Šã®ä¸»è¦æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿
            estimated_weight_g: æ¨å®šã‚°ãƒ©ãƒ æ•°
            
        Returns:
            CalculatedNutrients: è¨ˆç®—æ¸ˆã¿æ „é¤Šç´ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        if not key_nutrients_per_100g or estimated_weight_g <= 0:
            logger.warning(f"Invalid input: key_nutrients_per_100g={key_nutrients_per_100g}, estimated_weight_g={estimated_weight_g}")
            return CalculatedNutrients()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆå…¨ã¦0.0ï¼‰ã‚’è¿”ã™
        
        try:
            # è¨ˆç®—å¼: (Nutrient_Value_per_100g / 100) Ã— estimated_weight_g
            multiplier = estimated_weight_g / 100.0
            
            # å„æ „é¤Šç´ ã‚’è¨ˆç®—ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„/Noneã®å ´åˆã¯0.0ã¨ã—ã¦æ‰±ã†ï¼‰
            calories_kcal = round((key_nutrients_per_100g.get('calories_kcal', 0.0) or 0.0) * multiplier, 2)
            protein_g = round((key_nutrients_per_100g.get('protein_g', 0.0) or 0.0) * multiplier, 2)
            carbohydrates_g = round((key_nutrients_per_100g.get('carbohydrates_g', 0.0) or 0.0) * multiplier, 2)
            fat_g = round((key_nutrients_per_100g.get('fat_g', 0.0) or 0.0) * multiplier, 2)
            
            # v2.1ã§è¿½åŠ ã•ã‚ŒãŸæ „é¤Šç´ ã‚‚è¨ˆç®—
            fiber_g = key_nutrients_per_100g.get('fiber_g')
            fiber_g = round(fiber_g * multiplier, 2) if fiber_g is not None else None
            
            sugars_g = key_nutrients_per_100g.get('sugars_g')
            sugars_g = round(sugars_g * multiplier, 2) if sugars_g is not None else None
            
            sodium_mg = key_nutrients_per_100g.get('sodium_mg')
            sodium_mg = round(sodium_mg * multiplier, 2) if sodium_mg is not None else None
            
            result = CalculatedNutrients(
                calories_kcal=calories_kcal,
                protein_g=protein_g,
                carbohydrates_g=carbohydrates_g,
                fat_g=fat_g,
                fiber_g=fiber_g,
                sugars_g=sugars_g,
                sodium_mg=sodium_mg
            )
            
            logger.debug(f"Calculated nutrients for {estimated_weight_g}g: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error calculating actual nutrients: {e}")
            return CalculatedNutrients()  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
    
    @staticmethod
    def aggregate_nutrients_for_dish_from_ingredients(
        ingredients: List[RefinedIngredientResponse]
    ) -> CalculatedNutrients:
        """
        ææ–™ãƒªã‚¹ãƒˆã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ (v2.1ä»•æ§˜)
        
        Args:
            ingredients: RefinedIngredientResponseã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¨ˆç®—æ¸ˆã¿ã®actual_nutrientsã‚’æŒã¤ï¼‰
            
        Returns:
            CalculatedNutrients: æ–™ç†ã®é›†è¨ˆæ „é¤Šç´ 
        """
        if not ingredients:
            logger.warning("No ingredients provided for aggregation")
            return CalculatedNutrients()
        
        try:
            total_calories = 0.0
            total_protein = 0.0
            total_carbohydrates = 0.0
            total_fat = 0.0
            total_fiber = 0.0
            total_sugars = 0.0
            total_sodium = 0.0
            
            # Optionalæ „é¤Šç´ ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            fiber_count = 0
            sugars_count = 0
            sodium_count = 0
            calculated_count = 0
            
            for ingredient in ingredients:
                if ingredient.actual_nutrients:
                    total_calories += ingredient.actual_nutrients.calories_kcal
                    total_protein += ingredient.actual_nutrients.protein_g
                    total_carbohydrates += ingredient.actual_nutrients.carbohydrates_g
                    total_fat += ingredient.actual_nutrients.fat_g
                    
                    # Optionalæ „é¤Šç´ ã®å‡¦ç†
                    if ingredient.actual_nutrients.fiber_g is not None:
                        total_fiber += ingredient.actual_nutrients.fiber_g
                        fiber_count += 1
                    
                    if ingredient.actual_nutrients.sugars_g is not None:
                        total_sugars += ingredient.actual_nutrients.sugars_g
                        sugars_count += 1
                    
                    if ingredient.actual_nutrients.sodium_mg is not None:
                        total_sodium += ingredient.actual_nutrients.sodium_mg
                        sodium_count += 1
                    
                    calculated_count += 1
                else:
                    logger.warning(f"Ingredient '{ingredient.ingredient_name}' has no actual_nutrients")
            
            # å°æ•°ç‚¹ä»¥ä¸‹2æ¡ã«ä¸¸ã‚ã‚‹
            result = CalculatedNutrients(
                calories_kcal=round(total_calories, 2),
                protein_g=round(total_protein, 2),
                carbohydrates_g=round(total_carbohydrates, 2),
                fat_g=round(total_fat, 2),
                fiber_g=round(total_fiber, 2) if fiber_count > 0 else None,
                sugars_g=round(total_sugars, 2) if sugars_count > 0 else None,
                sodium_mg=round(total_sodium, 2) if sodium_count > 0 else None
            )
            
            logger.info(f"Aggregated nutrients from {calculated_count}/{len(ingredients)} ingredients: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error aggregating nutrients for dish: {e}")
            return CalculatedNutrients()
    
    @staticmethod
    def aggregate_nutrients_for_meal(
        dishes: List[RefinedDishResponse]
    ) -> CalculatedNutrients:
        """
        æ–™ç†ãƒªã‚¹ãƒˆã‹ã‚‰é£Ÿäº‹å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ (v2.1ä»•æ§˜)
        
        Args:
            dishes: RefinedDishResponseã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¨ˆç®—æ¸ˆã¿ã®dish_total_actual_nutrientsã‚’æŒã¤ï¼‰
            
        Returns:
            CalculatedNutrients: é£Ÿäº‹å…¨ä½“ã®ç·æ „é¤Šç´ 
        """
        if not dishes:
            logger.warning("No dishes provided for meal aggregation")
            return CalculatedNutrients()
        
        try:
            total_calories = 0.0
            total_protein = 0.0
            total_carbohydrates = 0.0
            total_fat = 0.0
            total_fiber = 0.0
            total_sugars = 0.0
            total_sodium = 0.0
            
            # Optionalæ „é¤Šç´ ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            fiber_count = 0
            sugars_count = 0
            sodium_count = 0
            calculated_count = 0
            
            for dish in dishes:
                if dish.dish_total_actual_nutrients:
                    total_calories += dish.dish_total_actual_nutrients.calories_kcal
                    total_protein += dish.dish_total_actual_nutrients.protein_g
                    total_carbohydrates += dish.dish_total_actual_nutrients.carbohydrates_g
                    total_fat += dish.dish_total_actual_nutrients.fat_g
                    
                    # Optionalæ „é¤Šç´ ã®å‡¦ç†
                    if dish.dish_total_actual_nutrients.fiber_g is not None:
                        total_fiber += dish.dish_total_actual_nutrients.fiber_g
                        fiber_count += 1
                    
                    if dish.dish_total_actual_nutrients.sugars_g is not None:
                        total_sugars += dish.dish_total_actual_nutrients.sugars_g
                        sugars_count += 1
                    
                    if dish.dish_total_actual_nutrients.sodium_mg is not None:
                        total_sodium += dish.dish_total_actual_nutrients.sodium_mg
                        sodium_count += 1
                    
                    calculated_count += 1
                else:
                    logger.warning(f"Dish '{dish.dish_name}' has no dish_total_actual_nutrients")
            
            # å°æ•°ç‚¹ä»¥ä¸‹2æ¡ã«ä¸¸ã‚ã‚‹
            result = CalculatedNutrients(
                calories_kcal=round(total_calories, 2),
                protein_g=round(total_protein, 2),
                carbohydrates_g=round(total_carbohydrates, 2),
                fat_g=round(total_fat, 2),
                fiber_g=round(total_fiber, 2) if fiber_count > 0 else None,
                sugars_g=round(total_sugars, 2) if sugars_count > 0 else None,
                sodium_mg=round(total_sodium, 2) if sodium_count > 0 else None
            )
            
            logger.info(f"Aggregated meal nutrients from {calculated_count}/{len(dishes)} dishes: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error aggregating nutrients for meal: {e}")
            return CalculatedNutrients()


# ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
def get_nutrition_calculation_service() -> NutritionCalculationService:
    """
    æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
    
    Returns:
        NutritionCalculationService: æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return NutritionCalculationService() 
```

============================================================

ğŸ“„ FILE: app/services/logging_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 13198 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:54:52
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import json
import logging
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)

class LogLevel(str, Enum):
    """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«å®šç¾©"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class ProcessingPhase(str, Enum):
    """å‡¦ç†ãƒ•ã‚§ãƒ¼ã‚ºå®šç¾©"""
    REQUEST_RECEIVED = "REQUEST_RECEIVED"
    PHASE1_START = "PHASE1_START"
    PHASE1_COMPLETE = "PHASE1_COMPLETE"
    USDA_SEARCH_START = "USDA_SEARCH_START"
    USDA_SEARCH_COMPLETE = "USDA_SEARCH_COMPLETE"
    PHASE2_START = "PHASE2_START"
    PHASE2_COMPLETE = "PHASE2_COMPLETE"
    NUTRITION_CALC_START = "NUTRITION_CALC_START"
    NUTRITION_CALC_COMPLETE = "NUTRITION_CALC_COMPLETE"
    RESPONSE_SENT = "RESPONSE_SENT"
    ERROR_OCCURRED = "ERROR_OCCURRED"

@dataclass
class LogEntry:
    """ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®æ¨™æº–æ§‹é€ """
    timestamp: str
    request_id: str
    log_level: LogLevel
    phase: ProcessingPhase
    message: str
    data: Optional[Dict[str, Any]] = None
    execution_time_ms: Optional[float] = None
    error_details: Optional[str] = None

@dataclass
class MealAnalysisSession:
    """é£Ÿäº‹åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®ãƒ­ã‚°"""
    session_id: str
    start_time: str
    end_time: Optional[str] = None
    endpoint: str = ""
    image_filename: Optional[str] = None
    image_size_bytes: Optional[int] = None
    
    # ãƒ•ã‚§ãƒ¼ã‚º1çµæœ
    phase1_duration_ms: Optional[float] = None
    phase1_dishes_count: Optional[int] = None
    phase1_usda_queries_count: Optional[int] = None
    phase1_output: Optional[Dict[str, Any]] = None
    
    # USDAæ¤œç´¢çµæœ
    usda_search_duration_ms: Optional[float] = None
    usda_queries_executed: Optional[int] = None
    usda_results_found: Optional[int] = None
    usda_search_details: Optional[List[Dict[str, Any]]] = None
    
    # ãƒ•ã‚§ãƒ¼ã‚º2çµæœ
    phase2_duration_ms: Optional[float] = None
    phase2_strategy_decisions: Optional[Dict[str, Any]] = None
    phase2_fdc_selections: Optional[Dict[str, Any]] = None
    phase2_output: Optional[Dict[str, Any]] = None
    
    # æ „é¤Šè¨ˆç®—çµæœ
    nutrition_calc_duration_ms: Optional[float] = None
    total_calories: Optional[float] = None
    final_nutrition: Optional[Dict[str, Any]] = None
    
    # ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Š
    warnings: Optional[List[str]] = None
    errors: Optional[List[str]] = None
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    total_duration_ms: Optional[float] = None
    gemini_api_calls: Optional[int] = None
    usda_api_calls: Optional[int] = None

class MealAnalysisLogger:
    """é£Ÿäº‹åˆ†æå°‚ç”¨ãƒ­ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        self.active_sessions: Dict[str, MealAnalysisSession] = {}
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
        self.setup_file_logging()
    
    def setup_file_logging(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚°ã®è¨­å®š"""
        # è©³ç´°ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        detailed_log_file = self.log_dir / "meal_analysis_detailed.jsonl"
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        session_log_file = self.log_dir / "meal_analysis_sessions.jsonl"
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        error_log_file = self.log_dir / "meal_analysis_errors.log"
        
        self.detailed_log_file = detailed_log_file
        self.session_log_file = session_log_file
        self.error_log_file = error_log_file
    
    def start_session(
        self, 
        endpoint: str,
        image_filename: Optional[str] = None,
        image_size_bytes: Optional[int] = None
    ) -> str:
        """æ–°ã—ã„åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        session_id = str(uuid.uuid4())
        
        session = MealAnalysisSession(
            session_id=session_id,
            start_time=datetime.now(timezone.utc).isoformat(),
            endpoint=endpoint,
            image_filename=image_filename,
            image_size_bytes=image_size_bytes
        )
        
        self.active_sessions[session_id] = session
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message=f"Started meal analysis session for endpoint: {endpoint}",
            data={
                "endpoint": endpoint,
                "image_filename": image_filename,
                "image_size_bytes": image_size_bytes
            }
        )
        
        return session_id
    
    def log_entry(
        self,
        session_id: str,
        level: LogLevel,
        phase: ProcessingPhase,
        message: str,
        data: Optional[Dict[str, Any]] = None,
        execution_time_ms: Optional[float] = None,
        error_details: Optional[str] = None
    ):
        """å€‹åˆ¥ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’è¨˜éŒ²"""
        entry = LogEntry(
            timestamp=datetime.now(timezone.utc).isoformat(),
            request_id=session_id,
            log_level=level,
            phase=phase,
            message=message,
            data=data,
            execution_time_ms=execution_time_ms,
            error_details=error_details
        )
        
        # JSONLãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
        try:
            with open(self.detailed_log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(entry), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write detailed log: {e}")
        
        # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã®å ´åˆã¯å°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚è¨˜éŒ²
        if level in [LogLevel.ERROR, LogLevel.CRITICAL]:
            try:
                with open(self.error_log_file, "a", encoding="utf-8") as f:
                    f.write(f"[{entry.timestamp}] {session_id} - {message}\n")
                    if error_details:
                        f.write(f"  Error Details: {error_details}\n")
                    if data:
                        f.write(f"  Data: {json.dumps(data, ensure_ascii=False)}\n")
                    f.write("\n")
            except Exception as e:
                logger.error(f"Failed to write error log: {e}")
    
    def update_phase1_results(
        self,
        session_id: str,
        duration_ms: float,
        dishes_count: int,
        usda_queries_count: int,
        phase1_output: Dict[str, Any]
    ):
        """ãƒ•ã‚§ãƒ¼ã‚º1çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.phase1_duration_ms = duration_ms
            session.phase1_dishes_count = dishes_count
            session.phase1_usda_queries_count = usda_queries_count
            session.phase1_output = phase1_output
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE1_COMPLETE,
            message=f"Phase 1 completed: {dishes_count} dishes, {usda_queries_count} USDA queries",
            data={
                "duration_ms": duration_ms,
                "dishes_count": dishes_count,
                "usda_queries_count": usda_queries_count,
                "phase1_output": phase1_output
            },
            execution_time_ms=duration_ms
        )
    
    def update_usda_search_results(
        self,
        session_id: str,
        duration_ms: float,
        queries_executed: int,
        results_found: int,
        search_details: List[Dict[str, Any]]
    ):
        """USDAæ¤œç´¢çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.usda_search_duration_ms = duration_ms
            session.usda_queries_executed = queries_executed
            session.usda_results_found = results_found
            session.usda_search_details = search_details
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.USDA_SEARCH_COMPLETE,
            message=f"USDA search completed: {queries_executed} queries, {results_found} results",
            data={
                "duration_ms": duration_ms,
                "queries_executed": queries_executed,
                "results_found": results_found,
                "search_summary": search_details
            },
            execution_time_ms=duration_ms
        )
    
    def update_phase2_results(
        self,
        session_id: str,
        duration_ms: float,
        strategy_decisions: Dict[str, Any],
        fdc_selections: Dict[str, Any],
        phase2_output: Dict[str, Any]
    ):
        """ãƒ•ã‚§ãƒ¼ã‚º2çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.phase2_duration_ms = duration_ms
            session.phase2_strategy_decisions = strategy_decisions
            session.phase2_fdc_selections = fdc_selections
            session.phase2_output = phase2_output
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE2_COMPLETE,
            message="Phase 2 completed: Strategy decisions and FDC ID selections made",
            data={
                "duration_ms": duration_ms,
                "strategy_decisions": strategy_decisions,
                "fdc_selections": fdc_selections,
                "phase2_output": phase2_output
            },
            execution_time_ms=duration_ms
        )
    
    def update_nutrition_results(
        self,
        session_id: str,
        duration_ms: float,
        total_calories: float,
        final_nutrition: Dict[str, Any]
    ):
        """æ „é¤Šè¨ˆç®—çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.nutrition_calc_duration_ms = duration_ms
            session.total_calories = total_calories
            session.final_nutrition = final_nutrition
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.NUTRITION_CALC_COMPLETE,
            message=f"Nutrition calculation completed: {total_calories:.1f} kcal total",
            data={
                "duration_ms": duration_ms,
                "total_calories": total_calories,
                "final_nutrition": final_nutrition
            },
            execution_time_ms=duration_ms
        )
    
    def end_session(
        self,
        session_id: str,
        warnings: Optional[List[str]] = None,
        errors: Optional[List[str]] = None
    ):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã€å®Œå…¨ãªãƒ­ã‚°ã‚’ä¿å­˜"""
        if session_id not in self.active_sessions:
            return
        
        session = self.active_sessions[session_id]
        session.end_time = datetime.now(timezone.utc).isoformat()
        session.warnings = warnings
        session.errors = errors
        
        # ç·å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
        if session.start_time and session.end_time:
            start = datetime.fromisoformat(session.start_time.replace('Z', '+00:00'))
            end = datetime.fromisoformat(session.end_time.replace('Z', '+00:00'))
            session.total_duration_ms = (end - start).total_seconds() * 1000
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        try:
            with open(self.session_log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(session), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write session log: {e}")
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.RESPONSE_SENT,
            message=f"Session completed in {session.total_duration_ms:.1f}ms",
            data={
                "total_duration_ms": session.total_duration_ms,
                "warnings_count": len(warnings) if warnings else 0,
                "errors_count": len(errors) if errors else 0
            },
            execution_time_ms=session.total_duration_ms
        )
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å‰Šé™¤
        del self.active_sessions[session_id]
    
    def log_error(
        self,
        session_id: str,
        phase: ProcessingPhase,
        error_message: str,
        error_details: str,
        data: Optional[Dict[str, Any]] = None
    ):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        self.log_entry(
            session_id=session_id,
            level=LogLevel.ERROR,
            phase=phase,
            message=error_message,
            data=data,
            error_details=error_details
        )

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
meal_analysis_logger = MealAnalysisLogger()

def get_meal_analysis_logger() -> MealAnalysisLogger:
    """ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return meal_analysis_logger 
```

============================================================

ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤ (v2.1ã‚¹ã‚­ãƒ¼ãƒ)
============================================================

ğŸ“„ FILE: app/api/v1/schemas/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/schemas/meal.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 17460 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:37:41
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from typing import List, Optional, Dict, Literal
from pydantic import BaseModel, Field, field_validator

# --- å…±é€šãƒ¢ãƒ‡ãƒ« ---

class CalculatedNutrients(BaseModel):
    """è¨ˆç®—æ¸ˆã¿æ „é¤Šç´ ãƒ¢ãƒ‡ãƒ«"""
    calories_kcal: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ã‚«ãƒ­ãƒªãƒ¼ (kcal)")
    protein_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ã‚¿ãƒ³ãƒ‘ã‚¯è³ª (g)")
    carbohydrates_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ç‚­æ°´åŒ–ç‰© (g)")
    fat_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·è„‚è³ª (g)")
    fiber_g: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·é£Ÿç‰©ç¹Šç¶­ (g)")
    sugars_g: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·ç³–è³ª (g)")
    sodium_mg: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·ãƒŠãƒˆãƒªã‚¦ãƒ  (mg)")

class USDANutrient(BaseModel):
    """USDAæ „é¤Šç´ æƒ…å ±ãƒ¢ãƒ‡ãƒ« (USDA ServiceãŒè¿”ã™)"""
    name: str = Field(..., description="æ „é¤Šç´ å")
    amount: float = Field(..., description="100gã¾ãŸã¯100mlã‚ãŸã‚Šã®é‡")
    unit_name: str = Field(..., description="å˜ä½å (ä¾‹: g, mg, kcal)")
    nutrient_id: Optional[int] = Field(None, description="USDAæ „é¤Šç´ ID")
    nutrient_number: Optional[str] = Field(None, description="USDAæ „é¤Šç´ ç•ªå·")

class USDASearchResultItem(BaseModel):
    """USDAæ¤œç´¢çµæœã‚¢ã‚¤ãƒ†ãƒ ãƒ¢ãƒ‡ãƒ« (USDA ServiceãŒè¿”ã™)"""
    fdc_id: int = Field(..., description="USDA FoodData Central ID")
    description: str = Field(..., description="é£Ÿå“ã®å…¬å¼åç§°")
    data_type: Optional[str] = Field(None, description="USDAãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— (ä¾‹: SR Legacy, Branded)")
    brand_owner: Optional[str] = Field(None, description="ãƒ–ãƒ©ãƒ³ãƒ‰æ‰€æœ‰è€… (Branded Foodsã®å ´åˆ)")
    ingredients_text: Optional[str] = Field(None, description="åŸææ–™ãƒªã‚¹ãƒˆæ–‡å­—åˆ— (Branded/FNDDSã®å ´åˆ, **Assumption: String**)")
    food_nutrients: List[USDANutrient] = Field(default_factory=list, description="ä¸»è¦ãªæ „é¤Šç´ æƒ…å ±ã®ãƒªã‚¹ãƒˆ")
    score: Optional[float] = Field(None, description="æ¤œç´¢çµæœã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢")

# --- Phase 1 Gemini å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« ---

class USDACandidateQuery(BaseModel):
    """Phase 1ã§GeminiãŒå‡ºåŠ›ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œ"""
    query_term: str = Field(..., description="USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)")
    granularity_level: Literal["dish", "ingredient", "branded_product"] = Field(..., description="ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«")
    original_term: str = Field("", description="ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå")
    reason_for_query: str = Field("", description="ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±")

class Phase1Ingredient(BaseModel):
    """Phase 1 ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§° (è‹±èª)")
    weight_g: float = Field(..., description="æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰", ge=0.1)

class Phase1Dish(BaseModel):
    """Phase 1 æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str = Field(..., description="ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§° (è‹±èª)")
    type: str = Field(..., description="æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: Main course, Side dishï¼‰")
    quantity_on_plate: str = Field(..., description="çš¿ã®ä¸Šã®é‡ã‚„å€‹æ•°")
    ingredients: List[Phase1Ingredient] = Field(..., description="å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ")
    # NEW: Phase 1ã§ã‚¯ã‚¨ãƒªå€™è£œã‚’å‡ºåŠ›
    usda_query_candidates: List[USDACandidateQuery] = Field(..., description="ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆ")

class Phase1AnalysisResponse(BaseModel):
    """Phase 1 é£Ÿäº‹åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[Phase1Dish] = Field(..., description="ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ")

# --- Phase 2 Gemini å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« (Geminiå‘ã‘ã‚¹ã‚­ãƒ¼ãƒ) ---

class RefinedIngredientGeminiOutput(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚")
    fdc_id: Optional[int] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã€‚ingredient_levelã®å ´åˆã€ã¾ãŸã¯dish_levelã®Fallbackæ™‚ã«è¨­å®šã€‚")
    usda_source_description: Optional[str] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°ã€‚")
    reason_for_choice: Optional[str] = Field(None, description="ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€ã¾ãŸã¯é¸æŠã—ãªã‹ã£ãŸç†ç”±ã€‚")

class RefinedDishGeminiOutput(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str = Field(..., description="æ–™ç†ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚")
    calculation_strategy: Literal["dish_level", "ingredient_level"] = Field(..., description="ã“ã®æ–™ç†ã®æ „é¤Šè¨ˆç®—æ–¹é‡ã€‚")
    reason_for_strategy: str = Field(..., description="ã“ã®è¨ˆç®—æˆ¦ç•¥ã‚’é¸æŠã—ãŸç†ç”±ã€‚")
    fdc_id: Optional[int] = Field(None, description="dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC IDã€‚")
    usda_source_description: Optional[str] = Field(None, description="dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°ã€‚")
    reason_for_choice: Optional[str] = Field(None, description="dish_levelã®å ´åˆã€ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€‚")
    ingredients: List[RefinedIngredientGeminiOutput] = Field(..., description="ææ–™ãƒªã‚¹ãƒˆã€‚å„ææ–™ã«ã¤ã„ã¦FDC IDã¨é¸æŠç†ç”±ã‚’è¨˜è¿°ã€‚")

class Phase2GeminiResponse(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - å…¨ä½“ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[RefinedDishGeminiOutput] = Field(..., description="ç²¾ç·»åŒ–ã•ã‚ŒãŸæ–™ç†ãƒªã‚¹ãƒˆã€‚")

# --- Phase 2 API å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« (æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹) ---

class RefinedIngredientResponse(BaseModel):
    """Phase 2 APIå‡ºåŠ›ç”¨ - ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str
    weight_g: float
    fdc_id: Optional[int]
    usda_source_description: Optional[str]
    reason_for_choice: Optional[str] # From Gemini
    key_nutrients_per_100g: Optional[Dict[str, float]] # From USDA Service
    actual_nutrients: Optional[CalculatedNutrients] # From Nutrition Calculation

class RefinedDishResponse(BaseModel):
    """Phase 2 APIå‡ºåŠ›ç”¨ - æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str
    type: str # From Phase 1
    quantity_on_plate: str # From Phase 1
    calculation_strategy: Literal["dish_level", "ingredient_level"] # From Gemini
    reason_for_strategy: Optional[str] # From Gemini
    fdc_id: Optional[int] # From Gemini (dish_level)
    usda_source_description: Optional[str] # From Gemini (dish_level)
    reason_for_choice: Optional[str] # From Gemini (dish_level)
    key_nutrients_per_100g: Optional[Dict[str, float]] # From USDA Service (dish_level)
    ingredients: List[RefinedIngredientResponse]
    dish_total_actual_nutrients: Optional[CalculatedNutrients] # From Nutrition Calculation

class MealAnalysisRefinementResponse(BaseModel):
    """Phase 2 é£Ÿäº‹åˆ†æç²¾ç·»åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[RefinedDishResponse]
    total_meal_nutrients: Optional[CalculatedNutrients]
    warnings: Optional[List[str]] = Field(None, description="å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸè­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚")
    errors: Optional[List[str]] = Field(None, description="å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚")

# --- å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚‚ä¿æŒ ---

class Ingredient(BaseModel):
    """ææ–™æƒ…å ±ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§°")
    weight_g: float = Field(..., description="æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰", ge=0.1)

class Dish(BaseModel):
    """æ–™ç†æƒ…å ±ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    dish_name: str = Field(..., description="ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°")
    type: str = Field(..., description="æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—ï¼‰")
    quantity_on_plate: str = Field(..., description="çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°")
    ingredients: List[Ingredient] = Field(..., description="ãã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ")

class MealAnalysisResponse(BaseModel):
    """é£Ÿäº‹åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    dishes: List[Dish] = Field(..., description="ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ")

class ErrorResponse(BaseModel):
    """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    error: dict = Field(..., description="ã‚¨ãƒ©ãƒ¼æƒ…å ±")
    
    class Config:
        json_schema_extra = {
            "example": {
                "error": {
                    "code": "INVALID_INPUT", 
                    "message": "æä¾›ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                }
            }
        }

# --- å¾Œæ–¹äº’æ›æ€§ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ ---
InitialAnalysisIngredient = Ingredient  
InitialAnalysisDish = Dish  
InitialAnalysisData = MealAnalysisResponse  

# --- RefinedIngredient/RefinedDish ã¯ RefinedIngredientResponse/RefinedDishResponse ã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ ---
RefinedIngredient = RefinedIngredientResponse
RefinedDish = RefinedDishResponse

# --- Geminiå‘ã‘JSONã‚¹ã‚­ãƒ¼ãƒå®šç¾© (æ‰‹å‹•ã§ä¿®æ­£) ---

# Phase 1 Schema - æ‰‹å‹•ã§å®šç¾©ã—ã¦Gemini APIäº’æ›ã«ã™ã‚‹
PHASE_1_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§° (è‹±èª)"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: Main course, Side dishï¼‰"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã®é‡ã‚„å€‹æ•°"},
                    "ingredients": {
                        "type": "array",
                        "description": "å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§° (è‹±èª)"},
                                "weight_g": {"type": "number", "description": "æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰", "minimum": 0.1}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    },
                    "usda_query_candidates": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆ",
                        "items": {
                            "type": "object",
                            "properties": {
                                "query_term": {"type": "string", "description": "USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)"},
                                "granularity_level": {
                                    "type": "string",
                                    "enum": ["dish", "ingredient", "branded_product"],
                                    "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«"
                                },
                                "original_term": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå"},
                                "reason_for_query": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±"}
                            },
                            "required": ["query_term", "granularity_level", "original_term", "reason_for_query"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients", "usda_query_candidates"]
            }
        }
    },
    "required": ["dishes"]
}

# Phase 2 Schema - æ‰‹å‹•ã§å®šç¾©ã—ã¦Gemini APIäº’æ›ã«ã™ã‚‹
PHASE_2_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç²¾ç·»åŒ–ã•ã‚ŒãŸæ–™ç†ãƒªã‚¹ãƒˆ",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "æ–™ç†ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚"},
                    "calculation_strategy": {
                        "type": "string",
                        "enum": ["dish_level", "ingredient_level"],
                        "description": "ã“ã®æ–™ç†ã®æ „é¤Šè¨ˆç®—æ–¹é‡"
                    },
                    "reason_for_strategy": {"type": "string", "description": "ã“ã®è¨ˆç®—æˆ¦ç•¥ã‚’é¸æŠã—ãŸç†ç”±"},
                    "fdc_id": {"type": "integer", "description": "dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC ID"},
                    "usda_source_description": {"type": "string", "description": "dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°"},
                    "reason_for_choice": {"type": "string", "description": "dish_levelã®å ´åˆã€ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±"},
                    "ingredients": {
                        "type": "array",
                        "description": "ææ–™ãƒªã‚¹ãƒˆã€‚å„ææ–™ã«ã¤ã„ã¦FDC IDã¨é¸æŠç†ç”±ã‚’è¨˜è¿°",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£"},
                                "fdc_id": {"type": "integer", "description": "é¸æŠã•ã‚ŒãŸFDC IDã€‚ingredient_levelã®å ´åˆã€ã¾ãŸã¯dish_levelã®Fallbackæ™‚ã«è¨­å®š"},
                                "usda_source_description": {"type": "string", "description": "é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°"},
                                "reason_for_choice": {"type": "string", "description": "ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€ã¾ãŸã¯é¸æŠã—ãªã‹ã£ãŸç†ç”±"}
                            },
                            "required": ["ingredient_name"]
                        }
                    }
                },
                "required": ["dish_name", "calculation_strategy", "reason_for_strategy", "ingredients"]
            }
        }
    },
    "required": ["dishes"]
}

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ã‚¹ã‚­ãƒ¼ãƒã‚‚ä¿æŒ
MEAL_ANALYSIS_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆã€‚",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°ã€‚"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—, ãƒ‡ã‚¶ãƒ¼ãƒˆï¼‰ã€‚"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°ï¼ˆä¾‹: '1æ¯', '2åˆ‡ã‚Œ', 'ç´„200g'ï¼‰ã€‚"},
                    "ingredients": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ã¨æ¨å®šã•ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§°ã€‚"},
                                "weight_g": {"type": "number", "description": "ãã®ææ–™ã®æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰ã€‚"}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    },
                    "usda_query_candidates": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "query_term": {"type": "string", "description": "USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)"},
                                "granularity_level": {
                                    "type": "string", 
                                    "enum": ["dish", "ingredient", "branded_product"],
                                    "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«"
                                },
                                "original_term": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå"},
                                "reason_for_query": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±"}
                            },
                            "required": ["query_term", "granularity_level"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients", "usda_query_candidates"]
            }
        }
    },
    "required": ["dishes"]
}

REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA = PHASE_2_GEMINI_SCHEMA 
```

============================================================

ğŸ“ è¨­å®šç®¡ç†
============================================================

ğŸ“„ FILE: app/core/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/core/config.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 2180 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from typing import Optional, List
from pydantic_settings import BaseSettings
from functools import lru_cache


class Settings(BaseSettings):
    """
    APIè¨­å®šã‚¯ãƒ©ã‚¹
    ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå€¤ã‚’èª­ã¿è¾¼ã‚€
    """
    # Vertex AIè¨­å®š
    GEMINI_PROJECT_ID: str  # GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDï¼ˆå¿…é ˆï¼‰
    GEMINI_LOCATION: str = "us-central1"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    GEMINI_MODEL_NAME: str = "gemini-1.5-flash"
    
    # USDA APIè¨­å®š
    USDA_API_KEY: str  # USDA FoodData Central APIã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
    USDA_API_BASE_URL: str = "https://api.nal.usda.gov/fdc/v1"
    USDA_API_TIMEOUT: float = 10.0  # APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°
    USDA_SEARCH_CANDIDATES_LIMIT: int = 5  # 1å›ã®æ¤œç´¢ã§å–å¾—ã™ã‚‹æœ€å¤§å€™è£œæ•°
    # ä¸»è¦æ „é¤Šç´ ç•ªå·ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã¨ã—ã¦ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼‰
    USDA_KEY_NUTRIENT_NUMBERS_STR: str = "208,203,204,205,291,269,307"
    # 208: Energy (kcal), 203: Protein, 204: Total lipid (fat), 
    # 205: Carbohydrate, 291: Fiber, 269: Total sugars, 307: Sodium
    
    @property
    def USDA_KEY_NUTRIENT_NUMBERS(self) -> List[str]:
        """ä¸»è¦æ „é¤Šç´ ç•ªå·ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
        return self.USDA_KEY_NUTRIENT_NUMBERS_STR.split(",")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
    CACHE_TYPE: str = "simple"  # "simple", "redis", "memcached"
    CACHE_REDIS_URL: Optional[str] = None  # Redisã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®URL
    USDA_CACHE_TTL_SECONDS: int = 3600  # USDAãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé–“ï¼ˆ1æ™‚é–“ï¼‰
    
    # APIè¨­å®š
    API_LOG_LEVEL: str = "INFO"
    FASTAPI_ENV: str = "development"
    
    # ã‚µãƒ¼ãƒãƒ¼è¨­å®š
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    
    # APIãƒãƒ¼ã‚¸ãƒ§ãƒ³
    API_VERSION: str = "v1"
    
    # Google Cloudèªè¨¼è¨­å®š
    # GOOGLE_APPLICATION_CREDENTIALSã¯é€šå¸¸ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä¸è¦
    # gcloud auth application-default login ã§ã‚‚å¯
    
    class Config:
        env_file = ".env"
        case_sensitive = True


@lru_cache()
def get_settings() -> Settings:
    """
    è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ï¼‰
    """
    return Settings() 
```

============================================================

ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†å±¤ (v2.1)
============================================================

ğŸ“„ FILE: app/prompts/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 114 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

from .prompt_loader import PromptLoader

__all__ = ['PromptLoader'] 
```

============================================================

ğŸ“„ FILE: app/prompts/prompt_loader.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 4029 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:41:19
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import os
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class PromptLoader:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, prompts_dir: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            prompts_dir: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
                        Noneã®å ´åˆã¯ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
        """
        if prompts_dir is None:
            self.prompts_dir = Path(__file__).parent
        else:
            self.prompts_dir = Path(prompts_dir)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._prompt_cache = {}
    
    def _load_prompt_file(self, filename: str) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            filename: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
            IOError: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
        """
        if filename in self._prompt_cache:
            return self._prompt_cache[filename]
        
        file_path = self.prompts_dir / filename
        
        if not file_path.exists():
            raise FileNotFoundError(f"Prompt file not found: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            self._prompt_cache[filename] = content
            logger.debug(f"Loaded prompt file: {filename}")
            return content
        
        except Exception as e:
            logger.error(f"Error loading prompt file {filename}: {e}")
            raise IOError(f"Failed to load prompt file {filename}: {e}") from e
    
    def get_phase1_system_prompt(self) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
        return self._load_prompt_file("phase1_system_prompt.txt")
    
    def get_phase1_user_prompt(self, optional_text: Optional[str] = None) -> str:
        """
        ãƒ•ã‚§ãƒ¼ã‚º1ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        
        Args:
            optional_text: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        template = self._load_prompt_file("phase1_user_prompt_template.txt")
        
        if optional_text and optional_text.strip():
            optional_text_section = f" Additional information from user: {optional_text}"
        else:
            optional_text_section = ""
        
        return template.format(optional_text_section=optional_text_section)
    
    def get_phase2_system_prompt(self) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
        return self._load_prompt_file("phase2_system_prompt.txt")
    
    def get_phase2_user_prompt(
        self, 
        initial_ai_output: str,
        usda_candidates: str
    ) -> str:
        """
        ãƒ•ã‚§ãƒ¼ã‚º2ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        
        Args:
            initial_ai_output: ãƒ•ã‚§ãƒ¼ã‚º1ã®AIå‡ºåŠ›ï¼ˆJSONæ–‡å­—åˆ—ï¼‰
            usda_candidates: USDAå€™è£œæƒ…å ±
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        template = self._load_prompt_file("phase2_user_prompt_template.txt")
        
        return template.format(
            initial_ai_output=initial_ai_output,
            usda_candidates=usda_candidates
        )
    
    def reload_prompts(self):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦å†èª­ã¿è¾¼ã¿ã‚’ä¿ƒã™"""
        self._prompt_cache.clear()
        logger.info("Prompt cache cleared. Prompts will be reloaded on next access.") 
```

============================================================

ğŸ“ ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ« (v2.1æ–°æ©Ÿèƒ½)
============================================================

ğŸ“„ FILE: app/utils/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 16 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:37:01
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
# utils package 
```

============================================================

ğŸ“„ FILE: app/utils/log_analyzer.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 10723 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:02:35
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
from collections import defaultdict
import pandas as pd

logger = logging.getLogger(__name__)

@dataclass
class AnalysisStats:
    """åˆ†æçµ±è¨ˆæƒ…å ±"""
    total_sessions: int
    successful_sessions: int
    failed_sessions: int
    avg_duration_ms: float
    avg_phase1_duration_ms: float
    avg_usda_search_duration_ms: float
    avg_phase2_duration_ms: float
    avg_nutrition_calc_duration_ms: float
    
    # æˆ¦ç•¥çµ±è¨ˆ
    dish_level_count: int
    ingredient_level_count: int
    
    # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
    common_errors: Dict[str, int]
    warning_counts: Dict[str, int]

class MealAnalysisLogAnalyzer:
    """é£Ÿäº‹åˆ†æãƒ­ã‚°ã®åˆ†æãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        if not self.log_dir.exists():
            raise ValueError(f"Log directory does not exist: {log_dir}")
    
    def load_session_logs(self, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None) -> List[Dict[str, Any]]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿"""
        session_log_file = self.log_dir / "meal_analysis_sessions.jsonl"
        
        if not session_log_file.exists():
            logger.warning(f"Session log file not found: {session_log_file}")
            return []
        
        sessions = []
        with open(session_log_file, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    session = json.loads(line.strip())
                    
                    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if start_date or end_date:
                        session_time = datetime.fromisoformat(session['start_time'].replace('Z', '+00:00'))
                        if start_date and session_time < start_date:
                            continue
                        if end_date and session_time > end_date:
                            continue
                    
                    sessions.append(session)
                except json.JSONDecodeError as e:
                    logger.warning(f"Failed to parse session log line: {e}")
        
        return sessions
    
    def analyze_sessions(self, sessions: List[Dict[str, Any]]) -> AnalysisStats:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¾¤ã‚’åˆ†æ"""
        if not sessions:
            return AnalysisStats(
                total_sessions=0, successful_sessions=0, failed_sessions=0,
                avg_duration_ms=0, avg_phase1_duration_ms=0,
                avg_usda_search_duration_ms=0, avg_phase2_duration_ms=0,
                avg_nutrition_calc_duration_ms=0,
                dish_level_count=0, ingredient_level_count=0,
                common_errors={}, warning_counts={}
            )
        
        total_sessions = len(sessions)
        successful_sessions = sum(1 for s in sessions if not s.get('errors'))
        failed_sessions = total_sessions - successful_sessions
        
        # å®Ÿè¡Œæ™‚é–“çµ±è¨ˆ
        durations = [s.get('total_duration_ms', 0) for s in sessions if s.get('total_duration_ms')]
        phase1_durations = [s.get('phase1_duration_ms', 0) for s in sessions if s.get('phase1_duration_ms')]
        usda_durations = [s.get('usda_search_duration_ms', 0) for s in sessions if s.get('usda_search_duration_ms')]
        phase2_durations = [s.get('phase2_duration_ms', 0) for s in sessions if s.get('phase2_duration_ms')]
        nutrition_durations = [s.get('nutrition_calc_duration_ms', 0) for s in sessions if s.get('nutrition_calc_duration_ms')]
        
        # æˆ¦ç•¥çµ±è¨ˆ
        dish_level_count = 0
        ingredient_level_count = 0
        
        for session in sessions:
            strategy_decisions = session.get('phase2_strategy_decisions', {})
            for dish_name, decision in strategy_decisions.items():
                if decision.get('strategy') == 'dish_level':
                    dish_level_count += 1
                elif decision.get('strategy') == 'ingredient_level':
                    ingredient_level_count += 1
        
        # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
        error_counts = defaultdict(int)
        warning_counts = defaultdict(int)
        
        for session in sessions:
            errors = session.get('errors', [])
            warnings = session.get('warnings', [])
            
            for error in errors:
                error_counts[error] += 1
            
            for warning in warnings:
                warning_counts[warning] += 1
        
        return AnalysisStats(
            total_sessions=total_sessions,
            successful_sessions=successful_sessions,
            failed_sessions=failed_sessions,
            avg_duration_ms=sum(durations) / len(durations) if durations else 0,
            avg_phase1_duration_ms=sum(phase1_durations) / len(phase1_durations) if phase1_durations else 0,
            avg_usda_search_duration_ms=sum(usda_durations) / len(usda_durations) if usda_durations else 0,
            avg_phase2_duration_ms=sum(phase2_durations) / len(phase2_durations) if phase2_durations else 0,
            avg_nutrition_calc_duration_ms=sum(nutrition_durations) / len(nutrition_durations) if nutrition_durations else 0,
            dish_level_count=dish_level_count,
            ingredient_level_count=ingredient_level_count,
            common_errors=dict(error_counts),
            warning_counts=dict(warning_counts)
        )
    
    def generate_report(self, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None) -> str:
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        sessions = self.load_session_logs(start_date, end_date)
        stats = self.analyze_sessions(sessions)
        
        period_str = ""
        if start_date:
            period_str += f"From: {start_date.strftime('%Y-%m-%d %H:%M:%S')}\n"
        if end_date:
            period_str += f"To: {end_date.strftime('%Y-%m-%d %H:%M:%S')}\n"
        
        report = f"""
# é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

{period_str}

## ğŸ“Š åŸºæœ¬çµ±è¨ˆ

- **ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°**: {stats.total_sessions}
- **æˆåŠŸã‚»ãƒƒã‚·ãƒ§ãƒ³**: {stats.successful_sessions} ({stats.successful_sessions/max(stats.total_sessions,1)*100:.1f}%)
- **å¤±æ•—ã‚»ãƒƒã‚·ãƒ§ãƒ³**: {stats.failed_sessions} ({stats.failed_sessions/max(stats.total_sessions,1)*100:.1f}%)

## â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ

- **å¹³å‡ç·å®Ÿè¡Œæ™‚é–“**: {stats.avg_duration_ms:.1f}ms
- **å¹³å‡Phase1æ™‚é–“**: {stats.avg_phase1_duration_ms:.1f}ms
- **å¹³å‡USDAæ¤œç´¢æ™‚é–“**: {stats.avg_usda_search_duration_ms:.1f}ms
- **å¹³å‡Phase2æ™‚é–“**: {stats.avg_phase2_duration_ms:.1f}ms
- **å¹³å‡æ „é¤Šè¨ˆç®—æ™‚é–“**: {stats.avg_nutrition_calc_duration_ms:.1f}ms

## ğŸ¯ æˆ¦ç•¥çµ±è¨ˆ

- **Dish Levelæˆ¦ç•¥**: {stats.dish_level_count}å›
- **Ingredient Levelæˆ¦ç•¥**: {stats.ingredient_level_count}å›
- **æˆ¦ç•¥æ¯”ç‡**: Dish {stats.dish_level_count/(max(stats.dish_level_count+stats.ingredient_level_count,1))*100:.1f}% vs Ingredient {stats.ingredient_level_count/(max(stats.dish_level_count+stats.ingredient_level_count,1))*100:.1f}%

## âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šçµ±è¨ˆ

### ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼:
"""
        
        for error, count in sorted(stats.common_errors.items(), key=lambda x: x[1], reverse=True)[:10]:
            report += f"- {error}: {count}å›\n"
        
        report += "\n### ã‚ˆãã‚ã‚‹è­¦å‘Š:\n"
        for warning, count in sorted(stats.warning_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
            report += f"- {warning}: {count}å›\n"
        
        return report
    
    def export_to_csv(self, output_file: str, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        sessions = self.load_session_logs(start_date, end_date)
        
        if not sessions:
            logger.warning("No sessions to export")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’å¹³å¦åŒ–
        rows = []
        for session in sessions:
            row = {
                'session_id': session.get('session_id'),
                'start_time': session.get('start_time'),
                'end_time': session.get('end_time'),
                'endpoint': session.get('endpoint'),
                'image_filename': session.get('image_filename'),
                'image_size_bytes': session.get('image_size_bytes'),
                'total_duration_ms': session.get('total_duration_ms'),
                'phase1_duration_ms': session.get('phase1_duration_ms'),
                'usda_search_duration_ms': session.get('usda_search_duration_ms'),
                'phase2_duration_ms': session.get('phase2_duration_ms'),
                'nutrition_calc_duration_ms': session.get('nutrition_calc_duration_ms'),
                'dishes_count': session.get('phase1_dishes_count'),
                'usda_queries_count': session.get('phase1_usda_queries_count'),
                'usda_results_found': session.get('usda_results_found'),
                'total_calories': session.get('total_calories'),
                'has_errors': bool(session.get('errors')),
                'has_warnings': bool(session.get('warnings')),
                'error_count': len(session.get('errors', [])),
                'warning_count': len(session.get('warnings', []))
            }
            rows.append(row)
        
        df = pd.DataFrame(rows)
        df.to_csv(output_file, index=False)
        logger.info(f"Exported {len(rows)} sessions to {output_file}")
    
    def find_slow_sessions(self, threshold_ms: float = 10000) -> List[Dict[str, Any]]:
        """é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç‰¹å®š"""
        sessions = self.load_session_logs()
        slow_sessions = [
            s for s in sessions 
            if s.get('total_duration_ms', 0) > threshold_ms
        ]
        return sorted(slow_sessions, key=lambda x: x.get('total_duration_ms', 0), reverse=True)
    
    def find_error_patterns(self) -> Dict[str, List[str]]:
        """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        sessions = self.load_session_logs()
        error_patterns = defaultdict(list)
        
        for session in sessions:
            errors = session.get('errors', [])
            session_id = session.get('session_id', 'unknown')
            
            for error in errors:
                error_patterns[error].append(session_id)
        
        return dict(error_patterns)

def create_log_analyzer(log_dir: str = "logs") -> MealAnalysisLogAnalyzer:
    """ãƒ­ã‚°ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°"""
    return MealAnalysisLogAnalyzer(log_dir) 
```

============================================================

ğŸ“„ FILE: analyze_logs.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 6771 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:03:24
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«

ä½¿ç”¨ä¾‹:
python analyze_logs.py --report                    # åŸºæœ¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
python analyze_logs.py --export sessions.csv       # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
python analyze_logs.py --slow --threshold 5000     # 5ç§’ä»¥ä¸Šã®é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆ†æ
python analyze_logs.py --errors                    # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
python analyze_logs.py --days 7                    # éå»7æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿åˆ†æ
"""

import argparse
import sys
from datetime import datetime, timedelta
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from app.utils.log_analyzer import create_log_analyzer

def main():
    parser = argparse.ArgumentParser(
        description="é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        "--log-dir", 
        default="logs", 
        help="ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: logs)"
    )
    
    # åˆ†æã‚¿ã‚¤ãƒ—
    parser.add_argument(
        "--report", 
        action="store_true", 
        help="åŸºæœ¬åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"
    )
    
    parser.add_argument(
        "--export", 
        metavar="FILE", 
        help="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
    )
    
    parser.add_argument(
        "--slow", 
        action="store_true", 
        help="é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆ†æ"
    )
    
    parser.add_argument(
        "--threshold", 
        type=float, 
        default=10000, 
        help="é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–¾å€¤ (ãƒŸãƒªç§’, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10000)"
    )
    
    parser.add_argument(
        "--errors", 
        action="store_true", 
        help="ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"
    )
    
    # æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿
    parser.add_argument(
        "--days", 
        type=int, 
        help="éå»Næ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿åˆ†æ"
    )
    
    parser.add_argument(
        "--start-date", 
        help="é–‹å§‹æ—¥æ™‚ (ISOå½¢å¼: YYYY-MM-DD ã¾ãŸã¯ YYYY-MM-DD HH:MM:SS)"
    )
    
    parser.add_argument(
        "--end-date", 
        help="çµ‚äº†æ—¥æ™‚ (ISOå½¢å¼: YYYY-MM-DD ã¾ãŸã¯ YYYY-MM-DD HH:MM:SS)"
    )
    
    args = parser.parse_args()
    
    # æœ€ä½1ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦
    if not any([args.report, args.export, args.slow, args.errors]):
        args.report = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
    
    try:
        analyzer = create_log_analyzer(args.log_dir)
    except ValueError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã®æº–å‚™
    start_date = None
    end_date = None
    
    if args.days:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=args.days)
        print(f"ğŸ“… éå»{args.days}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ ({start_date.strftime('%Y-%m-%d')} ã€œ {end_date.strftime('%Y-%m-%d')})")
    
    if args.start_date:
        try:
            # YYYY-MM-DD HH:MM:SS ã¾ãŸã¯ YYYY-MM-DD ã®å½¢å¼ã‚’å—ã‘å…¥ã‚Œ
            if len(args.start_date) == 10:  # YYYY-MM-DD
                start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
            else:  # YYYY-MM-DD HH:MM:SS
                start_date = datetime.strptime(args.start_date, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            print(f"âŒ ç„¡åŠ¹ãªé–‹å§‹æ—¥æ™‚å½¢å¼: {args.start_date}")
            return 1
    
    if args.end_date:
        try:
            if len(args.end_date) == 10:  # YYYY-MM-DD
                end_date = datetime.strptime(args.end_date + " 23:59:59", "%Y-%m-%d %H:%M:%S")
            else:  # YYYY-MM-DD HH:MM:SS
                end_date = datetime.strptime(args.end_date, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            print(f"âŒ ç„¡åŠ¹ãªçµ‚äº†æ—¥æ™‚å½¢å¼: {args.end_date}")
            return 1
    
    # å„åˆ†æå®Ÿè¡Œ
    if args.report:
        print("\n" + "="*60)
        print("ğŸ“Š é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*60)
        
        report = analyzer.generate_report(start_date, end_date)
        print(report)
    
    if args.export:
        print("\nğŸ“ CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­: {args.export}")
        try:
            analyzer.export_to_csv(args.export, start_date, end_date)
            print(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {args.export}")
        except Exception as e:
            print(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    if args.slow:
        print("\nğŸŒ é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†æ (é–¾å€¤: {args.threshold}ms)")
        slow_sessions = analyzer.find_slow_sessions(args.threshold)
        
        if not slow_sessions:
            print("âœ… é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            print(f"âš ï¸  {len(slow_sessions)}å€‹ã®é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            
            for i, session in enumerate(slow_sessions[:10], 1):
                duration = session.get('total_duration_ms', 0)
                session_id = session.get('session_id', 'unknown')
                start_time = session.get('start_time', 'unknown')
                
                print(f"  {i}. ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id[:8]}... - {duration:.1f}ms ({start_time})")
                
                # å„ãƒ•ã‚§ãƒ¼ã‚ºã®æ™‚é–“å†…è¨³ã‚’è¡¨ç¤º
                phase1 = session.get('phase1_duration_ms', 0)
                usda = session.get('usda_search_duration_ms', 0)
                phase2 = session.get('phase2_duration_ms', 0)
                nutrition = session.get('nutrition_calc_duration_ms', 0)
                
                print(f"     â”” Phase1: {phase1:.1f}ms, USDA: {usda:.1f}ms, Phase2: {phase2:.1f}ms, æ „é¤Šè¨ˆç®—: {nutrition:.1f}ms")
    
    if args.errors:
        print("\nğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        error_patterns = analyzer.find_error_patterns()
        
        if not error_patterns:
            print("âœ… ã‚¨ãƒ©ãƒ¼ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            print(f"âš ï¸  {len(error_patterns)}ç¨®é¡ã®ã‚¨ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            
            for error, session_ids in sorted(error_patterns.items(), key=lambda x: len(x[1]), reverse=True):
                count = len(session_ids)
                print(f"\n  ğŸ“Œ {error} ({count}å›)")
                
                # æœ€åˆã®5ã¤ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’è¡¨ç¤º
                for session_id in session_ids[:5]:
                    print(f"     - ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_id}")
                
                if len(session_ids) > 5:
                    print(f"     ... ãŠã‚ˆã³ä»–{len(session_ids) - 5}ä»¶")
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ¯ SUMMARY v2.1
----------------------------------------
ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 22
å­˜åœ¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 22
åˆ†æå®Œäº†æ™‚åˆ»: 2025-05-29 18:39:57

ğŸ“‹ v2.1ã®ä¸»è¦æ”¹å–„ç‚¹:
âœ… USDAã‚¯ã‚¨ãƒªå€™è£œã®è‡ªå‹•ç”Ÿæˆ
âœ… é«˜åº¦ãªæˆ¦ç•¥æ±ºå®šã‚·ã‚¹ãƒ†ãƒ 
âœ… å‹•çš„æ „é¤Šè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
âœ… åŒ…æ‹¬çš„ãƒ­ã‚°æ©Ÿèƒ½
âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ„ãƒ¼ãƒ«

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€test_english_phase1_v2.py ãŠã‚ˆã³
test_english_phase2_v2.pyå®Ÿè¡Œæ™‚ã«é–¢ã‚ã‚‹å…¨ã¦ã®
Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãªå†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
