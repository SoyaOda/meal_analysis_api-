====================================================================================================
MEAL ANALYSIS API v2.1 - Multi-Image Analysis System Architecture
====================================================================================================
Generated: 2025-06-15 15:34:52
Analysis Target: All files related to test_multi_image_analysis.py execution
====================================================================================================

🎯 LATEST MULTI-IMAGE ANALYSIS SUMMARY
------------------------------------------------------------
📂 Result Directory: multi_image_analysis_20250615_145032
📄 Summary Preview:
# 🍽️ Multi-Image Nutrition Analysis - 包括的サマリー

**分析日時:** 2025年06月15日 14:52:12  
**分析画像数:** 5枚  
**成功分析:** 5枚  
**失敗分析:** 0枚  

## 📊 全画像栄養サマリー

| 画像 | 料理数 | 食材数 | 総カロリー | タンパク質 | 脂質 | 炭水化物 | 処理時間 |
|------|--------|--------|------------|------------|------|----------|----------|
| food1 | 3 | 9 | 823.1 kcal | 26.5g | 24.9g | 125.1g | 19.3s |
| food2 | 5 | 13 | 1255.1 kcal | 60.4g | 55.7g | 129.2g | 25.2s |
| food3 | 3 | 13 | 810.3 kcal | 66.5g | 31.8g | 63.4g | 17.2s |
| food4 | 3 | 17 | 647.6 kcal | 43.3g | 30.4g | 57.3g | 12.6s |
| food5 | 2 | 14 | 785.3 kcal | 36.7g | 49.0g | 49.4g | 25.2s |
| **合計** | - | - | **4321.5 kcal** | **233.3g** | **191.8g** | **424.4g** | **99.4s** |
| **平均** | - | - | **864.3 kcal** | **46.7g** | **38.4g** | **84.9g** | **19.9s** |


## 🎯 分析統計

### 📈 栄養統計
- **総カロリー摂取量:** 4321.5 kcal
- **総タンパク質:** 233.3 g

====================================================================================================

🚀 MYNETDIARY-CONSTRAINED SEARCH & NUTRITION CALCULATION ARCHITECTURE
--------------------------------------------------------------------------------

🔄 EXECUTION FLOW:
1.  test_multi_image_analysis.py: Initiates batch processing of multiple JPG images.
2.  FastAPI Endpoint (/api/v1/meal-analyses/complete): Receives each image for full analysis.
    - `use_mynetdiary_specialized=True` flag is set.
3.  Orchestrator: Controls the pipeline execution.
4.  Phase 1 (Gemini Vision Analysis):
    - `phase1_prompts.py`: Uses a prompt now including the 1,142 MyNetDiary ingredients list and a new `weight_g` estimation requirement.
    - `gemini_service.py`: Calls the model and structures the output.
    - `phase1_models.py`: Pydantic model `Ingredient` now requires `weight_g`.
5.  Phase 2 (MyNetDiary-Constrained Search):
    - `mynetdiary_nutrition_search_component.py` is selected by the orchestrator.
    - `_strict_ingredient_search()`: Searches for ingredients with an "exactly one" match rule.
    - `_flexible_dish_search()`: Performs a standard flexible search for dishes.
6.  Phase 3 (Nutrition Calculation):
    - `nutrition_calculation_component.py`:
        - Takes `weight_g` from Phase 1 and nutrition data (per 100g) from Phase 2.
        - Calculates nutrition for the actual ingredient weight.
        - Aggregates nutrition totals for each dish and the entire meal.
7.  Result Manager: Saves all intermediate and final results to the filesystem.

🏗️ KEY ARCHITECTURE COMPONENTS:
├── Test Layer
│   └── test_multi_image_analysis.py
├── FastAPI Application Layer (app_v2)
│   └── pipeline/orchestrator.py (Conditionally selects search component)
├── Component Layer
│   ├── phase1_component.py
│   ├── mynetdiary_nutrition_search_component.py (New: Strict & flexible search)
│   └── nutrition_calculation_component.py (New: Weight-based calculation)
├── AI Service & Prompts
│   ├── services/gemini_service.py
│   └── config/prompts/phase1_prompts.py (Updated with ingredient list & weight estimation)
├── Data Models
│   ├── models/phase1_models.py (Ingredient includes `weight_g`)
│   └── models/nutrition_calculation_models.py (New: For structured nutrition output)
└── Utilities & Data
    ├── utils/mynetdiary_utils.py (New: Handles ingredient list)
    └── data/mynetdiary_search_names.txt (New: 1,142 ingredient constraints)

====================================================================================================


################################################################################
## CATEGORY: Multi-Image Analysis テスト実行ファイル
################################################################################

----------------------------------------------------------------------
### FILE: test_multi_image_analysis.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/test_multi_image_analysis.py
----------------------------------------------------------------------

#!/usr/bin/env python3
"""
Multi-Image Nutrition Analysis Test - food1-5 Batch Processing
food1.jpg から food5.jpg まで5つの画像を一括分析し、
見やすい形で結果を保存するテストスクリプト
"""

import asyncio
import os
import sys
import logging
import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

# プロジェクトルートをPythonパスに追加
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app_v2.pipeline import MealAnalysisPipeline

# ロギング設定
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def setup_environment():
    """環境変数の設定"""
    os.environ.setdefault("GOOGLE_APPLICATION_CREDENTIALS", "/Users/odasoya/meal_analysis_api_2/service-account-key.json")
    os.environ.setdefault("GEMINI_PROJECT_ID", "recording-diet-ai-3e7cf")
    os.environ.setdefault("GEMINI_LOCATION", "us-central1")
    os.environ.setdefault("GEMINI_MODEL_NAME", "gemini-2.5-flash-preview-05-20")


def get_image_mime_type(file_path: str) -> str:
    """ファイル拡張子からMIMEタイプを推定"""
    ext = Path(file_path).suffix.lower()
    mime_types = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.bmp': 'image/bmp',
        '.webp': 'image/webp'
    }
    return mime_types.get(ext, 'image/jpeg')


async def analyze_single_image(image_path: str, results_dir: str, image_index: int) -> Dict[str, Any]:
    """単一画像の分析を実行"""
    
    # 画像ファイルの存在確認
    if not os.path.exists(image_path):
        print(f"❌ エラー: 画像ファイルが見つかりません: {image_path}")
        return None
    
    # 画像データの読み込み
    with open(image_path, 'rb') as f:
        image_bytes = f.read()
    
    image_mime_type = get_image_mime_type(image_path)
    image_name = Path(image_path).stem
    
    print(f"\n{'='*80}")
    print(f"🍽️  画像 {image_index}/5: {image_name}")
    print(f"📁 分析対象: {image_path}")
    print(f"📊 画像サイズ: {len(image_bytes):,} bytes")
    print(f"🔍 MIMEタイプ: {image_mime_type}")
    print(f"{'='*80}")
    
    # 画像専用の結果ディレクトリを作成
    image_results_dir = f"{results_dir}/{image_name}"
    os.makedirs(image_results_dir, exist_ok=True)
    
    # パイプラインの初期化（ファジーマッチング検索を使用）
    pipeline = MealAnalysisPipeline(
        use_elasticsearch_search=True,
        use_fuzzy_matching=True  # 新しいファジーマッチングシステムを使用
    )
    
    try:
        print(f"🔄 {image_name} 分析開始...")
        analysis_start_time = time.time()
        
        result = await pipeline.execute_complete_analysis(
            image_bytes=image_bytes,
            image_mime_type=image_mime_type,
            save_detailed_logs=True,
            test_execution=True,
            test_results_dir=image_results_dir
        )
        
        analysis_end_time = time.time()
        analysis_time = analysis_end_time - analysis_start_time
        
        print(f"✅ {image_name} 分析完了！ ({analysis_time:.2f}秒)")
        
        # 基本結果の表示
        print_image_analysis_summary(result, image_name)
        
        # 結果にメタデータを追加
        result["image_metadata"] = {
            "image_name": image_name,
            "image_path": image_path,
            "image_size_bytes": len(image_bytes),
            "analysis_time_seconds": analysis_time,
            "analysis_timestamp": datetime.now().isoformat()
        }
        
        # 画像専用の詳細結果を保存
        await save_image_detailed_results(result, image_results_dir, image_name)
        
        return result
        
    except Exception as e:
        print(f"❌ {image_name} 分析エラー: {str(e)}")
        logger.error(f"Analysis failed for {image_name}: {str(e)}", exc_info=True)
        return {
            "error": str(e),
            "image_name": image_name,
            "image_path": image_path,
            "analysis_timestamp": datetime.now().isoformat()
        }


def print_image_analysis_summary(result: dict, image_name: str):
    """画像分析結果の基本サマリーを表示"""
    
    print(f"\n📋 {image_name} 分析結果サマリー")
    print(f"{'─'*60}")
    
    # Phase1結果
    phase1_result = result.get("phase1_result", {})
    dishes = phase1_result.get("dishes", [])
    
    print(f"🍽️  検出された料理: {len(dishes)}個")
    for i, dish in enumerate(dishes, 1):
        dish_name = dish.get("dish_name", "不明")
        confidence = dish.get("confidence", 0.0)
        ingredients = dish.get("ingredients", [])
        print(f"   {i}. {dish_name} (信頼度: {confidence:.2f}, 食材: {len(ingredients)}個)")
    
    # 栄養計算結果
    final_nutrition = result.get("final_nutrition_result", {})
    total_nutrition = final_nutrition.get("total_nutrition", {})
    
    if total_nutrition:
        calories = total_nutrition.get("calories", 0)
        protein = total_nutrition.get("protein", 0)
        fat = total_nutrition.get("fat", 0)
        carbs = total_nutrition.get("carbs", 0)
        
        print(f"\n🔢 栄養計算結果:")
        print(f"   📊 総カロリー: {calories:.1f} kcal")
        print(f"   🥩 タンパク質: {protein:.1f} g")
        print(f"   🧈 脂質: {fat:.1f} g")
        print(f"   🍞 炭水化物: {carbs:.1f} g")
    
    # 処理サマリー
    processing_summary = result.get("processing_summary", {})
    total_ingredients = processing_summary.get("total_ingredients", 0)
    match_rate = processing_summary.get("nutrition_search_match_rate", "不明")
    processing_time = processing_summary.get("processing_time_seconds", 0)
    
    print(f"\n⚡ 処理サマリー:")
    print(f"   🥕 総食材数: {total_ingredients}個")
    print(f"   🎯 マッチ率: {match_rate}")
    print(f"   ⏱️  処理時間: {processing_time:.2f}秒")


async def save_image_detailed_results(result: dict, image_results_dir: str, image_name: str):
    """画像の詳細結果を保存"""
    
    # 1. 完全な結果をJSONで保存
    complete_result_path = f"{image_results_dir}/complete_analysis_result.json"
    with open(complete_result_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # 2. 栄養計算結果のサマリーをMarkdownで保存
    nutrition_summary_path = f"{image_results_dir}/nutrition_summary.md"
    await create_nutrition_summary_markdown(result, nutrition_summary_path, image_name)
    
    # 3. 料理別詳細をMarkdownで保存
    dish_details_path = f"{image_results_dir}/dish_details.md"
    await create_dish_details_markdown(result, dish_details_path, image_name)
    
    print(f"💾 {image_name} 詳細結果保存完了:")
    print(f"   📄 完全結果: {complete_result_path}")
    print(f"   📊 栄養サマリー: {nutrition_summary_path}")
    print(f"   🍽️  料理詳細: {dish_details_path}")


async def create_nutrition_summary_markdown(result: dict, file_path: str, image_name: str):
    """栄養計算結果のサマリーMarkdownを作成"""
    
    final_nutrition = result.get("final_nutrition_result", {})
    total_nutrition = final_nutrition.get("total_nutrition", {})
    dishes = final_nutrition.get("dishes", [])
    
    content = f"""# {image_name} 栄養分析サマリー

## 📊 食事全体の栄養情報

| 栄養素 | 値 |
|--------|-----|
| 🔥 カロリー | {total_nutrition.get('calories', 0):.1f} kcal |
| 🥩 タンパク質 | {total_nutrition.get('protein', 0):.1f} g |
| 🧈 脂質 | {total_nutrition.get('fat', 0):.1f} g |
| 🍞 炭水化物 | {total_nutrition.get('carbs', 0):.1f} g |
| 🌾 食物繊維 | {total_nutrition.get('fiber') or '不明'} g |
| 🍯 糖質 | {total_nutrition.get('sugar') or '不明'} g |
| 🧂 ナトリウム | {total_nutrition.get('sodium') or '不明'} mg |

## 🍽️ 料理別栄養情報

"""
    
    for i, dish in enumerate(dishes, 1):
        dish_name = dish.get("dish_name", "不明")
        dish_nutrition = dish.get("total_nutrition", {})
        ingredients = dish.get("ingredients", [])
        
        content += f"""### {i}. {dish_name}

**栄養情報:**
- 🔥 カロリー: {dish_nutrition.get('calories', 0):.1f} kcal
- 🥩 タンパク質: {dish_nutrition.get('protein', 0):.1f} g
- 🧈 脂質: {dish_nutrition.get('fat', 0):.1f} g
- 🍞 炭水化物: {dish_nutrition.get('carbs', 0):.1f} g

**含まれる食材:** {len(ingredients)}個

"""
        
        for ingredient in ingredients:
            ing_name = ingredient.get("ingredient_name", "不明")
            weight = ingredient.get("weight_g", 0)
            ing_nutrition = ingredient.get("calculated_nutrition", {})
            
            content += f"- **{ing_name}** ({weight}g): {ing_nutrition.get('calories', 0):.1f} kcal\n"
        
        content += "\n"
    
    # 分析メタデータ
    image_metadata = result.get("image_metadata", {})
    processing_summary = result.get("processing_summary", {})
    
    content += f"""## 📈 分析メタデータ

- **分析日時:** {image_metadata.get('analysis_timestamp', '不明')}
- **処理時間:** {image_metadata.get('analysis_time_seconds', 0):.2f}秒
- **総食材数:** {processing_summary.get('total_ingredients', 0)}個
- **マッチ率:** {processing_summary.get('nutrition_search_match_rate', '不明')}
- **画像サイズ:** {image_metadata.get('image_size_bytes', 0):,} bytes

---
*Generated by Multi-Image Nutrition Analysis System*
"""
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)


async def create_dish_details_markdown(result: dict, file_path: str, image_name: str):
    """料理別詳細情報のMarkdownを作成"""
    
    phase1_result = result.get("phase1_result", {})
    dishes = phase1_result.get("dishes", [])
    final_nutrition = result.get("final_nutrition_result", {})
    nutrition_dishes = final_nutrition.get("dishes", [])
    
    content = f"""# {image_name} 料理詳細分析

## 🔍 検出された料理一覧

"""
    
    for i, (phase1_dish, nutrition_dish) in enumerate(zip(dishes, nutrition_dishes), 1):
        dish_name = phase1_dish.get("dish_name", "不明")
        confidence = phase1_dish.get("confidence", 0.0)
        ingredients = phase1_dish.get("ingredients", [])
        nutrition_ingredients = nutrition_dish.get("ingredients", [])
        
        content += f"""## {i}. {dish_name}

**基本情報:**
- 🎯 信頼度: {confidence:.2f}
- 🥕 食材数: {len(ingredients)}個
- ⚖️ 総重量: {sum(ing.get('weight_g', 0) for ing in ingredients)}g

### 📋 食材詳細

| 食材名 | 重量 | カロリー | タンパク質 | 脂質 | 炭水化物 | データソース |
|--------|------|----------|------------|------|----------|--------------|
"""
        
        for phase1_ing, nutrition_ing in zip(ingredients, nutrition_ingredients):
            ing_name = phase1_ing.get("ingredient_name", "不明")
            weight = phase1_ing.get("weight_g", 0)
            nutrition = nutrition_ing.get("calculated_nutrition", {})
            source_db = nutrition_ing.get("source_db", "不明")
            
            content += f"| {ing_name} | {weight}g | {nutrition.get('calories', 0):.1f} kcal | {nutrition.get('protein', 0):.1f}g | {nutrition.get('fat', 0):.1f}g | {nutrition.get('carbs', 0):.1f}g | {source_db} |\n"
        
        # 料理の栄養合計
        dish_nutrition = nutrition_dish.get("total_nutrition", {})
        content += f"""
### 🔢 料理合計栄養

- **🔥 総カロリー:** {dish_nutrition.get('calories', 0):.1f} kcal
- **🥩 総タンパク質:** {dish_nutrition.get('protein', 0):.1f} g
- **🧈 総脂質:** {dish_nutrition.get('fat', 0):.1f} g
- **🍞 総炭水化物:** {dish_nutrition.get('carbs', 0):.1f} g

---

"""
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)


async def create_comprehensive_summary(all_results: List[Dict[str, Any]], results_dir: str):
    """全画像の包括的サマリーを作成"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    summary_path = f"{results_dir}/comprehensive_analysis_summary.md"
    
    # 成功した分析のみを抽出
    successful_results = [r for r in all_results if r and "error" not in r]
    failed_results = [r for r in all_results if r and "error" in r]
    
    content = f"""# 🍽️ Multi-Image Nutrition Analysis - 包括的サマリー

**分析日時:** {datetime.now().strftime("%Y年%m月%d日 %H:%M:%S")}  
**分析画像数:** {len(all_results)}枚  
**成功分析:** {len(successful_results)}枚  
**失敗分析:** {len(failed_results)}枚  

## 📊 全画像栄養サマリー

| 画像 | 料理数 | 食材数 | 総カロリー | タンパク質 | 脂質 | 炭水化物 | 処理時間 |
|------|--------|--------|------------|------------|------|----------|----------|
"""
    
    total_calories = 0
    total_protein = 0
    total_fat = 0
    total_carbs = 0
    total_processing_time = 0
    
    for result in successful_results:
        image_name = result.get("image_metadata", {}).get("image_name", "不明")
        processing_summary = result.get("processing_summary", {})
        final_nutrition = result.get("final_nutrition_result", {})
        total_nutrition = final_nutrition.get("total_nutrition", {})
        
        dishes_count = processing_summary.get("total_dishes", 0)
        ingredients_count = processing_summary.get("total_ingredients", 0)
        calories = total_nutrition.get("calories", 0)
        protein = total_nutrition.get("protein", 0)
        fat = total_nutrition.get("fat", 0)
        carbs = total_nutrition.get("carbs", 0)
        processing_time = result.get("image_metadata", {}).get("analysis_time_seconds", 0)
        
        content += f"| {image_name} | {dishes_count} | {ingredients_count} | {calories:.1f} kcal | {protein:.1f}g | {fat:.1f}g | {carbs:.1f}g | {processing_time:.1f}s |\n"
        
        total_calories += calories
        total_protein += protein
        total_fat += fat
        total_carbs += carbs
        total_processing_time += processing_time
    
    # 合計行
    content += f"| **合計** | - | - | **{total_calories:.1f} kcal** | **{total_protein:.1f}g** | **{total_fat:.1f}g** | **{total_carbs:.1f}g** | **{total_processing_time:.1f}s** |\n"
    
    # 平均値
    if successful_results:
        avg_calories = total_calories / len(successful_results)
        avg_protein = total_protein / len(successful_results)
        avg_fat = total_fat / len(successful_results)
        avg_carbs = total_carbs / len(successful_results)
        avg_processing_time = total_processing_time / len(successful_results)
        
        content += f"| **平均** | - | - | **{avg_calories:.1f} kcal** | **{avg_protein:.1f}g** | **{avg_fat:.1f}g** | **{avg_carbs:.1f}g** | **{avg_processing_time:.1f}s** |\n"
    
    content += f"""

## 🎯 分析統計

### 📈 栄養統計
- **総カロリー摂取量:** {total_calories:.1f} kcal
- **総タンパク質:** {total_protein:.1f} g
- **総脂質:** {total_fat:.1f} g
- **総炭水化物:** {total_carbs:.1f} g

### ⚡ パフォーマンス統計
- **総処理時間:** {total_processing_time:.1f}秒
- **平均処理時間:** {avg_processing_time:.1f}秒/画像
- **成功率:** {len(successful_results)/len(all_results)*100:.1f}%

## 🍽️ 画像別詳細

"""
    
    for i, result in enumerate(successful_results, 1):
        image_name = result.get("image_metadata", {}).get("image_name", "不明")
        phase1_result = result.get("phase1_result", {})
        dishes = phase1_result.get("dishes", [])
        
        content += f"""### {i}. {image_name}

**検出された料理:**
"""
        
        for j, dish in enumerate(dishes, 1):
            dish_name = dish.get("dish_name", "不明")
            confidence = dish.get("confidence", 0.0)
            ingredients = dish.get("ingredients", [])
            content += f"- {j}. {dish_name} (信頼度: {confidence:.2f}, 食材: {len(ingredients)}個)\n"
        
        content += "\n"
    
    # エラー情報
    if failed_results:
        content += f"""## ❌ 分析エラー

"""
        for result in failed_results:
            image_name = result.get("image_name", "不明")
            error = result.get("error", "不明なエラー")
            content += f"- **{image_name}:** {error}\n"
    
    content += f"""

---
*Generated by Multi-Image Nutrition Analysis System - {timestamp}*
"""
    
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"\n📋 包括的サマリー保存完了: {summary_path}")
    return summary_path


async def analyze_all_food_images():
    """food1-5の全画像を分析"""
    
    # 環境設定
    setup_environment()
    
    # 結果保存用ディレクトリを作成
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"analysis_results/multi_image_analysis_{timestamp}"
    os.makedirs(results_dir, exist_ok=True)
    
    print(f"🚀 Multi-Image Nutrition Analysis 開始")
    print(f"📁 結果保存ディレクトリ: {results_dir}")
    print(f"🔧 検索方法: MyNetDiary専用検索 + 栄養計算")
    print(f"📊 対象画像: food1.jpg - food5.jpg (5枚)")
    
    # 画像パスのリスト
    image_paths = [
        "test_images/food1.jpg",
        "test_images/food2.jpg", 
        "test_images/food3.jpg",
        "test_images/food4.jpg",
        "test_images/food5.jpg"
    ]
    
    all_results = []
    total_start_time = time.time()
    
    # 各画像を順次分析
    for i, image_path in enumerate(image_paths, 1):
        try:
            result = await analyze_single_image(image_path, results_dir, i)
            all_results.append(result)
        except Exception as e:
            print(f"❌ 画像 {i} の分析でエラーが発生: {str(e)}")
            all_results.append({
                "error": str(e),
                "image_name": Path(image_path).stem,
                "image_path": image_path
            })
    
    total_end_time = time.time()
    total_processing_time = total_end_time - total_start_time
    
    # 包括的サマリーを作成
    summary_path = await create_comprehensive_summary(all_results, results_dir)
    
    # 最終結果の表示
    successful_results = [r for r in all_results if r and "error" not in r]
    failed_results = [r for r in all_results if r and "error" in r]
    
    print(f"\n{'='*80}")
    print(f"🎯 Multi-Image Nutrition Analysis 完了!")
    print(f"{'='*80}")
    print(f"📊 分析結果サマリー:")
    print(f"   ✅ 成功: {len(successful_results)}/{len(all_results)} 画像")
    print(f"   ❌ 失敗: {len(failed_results)}/{len(all_results)} 画像")
    print(f"   ⏱️  総処理時間: {total_processing_time:.2f}秒")
    print(f"   📁 結果保存先: {results_dir}")
    print(f"   📋 包括的サマリー: {summary_path}")
    
    if successful_results:
        total_calories = sum(r.get("final_nutrition_result", {}).get("total_nutrition", {}).get("calories", 0) for r in successful_results)
        print(f"   🔥 総カロリー: {total_calories:.1f} kcal")
    
    print(f"{'='*80}")
    
    return all_results, results_dir


def main():
    """メイン実行関数"""
    print("🍽️ Multi-Image Nutrition Analysis Test")
    print("food1.jpg から food5.jpg まで5つの画像を一括分析します")
    print()
    
    # 非同期実行
    asyncio.run(analyze_all_food_images())


if __name__ == "__main__":
    main() 


################################################################################
## CATEGORY: FastAPI アプリケーション層 (app_v2)
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/main/app.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/main/app.py
----------------------------------------------------------------------

import os
import logging
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from ..api.v1.endpoints import meal_analysis
from ..config import get_settings

# 環境変数の設定
os.environ.setdefault("GOOGLE_APPLICATION_CREDENTIALS", "/Users/odasoya/meal_analysis_api /service-account-key.json")
os.environ.setdefault("GEMINI_PROJECT_ID", "recording-diet-ai-3e7cf")
os.environ.setdefault("GEMINI_LOCATION", "us-central1")
os.environ.setdefault("GEMINI_MODEL_NAME", "gemini-2.5-flash-preview-05-20")

# ロギング設定
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# FastAPIアプリの作成
app = FastAPI(
    title="食事分析 API v2.0",
    description="コンポーネント化された食事分析システム",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS設定
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ルーターの登録
app.include_router(
    meal_analysis.router,
    prefix="/api/v1/meal-analyses",
    tags=["Complete Meal Analysis v2.0"]
)

# ルートエンドポイント
@app.get("/")
async def root():
    """ルートエンドポイント"""
    return {
        "message": "食事分析 API v2.0 - コンポーネント化版",
        "version": "2.0.0",
        "architecture": "Component-based Pipeline",
        "docs": "/docs"
    }

@app.get("/health")
async def health():
    """ヘルスチェック"""
    return {
        "status": "healthy",
        "version": "v2.0",
        "components": ["Phase1Component", "ElasticsearchNutritionSearchComponent"]
    }

if __name__ == "__main__":
    import uvicorn
    settings = get_settings()
    uvicorn.run(
        "app_v2.main.app:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=True
    ) 

----------------------------------------------------------------------
### FILE: app_v2/api/v1/endpoints/meal_analysis.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/api/v1/endpoints/meal_analysis.py
----------------------------------------------------------------------

from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse
from typing import Optional
import logging

from ....pipeline import MealAnalysisPipeline

logger = logging.getLogger(__name__)

router = APIRouter()


@router.post("/complete")
async def complete_meal_analysis(
    image: UploadFile = File(...),
    save_detailed_logs: bool = Form(True),
    test_execution: bool = Form(False),
    test_results_dir: Optional[str] = Form(None)
):
    """
    完全な食事分析を実行（v2.0 コンポーネント化版）
    
    - Phase 1: Gemini AIによる画像分析
    - Nutrition Search: 食材の栄養データベース照合
    - Phase 2: 計算戦略決定と栄養価精緻化 (TODO)
    - Nutrition Calculation: 最終栄養価計算 (TODO)
    
    Args:
        image: 分析対象の食事画像
        save_detailed_logs: 分析ログを保存するかどうか (デフォルト: True)
    
    Returns:
        完全な分析結果と栄養価計算、分析ログファイルパス
    """
    
    try:
        # 画像の検証
        if not image.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="アップロードされたファイルは画像である必要があります")
        
        # 画像データの読み込み
        image_data = await image.read()
        logger.info(f"Starting complete meal analysis pipeline v2.0 (detailed_logs: {save_detailed_logs})")
        
        # パイプラインの実行
        pipeline = MealAnalysisPipeline()
        result = await pipeline.execute_complete_analysis(
            image_bytes=image_data,
            image_mime_type=image.content_type,
            save_detailed_logs=save_detailed_logs,
            test_execution=test_execution,
            test_results_dir=test_results_dir
        )
        
        logger.info(f"Complete analysis pipeline v2.0 finished successfully")
        
        return JSONResponse(
            status_code=200,
            content=result
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Complete analysis failed: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Complete analysis failed: {str(e)}"
        )


@router.get("/health")
async def health_check():
    """ヘルスチェック"""
    return {"status": "healthy", "version": "v2.0", "message": "食事分析API v2.0 - コンポーネント化版"}


@router.get("/pipeline-info")
async def get_pipeline_info():
    """パイプライン情報の取得"""
    pipeline = MealAnalysisPipeline()
    return pipeline.get_pipeline_info() 


################################################################################
## CATEGORY: パイプライン統制層
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/pipeline/orchestrator.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/pipeline/orchestrator.py
----------------------------------------------------------------------

import uuid
import json
import os
from datetime import datetime
from typing import Optional, Dict, Any
import logging

from ..components import Phase1Component, ElasticsearchNutritionSearchComponent, MyNetDiaryNutritionSearchComponent, FuzzyIngredientSearchComponent, NutritionCalculationComponent
from ..models import (
    Phase1Input, Phase1Output,
    NutritionQueryInput
)
from ..models.nutrition_calculation_models import NutritionCalculationInput
from ..config import get_settings
from .result_manager import ResultManager

logger = logging.getLogger(__name__)


class MealAnalysisPipeline:
    """
    食事分析パイプラインのオーケストレーター
    
    4つのフェーズを統合して完全な分析を実行します。
    """
    
    def __init__(self, use_local_nutrition_search: Optional[bool] = None, use_elasticsearch_search: Optional[bool] = None, use_mynetdiary_specialized: Optional[bool] = False, use_fuzzy_matching: Optional[bool] = None):
        """
        パイプラインの初期化
        
        Args:
            use_local_nutrition_search: 廃止予定（互換性のため残存）
            use_elasticsearch_search: Elasticsearch栄養データベース検索を使用するかどうか
                                    None: 設定ファイルから自動取得（デフォルト: True）
                                    True: ElasticsearchNutritionSearchComponent使用（推奨）
                                    False: ElasticsearchNutritionSearchComponent使用（デフォルト設定）
            use_mynetdiary_specialized: MyNetDiary専用検索を使用するかどうか
                                      True: MyNetDiaryNutritionSearchComponent使用（ingredient厳密検索）
                                      False: 従来のElasticsearch検索使用（デフォルト）
            use_fuzzy_matching: ファジーマッチング検索を使用するかどうか
                              True: FuzzyIngredientSearchComponent使用（高精度ファジーマッチング）
                              False: 従来の検索使用
                              None: 設定ファイルから自動取得（デフォルト: True）
        """
        self.pipeline_id = str(uuid.uuid4())[:8]
        self.settings = get_settings()
        
        # Elasticsearch検索優先度の決定
        if use_elasticsearch_search is not None:
            self.use_elasticsearch_search = use_elasticsearch_search
        elif hasattr(self.settings, 'USE_ELASTICSEARCH_SEARCH'):
            self.use_elasticsearch_search = self.settings.USE_ELASTICSEARCH_SEARCH
        else:
            # デフォルトはElasticsearch使用
            self.use_elasticsearch_search = True
        
        # レガシーパラメータは無視（常にElasticsearch使用）
        self.use_local_nutrition_search = False
        
        # ファジーマッチング使用の決定
        if use_fuzzy_matching is not None:
            self.use_fuzzy_matching = use_fuzzy_matching
        elif hasattr(self.settings, 'fuzzy_search_enabled'):
            self.use_fuzzy_matching = self.settings.fuzzy_search_enabled
        else:
            # デフォルトはファジーマッチング使用
            self.use_fuzzy_matching = True
        
        # コンポーネントの初期化
        self.phase1_component = Phase1Component()
        
        # 栄養データベース検索コンポーネントの選択
        if self.use_fuzzy_matching:
            # 新しいファジーマッチング検索コンポーネント（推奨）
            self.nutrition_search_component = FuzzyIngredientSearchComponent()
            self.search_component_name = "FuzzyIngredientSearchComponent"
            logger.info("Using Fuzzy Ingredient Search (5-tier cascade, high-precision matching)")
        elif use_mynetdiary_specialized:
            # MyNetDiary専用検索コンポーネント
            self.nutrition_search_component = MyNetDiaryNutritionSearchComponent(
                results_per_db=5
            )
            self.search_component_name = "MyNetDiaryNutritionSearchComponent"
            logger.info("Using MyNetDiary specialized nutrition search (ingredient strict matching)")
        else:
            # 従来のElasticsearch検索コンポーネント
            self.nutrition_search_component = ElasticsearchNutritionSearchComponent(
                strategic_search_mode=True,
                results_per_db=5
            )
            self.search_component_name = "ElasticsearchNutritionSearchComponent"
            logger.info("Using Elasticsearch nutrition database search (high-performance, multi-DB mode)")
            
        # 栄養計算コンポーネントの初期化
        self.nutrition_calculation_component = NutritionCalculationComponent()
        
        # TODO: Phase2Componentを追加
        
        self.logger = logging.getLogger(f"{__name__}.{self.pipeline_id}")
        
    async def execute_complete_analysis(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        optional_text: Optional[str] = None,
        save_detailed_logs: bool = True,
        test_execution: bool = False,
        test_results_dir: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        完全な食事分析を実行
        
        Args:
            image_bytes: 画像データ
            image_mime_type: 画像のMIMEタイプ
            optional_text: オプションのテキスト
            save_detailed_logs: 分析ログを保存するかどうか
            
        Returns:
            完全な分析結果
        """
        analysis_id = str(uuid.uuid4())[:8]
        start_time = datetime.now()
        
        # ResultManagerの初期化
        if save_detailed_logs:
            if test_execution and test_results_dir:
                # テスト実行時はテスト結果ディレクトリ内のapi_calls/フォルダに保存
                api_calls_dir = f"{test_results_dir}/api_calls"
                result_manager = ResultManager(analysis_id, save_directory=api_calls_dir)
            else:
                # 通常の実行時は既存の保存先
                result_manager = ResultManager(analysis_id)
        else:
            result_manager = None
        
        self.logger.info(f"[{analysis_id}] Starting complete meal analysis pipeline")
        self.logger.info(f"[{analysis_id}] Nutrition search method: Elasticsearch (high-performance)")
        
        try:
            # === Phase 1: 画像分析 ===
            self.logger.info(f"[{analysis_id}] Phase 1: Image analysis")
            
            phase1_input = Phase1Input(
                image_bytes=image_bytes,
                image_mime_type=image_mime_type,
                optional_text=optional_text
            )
            
            # Phase1の詳細ログを作成
            phase1_log = result_manager.create_execution_log("Phase1Component", f"{analysis_id}_phase1") if result_manager else None
            
            phase1_result = await self.phase1_component.execute(phase1_input, phase1_log)
            
            self.logger.info(f"[{analysis_id}] Phase 1 completed - Detected {len(phase1_result.dishes)} dishes")
            
            # === Nutrition Search Phase: データベース照合 ===
            if self.use_fuzzy_matching:
                search_phase_name = "Fuzzy Ingredient Search"
            else:
                search_phase_name = "Elasticsearch Search"
            self.logger.info(f"[{analysis_id}] {search_phase_name} Phase: Database matching")
            
            # === 統一された栄養検索入力を作成 ===
            if self.use_fuzzy_matching:
                # ファジーマッチング検索の場合は、食材名のリストを直接渡す
                ingredient_names = phase1_result.get_all_ingredient_names()
                nutrition_search_input = [{"name": name} for name in ingredient_names]
            else:
                # 従来のElasticsearch検索を使用
                preferred_source = "elasticsearch"
                nutrition_search_input = NutritionQueryInput(
                    ingredient_names=phase1_result.get_all_ingredient_names(),
                    dish_names=phase1_result.get_all_dish_names(),
                    preferred_source=preferred_source
                )
            
            # Nutrition Searchの詳細ログを作成
            search_log = result_manager.create_execution_log(self.search_component_name, f"{analysis_id}_nutrition_search") if result_manager else None
            
            if self.use_fuzzy_matching:
                # ファジーマッチングコンポーネントの場合はprocessメソッドを使用
                nutrition_search_result = await self.nutrition_search_component.process(nutrition_search_input)
            else:
                # 従来のコンポーネントの場合はexecuteメソッドを使用
                nutrition_search_result = await self.nutrition_search_component.execute(nutrition_search_input, search_log)
            
            self.logger.info(f"[{analysis_id}] {search_phase_name} completed - {nutrition_search_result.get_match_rate():.1%} match rate")
            
            # === Nutrition Calculation Phase: 栄養計算 ===
            self.logger.info(f"[{analysis_id}] Nutrition Calculation Phase: Computing nutrition values")
            
            nutrition_calculation_input = NutritionCalculationInput(
                phase1_result=phase1_result,
                nutrition_search_result=nutrition_search_result
            )
            
            # Nutrition Calculationの詳細ログを作成
            calculation_log = result_manager.create_execution_log("NutritionCalculationComponent", f"{analysis_id}_nutrition_calculation") if result_manager else None
            
            nutrition_calculation_result = await self.nutrition_calculation_component.execute(nutrition_calculation_input, calculation_log)
            
            self.logger.info(f"[{analysis_id}] Nutrition Calculation completed - {nutrition_calculation_result.meal_nutrition.calculation_summary['total_ingredients']} ingredients, {nutrition_calculation_result.meal_nutrition.total_nutrition.calories:.1f} kcal total")
            
            # === 結果の構築 ===
            
            # Phase1の結果を辞書形式に変換（構造化データを含む）
            phase1_dict = {
                "detected_food_items": [
                    {
                        "item_name": item.item_name,
                        "confidence": item.confidence,
                        "attributes": [
                            {
                                "type": attr.type.value if hasattr(attr.type, 'value') else str(attr.type),
                                "value": attr.value,
                                "confidence": attr.confidence
                            }
                            for attr in item.attributes
                        ],
                        "brand": item.brand or "",
                        "category_hints": item.category_hints,
                        "negative_cues": item.negative_cues
                    }
                    for item in phase1_result.detected_food_items
                ],
                "dishes": [
                    {
                        "dish_name": dish.dish_name,
                        "confidence": dish.confidence,
                        "ingredients": [
                            {
                                "ingredient_name": ing.ingredient_name,
                                "confidence": ing.confidence,
                                "weight_g": ing.weight_g
                            }
                            for ing in dish.ingredients
                        ],
                        "attributes": [
                            {
                                "type": attr.type.value if hasattr(attr.type, 'value') else str(attr.type),
                                "value": attr.value,
                                "confidence": attr.confidence
                            }
                            for attr in dish.detected_attributes
                        ]
                    }
                    for dish in phase1_result.dishes
                ],
                "analysis_confidence": phase1_result.analysis_confidence,
                "processing_notes": phase1_result.processing_notes
            }
            
            # 栄養計算結果を辞書形式に変換
            nutrition_calculation_dict = {
                "dishes": [
                    {
                        "dish_name": dish.dish_name,
                        "confidence": dish.confidence,
                        "ingredients": [
                            {
                                "ingredient_name": ing.ingredient_name,
                                "weight_g": ing.weight_g,
                                "nutrition_per_100g": ing.nutrition_per_100g,
                                "calculated_nutrition": {
                                    "calories": ing.calculated_nutrition.calories,
                                    "protein": ing.calculated_nutrition.protein,
                                    "fat": ing.calculated_nutrition.fat,
                                    "carbs": ing.calculated_nutrition.carbs,
                                    "fiber": ing.calculated_nutrition.fiber,
                                    "sugar": ing.calculated_nutrition.sugar,
                                    "sodium": ing.calculated_nutrition.sodium
                                },
                                "source_db": ing.source_db,
                                "calculation_notes": ing.calculation_notes
                            }
                            for ing in dish.ingredients
                        ],
                        "total_nutrition": {
                            "calories": dish.total_nutrition.calories,
                            "protein": dish.total_nutrition.protein,
                            "fat": dish.total_nutrition.fat,
                            "carbs": dish.total_nutrition.carbs,
                            "fiber": dish.total_nutrition.fiber,
                            "sugar": dish.total_nutrition.sugar,
                            "sodium": dish.total_nutrition.sodium
                        },
                        "calculation_metadata": dish.calculation_metadata
                    }
                    for dish in nutrition_calculation_result.meal_nutrition.dishes
                ],
                "total_nutrition": {
                    "calories": nutrition_calculation_result.meal_nutrition.total_nutrition.calories,
                    "protein": nutrition_calculation_result.meal_nutrition.total_nutrition.protein,
                    "fat": nutrition_calculation_result.meal_nutrition.total_nutrition.fat,
                    "carbs": nutrition_calculation_result.meal_nutrition.total_nutrition.carbs,
                    "fiber": nutrition_calculation_result.meal_nutrition.total_nutrition.fiber,
                    "sugar": nutrition_calculation_result.meal_nutrition.total_nutrition.sugar,
                    "sodium": nutrition_calculation_result.meal_nutrition.total_nutrition.sodium
                },
                "calculation_summary": nutrition_calculation_result.meal_nutrition.calculation_summary,
                "warnings": nutrition_calculation_result.meal_nutrition.warnings
            }
            
            # 検索方法の特定（常にElasticsearch）
            search_method = "elasticsearch"
            search_api_method = "elasticsearch"
            
            # 完全分析結果の構築
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            complete_result = {
                "analysis_id": analysis_id,
                "phase1_result": phase1_dict,
                "nutrition_search_result": {
                    "matches_count": len(nutrition_search_result.matches),
                    "match_rate": nutrition_search_result.get_match_rate(),
                    "search_summary": nutrition_search_result.search_summary,
                    "search_method": search_method
                },

                "processing_summary": {
                    "total_dishes": len(phase1_result.dishes),
                    "total_ingredients": len(phase1_result.get_all_ingredient_names()),
                    "nutrition_search_match_rate": self._calculate_match_rate_display(nutrition_search_input, nutrition_search_result),
                    "nutrition_calculation_status": "completed",
                    "total_calories": nutrition_calculation_result.meal_nutrition.total_nutrition.calories,
                    "pipeline_status": "completed",
                    "processing_time_seconds": processing_time,
                    "search_method": search_method
                },
                # 最終栄養結果
                "final_nutrition_result": nutrition_calculation_dict,
                "metadata": {
                    "pipeline_version": "v2.0",
                    "timestamp": datetime.now().isoformat(),
                    "components_used": ["Phase1Component", self.search_component_name, "NutritionCalculationComponent"],
                    "nutrition_search_method": search_api_method
                }
            }
            
            # ResultManagerに最終結果を設定
            if result_manager:
                result_manager.set_final_result(complete_result)
                result_manager.finalize_pipeline()
            
            # 結果の保存
            saved_files = {}
            if save_detailed_logs and result_manager:
                # 新しいフェーズ別保存方式
                saved_files = result_manager.save_phase_results()
                complete_result["analysis_folder"] = result_manager.get_analysis_folder_path()
                complete_result["saved_files"] = saved_files
                
                logger.info(f"[{analysis_id}] Analysis logs saved to folder: {result_manager.get_analysis_folder_path()}")
                logger.info(f"[{analysis_id}] Saved {len(saved_files)} files across all phases")
            

            
            self.logger.info(f"[{analysis_id}] Complete analysis pipeline finished successfully in {processing_time:.2f}s")
            
            return complete_result
            
        except Exception as e:
            self.logger.error(f"[{analysis_id}] Complete analysis failed: {str(e)}", exc_info=True)
            
            # エラー時もResultManagerを保存
            if result_manager:
                result_manager.set_final_result({"error": str(e), "timestamp": datetime.now().isoformat()})
                result_manager.finalize_pipeline()
                error_saved_files = result_manager.save_phase_results()
                self.logger.info(f"[{analysis_id}] Error analysis logs saved to folder: {result_manager.get_analysis_folder_path()}")
            
            raise
    
    def get_pipeline_info(self) -> Dict[str, Any]:
        """パイプライン情報を取得"""
        search_method = "elasticsearch"
            
        return {
            "pipeline_id": self.pipeline_id,
            "version": "v2.0",
            "nutrition_search_method": search_method,
            "components": [
                {
                    "component_name": "Phase1Component",
                    "component_type": "analysis",
                    "execution_count": 0
                },
                {
                    "component_name": self.search_component_name,
                    "component_type": "nutrition_search",
                    "execution_count": 0
                },
                {
                    "component_name": "NutritionCalculationComponent",
                    "component_type": "nutrition_calculation",
                    "execution_count": 0
                }
            ]
        } 

    def _calculate_match_rate_display(self, nutrition_search_input, nutrition_search_result):
        """マッチ率の表示文字列を計算"""
        if self.use_fuzzy_matching:
            # ファジーマッチングの場合はリスト形式
            total_searches = len(nutrition_search_input)
            successful_matches = len(nutrition_search_result.matches)
            match_rate = successful_matches / total_searches if total_searches > 0 else 0
            return f"{successful_matches}/{total_searches} ({match_rate:.1%})"
        else:
            # 従来の検索の場合はNutritionQueryInputオブジェクト
            total_searches = len(nutrition_search_input.get_all_search_terms())
            successful_matches = len(nutrition_search_result.matches)
            match_rate = nutrition_search_result.get_match_rate()
            return f"{successful_matches}/{total_searches} ({match_rate:.1%})" 

----------------------------------------------------------------------
### FILE: app_v2/pipeline/result_manager.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/pipeline/result_manager.py
----------------------------------------------------------------------

import json
import os
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class DetailedExecutionLog:
    """各コンポーネントの詳細実行ログ"""
    
    def __init__(self, component_name: str, execution_id: str):
        self.component_name = component_name
        self.execution_id = execution_id
        self.execution_start_time = datetime.now()
        self.execution_end_time = None
        self.input_data = {}
        self.output_data = {}
        self.processing_details = {}
        self.prompts_used = {}
        self.reasoning = {}
        self.confidence_scores = {}
        self.warnings = []
        self.errors = []
        
    def set_input(self, input_data: Dict[str, Any]):
        """入力データを記録（機密情報は除外）"""
        # 画像データは大きすぎるので、メタデータのみ保存
        safe_input = {}
        for key, value in input_data.items():
            if key == 'image_bytes':
                safe_input[key] = {
                    "size_bytes": len(value) if value else 0,
                    "type": "binary_image_data"
                }
            else:
                safe_input[key] = value
        self.input_data = safe_input
    
    def set_output(self, output_data: Dict[str, Any]):
        """出力データを記録"""
        self.output_data = output_data
        
    def add_prompt(self, prompt_name: str, prompt_content: str, variables: Dict[str, Any] = None):
        """使用されたプロンプトを記録"""
        self.prompts_used[prompt_name] = {
            "content": prompt_content,
            "variables": variables or {},
            "timestamp": datetime.now().isoformat()
        }
    
    def add_reasoning(self, decision_point: str, reason: str, confidence: float = None):
        """推論理由を記録"""
        self.reasoning[decision_point] = {
            "reason": reason,
            "confidence": confidence,
            "timestamp": datetime.now().isoformat()
        }
    
    def add_processing_detail(self, detail_key: str, detail_value: Any):
        """処理詳細を記録"""
        self.processing_details[detail_key] = detail_value
    
    def add_confidence_score(self, metric_name: str, score: float):
        """信頼度スコアを記録"""
        self.confidence_scores[metric_name] = score
    
    def add_warning(self, warning: str):
        """警告を記録"""
        self.warnings.append({
            "message": warning,
            "timestamp": datetime.now().isoformat()
        })
    
    def add_error(self, error: str):
        """エラーを記録"""
        self.errors.append({
            "message": error,
            "timestamp": datetime.now().isoformat()
        })
    
    def finalize(self):
        """実行完了時の最終処理"""
        self.execution_end_time = datetime.now()
    
    def get_execution_time(self) -> float:
        """実行時間を取得（秒）"""
        if self.execution_end_time:
            return (self.execution_end_time - self.execution_start_time).total_seconds()
        return 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        """辞書形式で取得"""
        return {
            "component_name": self.component_name,
            "execution_id": self.execution_id,
            "execution_start_time": self.execution_start_time.isoformat(),
            "execution_end_time": self.execution_end_time.isoformat() if self.execution_end_time else None,
            "execution_time_seconds": self.get_execution_time(),
            "input_data": self.input_data,
            "output_data": self.output_data,
            "processing_details": self.processing_details,
            "prompts_used": self.prompts_used,
            "reasoning": self.reasoning,
            "confidence_scores": self.confidence_scores,
            "warnings": self.warnings,
            "errors": self.errors
        }


class ResultManager:
    """解析結果と詳細ログの管理クラス（フェーズ別整理版）"""
    
    def __init__(self, analysis_id: str, save_directory: str = "analysis_results"):
        self.analysis_id = analysis_id
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # 実行ごとのフォルダを作成（分かりやすい階層構造）
        timestamp_dir = Path(save_directory) / f"meal_analysis_{self.timestamp}"
        timestamp_dir.mkdir(parents=True, exist_ok=True)
        
        self.analysis_folder_name = f"analysis_{self.analysis_id}"
        self.analysis_dir = timestamp_dir / self.analysis_folder_name
        self.analysis_dir.mkdir(parents=True, exist_ok=True)
        
        # 各フェーズのフォルダを作成
        self.phase1_dir = self.analysis_dir / "phase1"
        self.nutrition_search_dir = self.analysis_dir / "nutrition_search_query"
        self.phase2_dir = self.analysis_dir / "phase2"
        self.nutrition_dir = self.analysis_dir / "nutrition_calculation"
        
        for phase_dir in [self.phase1_dir, self.nutrition_search_dir, self.phase2_dir, self.nutrition_dir]:
            phase_dir.mkdir(exist_ok=True)
        
        self.pipeline_start_time = datetime.now()
        self.pipeline_end_time = None
        self.execution_logs: List[DetailedExecutionLog] = []
        self.final_result = {}
        self.pipeline_metadata = {
            "analysis_id": analysis_id,
            "version": "v2.0",
            "analysis_folder": self.analysis_folder_name,
            "pipeline_start_time": self.pipeline_start_time.isoformat()
        }
        
    def create_execution_log(self, component_name: str, execution_id: str) -> DetailedExecutionLog:
        """新しい実行ログを作成"""
        log = DetailedExecutionLog(component_name, execution_id)
        self.execution_logs.append(log)
        return log
    
    def set_final_result(self, result: Dict[str, Any]):
        """最終結果を設定"""
        self.final_result = result
        
    def finalize_pipeline(self):
        """パイプライン完了時の最終処理"""
        self.pipeline_end_time = datetime.now()
        self.pipeline_metadata["pipeline_end_time"] = self.pipeline_end_time.isoformat()
        self.pipeline_metadata["total_execution_time_seconds"] = (
            self.pipeline_end_time - self.pipeline_start_time
        ).total_seconds()
    
    def save_phase_results(self) -> Dict[str, str]:
        """フェーズ別に結果を保存"""
        saved_files = {}
        
        # 実行されたコンポーネントのログを処理
        executed_components = set()
        for log in self.execution_logs:
            if log.component_name == "Phase1Component":
                files = self._save_phase1_results(log)
                saved_files.update(files)
                executed_components.add("Phase1Component")
            elif log.component_name in ["ElasticsearchNutritionSearchComponent"]:
                files = self._save_nutrition_search_results(log)
                saved_files.update(files)
                executed_components.add(log.component_name)
            elif log.component_name == "Phase2Component":
                files = self._save_phase2_results(log)
                saved_files.update(files)
                executed_components.add("Phase2Component")
            elif log.component_name == "NutritionCalculationComponent":
                files = self._save_nutrition_results(log)
                saved_files.update(files)
                executed_components.add("NutritionCalculationComponent")
        
        # 未実装/未実行のコンポーネントにプレースホルダーファイルを作成
        if "Phase2Component" not in executed_components:
            placeholder_log = DetailedExecutionLog("Phase2Component", f"{self.analysis_id}_phase2_placeholder")
            placeholder_log.input_data = {"note": "Phase2Component not yet implemented"}
            placeholder_log.output_data = {"note": "Phase2Component not yet implemented"}
            placeholder_log.finalize()
            files = self._save_phase2_results(placeholder_log)
            saved_files.update(files)
        
        if "NutritionCalculationComponent" not in executed_components:
            placeholder_log = DetailedExecutionLog("NutritionCalculationComponent", f"{self.analysis_id}_nutrition_placeholder")
            placeholder_log.input_data = {"note": "NutritionCalculationComponent not yet implemented"}
            placeholder_log.output_data = {"note": "NutritionCalculationComponent not yet implemented"}
            placeholder_log.finalize()
            files = self._save_nutrition_results(placeholder_log)
            saved_files.update(files)
        
        # パイプライン全体のサマリーを保存
        summary_files = self._save_pipeline_summary()
        saved_files.update(summary_files)
        
        return saved_files
    
    def _save_phase1_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """Phase1の結果を保存"""
        files = {}
        
        # 1. JSON形式の入出力データ
        input_output_file = self.phase1_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time()
            }, f, indent=2, ensure_ascii=False)
        files["phase1_input_output"] = str(input_output_file)
        
        # 2. プロンプトと推論理由のマークダウン
        prompts_md_file = self.phase1_dir / "prompts_and_reasoning.md"
        prompts_content = self._generate_phase1_prompts_md(log)
        with open(prompts_md_file, 'w', encoding='utf-8') as f:
            f.write(prompts_content)
        files["phase1_prompts_md"] = str(prompts_md_file)
        
        # 3. 検出された料理・食材のテキスト
        detected_items_file = self.phase1_dir / "detected_items.txt"
        detected_content = self._generate_phase1_detected_items_txt(log)
        with open(detected_items_file, 'w', encoding='utf-8') as f:
            f.write(detected_content)
        files["phase1_detected_txt"] = str(detected_items_file)
        
        return files
    
    def _save_nutrition_search_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """栄養データベース検索の結果を保存（ElasticsearchNutritionSearchComponent対応）"""
        files = {}
        
        # 検索方法の判定
        search_method = "unknown"
        db_source = "unknown"
        
        if log.component_name == "ElasticsearchNutritionSearchComponent":
            search_method = "elasticsearch"
            db_source = "elasticsearch_nutrition_db"
        
        # 1. JSON形式の入出力データ（検索方法情報を含む）
        input_output_file = self.nutrition_search_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time(),
                "search_metadata": {
                    "component_name": log.component_name,
                    "search_method": search_method,
                    "database_source": db_source,
                    "timestamp": log.execution_end_time.isoformat() if log.execution_end_time else None
                }
            }, f, indent=2, ensure_ascii=False)
        files["nutrition_search_input_output"] = str(input_output_file)
        
        # 2. 検索結果の詳細マークダウン
        search_results_md_file = self.nutrition_search_dir / "search_results.md"
        search_content = self._generate_nutrition_search_results_md(log, search_method, db_source)
        with open(search_results_md_file, 'w', encoding='utf-8') as f:
            f.write(search_content)
        files["nutrition_search_results_md"] = str(search_results_md_file)
        
        # 3. マッチ詳細のテキスト
        match_details_file = self.nutrition_search_dir / "match_details.txt"
        match_content = self._generate_nutrition_match_details_txt(log, search_method, db_source)
        with open(match_details_file, 'w', encoding='utf-8') as f:
            f.write(match_content)
        files["nutrition_search_match_details"] = str(match_details_file)
        
        return files
    
    def _save_phase2_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """Phase2の結果を保存（将来実装用）"""
        files = {}
        
        # 1. JSON形式の入出力データ
        input_output_file = self.phase2_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time(),
                "note": "Phase2Component is not yet implemented"
            }, f, indent=2, ensure_ascii=False)
        files["phase2_input_output"] = str(input_output_file)
        
        # 2. 戦略決定のマークダウン
        strategy_md_file = self.phase2_dir / "strategy_decisions.md"
        with open(strategy_md_file, 'w', encoding='utf-8') as f:
            f.write("# Phase2 Strategy Decisions\n\n*Phase2Component is not yet implemented*\n")
        files["phase2_strategy_md"] = str(strategy_md_file)
        
        # 3. 選択項目のテキスト
        selected_items_file = self.phase2_dir / "selected_items.txt"
        with open(selected_items_file, 'w', encoding='utf-8') as f:
            f.write("Phase2Component is not yet implemented\n")
        files["phase2_items_txt"] = str(selected_items_file)
        
        return files
    
    def _save_nutrition_results(self, log: DetailedExecutionLog) -> Dict[str, str]:
        """栄養計算の結果を保存（将来実装用）"""
        files = {}
        
        # 1. JSON形式の入出力データ
        input_output_file = self.nutrition_dir / "input_output.json"
        with open(input_output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "input_data": log.input_data,
                "output_data": log.output_data,
                "execution_time_seconds": log.get_execution_time(),
                "note": "NutritionCalculationComponent is not yet implemented"
            }, f, indent=2, ensure_ascii=False)
        files["nutrition_input_output"] = str(input_output_file)
        
        # 2. 計算式のマークダウン
        formulas_md_file = self.nutrition_dir / "calculation_formulas.md"
        with open(formulas_md_file, 'w', encoding='utf-8') as f:
            f.write("# Nutrition Calculation Formulas\n\n*NutritionCalculationComponent is not yet implemented*\n")
        files["nutrition_formulas_md"] = str(formulas_md_file)
        
        # 3. 栄養サマリーのテキスト
        summary_txt_file = self.nutrition_dir / "nutrition_summary.txt"
        with open(summary_txt_file, 'w', encoding='utf-8') as f:
            f.write("NutritionCalculationComponent is not yet implemented\n")
        files["nutrition_summary_txt"] = str(summary_txt_file)
        
        return files
    
    def _save_pipeline_summary(self) -> Dict[str, str]:
        """パイプライン全体のサマリーを保存"""
        files = {}
        
        # 1. パイプラインサマリーJSON
        summary_file = self.analysis_dir / "pipeline_summary.json"
        summary_data = {
            "analysis_id": self.analysis_id,
            "timestamp": self.timestamp,
            "pipeline_metadata": self.pipeline_metadata,
            "execution_summary": {
                log.component_name: {
                    "execution_time": log.get_execution_time(),
                    "success": len(log.errors) == 0,
                    "warnings_count": len(log.warnings),
                    "errors_count": len(log.errors)
                }
                for log in self.execution_logs
            },
            "final_result": self.final_result
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)
        files["pipeline_summary"] = str(summary_file)
        
        # 2. 完全な詳細ログJSON
        complete_log_file = self.analysis_dir / "complete_analysis_log.json"
        complete_data = {
            "pipeline_metadata": self.pipeline_metadata,
            "execution_logs": [log.to_dict() for log in self.execution_logs],
            "final_result": self.final_result,
            "summary": {
                "total_components": len(self.execution_logs),
                "total_warnings": sum(len(log.warnings) for log in self.execution_logs),
                "total_errors": sum(len(log.errors) for log in self.execution_logs)
            }
        }
        
        with open(complete_log_file, 'w', encoding='utf-8') as f:
            json.dump(complete_data, f, indent=2, ensure_ascii=False)
        files["complete_log"] = str(complete_log_file)
        
        return files
    
    def _generate_phase1_prompts_md(self, log: DetailedExecutionLog) -> str:
        """Phase1のプロンプトと推論理由のマークダウンを生成"""
        content = f"""# Phase1: 画像分析 - プロンプトと推論

## 実行情報
- 実行ID: {log.execution_id}
- 開始時刻: {log.execution_start_time.isoformat()}
- 終了時刻: {log.execution_end_time.isoformat() if log.execution_end_time else 'N/A'}
- 実行時間: {log.get_execution_time():.2f}秒

## 使用されたプロンプト

"""
        
        # プロンプト情報
        for prompt_name, prompt_data in log.prompts_used.items():
            content += f"### {prompt_name.replace('_', ' ').title()}\n\n"
            content += f"**タイムスタンプ**: {prompt_data['timestamp']}\n\n"
            content += f"```\n{prompt_data['content']}\n```\n\n"
            
            if prompt_data.get('variables'):
                content += f"**変数**:\n"
                for var_name, var_value in prompt_data['variables'].items():
                    content += f"- {var_name}: {var_value}\n"
                content += "\n"
        
        # 推論理由
        content += "## AI推論の詳細\n\n"
        
        # 料理識別の推論
        dish_reasoning = [r for r in log.reasoning.items() if r[0].startswith('dish_identification_')]
        if dish_reasoning:
            content += "### 料理識別の推論\n\n"
            for decision_point, reasoning_data in dish_reasoning:
                dish_num = decision_point.split('_')[-1]
                content += f"**料理 {dish_num}**:\n"
                content += f"- 推論: {reasoning_data['reason']}\n"
                content += f"- タイムスタンプ: {reasoning_data['timestamp']}\n\n"
        
        # 食材選択の推論
        ingredient_reasoning = [r for r in log.reasoning.items() if r[0].startswith('ingredient_selection_')]
        if ingredient_reasoning:
            content += "### 食材選択の推論\n\n"
            for decision_point, reasoning_data in ingredient_reasoning:
                content += f"**{decision_point.replace('_', ' ').title()}**:\n"
                content += f"- 推論: {reasoning_data['reason']}\n"
                content += f"- タイムスタンプ: {reasoning_data['timestamp']}\n\n"
        
        # 警告とエラー
        if log.warnings:
            content += "## 警告\n\n"
            for warning in log.warnings:
                content += f"- {warning['message']} (at {warning['timestamp']})\n"
            content += "\n"
        
        if log.errors:
            content += "## エラー\n\n"
            for error in log.errors:
                content += f"- {error['message']} (at {error['timestamp']})\n"
            content += "\n"
        
        return content
    
    def _generate_phase1_detected_items_txt(self, log: DetailedExecutionLog) -> str:
        """Phase1で検出された料理・食材のテキストを生成"""
        content = f"Phase1 検出結果 - {log.execution_start_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        content += "=" * 60 + "\n\n"
        
        if 'output_data' in log.output_data and 'dishes' in log.output_data['output_data']:
            dishes = log.output_data['output_data']['dishes']
            content += f"検出された料理数: {len(dishes)}\n\n"
            
            for i, dish in enumerate(dishes, 1):
                content += f"料理 {i}: {dish['dish_name']}\n"
                content += f"  食材数: {len(dish['ingredients'])}\n"
                content += "  食材詳細:\n"
                
                for j, ingredient in enumerate(dish['ingredients'], 1):
                    content += f"    {j}. {ingredient['ingredient_name']}\n"
                content += "\n"
        

        
        # 処理詳細
        if log.processing_details:
            content += "処理詳細:\n"
            for detail_key, detail_value in log.processing_details.items():
                if isinstance(detail_value, (dict, list)):
                    content += f"  {detail_key}: {json.dumps(detail_value, ensure_ascii=False)}\n"
                else:
                    content += f"  {detail_key}: {detail_value}\n"
        
        return content
    
    def _generate_nutrition_search_results_md(self, log: DetailedExecutionLog, search_method: str, db_source: str) -> str:
        """栄養データベース検索結果のマークダウンを生成（ローカル/Elasticsearch対応）"""
        content = []
        
        content.append(f"# Nutrition Database Search Results")
        content.append(f"")
        content.append(f"**Search Method:** {search_method}")
        content.append(f"**Database Source:** {db_source}")
        content.append(f"**Component:** {log.component_name}")
        content.append(f"**Execution Time:** {log.get_execution_time():.3f} seconds")
        content.append(f"**Timestamp:** {log.execution_start_time.isoformat()}")
        content.append(f"")
        
        # 入力データの表示
        if log.input_data:
            content.append(f"## Input Data")
            if 'ingredient_names' in log.input_data:
                ingredients = log.input_data['ingredient_names']
                content.append(f"**Ingredients ({len(ingredients)}):** {', '.join(ingredients)}")
            
            if 'dish_names' in log.input_data:
                dishes = log.input_data['dish_names']
                content.append(f"**Dishes ({len(dishes)}):** {', '.join(dishes)}")
            content.append(f"")
        
        # 出力データの表示
        if log.output_data and 'matches' in log.output_data:
            matches = log.output_data['matches']
            content.append(f"## Search Results")
            content.append(f"**Total Matches:** {len(matches)}")
            content.append(f"")
            
            for i, (search_term, match_data) in enumerate(matches.items(), 1):
                content.append(f"### {i}. {search_term}")
                if isinstance(match_data, dict):
                    content.append(f"**ID:** {match_data.get('id', 'N/A')}")
                    
                    # search_name と description を適切に表示
                    search_name = match_data.get('search_name', 'N/A')
                    description = match_data.get('description', None)
                    content.append(f"**Search Name:** {search_name}")
                    if description:
                        content.append(f"**Description:** {description}")
                    else:
                        content.append(f"**Description:** None")
                    
                    content.append(f"**Data Type:** {match_data.get('data_type', 'N/A')}")
                    content.append(f"**Source:** {match_data.get('source', 'N/A')}")
                    
                    # スコア情報を改善
                    score = match_data.get('score', 'N/A')
                    if score != 'N/A' and 'search_metadata' in match_data:
                        metadata = match_data['search_metadata']
                        score_breakdown = metadata.get('score_breakdown', {})
                        calculation = metadata.get('calculation', '')
                        match_type = score_breakdown.get('match_type', 'unknown')
                        
                        if calculation:
                            content.append(f"**Score:** {score} *({match_type}: {calculation})*")
                        else:
                            content.append(f"**Score:** {score} *(text similarity + data type priority)*")
                    else:
                        content.append(f"**Score:** {score}")
                    
                    if 'nutrients' in match_data and match_data['nutrients']:
                        content.append(f"**Nutrients ({len(match_data['nutrients'])}):**")
                        for nutrient in match_data['nutrients'][:5]:  # 最初の5つだけ表示
                            if isinstance(nutrient, dict):
                                name = nutrient.get('name', 'Unknown')
                                amount = nutrient.get('amount', 0)
                                unit = nutrient.get('unit_name', '')
                                content.append(f"  - {name}: {amount} {unit}")
                        if len(match_data['nutrients']) > 5:
                            content.append(f"  - ... and {len(match_data['nutrients']) - 5} more nutrients")
                content.append(f"")
        
        # 検索サマリー
        if log.output_data and 'search_summary' in log.output_data:
            summary = log.output_data['search_summary']
            content.append(f"## Search Summary")
            content.append(f"**Total Searches:** {summary.get('total_searches', 0)}")
            content.append(f"**Successful Matches:** {summary.get('successful_matches', 0)}")
            content.append(f"**Failed Searches:** {summary.get('failed_searches', 0)}")
            content.append(f"**Match Rate:** {summary.get('match_rate_percent', 0)}%")
            content.append(f"**Search Method:** {summary.get('search_method', 'unknown')}")
            content.append(f"")
        
        # 推論理由があれば表示
        if log.reasoning:
            content.append(f"## Search Reasoning")
            for decision_point, reason_data in log.reasoning.items():
                reason = reason_data.get('reason', '') if isinstance(reason_data, dict) else str(reason_data)
                content.append(f"**{decision_point}:** {reason}")
            content.append(f"")
        
        # 警告・エラーがあれば表示
        if log.warnings:
            content.append(f"## Warnings")
            for warning in log.warnings:
                content.append(f"- {warning}")
            content.append(f"")
        
        if log.errors:
            content.append(f"## Errors")
            for error in log.errors:
                content.append(f"- {error}")
            content.append(f"")
        
        return "\n".join(content)
    
    def _generate_nutrition_match_details_txt(self, log: DetailedExecutionLog, search_method: str, db_source: str) -> str:
        """栄養データベース検索のマッチ詳細テキストを生成（ローカル/Elasticsearch/マルチDB対応）"""
        lines = []
        
        lines.append(f"Nutrition Database Search Match Details")
        lines.append(f"=" * 50)
        lines.append(f"Search Method: {search_method}")
        lines.append(f"Database Source: {db_source}")
        lines.append(f"Component: {log.component_name}")
        lines.append(f"Execution Time: {log.get_execution_time():.3f} seconds")
        lines.append(f"Timestamp: {log.execution_start_time.isoformat()}")
        lines.append(f"")
        
        if log.output_data and 'matches' in log.output_data:
            matches = log.output_data['matches']
            
            # 総マッチ数を計算（単一結果とリスト結果両方に対応）
            total_matches = 0
            for match_data in matches.values():
                if isinstance(match_data, list):
                    total_matches += len(match_data)
                elif isinstance(match_data, dict):
                    total_matches += 1
            
            lines.append(f"Total Matches: {total_matches}")
            lines.append(f"")
            
            for search_term, match_data in matches.items():
                lines.append(f"Query: {search_term}")
                lines.append(f"-" * 30)
                
                # マルチDB検索結果（リスト形式）への対応
                if isinstance(match_data, list):
                    lines.append(f"  Found {len(match_data)} results from multiple databases:")
                    lines.append(f"")
                    
                    for i, match_item in enumerate(match_data, 1):
                        lines.append(f"  Result {i}:")
                        lines.append(f"    ID: {match_item.get('id', 'N/A')}")
                        
                        search_name = match_item.get('search_name', 'N/A')
                        description = match_item.get('description', None)
                        lines.append(f"    Search Name: {search_name}")
                        if description:
                            lines.append(f"    Description: {description}")
                        else:
                            lines.append(f"    Description: None")
                        
                        lines.append(f"    Data Type: {match_item.get('data_type', 'N/A')}")
                        lines.append(f"    Source: {match_item.get('source', 'N/A')}")
                        
                        # スコア情報
                        score = match_item.get('score', 'N/A')
                        if score != 'N/A' and 'search_metadata' in match_item:
                            metadata = match_item['search_metadata']
                            source_db = metadata.get('source_database', 'unknown')
                            lines.append(f"    Score: {score:.3f} (from {source_db})")
                        else:
                            lines.append(f"    Score: {score}")
                        
                        # 栄養情報（簡略版）
                        if 'nutrition' in match_item and match_item['nutrition']:
                            nutrition = match_item['nutrition']
                            calories = nutrition.get('calories', 0)
                            protein = nutrition.get('protein', 0)
                            fat = nutrition.get('fat', 0)
                            carbs = nutrition.get('carbs', 0)
                            lines.append(f"    Nutrition (100g): {calories:.1f} kcal, P:{protein:.1f}g, F:{fat:.1f}g, C:{carbs:.1f}g")
                        
                        lines.append(f"")
                
                # 単一結果（辞書形式）への対応（従来の方式）
                elif isinstance(match_data, dict):
                    lines.append(f"  ID: {match_data.get('id', 'N/A')}")
                    
                    search_name = match_data.get('search_name', 'N/A')
                    description = match_data.get('description', None)
                    lines.append(f"  Search Name: {search_name}")
                    if description:
                        lines.append(f"  Description: {description}")
                    else:
                        lines.append(f"  Description: None")
                    
                    lines.append(f"  Data Type: {match_data.get('data_type', 'N/A')}")
                    lines.append(f"  Source: {match_data.get('source', 'N/A')}")
                    
                    # スコア情報を改善
                    score = match_data.get('score', 'N/A')
                    if score != 'N/A' and 'search_metadata' in match_data:
                        metadata = match_data['search_metadata']
                        score_breakdown = metadata.get('score_breakdown', {})
                        calculation = metadata.get('calculation', '')
                        match_type = score_breakdown.get('match_type', 'unknown')
                        
                        if calculation:
                            lines.append(f"  Score: {score} ({match_type}: {calculation})")
                        else:
                            lines.append(f"  Score: {score} (text similarity + data type priority)")
                    else:
                        lines.append(f"  Score: {score}")
                    
                    if 'nutrients' in match_data and match_data['nutrients']:
                        lines.append(f"  Nutrients ({len(match_data['nutrients'])}):")
                        for nutrient in match_data['nutrients']:
                            if isinstance(nutrient, dict):
                                name = nutrient.get('name', 'Unknown')
                                amount = nutrient.get('amount', 0)
                                unit = nutrient.get('unit_name', '')
                                lines.append(f"    - {name}: {amount} {unit}")
                    
                    if 'original_data' in match_data:
                        original_data = match_data['original_data']
                        if isinstance(original_data, dict):
                            lines.append(f"  Original Data Source: {original_data.get('source', 'Unknown')}")
                            if search_method == "local_search":
                                lines.append(f"  Local DB Source: {original_data.get('db_source', 'Unknown')}")
                    
                    lines.append(f"")
        
        # 検索統計
        if log.output_data and 'search_summary' in log.output_data:
            summary = log.output_data['search_summary']
            lines.append(f"Search Statistics:")
            lines.append(f"  Total Searches: {summary.get('total_searches', 0)}")
            lines.append(f"  Successful Matches: {summary.get('successful_matches', 0)}")
            lines.append(f"  Failed Searches: {summary.get('failed_searches', 0)}")
            lines.append(f"  Match Rate: {summary.get('match_rate_percent', 0)}%")
            
            # マルチDB検索の場合の追加情報
            if 'target_databases' in summary:
                lines.append(f"  Target Databases: {', '.join(summary['target_databases'])}")
                lines.append(f"  Results per Database: {summary.get('results_per_db', 'N/A')}")
                lines.append(f"  Total Results: {summary.get('total_results', 'N/A')}")
            
            if search_method == "local_search":
                lines.append(f"  Total Database Items: {summary.get('total_database_items', 0)}")
        
        return "\n".join(lines)
    
    def get_analysis_folder_path(self) -> str:
        """解析フォルダパスを取得"""
        return str(self.analysis_dir) 


################################################################################
## CATEGORY: コンポーネント層 - Phase1 AI分析
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/components/base.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/components/base.py
----------------------------------------------------------------------

from abc import ABC, abstractmethod
from typing import TypeVar, Generic, Any, Optional
import logging
from datetime import datetime

# 型変数の定義
InputType = TypeVar('InputType')
OutputType = TypeVar('OutputType')


class BaseComponent(ABC, Generic[InputType, OutputType]):
    """
    食事分析パイプラインのベースコンポーネント抽象クラス
    
    全てのコンポーネントはこのクラスを継承し、process メソッドを実装する必要があります。
    """
    
    def __init__(self, component_name: str, logger: Optional[logging.Logger] = None):
        """
        ベースコンポーネントの初期化
        
        Args:
            component_name: コンポーネント名
            logger: ロガーインスタンス（指定しない場合は自動生成）
        """
        self.component_name = component_name
        self.logger = logger or logging.getLogger(f"{__name__}.{component_name}")
        self.created_at = datetime.now()
        self.execution_count = 0
        self.current_execution_log = None  # 詳細ログ
        
    @abstractmethod
    async def process(self, input_data: InputType) -> OutputType:
        """
        メイン処理メソッド（抽象メソッド）
        
        Args:
            input_data: 入力データ
            
        Returns:
            OutputType: 処理結果
            
        Raises:
            ComponentError: 処理エラーが発生した場合
        """
        pass
    
    async def execute(self, input_data: InputType, execution_log: Optional['DetailedExecutionLog'] = None) -> OutputType:
        """
        ラップされた実行メソッド（ログ記録、エラーハンドリング付き）
        
        Args:
            input_data: 入力データ
            execution_log: 詳細実行ログ（オプション）
            
        Returns:
            OutputType: 処理結果
        """
        self.execution_count += 1
        execution_id = f"{self.component_name}_{self.execution_count}"
        
        # 詳細ログの設定
        if execution_log:
            self.current_execution_log = execution_log
            # 入力データを記録
            self.current_execution_log.set_input(self._safe_serialize_input(input_data))
        
        self.logger.info(f"[{execution_id}] Starting {self.component_name} processing")
        
        try:
            start_time = datetime.now()
            result = await self.process(input_data)
            end_time = datetime.now()
            
            processing_time = (end_time - start_time).total_seconds()
            self.logger.info(f"[{execution_id}] {self.component_name} completed in {processing_time:.2f}s")
            
            # 詳細ログに出力データを記録
            if self.current_execution_log:
                self.current_execution_log.set_output(self._safe_serialize_output(result))
                self.current_execution_log.finalize()
            
            return result
            
        except Exception as e:
            self.logger.error(f"[{execution_id}] {self.component_name} failed: {str(e)}", exc_info=True)
            
            # 詳細ログにエラーを記録
            if self.current_execution_log:
                self.current_execution_log.add_error(str(e))
                self.current_execution_log.finalize()
            
            raise ComponentError(f"{self.component_name} processing failed: {str(e)}") from e
        finally:
            self.current_execution_log = None
    
    def log_prompt(self, prompt_name: str, prompt_content: str, variables: dict = None):
        """プロンプトをログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_prompt(prompt_name, prompt_content, variables)
    
    def log_reasoning(self, decision_point: str, reason: str, confidence: float = None):
        """推論理由をログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_reasoning(decision_point, reason, confidence)
    
    def log_processing_detail(self, detail_key: str, detail_value: Any):
        """処理詳細をログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_processing_detail(detail_key, detail_value)
    
    def log_confidence_score(self, metric_name: str, score: float):
        """信頼度スコアをログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_confidence_score(metric_name, score)
    
    def log_warning(self, warning: str):
        """警告をログに記録"""
        if self.current_execution_log:
            self.current_execution_log.add_warning(warning)
    
    def _safe_serialize_input(self, input_data: InputType) -> dict:
        """入力データを安全にシリアライズ"""
        try:
            if hasattr(input_data, 'model_dump'):
                return input_data.model_dump()
            elif hasattr(input_data, '__dict__'):
                return input_data.__dict__
            else:
                return {"data": str(input_data)}
        except Exception as e:
            return {"serialization_error": str(e)}
    
    def _safe_serialize_output(self, output_data: OutputType) -> dict:
        """出力データを安全にシリアライズ"""
        try:
            if hasattr(output_data, 'model_dump'):
                return output_data.model_dump()
            elif hasattr(output_data, '__dict__'):
                return output_data.__dict__
            else:
                return {"data": str(output_data)}
        except Exception as e:
            return {"serialization_error": str(e)}
    
    def get_component_info(self) -> dict:
        """コンポーネント情報を取得"""
        return {
            "component_name": self.component_name,
            "created_at": self.created_at.isoformat(),
            "execution_count": self.execution_count,
            "component_type": self.__class__.__name__
        }


class ComponentError(Exception):
    """コンポーネント処理エラー"""
    
    def __init__(self, message: str, component_name: str = None, original_error: Exception = None):
        super().__init__(message)
        self.component_name = component_name
        self.original_error = original_error
        self.timestamp = datetime.now()
    
    def to_dict(self) -> dict:
        """エラー情報を辞書形式で取得"""
        return {
            "error_message": str(self),
            "component_name": self.component_name,
            "timestamp": self.timestamp.isoformat(),
            "original_error": str(self.original_error) if self.original_error else None
        } 

----------------------------------------------------------------------
### FILE: app_v2/components/phase1_component.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/components/phase1_component.py
----------------------------------------------------------------------

import json
from typing import Optional

from .base import BaseComponent
from ..models.phase1_models import (
    Phase1Input, Phase1Output, Dish, Ingredient, 
    DetectedFoodItem, FoodAttribute, AttributeType
)
from ..services.gemini_service import GeminiService
from ..config import get_settings
from ..config.prompts import Phase1Prompts


class Phase1Component(BaseComponent[Phase1Input, Phase1Output]):
    """
    Phase1: 画像分析コンポーネント（構造化出力対応・栄養データベース検索特化）
    
    Gemini AIを使用して食事画像を分析し、構造化された詳細情報
    （信頼度スコア、属性、ブランド情報等）を含む栄養データベース検索に適した出力を生成します。
    """
    
    def __init__(self, gemini_service: Optional[GeminiService] = None):
        super().__init__("Phase1Component")
        
        # GeminiServiceの初期化
        if gemini_service is None:
            settings = get_settings()
            self.gemini_service = GeminiService(
                project_id=settings.GEMINI_PROJECT_ID,
                location=settings.GEMINI_LOCATION,
                model_name=settings.GEMINI_MODEL_NAME
            )
        else:
            self.gemini_service = gemini_service
    
    async def process(self, input_data: Phase1Input) -> Phase1Output:
        """
        Phase1の主処理: 構造化画像分析（栄養データベース検索特化）
        
        Args:
            input_data: Phase1Input (image_bytes, image_mime_type, optional_text)
            
        Returns:
            Phase1Output: 構造化された分析結果（信頼度スコア、属性、ブランド情報等を含む）
        """
        self.logger.info(f"Starting Phase1 structured image analysis for enhanced nutrition database query generation")
        
        # プロンプト生成と記録（統一されたプロンプトシステム使用）
        system_prompt = Phase1Prompts.get_system_prompt()
        user_prompt = Phase1Prompts.get_user_prompt(input_data.optional_text)
        
        self.log_prompt("structured_system_prompt", system_prompt)
        self.log_prompt("user_prompt", user_prompt, {
            "optional_text": input_data.optional_text,
            "image_mime_type": input_data.image_mime_type
        })
        
        # 画像情報のログ記録
        self.log_processing_detail("image_size_bytes", len(input_data.image_bytes))
        self.log_processing_detail("image_mime_type", input_data.image_mime_type)
        
        try:
            # Gemini AIによる構造化画像分析
            self.log_processing_detail("gemini_structured_api_call_start", "Calling Gemini API for structured image analysis")
            
            gemini_result = await self.gemini_service.analyze_phase1_structured(
                image_bytes=input_data.image_bytes,
                image_mime_type=input_data.image_mime_type,
                optional_text=input_data.optional_text,
                system_prompt=system_prompt
            )
            
            self.log_processing_detail("gemini_structured_response", gemini_result)
            
            # 構造化データを処理
            detected_food_items = []
            if "detected_food_items" in gemini_result:
                for item_index, item_data in enumerate(gemini_result["detected_food_items"]):
                    # 属性を処理
                    attributes = []
                    for attr_data in item_data.get("attributes", []):
                        # AttributeTypeに存在しない場合はPREPARATIONにフォールバック
                        attr_type_str = attr_data.get("type", "ingredient")
                        try:
                            attr_type = AttributeType(attr_type_str)
                        except ValueError:
                            # 未知の属性タイプの場合は最も近い既存タイプにマッピング
                            if attr_type_str in ["cut", "chopped", "sliced", "diced"]:
                                attr_type = AttributeType.PREPARATION
                            elif attr_type_str in ["fresh", "cooked", "raw", "fried", "grilled"]:
                                attr_type = AttributeType.COOKING_METHOD
                            elif attr_type_str in ["sweet", "salty", "spicy", "sour"]:
                                attr_type = AttributeType.TEXTURE
                            else:
                                attr_type = AttributeType.PREPARATION  # デフォルト
                        
                        attribute = FoodAttribute(
                            type=attr_type,
                            value=attr_data["value"],
                            confidence=attr_data.get("confidence", 0.5)
                        )
                        attributes.append(attribute)
                    
                    # DetectedFoodItemを作成
                    detected_item = DetectedFoodItem(
                        item_name=item_data["item_name"],
                        confidence=item_data.get("confidence", 0.5),
                        attributes=attributes,
                        brand=item_data.get("brand"),
                        category_hints=item_data.get("category_hints", []),
                        negative_cues=item_data.get("negative_cues", [])
                    )
                    detected_food_items.append(detected_item)
                    
                    # 構造化アイテム識別の推論理由をログ
                    self.log_reasoning(
                        f"structured_item_identification_{item_index}",
                        f"Structured identification: '{item_data['item_name']}' (confidence: {item_data.get('confidence', 0.5):.2f}, "
                        f"attributes: {len(attributes)}, brand: {item_data.get('brand', 'N/A')})"
                    )
            
            # 従来互換性のためのdishesも生成
            dishes = []
            if "dishes" in gemini_result:
                for dish_index, dish_data in enumerate(gemini_result.get("dishes", [])):
                    ingredients = []
                    for ingredient_index, ingredient_data in enumerate(dish_data.get("ingredients", [])):
                        # 構造化属性を従来形式に変換
                        ingredient_attributes = []
                        if "attributes" in ingredient_data:
                            for attr_data in ingredient_data["attributes"]:
                                # AttributeTypeに存在しない場合の処理
                                attr_type_str = attr_data.get("type", "ingredient")
                                try:
                                    attr_type = AttributeType(attr_type_str)
                                except ValueError:
                                    # 未知の属性タイプの場合はマッピング
                                    if attr_type_str in ["cut", "chopped", "sliced", "diced"]:
                                        attr_type = AttributeType.PREPARATION
                                    elif attr_type_str in ["fresh", "cooked", "raw", "fried", "grilled"]:
                                        attr_type = AttributeType.COOKING_METHOD
                                    elif attr_type_str in ["sweet", "salty", "spicy", "sour"]:
                                        attr_type = AttributeType.TEXTURE
                                    else:
                                        attr_type = AttributeType.PREPARATION
                                
                                attr = FoodAttribute(
                                    type=attr_type,
                                    value=attr_data["value"],
                                    confidence=attr_data.get("confidence", 0.5)
                                )
                                ingredient_attributes.append(attr)
                        
                        # weight_gが必須フィールドなので、存在しない場合はエラー
                        if "weight_g" not in ingredient_data:
                            error_msg = f"Missing required field 'weight_g' for ingredient '{ingredient_data.get('ingredient_name', 'unknown')}'. Gemini must provide weight estimation for all ingredients."
                            self.logger.error(error_msg)
                            raise ValueError(error_msg)
                        
                        ingredient = Ingredient(
                            ingredient_name=ingredient_data["ingredient_name"],
                            weight_g=ingredient_data["weight_g"],
                            confidence=ingredient_data.get("confidence"),
                            detected_attributes=ingredient_attributes
                        )
                        ingredients.append(ingredient)
                    
                    # 料理レベルの属性
                    dish_attributes = []
                    if "attributes" in dish_data:
                        for attr_data in dish_data["attributes"]:
                            # AttributeTypeに存在しない場合の処理
                            attr_type_str = attr_data.get("type", "preparation")
                            try:
                                attr_type = AttributeType(attr_type_str)
                            except ValueError:
                                # 未知の属性タイプの場合はマッピング
                                if attr_type_str in ["cut", "chopped", "sliced", "diced"]:
                                    attr_type = AttributeType.PREPARATION
                                elif attr_type_str in ["fresh", "cooked", "raw", "fried", "grilled"]:
                                    attr_type = AttributeType.COOKING_METHOD
                                elif attr_type_str in ["sweet", "salty", "spicy", "sour"]:
                                    attr_type = AttributeType.TEXTURE
                                else:
                                    attr_type = AttributeType.PREPARATION
                            
                            attr = FoodAttribute(
                                type=attr_type,
                                value=attr_data["value"],
                                confidence=attr_data.get("confidence", 0.5)
                            )
                            dish_attributes.append(attr)
                    
                    dish = Dish(
                        dish_name=dish_data["dish_name"],
                        confidence=dish_data.get("confidence"),
                        ingredients=ingredients,
                        detected_attributes=dish_attributes
                    )
                    dishes.append(dish)
            
            # フォールバック: 構造化データから従来形式を生成
            if not dishes and detected_food_items:
                dishes = self._convert_structured_to_legacy(detected_food_items)
            
            # 分析統計の記録
            self.log_processing_detail("detected_structured_items_count", len(detected_food_items))
            self.log_processing_detail("detected_dishes_count", len(dishes))
            self.log_processing_detail("total_ingredients_count", sum(len(dish.ingredients) for dish in dishes))
            
            # 全体的な分析信頼度を計算
            overall_confidence = self._calculate_overall_confidence(detected_food_items, dishes)
            
            # 処理ノートを生成
            processing_notes = [
                f"Structured analysis generated {len(detected_food_items)} food items",
                f"Overall confidence: {overall_confidence:.2f}",
                f"Legacy compatibility: {len(dishes)} dishes generated"
            ]
            
            result = Phase1Output(
                detected_food_items=detected_food_items,
                dishes=dishes,
                analysis_confidence=overall_confidence,
                processing_notes=processing_notes,
                warnings=[]
            )
            
            self.log_processing_detail("structured_search_terms", result.get_structured_search_terms())
            self.log_reasoning(
                "structured_analysis_completion",
                f"Phase1 structured analysis completed: {len(detected_food_items)} structured items, "
                f"overall confidence {overall_confidence:.2f}"
            )
            
            self.logger.info(f"Phase1 structured analysis completed: {len(detected_food_items)} items, "
                           f"confidence {overall_confidence:.2f}")
            return result
            
        except Exception as e:
            self.logger.error(f"Phase1 structured processing failed: {str(e)}")
            raise
    

    
    def _convert_structured_to_legacy(self, detected_items: list) -> list:
        """構造化データを従来形式に変換（フォールバック用）"""
        # このメソッドは重量情報が不完全な場合に使用されるため、エラーを発生させる
        error_msg = "Cannot convert structured data to legacy format without weight information. Gemini must provide weight_g for all ingredients in the standard dishes format."
        self.logger.error(error_msg)
        raise ValueError(error_msg)
    
    def _calculate_overall_confidence(self, structured_items: list, dishes: list) -> float:
        """全体的な分析信頼度を計算"""
        if not structured_items and not dishes:
            return 0.0
        
        total_confidence = 0.0
        count = 0
        
        # 構造化アイテムの信頼度
        for item in structured_items:
            total_confidence += item.confidence
            count += 1
        
        # 料理の信頼度
        for dish in dishes:
            if dish.confidence is not None:
                total_confidence += dish.confidence
                count += 1
        
        return total_confidence / count if count > 0 else 0.5 


################################################################################
## CATEGORY: コンポーネント層 - MyNetDiary制約付き検索
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/components/mynetdiary_nutrition_search_component.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/components/mynetdiary_nutrition_search_component.py
----------------------------------------------------------------------

"""
MyNetDiary専用栄養データベース検索コンポーネント
"""
from datetime import datetime
from typing import List, Dict, Any, Optional
import logging

from .base import BaseComponent
from ..models.nutrition_search_models import NutritionQueryInput, NutritionQueryOutput, NutritionMatch
from ..utils.mynetdiary_utils import validate_ingredient_against_mynetdiary

# Elasticsearchの可用性チェック
try:
    from elasticsearch import Elasticsearch
    ELASTICSEARCH_AVAILABLE = True
except ImportError:
    ELASTICSEARCH_AVAILABLE = False
    Elasticsearch = None

class MyNetDiaryNutritionSearchComponent(BaseComponent[NutritionQueryInput, NutritionQueryOutput]):
    """
    MyNetDiary専用栄養データベース検索コンポーネント
    
    特徴:
    - ingredientに対しては完全一致の1つの項目のみを取得
    - 複数項目や0件の場合はエラーで全体の解析を停止
    - dishに対しては従来通りの検索を実行
    """
    
    def __init__(
        self, 
        elasticsearch_url: str = "http://localhost:9200",
        results_per_db: int = 3
    ):
        """
        MyNetDiaryNutritionSearchComponentの初期化
        
        Args:
            elasticsearch_url: ElasticsearchのURL
            results_per_db: データベースあたりの結果数（dishの場合）
        """
        super().__init__("MyNetDiaryNutritionSearchComponent")
        self.elasticsearch_url = elasticsearch_url
        self.results_per_db = results_per_db
        
        # インデックス名
        self.index_name = "nutrition_db"
        
        # Elasticsearchクライアントの初期化
        self.es_client = None
        self._initialize_elasticsearch()

    def _initialize_elasticsearch(self):
        """Elasticsearchクライアントを初期化"""
        if not ELASTICSEARCH_AVAILABLE:
            self.logger.error("Elasticsearch library not available")
            return
        
        try:
            self.es_client = Elasticsearch([self.elasticsearch_url])
            
            # 接続テスト
            if self.es_client.ping():
                self.logger.info(f"Successfully connected to Elasticsearch at {self.elasticsearch_url}")
                
                # インデックス存在確認
                if self.es_client.indices.exists(index=self.index_name):
                    self.logger.info(f"Index '{self.index_name}' exists and ready")
                else:
                    self.logger.error(f"Index '{self.index_name}' does not exist")
            else:
                self.logger.error(f"Failed to connect to Elasticsearch at {self.elasticsearch_url}")
                self.es_client = None
                
        except Exception as e:
            self.logger.error(f"Error initializing Elasticsearch: {e}")
            self.es_client = None

    async def process(self, input_data: NutritionQueryInput) -> NutritionQueryOutput:
        """
        MyNetDiary専用検索の主処理
        
        Args:
            input_data: NutritionQueryInput
            
        Returns:
            NutritionQueryOutput: MyNetDiary専用検索結果
            
        Raises:
            RuntimeError: Elasticsearchが利用できない場合、またはingredient検索で複数/0件の場合
        """
        # Elasticsearch利用可能性チェック
        if not ELASTICSEARCH_AVAILABLE or not self.es_client:
            raise RuntimeError("Elasticsearch not available for MyNetDiary search")
        
        start_time = datetime.now()
        
        search_terms = input_data.get_all_search_terms()
        self.logger.info(f"Starting MyNetDiary specialized search for {len(search_terms)} terms")
        
        matches = {}
        successful_matches = 0
        total_searches = len(search_terms)
        errors = []
        
        # 各検索語彙について処理
        for search_index, search_term in enumerate(search_terms):
            try:
                # ingredientかdishかを判定
                if search_term in input_data.ingredient_names:
                    # ingredient検索: 厳密な1件マッチング
                    result = await self._strict_ingredient_search(search_term)
                    if result:
                        matches[search_term] = result
                        successful_matches += 1
                        self.logger.info(f"Strict ingredient match for '{search_term}': {result.name}")
                    else:
                        # ingredient検索で結果がない場合はエラーで停止
                        error_msg = f"CRITICAL: No exact match found for ingredient '{search_term}' in MyNetDiary database"
                        self.logger.error(error_msg)
                        raise RuntimeError(error_msg)
                        
                elif search_term in input_data.dish_names:
                    # dish検索: 従来通りの検索
                    results = await self._flexible_dish_search(search_term)
                    if results:
                        matches[search_term] = results
                        successful_matches += 1
                        self.logger.info(f"Dish search for '{search_term}': {len(results)} results")
                    else:
                        self.logger.warning(f"No dish results found for '{search_term}'")
                        
            except Exception as e:
                error_msg = f"MyNetDiary search error for '{search_term}': {str(e)}"
                self.logger.error(error_msg)
                errors.append(error_msg)
                # ingredient検索のエラーの場合は全体を停止
                if search_term in input_data.ingredient_names:
                    raise RuntimeError(error_msg)
        
        # 結果の構築
        end_time = datetime.now()
        search_time_ms = int((end_time - start_time).total_seconds() * 1000)
        
        total_results = sum(len(result_list) if isinstance(result_list, list) else 1 for result_list in matches.values())
        match_rate = (successful_matches / total_searches * 100) if total_searches > 0 else 0
        
        search_summary = {
            "total_searches": total_searches,
            "successful_matches": successful_matches,
            "failed_searches": total_searches - successful_matches,
            "match_rate_percent": round(match_rate, 1),
            "search_method": "mynetdiary_specialized",
            "search_time_ms": search_time_ms,
            "total_results": total_results,
            "ingredient_strict_matching": True,
            "dish_flexible_matching": True
        }
        
        result = NutritionQueryOutput(
            matches=matches,
            search_summary=search_summary,
            errors=errors if errors else None
        )
        
        self.logger.info(f"MyNetDiary specialized search completed: {successful_matches}/{total_searches} matches in {search_time_ms}ms")
        
        return result

    async def _strict_ingredient_search(self, ingredient_name: str) -> Optional[NutritionMatch]:
        """
        ingredient用の厳密検索（完全一致の1件のみ）
        
        Args:
            ingredient_name: 検索する食材名
            
        Returns:
            NutritionMatch: 完全一致の1件、または None
            
        Raises:
            RuntimeError: 複数件マッチした場合
        """
        # まずMyNetDiaryリストに含まれているかチェック
        if not validate_ingredient_against_mynetdiary(ingredient_name):
            self.logger.error(f"Ingredient '{ingredient_name}' not found in MyNetDiary list")
            return None
        
        # MyNetDiaryデータベースから完全一致検索
        query = {
            "size": 10,  # 複数件チェック用
            "query": {
                "bool": {
                    "must": [
                        {"term": {"search_name.exact": ingredient_name}},
                        {"term": {"source_db": "mynetdiary"}}
                    ]
                }
            }
        }
        
        try:
            response = self.es_client.search(index=self.index_name, body=query)
            hits = response.get('hits', {}).get('hits', [])
            
            if len(hits) == 0:
                self.logger.error(f"No exact match found for ingredient '{ingredient_name}' in MyNetDiary database")
                return None
            elif len(hits) > 1:
                # 複数件マッチした場合はエラー
                hit_names = [hit['_source'].get('search_name', 'N/A') for hit in hits]
                error_msg = f"Multiple matches found for ingredient '{ingredient_name}': {hit_names}"
                self.logger.error(error_msg)
                raise RuntimeError(error_msg)
            else:
                # 正確に1件マッチした場合
                hit = hits[0]
                match = self._convert_es_hit_to_nutrition_match(hit, ingredient_name)
                match.search_metadata["search_type"] = "strict_ingredient"
                match.search_metadata["validation_passed"] = True
                return match
                
        except Exception as e:
            self.logger.error(f"Error in strict ingredient search for '{ingredient_name}': {e}")
            raise

    async def _flexible_dish_search(self, dish_name: str) -> List[NutritionMatch]:
        """
        dish用の柔軟検索（従来通り）
        
        Args:
            dish_name: 検索する料理名
            
        Returns:
            List[NutritionMatch]: 検索結果のリスト
        """
        # 複数データベースから検索
        query = {
            "size": self.results_per_db,
            "query": {
                "bool": {
                    "must": [
                        {
                            "multi_match": {
                                "query": dish_name,
                                "fields": [
                                    "search_name^3",
                                    "description^1"
                                ],
                                "type": "best_fields",
                                "fuzziness": "AUTO"
                            }
                        }
                    ],
                    "should": [
                        {"term": {"data_type": "dish"}},
                        {"term": {"data_type": "branded"}}
                    ]
                }
            },
            "sort": [
                {"_score": {"order": "desc"}}
            ]
        }
        
        try:
            response = self.es_client.search(index=self.index_name, body=query)
            hits = response.get('hits', {}).get('hits', [])
            
            results = []
            for hit in hits:
                match = self._convert_es_hit_to_nutrition_match(hit, dish_name)
                match.search_metadata["search_type"] = "flexible_dish"
                results.append(match)
            
            return results
            
        except Exception as e:
            self.logger.error(f"Error in flexible dish search for '{dish_name}': {e}")
            return []

    def _convert_es_hit_to_nutrition_match(self, hit: Dict[str, Any], search_term: str) -> NutritionMatch:
        """ElasticsearchのhitをNutritionMatchに変換"""
        source = hit['_source']
        score = hit['_score']
        
        return NutritionMatch(
            id=source.get('id', hit.get('_id', 'unknown')),
            name=source.get('search_name', 'Unknown'),
            search_name=source.get('search_name', 'Unknown'),
            description=source.get('description'),
            data_type=source.get('data_type', 'unknown'),
            source_db=source.get('source_db', 'unknown'),
            nutrition=source.get('nutrition', {}),
            weight=source.get('weight', 100),
            score=score,
            search_metadata={
                "search_term": search_term,
                "elasticsearch_score": score,
                "search_method": "mynetdiary_specialized",
                "source_database": source.get('source_db', 'unknown'),
                "index_name": self.index_name,
                "data_type": source.get('data_type', 'unknown')
            }
        ) 


################################################################################
## CATEGORY: コンポーネント層 - 栄養計算
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/components/nutrition_calculation_component.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/components/nutrition_calculation_component.py
----------------------------------------------------------------------

#!/usr/bin/env python3
"""
Nutrition Calculation Component

Phase1結果と栄養検索結果から実際の栄養素を計算するコンポーネント
"""

import logging
from datetime import datetime
from typing import Dict, List, Any, Optional

from .base import BaseComponent
from ..models.nutrition_calculation_models import (
    NutritionCalculationInput, 
    NutritionCalculationOutput,
    NutritionInfo,
    IngredientNutrition,
    DishNutrition,
    MealNutrition
)
from ..models.phase1_models import Phase1Output
from ..models.nutrition_search_models import NutritionQueryOutput, NutritionMatch


class NutritionCalculationComponent(BaseComponent[NutritionCalculationInput, NutritionCalculationOutput]):
    """栄養計算コンポーネント"""
    
    def __init__(self):
        super().__init__("NutritionCalculationComponent")
        
    async def process(self, input_data: NutritionCalculationInput) -> NutritionCalculationOutput:
        """
        栄養計算の主処理
        
        Args:
            input_data: Phase1結果と栄養検索結果
            
        Returns:
            NutritionCalculationOutput: 計算された栄養情報
        """
        start_time = datetime.now()
        
        phase1_result: Phase1Output = input_data.phase1_result
        nutrition_search_result: NutritionQueryOutput = input_data.nutrition_search_result
        
        self.logger.info(f"Starting nutrition calculation for {len(phase1_result.dishes)} dishes")
        
        # 料理別の栄養計算
        dish_nutritions = []
        total_meal_nutrition = None
        warnings = []
        
        for dish in phase1_result.dishes:
            try:
                dish_nutrition = await self._calculate_dish_nutrition(
                    dish, nutrition_search_result.matches
                )
                dish_nutritions.append(dish_nutrition)
                
                # 食事全体の栄養情報を累積
                if total_meal_nutrition is None:
                    total_meal_nutrition = dish_nutrition.total_nutrition
                else:
                    total_meal_nutrition = total_meal_nutrition + dish_nutrition.total_nutrition
                    
            except Exception as e:
                warning_msg = f"Failed to calculate nutrition for dish '{dish.dish_name}': {str(e)}"
                self.logger.warning(warning_msg)
                warnings.append(warning_msg)
        
        # デフォルト値の設定
        if total_meal_nutrition is None:
            total_meal_nutrition = NutritionInfo(
                calories=0.0, protein=0.0, fat=0.0, carbs=0.0
            )
        
        # 計算サマリーの作成
        end_time = datetime.now()
        processing_time_ms = int((end_time - start_time).total_seconds() * 1000)
        
        calculation_summary = {
            "total_dishes": len(phase1_result.dishes),
            "successful_calculations": len(dish_nutritions),
            "failed_calculations": len(phase1_result.dishes) - len(dish_nutritions),
            "total_ingredients": sum(len(dish.ingredients) for dish in dish_nutritions),
            "processing_time_ms": processing_time_ms
        }
        
        # 食事全体の栄養情報
        meal_nutrition = MealNutrition(
            dishes=dish_nutritions,
            total_nutrition=total_meal_nutrition,
            calculation_summary=calculation_summary,
            warnings=warnings
        )
        
        # メタデータ
        calculation_metadata = {
            "calculation_timestamp": end_time.isoformat(),
            "nutrition_search_method": nutrition_search_result.get_search_method(),
            "total_nutrition_matches": nutrition_search_result.get_total_matches()
        }
        
        result = NutritionCalculationOutput(
            meal_nutrition=meal_nutrition,
            calculation_metadata=calculation_metadata,
            processing_time_ms=processing_time_ms
        )
        
        self.logger.info(f"Nutrition calculation completed: {len(dish_nutritions)} dishes, "
                        f"{calculation_summary['total_ingredients']} ingredients, "
                        f"{total_meal_nutrition.calories:.1f} kcal total")
        
        return result
    
    async def _calculate_dish_nutrition(self, dish, nutrition_matches: Dict[str, Any]) -> DishNutrition:
        """
        料理レベルの栄養計算
        
        Args:
            dish: Phase1で検出された料理
            nutrition_matches: 栄養検索結果のマッチング
            
        Returns:
            DishNutrition: 料理の栄養計算結果
        """
        ingredient_nutritions = []
        dish_total_nutrition = None
        
        for ingredient in dish.ingredients:
            try:
                ingredient_nutrition = await self._calculate_ingredient_nutrition(
                    ingredient, nutrition_matches
                )
                ingredient_nutritions.append(ingredient_nutrition)
                
                # 料理全体の栄養情報を累積
                if dish_total_nutrition is None:
                    dish_total_nutrition = ingredient_nutrition.calculated_nutrition
                else:
                    dish_total_nutrition = dish_total_nutrition + ingredient_nutrition.calculated_nutrition
                    
            except Exception as e:
                self.logger.error(f"Failed to calculate nutrition for ingredient '{ingredient.ingredient_name}': {e}")
                raise
        
        # デフォルト値の設定
        if dish_total_nutrition is None:
            dish_total_nutrition = NutritionInfo(
                calories=0.0, protein=0.0, fat=0.0, carbs=0.0
            )
        
        # 計算メタデータ
        calculation_metadata = {
            "ingredient_count": len(ingredient_nutritions),
            "total_weight_g": sum(ing.weight_g for ing in ingredient_nutritions),
            "calculation_method": "weight_based_scaling"
        }
        
        return DishNutrition(
            dish_name=dish.dish_name,
            confidence=dish.confidence or 0.0,
            ingredients=ingredient_nutritions,
            total_nutrition=dish_total_nutrition,
            calculation_metadata=calculation_metadata
        )
    
    async def _calculate_ingredient_nutrition(self, ingredient, nutrition_matches: Dict[str, Any]) -> IngredientNutrition:
        """
        食材レベルの栄養計算
        
        Args:
            ingredient: Phase1で検出された食材
            nutrition_matches: 栄養検索結果のマッチング
            
        Returns:
            IngredientNutrition: 食材の栄養計算結果
        """
        ingredient_name = ingredient.ingredient_name
        weight_g = ingredient.weight_g
        
        # 栄養検索結果から該当する食材を取得
        if ingredient_name not in nutrition_matches:
            raise ValueError(f"No nutrition data found for ingredient '{ingredient_name}'")
        
        nutrition_match = nutrition_matches[ingredient_name]
        
        # リスト形式の場合は最初の要素を使用
        if isinstance(nutrition_match, list):
            if len(nutrition_match) == 0:
                raise ValueError(f"Empty nutrition match list for ingredient '{ingredient_name}'")
            nutrition_match = nutrition_match[0]
        
        # NutritionMatchオブジェクトから栄養情報を取得
        if not isinstance(nutrition_match, NutritionMatch):
            raise ValueError(f"Invalid nutrition match type for ingredient '{ingredient_name}': {type(nutrition_match)}")
        
        nutrition_per_100g = nutrition_match.nutrition
        source_db = nutrition_match.source_db
        
        # 重量に基づく栄養計算（100gあたり → 実際の重量）
        scaling_factor = weight_g / 100.0
        
        calculated_nutrition = NutritionInfo(
            calories=nutrition_per_100g.get('calories', 0.0) * scaling_factor,
            protein=nutrition_per_100g.get('protein', 0.0) * scaling_factor,
            fat=nutrition_per_100g.get('fat', 0.0) * scaling_factor,
            carbs=nutrition_per_100g.get('carbs', 0.0) * scaling_factor,
            fiber=nutrition_per_100g.get('fiber') * scaling_factor if nutrition_per_100g.get('fiber') is not None else None,
            sugar=nutrition_per_100g.get('sugar') * scaling_factor if nutrition_per_100g.get('sugar') is not None else None,
            sodium=nutrition_per_100g.get('sodium') * scaling_factor if nutrition_per_100g.get('sodium') is not None else None
        )
        
        # 計算ノート
        calculation_notes = [
            f"Scaled from 100g base data using factor {scaling_factor:.3f}",
            f"Source: {source_db} database"
        ]
        
        return IngredientNutrition(
            ingredient_name=ingredient_name,
            weight_g=weight_g,
            nutrition_per_100g=nutrition_per_100g,
            calculated_nutrition=calculated_nutrition,
            source_db=source_db,
            calculation_notes=calculation_notes
        ) 


################################################################################
## CATEGORY: データモデル層
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/models/phase1_models.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/models/phase1_models.py
----------------------------------------------------------------------

from typing import List, Optional, Dict, Any, Union
from pydantic import BaseModel, Field
from enum import Enum


class AttributeType(str, Enum):
    """属性タイプの列挙"""
    INGREDIENT = "ingredient"
    PREPARATION = "preparation"
    COLOR = "color"
    TEXTURE = "texture"
    COOKING_METHOD = "cooking_method"
    SERVING_STYLE = "serving_style"
    ALLERGEN = "allergen"


class FoodAttribute(BaseModel):
    """食品属性モデル（材料、調理法など）"""
    type: AttributeType = Field(..., description="属性のタイプ")
    value: str = Field(..., description="属性の値")
    confidence: float = Field(..., ge=0.0, le=1.0, description="この属性の信頼度スコア")


class DetectedFoodItem(BaseModel):
    """検出された食品アイテム（構造化）"""
    item_name: str = Field(..., description="食品名（主要な候補）")
    confidence: float = Field(..., ge=0.0, le=1.0, description="食品名の信頼度スコア")
    attributes: List[FoodAttribute] = Field(default=[], description="食品の属性リスト（材料、調理法など）")
    brand: Optional[str] = Field(None, description="認識されたブランド名（該当する場合）")
    category_hints: List[str] = Field(default=[], description="推定される食品カテゴリ")
    negative_cues: List[str] = Field(default=[], description="画像から判断できる「含まれない」要素")


class Ingredient(BaseModel):
    """食材情報モデル（栄養データベース検索用・従来互換性）"""
    ingredient_name: str = Field(..., description="食材の名称（栄養データベース検索で使用）")
    weight_g: float = Field(..., gt=0, description="写真から推定される食材の重量（グラム）")
    confidence: Optional[float] = Field(None, ge=0.0, le=1.0, description="食材特定の信頼度")
    detected_attributes: List[FoodAttribute] = Field(default=[], description="この食材に関連する属性")


class Dish(BaseModel):
    """料理情報モデル（栄養データベース検索用・従来互換性）"""
    dish_name: str = Field(..., description="特定された料理の名称（栄養データベース検索で使用）")
    confidence: Optional[float] = Field(None, ge=0.0, le=1.0, description="料理特定の信頼度")
    ingredients: List[Ingredient] = Field(..., description="その料理に含まれる食材のリスト")
    detected_attributes: List[FoodAttribute] = Field(default=[], description="この料理に関連する属性")


class Phase1Input(BaseModel):
    """Phase1コンポーネントの入力モデル"""
    image_bytes: bytes = Field(..., description="画像データ（バイト形式）")
    image_mime_type: str = Field(..., description="画像のMIMEタイプ")
    optional_text: Optional[str] = Field(None, description="オプションのテキスト情報")

    class Config:
        arbitrary_types_allowed = True


class Phase1Output(BaseModel):
    """Phase1コンポーネントの出力モデル（構造化・拡張版）"""
    # 新しい構造化出力
    detected_food_items: List[DetectedFoodItem] = Field(default=[], description="認識された食品アイテムのリスト（構造化）")
    
    # 従来互換性のための出力
    dishes: List[Dish] = Field(..., description="画像から特定された料理のリスト")
    
    # メタデータ
    analysis_confidence: float = Field(..., ge=0.0, le=1.0, description="全体的な分析の信頼度")
    processing_notes: List[str] = Field(default=[], description="処理に関する注記")
    warnings: Optional[List[str]] = Field(None, description="処理中の警告メッセージ")

    def get_all_ingredient_names(self) -> List[str]:
        """全ての食材名のリストを取得（栄養データベース検索用・従来互換性）"""
        ingredient_names = []
        for dish in self.dishes:
            for ingredient in dish.ingredients:
                ingredient_names.append(ingredient.ingredient_name)
        return ingredient_names

    def get_all_dish_names(self) -> List[str]:
        """全ての料理名のリストを取得（栄養データベース検索用・従来互換性）"""
        return [dish.dish_name for dish in self.dishes]
    
    def get_structured_search_terms(self) -> Dict[str, Any]:
        """構造化された検索用語を取得（新しい検索戦略用）"""
        return {
            "high_confidence_items": [
                {
                    "item_name": item.item_name,
                    "confidence": item.confidence,
                    "brand": item.brand
                }
                for item in self.detected_food_items 
                if item.confidence >= 0.8
            ],
            "medium_confidence_items": [
                {
                    "item_name": item.item_name,
                    "confidence": item.confidence,
                    "brand": item.brand
                }
                for item in self.detected_food_items 
                if 0.5 <= item.confidence < 0.8
            ],
            "brands": [
                item.brand for item in self.detected_food_items 
                if item.brand is not None and item.brand != ""
            ],
            "ingredients": [
                attr.value for item in self.detected_food_items 
                for attr in item.attributes 
                if attr.type == AttributeType.INGREDIENT
            ],
            "cooking_methods": [
                attr.value for item in self.detected_food_items 
                for attr in item.attributes 
                if attr.type == AttributeType.PREPARATION
            ],
            "negative_cues": [
                cue for item in self.detected_food_items 
                for cue in item.negative_cues
            ]
        }
    
    def get_primary_search_terms(self) -> List[str]:
        """プライマリ検索用語を取得（高信頼度アイテム）"""
        primary_terms = []
        
        # 高信頼度の検出アイテム
        for item in self.detected_food_items:
            if item.confidence >= 0.7:
                primary_terms.append(item.item_name)
        
        # フォールバック: 従来の料理名と食材名
        if not primary_terms:
            primary_terms.extend(self.get_all_dish_names())
            primary_terms.extend(self.get_all_ingredient_names())
        
        return primary_terms 

----------------------------------------------------------------------
### FILE: app_v2/models/nutrition_search_models.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/models/nutrition_search_models.py
----------------------------------------------------------------------

#!/usr/bin/env python3
"""
Nutrition Search Models

ローカル栄養データベース検索で使用する純粋なローカル形式のモデル（構造化入力対応）
"""

from typing import List, Dict, Optional, Any, Union
from pydantic import BaseModel, Field


class NutritionMatch(BaseModel):
    """栄養データベース照合結果モデル（純粋なローカル形式）"""
    id: Union[int, str] = Field(..., description="食品ID（ローカルID）")
    name: str = Field(..., description="食品名")  # search_nameから変更
    search_name: str = Field(..., description="検索名（簡潔な名称）")
    description: Optional[str] = Field(None, description="詳細説明")
    data_type: str = Field(..., description="データタイプ (dish, ingredient, branded)")
    source_db: str = Field(..., description="ソースデータベース（yazio, mynetdiary, eatthismuch）")
    source: str = Field(default="local_database", description="データソース（'local_database'）")
    
    # ローカルDBの生の栄養データ（100gあたり正規化済み）
    nutrition: Dict[str, float] = Field(default_factory=dict, description="ローカルDBの栄養データ（100gあたり）")
    weight: Optional[float] = Field(None, description="元データの重量（g）")
    
    # 検索スコア
    score: Optional[float] = Field(None, description="検索結果の関連度スコア")
    
    # 検索に関するメタデータ
    search_metadata: Optional[Dict[str, Any]] = Field(None, description="検索に関するメタデータ")


class AdvancedSearchOptions(BaseModel):
    """高度な検索オプション"""
    enable_fuzzy_matching: bool = Field(default=True, description="ファジーマッチングを有効にする")
    enable_two_stage_search: bool = Field(default=True, description="二段階検索を有効にする")
    primary_term_boost: float = Field(default=3.0, description="プライマリ用語のブースト値")
    brand_boost: float = Field(default=2.5, description="ブランド情報のブースト値")
    ingredient_boost: float = Field(default=1.5, description="材料情報のブースト値")
    preparation_boost: float = Field(default=1.2, description="調理法情報のブースト値")
    jaro_winkler_threshold: float = Field(default=0.8, description="Jaro-Winkler類似度の閾値")
    levenshtein_threshold: float = Field(default=0.7, description="Levenshtein類似度の閾値")
    first_stage_size: int = Field(default=50, description="第一段階で取得する候補数")
    final_result_size: int = Field(default=10, description="最終結果数")


class NutritionQueryInput(BaseModel):
    """栄養データベース検索入力モデル（構造化入力対応）"""
    ingredient_names: List[str] = Field(default_factory=list, description="食材名のリスト")
    dish_names: List[str] = Field(default_factory=list, description="料理名のリスト")
    search_options: Optional[Dict[str, Any]] = Field(None, description="検索オプション")
    preferred_source: str = Field(default="local_database", description="優先データソース")
    
    # 構造化データのサポート
    structured_analysis: Optional[Dict[str, Any]] = Field(None, description="Phase1からの構造化分析データ")
    phase1_output: Optional[Any] = Field(None, description="Phase1Outputオブジェクト（構造化データ含む）")
    
    # 高度な検索オプション
    advanced_search_options: Optional[AdvancedSearchOptions] = Field(None, description="高度な検索オプション")
    
    # 検索戦略
    search_strategy: str = Field(default="basic", description="検索戦略（basic, strategic, advanced_structured）")

    def get_all_search_terms(self) -> List[str]:
        """全ての検索語彙を取得"""
        return list(set(self.ingredient_names + self.dish_names))
    
    def get_structured_search_terms(self) -> Optional[Dict[str, Any]]:
        """構造化された検索用語を取得"""
        if self.phase1_output and hasattr(self.phase1_output, 'get_structured_search_terms'):
            return self.phase1_output.get_structured_search_terms()
        elif self.structured_analysis:
            return self.structured_analysis
        else:
            return None
    
    def get_primary_search_terms(self) -> List[str]:
        """プライマリ検索用語を取得（高信頼度アイテム）"""
        if self.phase1_output and hasattr(self.phase1_output, 'get_primary_search_terms'):
            return self.phase1_output.get_primary_search_terms()
        else:
            return self.get_all_search_terms()
    
    def has_structured_data(self) -> bool:
        """構造化データが利用可能かチェック"""
        return (
            self.structured_analysis is not None or
            (self.phase1_output and hasattr(self.phase1_output, 'detected_food_items'))
        )
    
    def is_advanced_search_enabled(self) -> bool:
        """高度な検索が有効かチェック"""
        return (
            self.search_strategy in ["advanced_structured", "strategic"] or
            self.has_structured_data()
        )


class NutritionQueryOutput(BaseModel):
    """栄養データベース検索結果モデル（構造化出力対応）"""
    # マルチデータベース検索対応：単一結果またはリスト結果を受け入れる
    matches: Dict[str, Union[NutritionMatch, List[NutritionMatch]]] = Field(
        default_factory=dict, 
        description="検索語彙と対応する照合結果のマッピング（単一結果またはマルチDB結果リスト）"
    )
    search_summary: Dict[str, Any] = Field(
        default_factory=dict, 
        description="検索結果のサマリー情報（柔軟な型対応）"
    )
    warnings: Optional[List[str]] = Field(None, description="警告メッセージのリスト")
    errors: Optional[List[str]] = Field(None, description="エラーメッセージのリスト")
    
    # 高度な検索結果のメタデータ
    advanced_search_metadata: Optional[Dict[str, Any]] = Field(None, description="高度な検索のメタデータ")

    def get_match_rate(self) -> float:
        """照合成功率を計算"""
        total_searches = self.search_summary.get("total_searches", 0)
        successful_matches = self.search_summary.get("successful_matches", 0)
        if total_searches == 0:
            return 0.0
        return successful_matches / total_searches

    def get_total_matches(self) -> int:
        """総照合件数を取得（マルチDB検索対応）"""
        total = 0
        for match_result in self.matches.values():
            if isinstance(match_result, list):
                total += len(match_result)
            else:
                total += 1
        return total
    
    def get_total_individual_results(self) -> int:
        """個別結果の総数を取得（マルチDB検索用）"""
        return self.get_total_matches()
    
    def has_errors(self) -> bool:
        """エラーが存在するかチェック"""
        return self.errors is not None and len(self.errors) > 0
    
    def has_warnings(self) -> bool:
        """警告が存在するかチェック"""
        return self.warnings is not None and len(self.warnings) > 0
    
    def get_search_method(self) -> str:
        """使用された検索方法を取得"""
        return self.search_summary.get("search_method", "unknown")
    
    def is_advanced_search_result(self) -> bool:
        """高度な検索の結果かチェック"""
        search_method = self.get_search_method()
        return search_method in [
            "advanced_structured_elasticsearch", 
            "elasticsearch_strategic",
            "two_stage_search"
        ] 

----------------------------------------------------------------------
### FILE: app_v2/models/nutrition_calculation_models.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/models/nutrition_calculation_models.py
----------------------------------------------------------------------

#!/usr/bin/env python3
"""
Nutrition Calculation Models

栄養計算フェーズで使用するモデル定義
"""

from typing import List, Dict, Optional, Any
from pydantic import BaseModel, Field


class NutritionInfo(BaseModel):
    """栄養情報モデル（実際の重量ベース）"""
    calories: float = Field(..., description="カロリー (kcal)")
    protein: float = Field(..., description="タンパク質 (g)")
    fat: float = Field(..., description="脂質 (g)")
    carbs: float = Field(..., description="炭水化物 (g)")
    fiber: Optional[float] = Field(None, description="食物繊維 (g)")
    sugar: Optional[float] = Field(None, description="糖質 (g)")
    sodium: Optional[float] = Field(None, description="ナトリウム (mg)")
    
    def __add__(self, other: 'NutritionInfo') -> 'NutritionInfo':
        """栄養情報の加算"""
        return NutritionInfo(
            calories=self.calories + other.calories,
            protein=self.protein + other.protein,
            fat=self.fat + other.fat,
            carbs=self.carbs + other.carbs,
            fiber=(self.fiber or 0) + (other.fiber or 0) if self.fiber is not None or other.fiber is not None else None,
            sugar=(self.sugar or 0) + (other.sugar or 0) if self.sugar is not None or other.sugar is not None else None,
            sodium=(self.sodium or 0) + (other.sodium or 0) if self.sodium is not None or other.sodium is not None else None
        )


class IngredientNutrition(BaseModel):
    """食材レベルの栄養計算結果"""
    ingredient_name: str = Field(..., description="食材名")
    weight_g: float = Field(..., description="重量 (g)")
    nutrition_per_100g: Dict[str, float] = Field(..., description="100gあたりの栄養情報（データベースから）")
    calculated_nutrition: NutritionInfo = Field(..., description="実際の重量に基づく栄養情報")
    source_db: str = Field(..., description="栄養データのソースデータベース")
    calculation_notes: List[str] = Field(default_factory=list, description="計算に関する注記")


class DishNutrition(BaseModel):
    """料理レベルの栄養計算結果"""
    dish_name: str = Field(..., description="料理名")
    confidence: float = Field(..., description="料理特定の信頼度")
    ingredients: List[IngredientNutrition] = Field(..., description="含まれる食材の栄養情報")
    total_nutrition: NutritionInfo = Field(..., description="料理全体の栄養情報")
    calculation_metadata: Dict[str, Any] = Field(default_factory=dict, description="計算メタデータ")


class MealNutrition(BaseModel):
    """食事全体の栄養計算結果"""
    dishes: List[DishNutrition] = Field(..., description="料理別の栄養情報")
    total_nutrition: NutritionInfo = Field(..., description="食事全体の栄養情報")
    calculation_summary: Dict[str, Any] = Field(default_factory=dict, description="計算サマリー")
    warnings: List[str] = Field(default_factory=list, description="計算時の警告")


class NutritionCalculationInput(BaseModel):
    """栄養計算コンポーネントの入力"""
    phase1_result: Any = Field(..., description="Phase1の結果（Phase1Output）")
    nutrition_search_result: Any = Field(..., description="栄養検索の結果（NutritionQueryOutput）")


class NutritionCalculationOutput(BaseModel):
    """栄養計算コンポーネントの出力"""
    meal_nutrition: MealNutrition = Field(..., description="食事全体の栄養計算結果")
    calculation_metadata: Dict[str, Any] = Field(default_factory=dict, description="計算プロセスのメタデータ")
    processing_time_ms: int = Field(..., description="処理時間（ミリ秒）") 


################################################################################
## CATEGORY: AI サービス層
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/services/gemini_service.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/services/gemini_service.py
----------------------------------------------------------------------

import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig, HarmCategory, HarmBlockThreshold
from typing import Dict, Optional
import json
import logging
from PIL import Image
import io

from ..config.prompts import Phase1Prompts

logger = logging.getLogger(__name__)

# Phase1用JSONスキーマ
MEAL_ANALYSIS_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
                            "description": "画像から特定された料理のリスト。",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "特定された料理の名称。"},
                    "ingredients": {
                        "type": "array",
                        "description": "この料理に含まれると推定される材料のリスト。",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "材料の名称。"}
                            },
                            "required": ["ingredient_name"]
                        }
                    }
                },
                "required": ["dish_name", "ingredients"]
            }
        }
    },
    "required": ["dishes"]
}

# 新しい構造化出力スキーマ
STRUCTURED_MEAL_ANALYSIS_SCHEMA = {
    "type": "object",
    "properties": {
        "detected_food_items": {
            "type": "array",
            "description": "認識された食品アイテムのリスト（構造化）。",
            "items": {
                "type": "object",
                "properties": {
                    "item_name": {"type": "string", "description": "食品名（主要な候補）"},
                    "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0, "description": "食品名の信頼度スコア"},
                    "attributes": {
                        "type": "array",
                        "description": "食品の属性リスト（材料、調理法など）",
                        "items": {
                            "type": "object",
                            "properties": {
                                "type": {
                                    "type": "string", 
                                    "enum": ["ingredient", "preparation", "color", "texture", "cooking_method", "serving_style", "allergen"],
                                    "description": "属性のタイプ"
                                },
                                "value": {"type": "string", "description": "属性の値"},
                                "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0, "description": "この属性の信頼度スコア"}
                            },
                            "required": ["type", "value", "confidence"]
                        }
                    },
                    "brand": {"type": "string", "description": "認識されたブランド名（該当する場合、nullの場合は空文字列）"},
                    "category_hints": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "推定される食品カテゴリ"
                    },
                    "negative_cues": {
                        "type": "array", 
                        "items": {"type": "string"},
                        "description": "画像から判断できる「含まれない」要素"
                    }
                },
                "required": ["item_name", "confidence", "attributes"]
            }
        },
        "dishes": {
            "type": "array",
            "description": "従来互換性のための料理リスト",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "料理名"},
                    "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0, "description": "料理特定の信頼度"},
                    "ingredients": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "食材名"},
                                "weight_g": {"type": "number", "minimum": 0.1, "description": "写真から推定される食材の重量（グラム）"},
                                "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0, "description": "食材特定の信頼度"},
                                "attributes": {
                                    "type": "array",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "type": {"type": "string", "description": "属性タイプ"},
                                            "value": {"type": "string", "description": "属性値"},
                                            "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0}
                                        },
                                        "required": ["type", "value", "confidence"]
                                    }
                                }
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    },
                    "attributes": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "type": {"type": "string"},
                                "value": {"type": "string"},
                                "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0}
                            },
                            "required": ["type", "value", "confidence"]
                        }
                    }
                },
                "required": ["dish_name", "ingredients"]
            }
        },
        "analysis_confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0, "description": "全体的な分析の信頼度"}
    },
    "required": ["detected_food_items", "dishes", "analysis_confidence"]
}




class GeminiService:
    """Vertex AI経由でGeminiを使用して食事画像を分析するサービスクラス"""
    
    def __init__(self, project_id: str, location: str, model_name: str = "gemini-2.5-flash-preview-05-20"):
        """
        初期化
        
        Args:
            project_id: GCPプロジェクトID
            location: Vertex AIのロケーション（例: us-central1）
            model_name: 使用するモデル名
        """
        # Vertex AIの初期化
        vertexai.init(project=project_id, location=location)
        
        # モデルの初期化
        self.model = GenerativeModel(model_name=model_name)
        
        # generation_configを作成 (Phase1用 - 従来版)
        self.generation_config = GenerationConfig(
            temperature=0.0,  # 完全にdeterministicに
            top_p=1.0,       # nucleus samplingを無効化
            top_k=1,         # 最も確率の高い選択肢のみ
            max_output_tokens=8192,
            candidate_count=1,  # レスポンス候補を1つに制限
            response_mime_type="application/json",
            response_schema=MEAL_ANALYSIS_GEMINI_SCHEMA
        )
        
        # 構造化分析用のgeneration_config
        self.structured_generation_config = GenerationConfig(
            temperature=0.1,  # わずかな変動を許可（より詳細な分析のため）
            top_p=0.95,
            top_k=40,
            max_output_tokens=16384,  # より多くの出力を許可
            candidate_count=1,
            response_mime_type="application/json",
            response_schema=STRUCTURED_MEAL_ANALYSIS_SCHEMA
        )
        
        # セーフティ設定
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        }
    
    async def analyze_phase1(
        self, 
        image_bytes: bytes, 
        image_mime_type: str, 
        optional_text: Optional[str] = None
    ) -> Dict:
        """
        Phase1: 画像とテキストを分析して食事情報を抽出（従来版）
        
        Args:
            image_bytes: 画像のバイトデータ
            image_mime_type: 画像のMIMEタイプ
            optional_text: オプションのテキスト説明
            
        Returns:
            分析結果の辞書
            
        Raises:
            RuntimeError: Gemini APIエラー時
        """
        try:
            # プロンプトを取得
            system_prompt = Phase1Prompts.get_system_prompt()
            user_prompt = Phase1Prompts.get_user_prompt(optional_text)
            
            # 完全なプロンプトを構築
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # コンテンツリストを作成
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            # Gemini APIを呼び出し
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            
            # レスポンスのテキストを取得
            if not response.text:
                raise ValueError("No response returned from Gemini.")
            
            # JSONレスポンスをパース
            result = json.loads(response.text)
            
            logger.info(f"Gemini Phase1 analysis completed successfully. Found {len(result.get('dishes', []))} dishes.")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error: {e}")
            raise RuntimeError(f"Error processing response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error: {e}")
            raise RuntimeError(f"Vertex AI/Gemini API request failed: {e}") from e
    
    async def analyze_phase1_structured(
        self, 
        image_bytes: bytes, 
        image_mime_type: str, 
        optional_text: Optional[str] = None,
        system_prompt: Optional[str] = None
    ) -> Dict:
        """
        Phase1: 構造化された詳細な画像分析（信頼度スコア、属性、ブランド情報等を含む）
        
        Args:
            image_bytes: 画像のバイトデータ
            image_mime_type: 画像のMIMEタイプ
            optional_text: オプションのテキスト説明
            system_prompt: カスタムシステムプロンプト（指定されない場合はデフォルト使用）
            
        Returns:
            構造化された分析結果の辞書
            
        Raises:
            RuntimeError: Gemini APIエラー時
        """
        try:
            # プロンプトを準備
            if system_prompt is None:
                system_prompt = Phase1Prompts.get_system_prompt()
            
            user_prompt = Phase1Prompts.get_user_prompt(optional_text)
            
            # 完全なプロンプトを構築
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # コンテンツリストを作成
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            logger.info("Starting structured Gemini Phase1 analysis...")
            
            # Gemini APIを呼び出し（構造化設定使用）
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=self.structured_generation_config,
                safety_settings=self.safety_settings
            )
            
            # レスポンスのテキストを取得
            if not response.text:
                raise ValueError("No response returned from Gemini structured analysis.")
            
            # JSONレスポンスをパース
            result = json.loads(response.text)
            
            # 結果の検証と修正
            result = self._validate_and_fix_structured_result(result)
            
            detected_items_count = len(result.get('detected_food_items', []))
            dishes_count = len(result.get('dishes', []))
            overall_confidence = result.get('analysis_confidence', 0.5)
            
            logger.info(f"Gemini Phase1 structured analysis completed: {detected_items_count} items, "
                       f"{dishes_count} dishes, confidence {overall_confidence:.2f}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error in structured analysis: {e}")
            raise RuntimeError(f"Error processing structured response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini structured API error: {e}")
            raise RuntimeError(f"Vertex AI/Gemini structured API request failed: {e}") from e
    
    def _validate_and_fix_structured_result(self, result: Dict) -> Dict:
        """構造化分析結果を検証し、必要に応じて修正"""
        # detected_food_itemsが存在しない場合の処理
        if 'detected_food_items' not in result:
            result['detected_food_items'] = []
        
        # dishesが存在しない場合の処理
        if 'dishes' not in result:
            result['dishes'] = []
        
        # analysis_confidenceが存在しない場合の処理
        if 'analysis_confidence' not in result:
            # 各アイテムの平均信頼度を計算
            confidences = []
            for item in result['detected_food_items']:
                if 'confidence' in item:
                    confidences.append(item['confidence'])
            
            for dish in result['dishes']:
                if 'confidence' in dish and dish['confidence'] is not None:
                    confidences.append(dish['confidence'])
            
            result['analysis_confidence'] = sum(confidences) / len(confidences) if confidences else 0.5
        
        # 各detected_food_itemの検証
        for item in result['detected_food_items']:
            # 必須フィールドのデフォルト値設定
            if 'confidence' not in item:
                item['confidence'] = 0.5
            if 'attributes' not in item:
                item['attributes'] = []
            if 'category_hints' not in item:
                item['category_hints'] = []
            if 'negative_cues' not in item:
                item['negative_cues'] = []
            
            # 属性の検証
            for attr in item['attributes']:
                if 'confidence' not in attr:
                    attr['confidence'] = 0.5
                if 'type' not in attr:
                    attr['type'] = 'ingredient'
        
        return result
    
 


################################################################################
## CATEGORY: 設定管理
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/config/settings.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/config/settings.py
----------------------------------------------------------------------

from typing import Optional, List
from pydantic_settings import BaseSettings
from functools import lru_cache


class Settings(BaseSettings):
    """
    API設定クラス
    環境変数から設定値を読み込む
    """
    # Vertex AI設定
    GEMINI_PROJECT_ID: str  # GCPプロジェクトID（必須）
    GEMINI_LOCATION: str = "us-central1"  # デフォルトのロケーション
    GEMINI_MODEL_NAME: str = "gemini-2.5-flash-preview-05-20"
    
    # 栄養データベース検索設定
    USE_ELASTICSEARCH_SEARCH: bool = True  # Elasticsearch栄養データベース検索を使用するかどうか
    USE_LOCAL_NUTRITION_SEARCH: bool = False  # ローカル栄養データベース検索を使用するかどうか（レガシー）
    NUTRITION_DB_EXPERIMENT_PATH: Optional[str] = None  # nutrition_db_experimentへのパス（自動検出する場合はNone）
    
    # Elasticsearch設定
    elasticsearch_url: str = "http://localhost:9200"
    elasticsearch_index_name: str = "nutrition_fuzzy_search"
    elasticsearch_timeout: int = 30
    
    # ファジーマッチング設定
    fuzzy_search_enabled: bool = True  # ファジーマッチング機能を有効にするかどうか
    jaro_winkler_threshold: float = 0.85  # Jaro-Winkler類似度の閾値
    fuzzy_min_score_tier3: float = 5.0  # Tier 3の最小スコア閾値
    fuzzy_max_candidates: int = 5  # Tier 4で取得する最大候補数
    
    # キャッシュ設定
    CACHE_TYPE: str = "simple"  # "simple", "redis", "memcached"
    CACHE_REDIS_URL: Optional[str] = None  # Redisを使用する場合のURL
    NUTRITION_CACHE_TTL_SECONDS: int = 3600  # 栄養データベースレスポンスのキャッシュ有効期間（1時間）
    
    # API設定
    API_LOG_LEVEL: str = "INFO"
    FASTAPI_ENV: str = "development"
    
    # サーバー設定
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    
    # APIバージョン
    API_VERSION: str = "v1"
    
    # 結果保存設定
    RESULTS_DIR: str = "analysis_results"
    
    class Config:
        env_file = ".env"
        case_sensitive = True
        extra = "ignore"  # 追加の環境変数を無視


@lru_cache()
def get_settings() -> Settings:
    """
    設定インスタンスを取得（キャッシュされる）
    """
    return Settings() 


################################################################################
## CATEGORY: プロンプト管理（Phase1 - MyNetDiary制約と重量推定）
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/config/prompts/phase1_prompts.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/config/prompts/phase1_prompts.py
----------------------------------------------------------------------

from ...utils.mynetdiary_utils import format_mynetdiary_ingredients_for_prompt

class Phase1Prompts:
    """Phase1（画像分析）のプロンプトテンプレート（MyNetDiary制約付き）"""
    
    @classmethod
    def _get_mynetdiary_ingredients_section(cls) -> str:
        """MyNetDiary食材名リストのセクションを生成"""
        try:
            ingredients_list = format_mynetdiary_ingredients_for_prompt()
            return f"""
MYNETDIARY INGREDIENT CONSTRAINT:
For ALL ingredients, you MUST select ONLY from the following MyNetDiary ingredient list. 
Do NOT create custom ingredient names. Use the EXACT names as they appear in this list:

{ingredients_list}

IMPORTANT: If you cannot find a suitable match in the MyNetDiary list for a visible ingredient, 
choose the closest available option or omit that ingredient rather than creating a custom name.
"""
        except Exception as e:
            # フォールバック: ファイルが読み込めない場合
            return """
MYNETDIARY INGREDIENT CONSTRAINT:
For ALL ingredients, you MUST select from the predefined MyNetDiary ingredient database.
Use standard, searchable ingredient names that exist in nutrition databases.
"""
    
    @classmethod
    def get_system_prompt(cls) -> str:
        """システムプロンプトを取得"""
        mynetdiary_section = cls._get_mynetdiary_ingredients_section()
        
        return f"""You are an advanced food recognition AI that analyzes food images and provides detailed structured output for nutrition calculation.

{mynetdiary_section}

DISH DECOMPOSITION RULE:
When you encounter complex dish names with multiple components connected by "and", "with", "plus", "alongside", etc., you MUST break them down into separate individual dishes.

NUTRITIONAL COMPLETENESS REQUIREMENTS:
For EACH dish, list ALL PRIMARY INGREDIENTS that materially contribute to nutrition calculations (protein, carbohydrate, fat sources, sauces, cooking oils, etc.):
• The goal is to avoid omitting any ingredient that would significantly affect calorie or macro-nutrient totals.
• This exhaustive ingredient list is critical because downstream nutrition calculation logic relies on having every significant component represented in the query set.
• ALL ingredient names MUST be selected from the MyNetDiary list provided above.

WEIGHT ESTIMATION REQUIREMENTS (MANDATORY):
For EACH ingredient, you MUST estimate the weight in grams (weight_g) based on visual analysis:
• This field is MANDATORY - the system will fail if any ingredient lacks weight_g
• Analyze the portion size, volume, and visual density of each ingredient in the photo
• Consider typical serving sizes and food density for accurate weight estimation
• Use visual cues like plate size, utensils, or other reference objects for scale
• For liquids: estimate volume and convert to weight (1ml ≈ 1g for most beverages)
• For solids: consider the 3D volume and typical density of the food item
• Provide realistic weights that reflect what is actually visible in the image
• Weight estimates should be practical and achievable (e.g., 50-200g for main ingredients, 5-30g for seasonings/sauces)
• NEVER omit the weight_g field - it is required for every single ingredient

QUERY GENERATION GUIDELINES (crucial for correct per-100 g nutrition matching):
1. For ingredients: ONLY use names from the MyNetDiary list above - NO custom names allowed
2. For dish names: Use simple, searchable names that exist as separate database entries
3. Avoid overly generic or misleading single-word queries
4. When a cooking or preservation method materially changes nutrition, include it
5. Output MUST be in English
6. Do NOT include quantities, units, brand marketing slogans, or flavour adjectives

CRITICAL FINAL VERIFICATION STEP:
Before finalizing your response, you MUST perform a strict verification check:
• Go through EVERY SINGLE ingredient name in your response
• Verify that each ingredient name appears EXACTLY as written in the MyNetDiary ingredient list provided above
• Check for exact spelling, capitalization, and word order matches
• If ANY ingredient name does not match EXACTLY, you MUST replace it with the correct name from the list
• If no exact match exists, choose the closest available option from the MyNetDiary list
• This verification is MANDATORY - ingredient names that don't match exactly will cause system failures

-------------------------------------------------------------
JSON RESPONSE STRUCTURE
-------------------------------------------------------------
Return a JSON object with the following structure:

{{
  "dishes": [
    {{
      "dish_name": "string",
      "confidence": 0.0-1.0,
      "ingredients": [
        {{
          "ingredient_name": "string (MUST be EXACT match from MyNetDiary list - verify before submitting)",
          "weight_g": "number (MANDATORY - estimated weight in grams based on visual analysis)",
          "confidence": 0.0-1.0
        }}
      ]
    }}
  ]
}}

REMINDER: After completing your JSON response, perform a final verification that every "ingredient_name" value matches EXACTLY with an entry in the MyNetDiary ingredient list provided above."""

    USER_PROMPT_TEMPLATE = "Please analyze this meal image and identify the dishes and their ingredients. For ingredients, you MUST select ONLY from the provided MyNetDiary ingredient list - do not create custom ingredient names. CRITICALLY IMPORTANT: You MUST estimate the weight in grams (weight_g) for EVERY SINGLE ingredient - this field is mandatory and the system will fail if any ingredient lacks weight_g. Base your weight estimates on visual analysis of portion sizes, volumes, and typical food densities. Use visual cues like plate size, utensils, or reference objects for scale. Focus on providing clear, searchable dish names for nutrition database queries. Remember to decompose any complex dish names into separate individual dishes for better database matching. FINAL STEP: Before submitting your response, double-check that EVERY ingredient name in your JSON response matches EXACTLY with the names in the MyNetDiary ingredient list provided - this verification is critical for system functionality."

    @classmethod
    def get_user_prompt(cls, optional_text: str = None) -> str:
        """ユーザープロンプトを取得"""
        base_prompt = cls.USER_PROMPT_TEMPLATE
        if optional_text:
            base_prompt += f"\n\nAdditional context: {optional_text}"
        return base_prompt 


################################################################################
## CATEGORY: ユーティリティ層 (MyNetDiaryデータハンドリング)
################################################################################

----------------------------------------------------------------------
### FILE: app_v2/utils/mynetdiary_utils.py
### FULL PATH: /Users/odasoya/meal_analysis_api_2/app_v2/utils/mynetdiary_utils.py
----------------------------------------------------------------------

"""
MyNetDiary関連のユーティリティ関数
"""
import os
from typing import List, Set
from pathlib import Path

def load_mynetdiary_ingredient_names() -> List[str]:
    """
    MyNetDiaryの食材名リストを読み込む
    
    Returns:
        List[str]: MyNetDiaryの食材名のリスト
    """
    # プロジェクトルートからの相対パス
    current_dir = Path(__file__).parent.parent.parent
    file_path = current_dir / "data" / "mynetdiary_search_names.txt"
    
    if not file_path.exists():
        raise FileNotFoundError(f"MyNetDiary食材名リストが見つかりません: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        ingredient_names = [line.strip() for line in f if line.strip()]
    
    return ingredient_names

def get_mynetdiary_ingredient_names_as_set() -> Set[str]:
    """
    MyNetDiaryの食材名リストをSetとして取得（高速検索用）
    
    Returns:
        Set[str]: MyNetDiaryの食材名のSet
    """
    return set(load_mynetdiary_ingredient_names())

def format_mynetdiary_ingredients_for_prompt() -> str:
    """
    MyNetDiaryの食材名リストをプロンプト用にフォーマット
    
    Returns:
        str: プロンプトに組み込み可能な形式の食材名リスト
    """
    ingredient_names = load_mynetdiary_ingredient_names()
    
    # 食材名を番号付きリストとしてフォーマット
    formatted_list = []
    for i, name in enumerate(ingredient_names, 1):
        formatted_list.append(f"{i}. {name}")
    
    return "\n".join(formatted_list)

def validate_ingredient_against_mynetdiary(ingredient_name: str) -> bool:
    """
    指定された食材名がMyNetDiaryのリストに含まれているかチェック
    
    Args:
        ingredient_name: チェックする食材名
        
    Returns:
        bool: MyNetDiaryのリストに含まれている場合True
    """
    mynetdiary_names = get_mynetdiary_ingredient_names_as_set()
    return ingredient_name in mynetdiary_names 


################################################################################
## CATEGORY: テスト画像
################################################################################

----------------------------------------------------------------------
### FILE: test_images/food1.jpg
### FULL PATH: /Users/odasoya/meal_analysis_api_2/test_images/food1.jpg
----------------------------------------------------------------------

ERROR: ファイルを読み取れませんでした: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

----------------------------------------------------------------------
### FILE: test_images/food2.jpg
### FULL PATH: /Users/odasoya/meal_analysis_api_2/test_images/food2.jpg
----------------------------------------------------------------------

ERROR: ファイルを読み取れませんでした: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

----------------------------------------------------------------------
### FILE: test_images/food3.jpg
### FULL PATH: /Users/odasoya/meal_analysis_api_2/test_images/food3.jpg
----------------------------------------------------------------------

ERROR: ファイルを読み取れませんでした: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

----------------------------------------------------------------------
### FILE: test_images/food4.jpg
### FULL PATH: /Users/odasoya/meal_analysis_api_2/test_images/food4.jpg
----------------------------------------------------------------------

ERROR: ファイルを読み取れませんでした: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

----------------------------------------------------------------------
### FILE: test_images/food5.jpg
### FULL PATH: /Users/odasoya/meal_analysis_api_2/test_images/food5.jpg
----------------------------------------------------------------------

ERROR: ファイルを読み取れませんでした: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte


################################################################################
## CATEGORY: 依存関係・設定ファイル
################################################################################

----------------------------------------------------------------------
### FILE: requirements.txt
### FULL PATH: /Users/odasoya/meal_analysis_api_2/requirements.txt
----------------------------------------------------------------------

fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0
google-cloud-aiplatform==1.94.0
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
httpx
pytest==7.4.3
pytest-asyncio==0.21.1
python-dotenv==1.0.0
Pillow==11.2.1
elasticsearch==8.15.1
rapidfuzz==3.6.1 

----------------------------------------------------------------------
### FILE: README.md
### FULL PATH: /Users/odasoya/meal_analysis_api_2/README.md
----------------------------------------------------------------------

# 食事分析 API (Meal Analysis API) v2.0

## 概要

この API は、**Google Gemini AI** と **Elasticsearch ベースマルチデータベース栄養検索システム**を使用した高度な食事画像分析システムです。**動的栄養計算機能**により、料理の特性に応じて最適な栄養計算戦略を自動選択し、正確な栄養価情報を提供します。

## 🌟 主な機能

### **🔥 新機能: Elasticsearch マルチデータベース栄養検索 v2.0**

- **⚡ Elasticsearch 高速検索**: 高性能な Elasticsearch インデックスによる大規模栄養データベース検索
- **📊 3 つのデータベース統合検索**: 1 つのクエリで複数のデータベースから包括的な栄養情報を取得
  - **YAZIO**: 1,825 項目 - バランスの取れた食品カテゴリ
  - **MyNetDiary**: 1,142 項目 - 科学的/栄養学的アプローチ
  - **EatThisMuch**: 8,878 項目 - 最大かつ最も包括的なデータベース
- **🔍 マルチ DB 検索モード**: 各データベースから最大 5 件ずつ、総合的な検索結果を提供
- **🎯 高精度マッチング**: 90.9%の成功率、各 DB から均等な結果分散
- **💾 詳細結果保存**: JSON・マークダウン・テキスト形式での検索結果自動保存

### **従来機能: 動的栄養計算システム**

- **🧠 AI 駆動の計算戦略決定**: Gemini AI が各料理に対して最適な栄養計算方法を自動選択
- **🎯 高精度栄養計算**: 食材重量 × 100g あたり栄養価で正確な実栄養価を算出
- **📊 3 層集計システム**: 食材 → 料理 → 食事全体の自動栄養集計

### **コア機能**

- **フェーズ 1**: Gemini AI による食事画像の分析（料理識別、食材抽出、重量推定）
- **マルチ DB 検索**: 3 つのデータベースからの包括的栄養情報取得
- **複数料理対応**: 1 枚の画像で複数の料理を同時分析
- **英語・日本語対応**: 多言語での食材・料理認識
- **OpenAPI 3.0 準拠**: 完全な API 文書化とタイプ安全性

## 🏗 プロジェクト構造

```
meal_analysis_api_2/
├── db/                                   # マルチデータベース（新機能）
│   ├── yazio_db.json                     # YAZIO栄養データベース（1,825項目）
│   ├── mynetdiary_db.json                # MyNetDiary栄養データベース（1,142項目）
│   └── eatthismuch_db.json               # EatThisMuch栄養データベース（8,878項目）
├── app_v2/                               # 新アーキテクチャ版
│   ├── components/                       # コンポーネントベース設計
│   │   ├── local_nutrition_search_component.py  # マルチDB検索コンポーネント
│   │   ├── phase1_component.py           # 画像分析コンポーネント
│   │   └── base.py                       # ベースコンポーネント
│   ├── pipeline/                         # パイプライン管理
│   │   ├── orchestrator.py               # メイン処理オーケストレーター
│   │   └── result_manager.py             # 結果管理システム
│   ├── models/                           # データモデル
│   │   ├── nutrition_search_models.py    # 栄養検索モデル
│   │   └── phase1_models.py              # Phase1モデル
│   ├── main/
│   │   └── app.py                        # FastAPIアプリケーション
│   └── config/                           # 設定管理
├── test_multi_db_nutrition_search.py     # マルチDB検索テストスクリプト（新機能）
├── test_local_nutrition_search_v2.py     # ローカル検索テストスクリプト
├── test_images/                          # テスト用画像
└── requirements.txt                      # Python依存関係
```

## 🚀 セットアップ

### 1. 依存関係のインストール

```bash
# 仮想環境の作成
python -m venv venv

# 仮想環境のアクティベート
source venv/bin/activate  # macOS/Linux
# または
venv\Scripts\activate     # Windows

# 依存関係のインストール
pip install -r requirements.txt
```

### 2. Google Cloud 設定

#### Google Cloud SDK のインストール

まだインストールしていない場合は、以下からインストールしてください：
https://cloud.google.com/sdk/docs/install

#### Google Cloud 認証の設定

開発環境では以下のコマンドで認証を設定：

```bash
# Google Cloudにログイン
gcloud auth login

# アプリケーションのデフォルト認証情報を設定
gcloud auth application-default login

# プロジェクトIDを設定
gcloud config set project YOUR_PROJECT_ID
```

本番環境ではサービスアカウントキーを使用：

```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your-service-account-key.json"
```

#### Vertex AI API の有効化

```bash
# Vertex AI APIを有効化
gcloud services enable aiplatform.googleapis.com
```

### 3. 環境変数の設定

以下の環境変数を設定してください：

```bash
# USDA API設定
export USDA_API_KEY="your-usda-api-key"

# Vertex AI設定
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account-key.json"
export GEMINI_PROJECT_ID="your-gcp-project-id"
export GEMINI_LOCATION="us-central1"
export GEMINI_MODEL_NAME="gemini-2.5-flash-preview-05-20"
```

## 🖥 サーバー起動

### app_v2 サーバーの起動（マルチ DB 対応）

```bash
# app_v2サーバーの起動
python -m app_v2.main.app
```

**⚠️ 注意**: 相対インポートエラーを回避するため、必ずモジュール形式で実行してください。

サーバーが起動すると、以下の URL でアクセス可能になります：

- **API**: http://localhost:8000
- **ドキュメント**: http://localhost:8000/docs
- **ヘルスチェック**: http://localhost:8000/health

## 🧪 テストの実行

### 🔥 マルチデータベース栄養検索テスト（最新機能）

**重要**: サーバーが起動している状態で実行してください。

```bash
# 別のターミナルで実行
python test_multi_db_nutrition_search.py
```

**期待される結果**:

- **検索速度**: 11 クエリを 0.10 秒で処理
- **マッチ率**: 各 DB90.9%のクエリで結果発見
- **総マッチ数**: 87 件（平均 7.9 件/クエリ）
- **データベース統計**:
  - YAZIO: 1,825 項目
  - MyNetDiary: 1,142 項目
  - EatThisMuch: 8,878 項目

**テスト結果例**:

```
📈 Multi-Database Search Results Summary:
- Total queries: 11
- Total matches found: 87
- Average matches per query: 7.9
- Search time: 0.10s

🔍 Detailed Query Results:
1. 'Roasted Potatoes' (dish)
   EatThisMuch: 3 matches
     Best: 'Roasted Potatoes' (score: 1.000)
     Nutrition: 91.0 kcal, 1.9g protein
```

### ローカル栄養検索テスト

```bash
# ローカル栄養データベース検索の統合テスト
python test_local_nutrition_search_v2.py
```

### 基本テスト（フェーズ 1 のみ）

```bash
python test_phase1_only.py
```

## 🚀 ローカル栄養データベース検索システム v2.0

### **新機能: ローカルデータベース統合**

システムが USDA API 依存からローカル栄養データベース検索に対応しました：

- **🔍 BM25F + マルチシグナルブースティング検索**: 高精度な食材マッチング
- **📊 8,878 項目のローカルデータベース**: オフライン栄養計算対応
- **⚡ 90.9%マッチ率**: 実測値による高い成功率
- **🔄 USDA 互換性**: 既存システムとの完全互換性維持

### サーバー起動（v2.0 対応）

#### 1. Elasticsearch の起動

```bash
# Elasticsearch 8.10.4 の起動
elasticsearch-8.10.4/bin/elasticsearch
```

**注意**: Elasticsearch が起動するまで約 20-30 秒かかります。以下のコマンドでヘルスチェックを行ってください：

```bash
# Elasticsearch ヘルスチェック
curl -X GET "localhost:9200/_cluster/health?pretty"
```

#### 2. API サーバーの起動

```bash
# app_v2サーバーの起動
python -m app_v2.main.app
```

**注意**: Elasticsearch が正常に起動してから API サーバーを起動してください。

### ローカル栄養検索テスト

**重要**: サーバーが起動している状態で実行してください。

```bash
# ローカル栄養データベース検索の統合テスト
python test_local_nutrition_search_v2.py
```

**期待される結果**:

- **マッチ率**: 90.9% (10/11 検索成功)
- **レスポンス時間**: ~11 秒
- **データベース**: ローカル栄養データ (8,878 項目)
- **検索方法**: BM25F + マルチシグナルブースティング

**テスト結果例**:

```
🔍 Local Nutrition Search Results:
- Matches found: 10
- Match rate: 90.9%
- Search method: local_nutrition_database
- Total searches: 11
- Successful matches: 10

🍽 Final Meal Nutrition:
- Calories: 400.00 kcal
- Protein: 60.00 g
- Carbohydrates: 220.00 g
- Fat: 120.00 g
```

### データベース詳細

**ローカル栄養データベース構成**:

- `dish_db.json`: 4,583 料理データ
- `ingredient_db.json`: 1,473 食材データ
- `branded_db.json`: 2,822 ブランド食品
- `unified_nutrition_db.json`: 8,878 統合データ

## 📡 API 使用方法

### 🔥 完全分析 (推奨): 全フェーズ統合

**1 つのリクエストで全ての分析を実行**

```bash
curl -X POST "http://localhost:8000/api/v1/meal-analyses/complete" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg"
```

このエンドポイントは以下を自動実行します：

- フェーズ 1: 画像分析
- USDA 照合: 食材データベース検索
- フェーズ 2: 計算戦略決定
- 栄養計算: 最終栄養価算出
- 結果保存: 自動的にファイル保存

**保存された結果の取得**

```bash
# 全結果一覧
curl "http://localhost:8000/api/v1/meal-analyses/results"

# 特定の結果取得
curl "http://localhost:8000/api/v1/meal-analyses/results/{analysis_id}"
```

### フェーズ 1: 基本分析

```bash
curl -X POST "http://localhost:8000/api/v1/meal-analyses" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg"
```

### フェーズ 2: 動的栄養計算

```bash
# 最初にフェーズ1の結果を取得
initial_result=$(curl -X POST "http://localhost:8000/api/v1/meal-analyses" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg")

# フェーズ2で動的栄養計算
curl -X POST "http://localhost:8000/api/v1/meal-analyses/refine" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg" \
  -F "initial_analysis_data=$initial_result"
```

## 📋 レスポンス例

### フェーズ 1 レスポンス

```json
{
  "dishes": [
    {
      "dish_name": "Fried Fish with Spaghetti and Tomato Sauce",
      "type": "Main Dish",
      "quantity_on_plate": "2 pieces of fish, 1 small serving of spaghetti",
      "ingredients": [
        {
          "ingredient_name": "White Fish Fillet",
          "weight_g": 150.0
        },
        {
          "ingredient_name": "Spaghetti (cooked)",
          "weight_g": 80.0
        }
      ]
    }
  ]
}
```

### フェーズ 2 レスポンス（動的栄養計算）

```json
{
  "dishes": [
    {
      "dish_name": "Spinach and Daikon Radish Aemono",
      "type": "Side Dish",
      "calculation_strategy": "ingredient_level",
      "fdc_id": null,
      "ingredients": [
        {
          "ingredient_name": "Spinach",
          "weight_g": 80.0,
          "fdc_id": 1905313,
          "usda_source_description": "SPINACH",
          "key_nutrients_per_100g": {
            "calories_kcal": 24.0,
            "protein_g": 3.53,
            "carbohydrates_g": 3.53,
            "fat_g": 0.0
          },
          "actual_nutrients": {
            "calories_kcal": 19.2,
            "protein_g": 2.82,
            "carbohydrates_g": 2.82,
            "fat_g": 0.0
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 57.45,
        "protein_g": 3.85,
        "carbohydrates_g": 4.57,
        "fat_g": 3.31
      }
    },
    {
      "dish_name": "Green Tea",
      "type": "Drink",
      "calculation_strategy": "dish_level",
      "fdc_id": 1810668,
      "usda_source_description": "GREEN TEA",
      "key_nutrients_per_100g": {
        "calories_kcal": 0.0,
        "protein_g": 0.0,
        "carbohydrates_g": 0.0,
        "fat_g": 0.0
      },
      "dish_total_actual_nutrients": {
        "calories_kcal": 0.0,
        "protein_g": 0.0,
        "carbohydrates_g": 0.0,
        "fat_g": 0.0
      }
    }
  ],
  "total_meal_nutrients": {
    "calories_kcal": 337.95,
    "protein_g": 13.32,
    "carbohydrates_g": 56.19,
    "fat_g": 6.67
  },
  "warnings": null,
  "errors": null
}
```

## 🔧 技術仕様

### 動的計算戦略の決定ロジック

**Dish Level (`dish_level`)**:

- シンプルな単品食品（果物、飲み物、基本食材）
- 標準化された既製品で適切な USDA ID が存在する場合
- 例: 緑茶、りんご、白米

**Ingredient Level (`ingredient_level`)**:

- 複雑な調理済み料理（炒め物、サラダ、スープ）
- 複数食材の組み合わせで料理全体の USDA ID が不適切な場合
- 例: 野菜炒め、手作りサラダ、味噌汁

### 栄養計算式

```
実栄養価 = (100gあたり栄養価 ÷ 100) × 推定重量(g)
```

### 集計階層

1. **食材レベル**: 個別食材の重量 × 100g 栄養価
2. **料理レベル**: 食材レベルの合計 または 料理全体計算
3. **食事レベル**: 全料理の栄養価合計

## ⚠️ エラーハンドリング

API は以下の HTTP ステータスコードを返します：

- `200 OK`: 正常な分析完了
- `400 Bad Request`: 不正なリクエスト（画像形式エラーなど）
- `422 Unprocessable Entity`: バリデーションエラー
- `503 Service Unavailable`: 外部サービス（USDA/Gemini）エラー
- `500 Internal Server Error`: サーバー内部エラー

## 🔍 トラブルシューティング

### 認証エラーが発生する場合

```bash
# 現在の認証状態を確認
gcloud auth list

# 現在のプロジェクト設定を確認
gcloud config list

# 必要に応じて再度認証
gcloud auth application-default login
```

### Vertex AI API が有効になっていない場合

```bash
# APIの有効状況を確認
gcloud services list --enabled | grep aiplatform

# 有効でない場合は有効化
gcloud services enable aiplatform.googleapis.com
```

### USDA API エラーが発生する場合

- API キーが正しく設定されているか確認
- レートリミット（3,600 件/時）に達していないか確認
- ネットワーク接続を確認

## 💻 開発情報

- **フレームワーク**: FastAPI 0.104+
- **AI サービス**: Google Vertex AI (Gemini 2.5 Flash)
- **栄養データベース**: USDA FoodData Central API
- **認証**: Google Cloud サービスアカウント
- **Python バージョン**: 3.9+
- **主要ライブラリ**:
  - `google-cloud-aiplatform` (Vertex AI)
  - `httpx` (非同期 HTTP)
  - `pydantic` (データバリデーション)
  - `pillow` (画像処理)

## 📄 ライセンス

このプロジェクトは MIT ライセンスの下で公開されています。

## 注意事項

**セキュリティ**: API キーやサービスアカウントキーは絶対にリポジトリにコミットしないでください。環境変数として安全に管理してください。


----------------------------------------------------------------------
### FILE: .gitignore
### FULL PATH: /Users/odasoya/meal_analysis_api_2/.gitignore
----------------------------------------------------------------------

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
venv/
ENV/
env/
.venv

# IDE
.idea/
.vscode/
*.swp
*.swo
*~
.cursor/

# Environment variables
# .env
.env.local
.env.*.local

# OS files
.DS_Store
Thumbs.db

# Test coverage
htmlcov/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Logs
*.log

# Database
*.db
*.sqlite3

# Jupyter Notebook
.ipynb_checkpoints

# pyenv
.python-version

# Test images (actual image files)
test_images/*.jpg
test_images/*.jpeg
test_images/*.png
test_images/*.webp
test_images/*.heic
test_images/*.heif

# Google Cloud Service Account Keys
service-account-key.json
*.json
!package.json
!tsconfig.json
!openapi.json 

# Sensitive analysis files that may contain credentials
test_advanced_elasticsearch_architecture_*.txt

/raw_nutrition_data/
elasticsearch-*/data/
elasticsearch-*/logs/
elasticsearch-8.10.4/



