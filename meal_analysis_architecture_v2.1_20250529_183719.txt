================================================================================
MEAL ANALYSIS API v2.1 - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ§‹é€ ã¨ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
================================================================================
ç”Ÿæˆæ—¥æ™‚: 2025-05-29 18:37:19
åˆ†æå¯¾è±¡: test_english_phase1_v2.py & test_english_phase2_v2.py å®Ÿè¡Œæ™‚ã«å‘¼ã³å‡ºã•ã‚Œã‚‹å…¨ãƒ•ã‚¡ã‚¤ãƒ«
================================================================================

ğŸ“Š ARCHITECTURE OVERVIEW v2.1
----------------------------------------

ğŸ”„ EXECUTION FLOW (Advanced 2-Phase Approach):
Phase 1: ç”»åƒ â†’ Gemini AI â†’ æ–™ç†ãƒ»é£Ÿæè­˜åˆ¥ + USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆ
Phase 2: Phase1çµæœ â†’ ä¸¦åˆ—USDAæ¤œç´¢ â†’ æˆ¦ç•¥æ±ºå®šAI â†’ FDC IDé¸æŠ â†’ å‹•çš„æ „é¤Šè¨ˆç®—

ğŸ—ï¸ LAYER STRUCTURE v2.1:
â”œâ”€â”€ APIå±¤ (FastAPI)
â”‚   â”œâ”€â”€ meal_analyses.py (Phase 1 v2.1: USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆ)
â”‚   â””â”€â”€ meal_analyses_refine.py (Phase 2 v2.1: é«˜åº¦æˆ¦ç•¥æ±ºå®š + æ „é¤Šè¨ˆç®—)
â”œâ”€â”€ ã‚µãƒ¼ãƒ“ã‚¹å±¤ (Enhanced)
â”‚   â”œâ”€â”€ gemini_service.py (2ãƒ•ã‚§ãƒ¼ã‚ºãƒ¡ã‚½ãƒƒãƒ‰: analyze_image_phase1, refine_analysis_phase2)
â”‚   â”œâ”€â”€ usda_service.py (Rich search + æ „é¤Šè©³ç´°å–å¾—)
â”‚   â”œâ”€â”€ nutrition_calculation_service.py (å‹•çš„è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³)
â”‚   â””â”€â”€ logging_service.py (ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† + è©³ç´°ãƒ­ã‚°è¨˜éŒ²)
â”œâ”€â”€ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤ (v2.1 Schemas)
â”‚   â””â”€â”€ meal.py (Phase1AnalysisResponse, Phase2GeminiResponse, MealAnalysisRefinementResponse)
â”œâ”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†å±¤ (2-Phase Templates)
â”‚   â”œâ”€â”€ prompt_loader.py (ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†)
â”‚   â””â”€â”€ prompt templates (phase1_*, phase2_*)
â”œâ”€â”€ ãƒ­ã‚°åˆ†æå±¤ (New)
â”‚   â”œâ”€â”€ log_analyzer.py (çµ±è¨ˆåˆ†æ + ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ)
â”‚   â””â”€â”€ analyze_logs.py (CLIåˆ†æãƒ„ãƒ¼ãƒ«)
â””â”€â”€ è¨­å®šå±¤
    â””â”€â”€ config.py (Environment configuration)

ğŸ”§ TECHNICAL FEATURES v2.1:
- âœ¨ é«˜åº¦æˆ¦ç•¥æ±ºå®šã‚·ã‚¹ãƒ†ãƒ  (dish_level vs ingredient_level)
- ğŸ” ä¸¦åˆ—USDAæ¤œç´¢ (25+å€™è£œã®åŒæ™‚å‡¦ç†)
- ğŸ“Š å‹•çš„æ „é¤Šè¨ˆç®— (æˆ¦ç•¥ãƒ™ãƒ¼ã‚¹è¨ˆç®—)
- ğŸ“ˆ åŒ…æ‹¬çš„ãƒ­ã‚°æ©Ÿèƒ½ (ã‚»ãƒƒã‚·ãƒ§ãƒ³è¿½è·¡ + ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ)
- ğŸ¯ FDC IDé¸æŠã¨ã‚½ãƒ¼ã‚¹èª¬æ˜
- ğŸ”„ 3å±¤æ „é¤Šé›†è¨ˆ (é£Ÿæ â†’ æ–™ç† â†’ é£Ÿäº‹)
- âš¡ éåŒæœŸå‡¦ç†æœ€é©åŒ–
- ğŸ“‹ æ§‹é€ åŒ–JSONå‡ºåŠ› (Gemini response_schema)

ğŸ†• NEW FEATURES v2.1:
- USDAã‚¯ã‚¨ãƒªå€™è£œã®è‡ªå‹•ç”Ÿæˆ
- æˆ¦ç•¥ç†ç”±ã¨é¸æŠç†ç”±ã®è©³ç´°è¨˜éŒ²
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°åˆ†æ
- CSV/JSONLãƒ­ã‚°ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã¨ã‚¨ãƒ©ãƒ¼åˆ†æ

================================================================================

ğŸ“ v2.1ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
============================================================

ğŸ“„ FILE: test_english_phase1_v2.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 7992 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:27:12
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
Phase 1 Analysis Test Script (v2.1) - USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å«ã‚€æ–°ã—ã„å‡ºåŠ›ã‚’ãƒ†ã‚¹ãƒˆ
"""

import requests
import json
import sys
import time
from pathlib import Path

# APIè¨­å®š
BASE_URL = "http://localhost:8000"
MEAL_ANALYSES_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/"

def test_phase1_analysis_v2():
    """Phase 1ã®æ–°ã—ã„ä»•æ§˜ï¼ˆv2.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    # ãƒ†ã‚¹ãƒˆç”»åƒã‚’æ¢ã™
    test_image_paths = [
        "test_images/food1.jpg",  # å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªæ¸ˆã¿
        "test_images/food2.jpg",
        "test_images/food3.jpg",
        "tests/assets/test_meal.jpg",
        "test_meal.jpg", 
        "sample_meal.jpg",
        # ä»–ã®ä¸€èˆ¬çš„ãªå ´æ‰€ã‚‚è©¦ã™
        Path.home() / "Downloads" / "meal.jpg",
        Path.cwd() / "meal.jpg"
    ]
    
    test_image_path = None
    for path in test_image_paths:
        if Path(path).exists():
            test_image_path = Path(path)
            break
    
    if not test_image_path:
        print("âŒ Test image not found. Please place a meal image in one of these locations:")
        for path in test_image_paths:
            print(f"   - {path}")
        return False
    
    print(f"ğŸ“· Using test image: {test_image_path}")
    
    # API ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    try:
        print("ğŸš€ Sending Phase 1 analysis request...")
        start_time = time.time()
        
        with open(test_image_path, 'rb') as image_file:
            files = {
                'image': ('test_meal.jpg', image_file, 'image/jpeg')
            }
            data = {
                'optional_text': 'This is a test meal for Phase 1 analysis with USDA query candidates.'
            }
            
            response = requests.post(
                MEAL_ANALYSES_ENDPOINT,
                files=files,
                data=data,
                timeout=60
            )
        
        elapsed_time = time.time() - start_time
        print(f"â±ï¸  Request completed in {elapsed_time:.2f} seconds")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
        print(f"ğŸ“Š Response status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ Error response: {response.text}")
            return False
        
        # JSON ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # çµæœã®è¡¨ç¤ºã¨æ¤œè¨¼
        print("\n" + "="*80)
        print("ğŸ“‹ PHASE 1 ANALYSIS RESULTS (v2.1)")
        print("="*80)
        
        # åŸºæœ¬æ§‹é€ ã®ç¢ºèª
        if 'dishes' not in result:
            print("âŒ Missing 'dishes' field in response")
            return False
        
        dishes = result['dishes']
        print(f"ğŸ½ï¸  Found {len(dishes)} dishes")
        
        # å„æ–™ç†ã®è©³ç´°è¡¨ç¤º
        for i, dish in enumerate(dishes, 1):
            print(f"\nğŸ“Œ DISH {i}: {dish.get('dish_name', 'Unknown')}")
            print(f"   Type: {dish.get('type', 'N/A')}")
            print(f"   Quantity: {dish.get('quantity_on_plate', 'N/A')}")
            
            # ææ–™ãƒªã‚¹ãƒˆ
            ingredients = dish.get('ingredients', [])
            print(f"   ğŸ¥— Ingredients ({len(ingredients)}):")
            for ing in ingredients:
                print(f"      - {ing.get('ingredient_name', 'Unknown')}: {ing.get('weight_g', 0)}g")
            
            # NEW: USDAã‚¯ã‚¨ãƒªå€™è£œã®ç¢ºèª (v2.1ã®é‡è¦ãªæ–°æ©Ÿèƒ½)
            usda_candidates = dish.get('usda_query_candidates', [])
            print(f"   ğŸ” USDA Query Candidates ({len(usda_candidates)}):")
            
            if not usda_candidates:
                print("      âŒ No USDA query candidates found - this is a problem for v2.1!")
                return False
            
            for j, candidate in enumerate(usda_candidates, 1):
                print(f"      {j}. Query: '{candidate.get('query_term', 'N/A')}'")
                print(f"         Granularity: {candidate.get('granularity_level', 'N/A')}")
                print(f"         Original: {candidate.get('original_term', 'N/A')}")
                print(f"         Reason: {candidate.get('reason_for_query', 'N/A')}")
        
        # v2.1 ä»•æ§˜ã®æ¤œè¨¼
        print(f"\nğŸ” V2.1 SPECIFICATION VALIDATION:")
        
        validation_passed = True
        
        # 1. å…¨ã¦ã®æ–™ç†ã«USDAã‚¯ã‚¨ãƒªå€™è£œãŒã‚ã‚‹ã‹
        for dish in dishes:
            if not dish.get('usda_query_candidates'):
                print(f"   âŒ Dish '{dish.get('dish_name')}' has no USDA query candidates")
                validation_passed = False
            else:
                print(f"   âœ… Dish '{dish.get('dish_name')}' has {len(dish.get('usda_query_candidates'))} USDA query candidates")
        
        # 2. ã‚¯ã‚¨ãƒªå€™è£œã®ç²’åº¦ãƒ¬ãƒ™ãƒ«ãŒé©åˆ‡ã‹
        granularity_levels = set()
        for dish in dishes:
            for candidate in dish.get('usda_query_candidates', []):
                level = candidate.get('granularity_level')
                if level in ['dish', 'ingredient', 'branded_product']:
                    granularity_levels.add(level)
                else:
                    print(f"   âŒ Invalid granularity level: {level}")
                    validation_passed = False
        
        print(f"   ğŸ“Š Granularity levels found: {list(granularity_levels)}")
        
        # 3. ç†ç”±ä»˜ã‘ãŒã‚ã‚‹ã‹
        reasoning_count = 0
        total_candidates = 0
        for dish in dishes:
            for candidate in dish.get('usda_query_candidates', []):
                total_candidates += 1
                if candidate.get('reason_for_query'):
                    reasoning_count += 1
        
        reasoning_percentage = (reasoning_count / total_candidates * 100) if total_candidates > 0 else 0
        print(f"   ğŸ“ Query reasoning coverage: {reasoning_percentage:.1f}% ({reasoning_count}/{total_candidates})")
        
        if reasoning_percentage < 80:
            print(f"   âš ï¸  Low reasoning coverage - should be > 80%")
            validation_passed = False
        
        # çµæœä¿å­˜
        output_file = "phase1_analysis_result_v2.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ Full result saved to: {output_file}")
        
        # æœ€çµ‚åˆ¤å®š
        if validation_passed:
            print(f"\nâœ… Phase 1 v2.1 test PASSED!")
            print("   - All dishes have USDA query candidates")
            print("   - Granularity levels are valid") 
            print("   - Reasoning coverage is sufficient")
            return True
        else:
            print(f"\nâŒ Phase 1 v2.1 test FAILED!")
            print("   Please check the validation errors above.")
            return False
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Request error: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON decode error: {e}")
        print(f"Raw response: {response.text}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False

def main():
    print("ğŸ§ª Phase 1 Analysis Test (v2.1) - USDA Query Candidates")
    print("-" * 60)
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    try:
        health_response = requests.get(f"{BASE_URL}/health", timeout=5)
        if health_response.status_code == 200:
            print("âœ… Server is healthy")
        else:
            print("âŒ Server health check failed")
            return 1
    except:
        print("âŒ Cannot connect to server. Is it running on http://localhost:8000?")
        return 1
    
    # Phase 1ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if test_phase1_analysis_v2():
        print("\nğŸ‰ All tests passed! Ready for Phase 2 integration.")
        return 0
    else:
        print("\nğŸ’¥ Tests failed! Please check the implementation.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ“„ FILE: test_english_phase2_v2.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 9883 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:36:43
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
Phase 2 Analysis Test Script (v2.1) - calculation_strategyã¨FDC IDé¸æŠã‚’ãƒ†ã‚¹ãƒˆ
"""

import requests
import json
import sys
import time
from pathlib import Path

# APIè¨­å®š
BASE_URL = "http://localhost:8000"
PHASE1_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/"
PHASE2_ENDPOINT = f"{BASE_URL}/api/v1/meal-analyses/refine"

def test_phase2_analysis_v2():
    """Phase 2ã®æ–°ã—ã„ä»•æ§˜ï¼ˆv2.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    # 1. Phase 1çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    phase1_result_file = "phase1_analysis_result_v2.json"
    if not Path(phase1_result_file).exists():
        print(f"âŒ Phase 1 result file not found: {phase1_result_file}")
        print("   Please run test_english_phase1_v2.py first")
        return False
    
    # Phase 1çµæœã‚’èª­ã¿è¾¼ã¿
    try:
        with open(phase1_result_file, 'r', encoding='utf-8') as f:
            phase1_result = json.load(f)
        print(f"âœ… Phase 1 result loaded from {phase1_result_file}")
    except Exception as e:
        print(f"âŒ Error loading Phase 1 result: {e}")
        return False
    
    # 2. ãƒ†ã‚¹ãƒˆç”»åƒã®ç¢ºèª
    test_image_paths = [
        "test_images/food1.jpg",
        "test_images/food2.jpg",
        "test_images/food3.jpg",
    ]
    
    test_image_path = None
    for path in test_image_paths:
        if Path(path).exists():
            test_image_path = Path(path)
            break
    
    if not test_image_path:
        print("âŒ Test image not found")
        return False
    
    print(f"ğŸ“· Using test image: {test_image_path}")
    
    # 3. Phase 2 API ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    try:
        print("ğŸš€ Sending Phase 2 analysis request...")
        start_time = time.time()
        
        with open(test_image_path, 'rb') as image_file:
            files = {
                'image': ('test_meal.jpg', image_file, 'image/jpeg')
            }
            data = {
                'phase1_analysis_json': json.dumps(phase1_result, ensure_ascii=False)
            }
            
            response = requests.post(
                PHASE2_ENDPOINT,
                files=files,
                data=data,
                timeout=120  # Phase 2ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§
            )
        
        elapsed_time = time.time() - start_time
        print(f"â±ï¸  Request completed in {elapsed_time:.2f} seconds")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
        print(f"ğŸ“Š Response status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ Error response: {response.text}")
            return False
        
        # JSON ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # çµæœã®è¡¨ç¤ºã¨æ¤œè¨¼
        print("\n" + "="*80)
        print("ğŸ“‹ PHASE 2 ANALYSIS RESULTS (v2.1)")
        print("="*80)
        
        # åŸºæœ¬æ§‹é€ ã®ç¢ºèª
        if 'dishes' not in result:
            print("âŒ Missing 'dishes' field in response")
            return False
        
        dishes = result['dishes']
        print(f"ğŸ½ï¸  Found {len(dishes)} dishes")
        
        # å„æ–™ç†ã®è©³ç´°è¡¨ç¤ºã¨æ¤œè¨¼
        validation_passed = True
        strategy_counts = {"dish_level": 0, "ingredient_level": 0}
        total_fdc_ids_selected = 0
        
        for i, dish in enumerate(dishes, 1):
            print(f"\nğŸ“Œ DISH {i}: {dish.get('dish_name', 'Unknown')}")
            print(f"   Type: {dish.get('type', 'N/A')}")
            
            # NEW v2.1: calculation_strategy ã®ç¢ºèª
            strategy = dish.get('calculation_strategy')
            print(f"   ğŸ¯ Calculation Strategy: {strategy}")
            
            if strategy not in ['dish_level', 'ingredient_level']:
                print(f"      âŒ Invalid calculation strategy: {strategy}")
                validation_passed = False
            else:
                strategy_counts[strategy] += 1
                print(f"   ğŸ“ Strategy Reason: {dish.get('reason_for_strategy', 'N/A')}")
            
            # FDC IDæƒ…å ±ã®ç¢ºèª
            dish_fdc_id = dish.get('fdc_id')
            if strategy == 'dish_level':
                if dish_fdc_id:
                    print(f"   ğŸ·ï¸  Dish FDC ID: {dish_fdc_id}")
                    print(f"   ğŸ“„ USDA Source: {dish.get('usda_source_description', 'N/A')}")
                    print(f"   ğŸ’­ Choice Reason: {dish.get('reason_for_choice', 'N/A')}")
                    total_fdc_ids_selected += 1
                else:
                    print(f"      âš ï¸  No FDC ID for dish-level strategy")
            
            # ææ–™ã®è©³ç´°
            ingredients = dish.get('ingredients', [])
            print(f"   ğŸ¥— Ingredients ({len(ingredients)}):")
            
            for ing in ingredients:
                ing_name = ing.get('ingredient_name', 'Unknown')
                weight = ing.get('weight_g', 0)
                ing_fdc_id = ing.get('fdc_id')
                
                print(f"      - {ing_name}: {weight}g", end="")
                if ing_fdc_id:
                    print(f" [FDC ID: {ing_fdc_id}]")
                    total_fdc_ids_selected += 1
                    if ing.get('reason_for_choice'):
                        print(f"        Reason: {ing.get('reason_for_choice')}")
                else:
                    print(f" [No FDC ID]")
            
            # æ „é¤Šç´ æƒ…å ±ã®ç¢ºèª
            nutrients = dish.get('dish_total_actual_nutrients')
            if nutrients:
                print(f"   ğŸ§® Nutrition (Total): {nutrients.get('calories_kcal', 0):.1f} kcal, "
                      f"{nutrients.get('protein_g', 0):.1f}g protein, "
                      f"{nutrients.get('carbohydrates_g', 0):.1f}g carbs, "
                      f"{nutrients.get('fat_g', 0):.1f}g fat")
            else:
                print(f"   âš ï¸  No nutritional data calculated")
        
        # é£Ÿäº‹å…¨ä½“ã®æ „é¤Š
        total_nutrients = result.get('total_meal_nutrients')
        if total_nutrients:
            print(f"\nğŸ½ï¸  MEAL TOTAL NUTRITION:")
            print(f"   Energy: {total_nutrients.get('calories_kcal', 0):.1f} kcal")
            print(f"   Protein: {total_nutrients.get('protein_g', 0):.1f}g")
            print(f"   Carbohydrates: {total_nutrients.get('carbohydrates_g', 0):.1f}g")
            print(f"   Fat: {total_nutrients.get('fat_g', 0):.1f}g")
            if total_nutrients.get('fiber_g'):
                print(f"   Fiber: {total_nutrients.get('fiber_g', 0):.1f}g")
            if total_nutrients.get('sodium_mg'):
                print(f"   Sodium: {total_nutrients.get('sodium_mg', 0):.1f}mg")
        
        # v2.1 ä»•æ§˜ã®æ¤œè¨¼
        print(f"\nğŸ” V2.1 SPECIFICATION VALIDATION:")
        print(f"   ğŸ“Š Strategy Distribution:")
        print(f"      - Dish Level: {strategy_counts['dish_level']} dishes")
        print(f"      - Ingredient Level: {strategy_counts['ingredient_level']} dishes") 
        print(f"   ğŸ·ï¸  Total FDC IDs Selected: {total_fdc_ids_selected}")
        
        # è­¦å‘Šã¨ã‚¨ãƒ©ãƒ¼ã®ç¢ºèª
        warnings = result.get('warnings', [])
        errors = result.get('errors', [])
        
        if warnings:
            print(f"   âš ï¸  Warnings ({len(warnings)}):")
            for warning in warnings:
                print(f"      - {warning}")
        
        if errors:
            print(f"   âŒ Errors ({len(errors)}):")
            for error in errors:
                print(f"      - {error}")
            validation_passed = False
        
        # çµæœä¿å­˜
        output_file = "phase2_analysis_result_v2.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ Full result saved to: {output_file}")
        
        # æœ€çµ‚åˆ¤å®š
        success_criteria = [
            len(dishes) > 0,
            all(d.get('calculation_strategy') in ['dish_level', 'ingredient_level'] for d in dishes),
            total_fdc_ids_selected > 0,
            total_nutrients is not None,
            not errors  # ã‚¨ãƒ©ãƒ¼ãŒãªã„ã“ã¨
        ]
        
        if all(success_criteria) and validation_passed:
            print(f"\nâœ… Phase 2 v2.1 test PASSED!")
            print("   - All dishes have valid calculation strategies")
            print("   - FDC IDs were successfully selected")
            print("   - Nutritional calculations completed")
            print("   - No critical errors")
            return True
        else:
            print(f"\nâŒ Phase 2 v2.1 test FAILED!")
            print("   Please check the validation errors above.")
            return False
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Request error: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON decode error: {e}")
        print(f"Raw response: {response.text}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False

def main():
    print("ğŸ§ª Phase 2 Analysis Test (v2.1) - Strategy & FDC ID Selection")
    print("-" * 70)
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    try:
        health_response = requests.get(f"{BASE_URL}/health", timeout=5)
        if health_response.status_code == 200:
            print("âœ… Server is healthy")
        else:
            print("âŒ Server health check failed")
            return 1
    except:
        print("âŒ Cannot connect to server. Is it running on http://localhost:8000?")
        return 1
    
    # Phase 2ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if test_phase2_analysis_v2():
        print("\nğŸ‰ Phase 2 test passed! v2.1 implementation is working correctly.")
        return 0
    else:
        print("\nğŸ’¥ Phase 2 test failed! Please check the implementation.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ“ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå±¤ (v2.1)
============================================================

ğŸ“„ FILE: app/main.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 3235 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import logging

from .api.v1.endpoints import meal_analyses, meal_analyses_refine
from .core.config import get_settings

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,  # ä¸€æ™‚çš„ã«DEBUGãƒ¬ãƒ™ãƒ«ã«å¤‰æ›´
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
    ]
)
logger = logging.getLogger(__name__)

# è¨­å®šã®å–å¾—
settings = get_settings()

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ
app = FastAPI(
    title="é£Ÿäº‹åˆ†æAPI (Meal Analysis API)",
    description="é£Ÿäº‹ã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€æ–™ç†ã¨ææ–™ã‚’ç‰¹å®šã™ã‚‹APIã€‚USDAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æºã«ã‚ˆã‚Šæ „é¤Šä¾¡è¨ˆç®—ã®ç²¾åº¦ã‚’å‘ä¸Šã€‚",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®è¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒç”¨ï¼‰
if settings.FASTAPI_ENV == "development":
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ã«åˆ¶é™ã™ã‚‹
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    """APIã®ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "é£Ÿäº‹åˆ†æAPI (Meal Analysis API)",
        "version": "2.0.0",
        "docs": "/docs",
        "health": "/health"
    }

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/health")
async def health_check():
    """APIã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "service": "meal-analysis-api"
    }

# v1 APIãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç™»éŒ²
app.include_router(
    meal_analyses.router,
    prefix=f"/api/{settings.API_VERSION}/meal-analyses",
    tags=["Meal Analysis"]
)

# v1 API ãƒ•ã‚§ãƒ¼ã‚º2ãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç™»éŒ²ï¼ˆ/refineã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
app.include_router(
    meal_analyses_refine.router,
    prefix=f"/api/{settings.API_VERSION}/meal-analyses",
    tags=["Meal Analysis"]
)

# ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆ
@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®å‡¦ç†"""
    logger.info("Meal Analysis API starting up...")
    logger.info(f"Environment: {settings.FASTAPI_ENV}")
    logger.info(f"API Version: {settings.API_VERSION}")
    logger.info(f"Gemini Model: {settings.GEMINI_MODEL_NAME}")
    logger.info("Phase 2 features with USDA integration enabled")

# ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆ
@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®å‡¦ç†"""
    logger.info("Meal Analysis API shutting down...")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": "INTERNAL_SERVER_ERROR",
                "message": "å†…éƒ¨ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
            }
        }
    ) 
```

============================================================

ğŸ“„ FILE: app/api/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/meal_analyses.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 7582 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:57:41
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import APIRouter, File, Form, UploadFile, HTTPException, Depends
from typing import Annotated, Optional
import logging
import time  # å®Ÿè¡Œæ™‚é–“æ¸¬å®šã®ãŸã‚

from ....services.gemini_service import GeminiMealAnalyzer
from ..schemas.meal import Phase1AnalysisResponse, MealAnalysisResponse, ErrorResponse
from ....services.logging_service import get_meal_analysis_logger, ProcessingPhase, LogLevel
from ....core.config import Settings, get_settings

logger = logging.getLogger(__name__)

router = APIRouter()

# Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_gemini_analyzer = None


async def get_gemini_analyzer(settings: Annotated[Settings, Depends(get_settings)]) -> GeminiMealAnalyzer:
    """
    Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
    """
    global _gemini_analyzer
    if _gemini_analyzer is None:
        _gemini_analyzer = GeminiMealAnalyzer(
            project_id=settings.GEMINI_PROJECT_ID,
            location=settings.GEMINI_LOCATION,
            model_name=settings.GEMINI_MODEL_NAME
        )
    return _gemini_analyzer


@router.post(
    "",
    response_model=Phase1AnalysisResponse,
    summary="Analyze Meal Image (Phase 1 v2.1)",
    description="v2.1: é£Ÿäº‹ç”»åƒã‚’åˆ†æã—ã€æ–™ç†ãƒ»é£Ÿæè­˜åˆ¥ã¨USDAã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚"
)
async def analyze_meal_v2_1(
    settings: Annotated[Settings, Depends(get_settings)],
    image: Annotated[UploadFile, File(description="Meal image file.")],
    optional_text: Annotated[Optional[str], None] = None
):
    """
    v2.1ä»•æ§˜ï¼šé£Ÿäº‹ç”»åƒã®åŸºæœ¬åˆ†æ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. ç”»åƒã®åŸºæœ¬ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    2. Gemini AI ã«ã‚ˆã‚‹é£Ÿäº‹åˆ†æï¼ˆPhase 1ï¼‰
    3. USDAã‚¯ã‚¨ãƒªå€™è£œã®ç”Ÿæˆ
    4. çµæœè¿”å´
    """
    # ãƒ­ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    meal_logger = get_meal_analysis_logger()
    session_id = meal_logger.start_session(
        endpoint="/api/v1/meal-analyses",
        image_filename=getattr(image, 'filename', None),
        image_size_bytes=None  # å¾Œã§è¨­å®š
    )
    
    start_time = time.time()
    
    try:
        # 1. Image validation
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message="Starting Phase 1 meal analysis"
        )
        
        if not image.content_type or not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Invalid image file format.")
        
        try:
            image_bytes = await image.read()
            # Update image size in session
            if session_id in meal_logger.active_sessions:
                meal_logger.active_sessions[session_id].image_size_bytes = len(image_bytes)
            
            # File size check (e.g., 10MB)
            if len(image_bytes) > 10 * 1024 * 1024:
                raise HTTPException(status_code=400, detail="Image file size too large (max 10MB).")
        except Exception as e:
            logger.error(f"Error reading image file: {e}")
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.REQUEST_RECEIVED,
                error_message="Failed to read image file",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail="Failed to read image file.")

        # 2. Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—
        gemini_service = await get_gemini_analyzer(settings)

        # 3. Call Gemini service (Phase 1)
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE1_START,
            message="Starting Gemini Phase 1 analysis"
        )
        
        phase1_start_time = time.time()
        try:
            result = await gemini_service.analyze_image_phase1(
                image_bytes=image_bytes,
                image_mime_type=image.content_type,
                optional_text=optional_text
            )
            phase1_duration = (time.time() - phase1_start_time) * 1000
            
            # Phase 1çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
            dishes_count = len(result.get('dishes', []))
            usda_queries_count = sum(
                len(dish.get('usda_query_candidates', [])) 
                for dish in result.get('dishes', [])
            )
            
            meal_logger.update_phase1_results(
                session_id=session_id,
                duration_ms=phase1_duration,
                dishes_count=dishes_count,
                usda_queries_count=usda_queries_count,
                phase1_output=result
            )
            
        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE1_START,
                error_message="Gemini Phase 1 analysis failed",
                error_details=str(e)
            )
            raise HTTPException(status_code=503, detail=f"Gemini API error: {e}")

        # 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
        response = Phase1AnalysisResponse(**result)
        
        meal_logger.end_session(
            session_id=session_id,
            warnings=None,
            errors=None
        )
        
        return response
        
    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
        meal_logger.log_error(
            session_id=session_id,
            phase=ProcessingPhase.ERROR_OCCURRED,
            error_message="Unexpected error during Phase 1 processing",
            error_details=str(e)
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        meal_logger.end_session(
            session_id=session_id,
            warnings=None,
            errors=[str(e)]
        )
        
        raise


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å¤ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚‚ç¶­æŒ
@router.post(
    "/legacy",
    response_model=MealAnalysisResponse,
    summary="Legacy Meal Analysis (v1.0 compatibility)",
    description="å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚æ–°ã—ã„æ©Ÿèƒ½ã«ã¯ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ `/` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
)
async def analyze_meal_legacy(
    image: Annotated[UploadFile, File(description="Meal image file to analyze.")],
    settings: Annotated[Settings, Depends(get_settings)],
    gemini_service: Annotated[GeminiMealAnalyzer, Depends(get_gemini_analyzer)],
    optional_text: Annotated[Optional[str], Form(description="Optional additional information about the meal.")] = None
):
    """
    å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    # åŒã˜æ¤œè¨¼ã‚’å®Ÿè¡Œ
    if not image.content_type or not image.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="Invalid image file format.")
    
    image_bytes = await image.read()
    if len(image_bytes) > 10 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="File too large.")
    
    try:
        # æ—§ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        analysis_result = await gemini_service.analyze_image_and_text(
            image_bytes=image_bytes,
            image_mime_type=image.content_type,
            optional_text=optional_text
        )
        
        response = MealAnalysisResponse(**analysis_result)
        return response
        
    except Exception as e:
        logger.error(f"Legacy analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e)) 
```

============================================================

ğŸ“„ FILE: app/api/v1/endpoints/meal_analyses_refine.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 21048 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:57:01
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from fastapi import APIRouter, File, Form, UploadFile, HTTPException, Depends
from typing import Annotated, List, Optional, Dict
import json
import logging
import asyncio  # éåŒæœŸå‡¦ç†ã®ãŸã‚
import time  # å®Ÿè¡Œæ™‚é–“æ¸¬å®šã®ãŸã‚

# æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«
from ..schemas.meal import (
    Phase1AnalysisResponse,  # Phase 1 å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«ä½¿ç”¨
    Phase2GeminiResponse,    # Phase 2 Geminiå‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«ä½¿ç”¨
    MealAnalysisRefinementResponse,
    USDASearchResultItem,
    RefinedDishResponse,
    RefinedIngredientResponse,
    CalculatedNutrients
)

# ã‚µãƒ¼ãƒ“ã‚¹
from ....services.usda_service import USDAService, get_usda_service
from ....services.gemini_service import GeminiMealAnalyzer
from ....services.nutrition_calculation_service import NutritionCalculationService, get_nutrition_calculation_service
from ....services.logging_service import get_meal_analysis_logger, ProcessingPhase, LogLevel
from ....core.config import Settings, get_settings

logger = logging.getLogger(__name__)

router = APIRouter()

# Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_gemini_analyzer = None

async def get_gemini_analyzer(settings: Annotated[Settings, Depends(get_settings)]) -> GeminiMealAnalyzer:
    """
    Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
    """
    global _gemini_analyzer
    if _gemini_analyzer is None:
        _gemini_analyzer = GeminiMealAnalyzer(
            project_id=settings.GEMINI_PROJECT_ID,
            location=settings.GEMINI_LOCATION,
            model_name=settings.GEMINI_MODEL_NAME
        )
    return _gemini_analyzer


@router.post(
    "/refine",
    response_model=MealAnalysisRefinementResponse,
    summary="Refine Meal Analysis with USDA Data & Enhanced Gemini Strategy (v2.1)",
    description="v2.1: Phase 1ã‹ã‚‰USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å—ä¿¡ã—ã€å…¨å€™è£œã§æ¤œç´¢ã‚’å®Ÿè¡Œã€‚Phase 2 GeminiãŒcalculation_strategyã‚’æ±ºå®šã—ã€FDC IDã‚’é¸æŠã€‚æ±ºå®šè«–çš„ã§ç²¾åº¦ã®é«˜ã„æ „é¤Šè¨ˆç®—ã‚’æä¾›ã€‚"
)
async def refine_meal_analysis(
    settings: Annotated[Settings, Depends(get_settings)],
    image: Annotated[UploadFile, File(description="Meal image file.")],
    # NEW: Phase 1 å‡ºåŠ›ã¯ JSON æ–‡å­—åˆ—ã¨ã—ã¦å—ã‘å–ã‚‹
    phase1_analysis_json: Annotated[str, Form(description="JSON response string from Phase 1 API.")],
    usda_service: Annotated[USDAService, Depends(get_usda_service)],
    gemini_service: Annotated[GeminiMealAnalyzer, Depends(get_gemini_analyzer)]
):
    """
    v2.1ä»•æ§˜ï¼šé£Ÿäº‹åˆ†æç²¾ç·»åŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. Phase 1åˆ†æçµæœã¨USDAã‚¯ã‚¨ãƒªå€™è£œã‚’å—ä¿¡
    2. å…¨USDAã‚¯ã‚¨ãƒªå€™è£œã§ä¸¦åˆ—æ¤œç´¢ã‚’å®Ÿè¡Œ
    3. Phase 2 Geminiã§ calculation_strategy æ±ºå®šã¨FDC IDé¸æŠ
    4. calculation_strategyã«åŸºã¥ãæ „é¤Šè¨ˆç®—
    5. ç²¾ç·»åŒ–ã•ã‚ŒãŸçµæœã‚’è¿”ã™
    """
    # ãƒ­ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    meal_logger = get_meal_analysis_logger()
    session_id = meal_logger.start_session(
        endpoint="/api/v1/meal-analyses/refine",
        image_filename=getattr(image, 'filename', None),
        image_size_bytes=None  # å¾Œã§è¨­å®š
    )
    
    start_time = time.time()
    warnings = []
    errors = []

    try:
        # 1. Image validation (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯)
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message="Validating image file"
        )
        
        if not image.content_type or not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Invalid image file format.")
        
        try:
            image_bytes = await image.read()
            # Update image size in session
            if session_id in meal_logger.active_sessions:
                meal_logger.active_sessions[session_id].image_size_bytes = len(image_bytes)
            
            # File size check (e.g., 10MB)
            if len(image_bytes) > 10 * 1024 * 1024:
                raise HTTPException(status_code=400, detail="Image file size too large (max 10MB).")
        except Exception as e:
            logger.error(f"Error reading image file: {e}")
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.REQUEST_RECEIVED,
                error_message="Failed to read image file",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail="Failed to read image file.")

        # 2. Parse Phase 1 analysis_data
        try:
            phase1_dict = json.loads(phase1_analysis_json)
            phase1_analysis = Phase1AnalysisResponse(**phase1_dict)
            
            # ãƒ­ã‚°ã«Phase 1æƒ…å ±ã‚’è¨˜éŒ²
            dishes_count = len(phase1_analysis.dishes)
            usda_queries_count = sum(len(dish.usda_query_candidates) for dish in phase1_analysis.dishes)
            
            meal_logger.log_entry(
                session_id=session_id,
                level=LogLevel.INFO,
                phase=ProcessingPhase.PHASE1_COMPLETE,
                message=f"Phase 1 data received: {dishes_count} dishes, {usda_queries_count} USDA queries",
                data={
                    "dishes_count": dishes_count,
                    "usda_queries_count": usda_queries_count,
                    "phase1_output": phase1_dict
                }
            )
            
        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE1_COMPLETE,
                error_message="Failed to parse Phase 1 JSON",
                error_details=str(e)
            )
            raise HTTPException(status_code=400, detail=f"Invalid Phase 1 JSON: {e}")

        # 3. Execute ALL USDA searches based on Phase 1 candidates
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.USDA_SEARCH_START,
            message="Starting USDA searches for all query candidates"
        )
        
        usda_search_start_time = time.time()
        usda_search_tasks = []
        query_map = {}  # ã‚¯ã‚¨ãƒªã¨å…ƒã®æ–™ç†/é£Ÿæåã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
        unique_queries = set()

        for dish in phase1_analysis.dishes:
            for candidate in dish.usda_query_candidates:
                if candidate.query_term not in unique_queries:
                    # NEW: search_foods_rich ã‚’ä½¿ç”¨
                    usda_search_tasks.append(usda_service.search_foods_rich(candidate.query_term))
                    query_map[candidate.query_term] = candidate.original_term or dish.dish_name
                    unique_queries.add(candidate.query_term)

        # éåŒæœŸã§USDAæ¤œç´¢ã‚’å®Ÿè¡Œ
        logger.info(f"Starting {len(usda_search_tasks)} USDA searches")
        usda_search_results_list = await asyncio.gather(*usda_search_tasks, return_exceptions=True)
        usda_search_duration = (time.time() - usda_search_start_time) * 1000

        # 4. Format USDA results for Gemini prompt
        usda_candidates_prompt_segments = []
        all_usda_search_results_map: Dict[int, USDASearchResultItem] = {}  # FDC ID ã§å¼•ã‘ã‚‹ã‚ˆã†ã«
        search_term_to_results: Dict[str, List[USDASearchResultItem]] = {}  # ã‚¯ã‚¨ãƒª -> çµæœ
        total_results_found = 0
        search_details = []

        for query, results_or_exc in zip(unique_queries, usda_search_results_list):
            original_term = query_map.get(query, query)
            if isinstance(results_or_exc, Exception):
                segment = f"Error searching USDA for '{query}' (related to '{original_term}'): {results_or_exc}\n"
                errors.append(f"USDA Search failed for {query}: {results_or_exc}")
                search_details.append({
                    "query": query,
                    "original_term": original_term,
                    "status": "error",
                    "error": str(results_or_exc)
                })
            elif not results_or_exc:
                segment = f"No USDA candidates found for '{query}' (related to '{original_term}').\n"
                search_details.append({
                    "query": query,
                    "original_term": original_term,
                    "status": "no_results"
                })
            else:
                search_term_to_results[query] = results_or_exc
                total_results_found += len(results_or_exc)
                segment = f"USDA candidates for '{query}' (related to '{original_term}'):\n"
                
                result_summaries = []
                for i, item in enumerate(results_or_exc):
                    all_usda_search_results_map[item.fdc_id] = item
                    # NEW: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã¨ãƒ–ãƒ©ãƒ³ãƒ‰æƒ…å ±ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
                    segment += (
                        f"  {i+1}. FDC ID: {item.fdc_id}, Name: {item.description} "
                        f"(Type: {item.data_type or 'N/A'}"
                        f"{f', Brand: {item.brand_owner}' if item.brand_owner else ''}), "
                        f"Score: {item.score:.2f}\n"
                        # å¿…è¦ã§ã‚ã‚Œã° ingredientsText ã‚„ nutrients ã‚‚ä¸€éƒ¨å«ã‚ã‚‹
                    )
                    if item.ingredients_text:
                        segment += f"    Ingredients: {item.ingredients_text[:150]}...\n"
                    
                    result_summaries.append({
                        "fdc_id": item.fdc_id,
                        "description": item.description,
                        "data_type": item.data_type,
                        "score": item.score
                    })
                
                search_details.append({
                    "query": query,
                    "original_term": original_term,
                    "status": "success",
                    "results_count": len(results_or_exc),
                    "results": result_summaries
                })
            
            usda_candidates_prompt_segments.append(segment)

        usda_candidates_prompt_text = "\n---\n".join(usda_candidates_prompt_segments)
        
        # USDAæ¤œç´¢çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        meal_logger.update_usda_search_results(
            session_id=session_id,
            duration_ms=usda_search_duration,
            queries_executed=len(unique_queries),
            results_found=total_results_found,
            search_details=search_details
        )

        # 5. Call Gemini service (Phase 2) for strategy and FDC ID selection
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE2_START,
            message="Starting Phase 2 Gemini for strategy determination and FDC ID selection"
        )
        
        phase2_start_time = time.time()
        try:
            logger.info("Calling Gemini Phase 2 for strategy determination and FDC ID selection")
            # NEW: refine_analysis_phase2 ã‚’ä½¿ç”¨
            gemini_output_dict = await gemini_service.refine_analysis_phase2(
                image_bytes=image_bytes,
                image_mime_type=image.content_type,
                phase1_output_text=phase1_analysis_json,
                usda_results_text=usda_candidates_prompt_text
            )
            gemini_phase2_response = Phase2GeminiResponse(**gemini_output_dict)
            phase2_duration = (time.time() - phase2_start_time) * 1000
            
            # Phase 2çµæœã‚’è§£æã—ã¦ãƒ­ã‚°ã«è¨˜éŒ²
            strategy_decisions = {}
            fdc_selections = {}
            for dish in gemini_phase2_response.dishes:
                strategy_decisions[dish.dish_name] = {
                    "strategy": dish.calculation_strategy,
                    "reason": dish.reason_for_strategy
                }
                fdc_selections[dish.dish_name] = {
                    "dish_fdc_id": dish.fdc_id,
                    "dish_reason": dish.reason_for_choice,
                    "ingredients": [{
                        "name": ing.ingredient_name,
                        "fdc_id": ing.fdc_id,
                        "reason": ing.reason_for_choice
                    } for ing in dish.ingredients]
                }
            
            meal_logger.update_phase2_results(
                session_id=session_id,
                duration_ms=phase2_duration,
                strategy_decisions=strategy_decisions,
                fdc_selections=fdc_selections,
                phase2_output=gemini_output_dict
            )

        except Exception as e:
            meal_logger.log_error(
                session_id=session_id,
                phase=ProcessingPhase.PHASE2_START,
                error_message="Gemini Phase 2 failed",
                error_details=str(e)
            )
            raise HTTPException(status_code=503, detail=f"Gemini Phase 2 error: {e}")

        # 6. Process Gemini output and perform Nutrition Calculation
        meal_logger.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.NUTRITION_CALC_START,
            message="Starting nutrition calculation based on Phase 2 strategy"
        )
        
        nutrition_calc_start_time = time.time()
        refined_dishes_response: List[RefinedDishResponse] = []
        nutrition_service = get_nutrition_calculation_service()  # æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹

        # Phase 1 ã®é‡é‡æƒ…å ±ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã‚„ã™ãã™ã‚‹
        phase1_weights_map = {
            (d.dish_name, i.ingredient_name): i.weight_g
            for d in phase1_analysis.dishes
            for i in d.ingredients
        }

        for gemini_dish in gemini_phase2_response.dishes:
            # Phase 1 Dish ã‚’åå‰ã§æ¢ã™ (å³å¯†ã«ã¯IDãªã©ã§å¼•ãã¹ãã ãŒã€ä»Šå›ã¯åå‰ã§)
            p1_dish = next((d for d in phase1_analysis.dishes if d.dish_name == gemini_dish.dish_name), None)
            if not p1_dish:
                warnings.append(f"Could not match Phase 2 dish '{gemini_dish.dish_name}' to Phase 1.")
                continue

            dish_total_nutrients = None
            refined_ingredients_list: List[RefinedIngredientResponse] = []
            dish_key_nutrients_100g = None

            if gemini_dish.calculation_strategy == "dish_level":
                dish_fdc_id = gemini_dish.fdc_id
                if dish_fdc_id:
                    dish_weight_g = sum(ing.weight_g for ing in p1_dish.ingredients)
                    dish_key_nutrients_100g = await usda_service.get_food_details_for_nutrition(dish_fdc_id)
                    if dish_key_nutrients_100g and dish_weight_g > 0:
                        dish_total_nutrients = nutrition_service.calculate_actual_nutrients(dish_key_nutrients_100g, dish_weight_g)
                    else:
                        warnings.append(f"Could not calculate dish-level nutrition for '{gemini_dish.dish_name}'")
                else:
                    warnings.append(f"Dish-level strategy selected for '{gemini_dish.dish_name}' but no FDC ID provided.")

                # ææ–™æƒ…å ±ã¯èª¬æ˜çš„ã«æ®‹ã™ãŒã€æ „é¤Šè¨ˆç®—ã¯ã—ãªã„ (Fallback FDC ID ã¯å–å¾—ãƒ»è¡¨ç¤º)
                for gemini_ing in gemini_dish.ingredients:
                    weight = phase1_weights_map.get((gemini_dish.dish_name, gemini_ing.ingredient_name), 0.0)
                    ing_nutrients_100g = await usda_service.get_food_details_for_nutrition(gemini_ing.fdc_id) if gemini_ing.fdc_id else None
                    refined_ingredients_list.append(RefinedIngredientResponse(
                        ingredient_name=gemini_ing.ingredient_name,
                        weight_g=weight,
                        fdc_id=gemini_ing.fdc_id,  # Fallback ID
                        usda_source_description=gemini_ing.usda_source_description,
                        reason_for_choice=gemini_ing.reason_for_choice,
                        key_nutrients_per_100g=ing_nutrients_100g,
                        actual_nutrients=None  # Not calculated here
                    ))

            elif gemini_dish.calculation_strategy == "ingredient_level":
                ingredient_nutrients_list = []
                for gemini_ing in gemini_dish.ingredients:
                    weight = phase1_weights_map.get((gemini_dish.dish_name, gemini_ing.ingredient_name), 0.0)
                    ing_fdc_id = gemini_ing.fdc_id
                    ing_nutrients_100g = None
                    ing_actual_nutrients = None

                    if ing_fdc_id and weight > 0:
                        ing_nutrients_100g = await usda_service.get_food_details_for_nutrition(ing_fdc_id)
                        if ing_nutrients_100g:
                            ing_actual_nutrients = nutrition_service.calculate_actual_nutrients(ing_nutrients_100g, weight)
                            ingredient_nutrients_list.append(ing_actual_nutrients)
                        else:
                            warnings.append(f"Could not get nutrition for ingredient '{gemini_ing.ingredient_name}' (FDC ID: {ing_fdc_id})")
                    else:
                        warnings.append(f"Missing FDC ID or weight for ingredient '{gemini_ing.ingredient_name}'")

                    refined_ingredients_list.append(RefinedIngredientResponse(
                        ingredient_name=gemini_ing.ingredient_name,
                        weight_g=weight,
                        fdc_id=ing_fdc_id,
                        usda_source_description=gemini_ing.usda_source_description,
                        reason_for_choice=gemini_ing.reason_for_choice,
                        key_nutrients_per_100g=ing_nutrients_100g,
                        actual_nutrients=ing_actual_nutrients
                    ))
                # ææ–™ã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šã‚’åˆè¨ˆ
                dish_total_nutrients = nutrition_service.aggregate_nutrients_for_dish_from_ingredients(
                    [ing for ing in refined_ingredients_list if ing.actual_nutrients]  # None ã‚’é™¤å¤–
                )

            # RefinedDishResponse ã‚’ä½œæˆ
            refined_dishes_response.append(RefinedDishResponse(
                dish_name=gemini_dish.dish_name,
                type=p1_dish.type,
                quantity_on_plate=p1_dish.quantity_on_plate,
                calculation_strategy=gemini_dish.calculation_strategy,
                reason_for_strategy=gemini_dish.reason_for_strategy,
                fdc_id=gemini_dish.fdc_id,
                usda_source_description=gemini_dish.usda_source_description,
                reason_for_choice=gemini_dish.reason_for_choice,
                key_nutrients_per_100g=dish_key_nutrients_100g,
                ingredients=refined_ingredients_list,
                dish_total_actual_nutrients=dish_total_nutrients
            ))

        # 7. Calculate total meal nutrients
        total_meal_nutrients = nutrition_service.aggregate_nutrients_for_meal(
            [dish.dish_total_actual_nutrients for dish in refined_dishes_response if dish.dish_total_actual_nutrients]
        )
        
        nutrition_calc_duration = (time.time() - nutrition_calc_start_time) * 1000
        total_calories = total_meal_nutrients.calories_kcal if total_meal_nutrients else 0.0
        
        # æ „é¤Šè¨ˆç®—çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        meal_logger.update_nutrition_results(
            session_id=session_id,
            duration_ms=nutrition_calc_duration,
            total_calories=total_calories,
            final_nutrition={
                "total_meal_nutrients": total_meal_nutrients.dict() if total_meal_nutrients else None,
                "dishes_count": len(refined_dishes_response),
                "warnings_count": len(warnings),
                "errors_count": len(errors)
            }
        )

        # 8. Create final response
        response = MealAnalysisRefinementResponse(
            dishes=refined_dishes_response,
            total_meal_nutrients=total_meal_nutrients,
            warnings=warnings if warnings else None,
            errors=errors if errors else None
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
        meal_logger.end_session(
            session_id=session_id,
            warnings=warnings,
            errors=errors
        )
        
        return response

    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
        meal_logger.log_error(
            session_id=session_id,
            phase=ProcessingPhase.ERROR_OCCURRED,
            error_message="Unexpected error during request processing",
            error_details=str(e)
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
        meal_logger.end_session(
            session_id=session_id,
            warnings=warnings,
            errors=errors + [str(e)]
        )
        
        raise 
```

============================================================

ğŸ“ ã‚µãƒ¼ãƒ“ã‚¹å±¤ (v2.1å¯¾å¿œ)
============================================================

ğŸ“„ FILE: app/services/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/services/gemini_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 12578 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:41:52
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import vertexai
from vertexai.generative_models import GenerativeModel, Part, GenerationConfig, HarmCategory, HarmBlockThreshold
from typing import Dict, Optional
import json
import logging
from PIL import Image
import io

# æ–°ã—ã„ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..api.v1.schemas.meal import PHASE_1_GEMINI_SCHEMA, PHASE_2_GEMINI_SCHEMA, MEAL_ANALYSIS_GEMINI_SCHEMA, REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA
from ..prompts import PromptLoader

logger = logging.getLogger(__name__)

# Geminiã®æ§‹é€ åŒ–å‡ºåŠ›ã®ãŸã‚ã®JSONã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©
MEAL_ANALYSIS_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆã€‚",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°ã€‚"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—, ãƒ‡ã‚¶ãƒ¼ãƒˆï¼‰ã€‚"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°ï¼ˆä¾‹: '1æ¯', '2åˆ‡ã‚Œ', 'ç´„200g'ï¼‰ã€‚"},
                    "ingredients": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ã¨æ¨å®šã•ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§°ã€‚"},
                                "weight_g": {"type": "number", "description": "ãã®ææ–™ã®æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰ã€‚"}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients"]
            }
        }
    },
    "required": ["dishes"]
}


class GeminiMealAnalyzer:
    """Vertex AIçµŒç”±ã§Geminiã‚’ä½¿ç”¨ã—ã¦é£Ÿäº‹ç”»åƒã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹ (v2.1å¯¾å¿œ)"""
    
    def __init__(self, project_id: str, location: str, model_name: str = "gemini-2.5-flash-preview-05-20"):
        """
        åˆæœŸåŒ–
        
        Args:
            project_id: GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
            location: Vertex AIã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¾‹: us-central1ï¼‰
            model_name: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        """
        # Vertex AIã®åˆæœŸåŒ–
        vertexai.init(project=project_id, location=location)
        
        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.model = GenerativeModel(model_name=model_name)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–ï¼ˆå¿…é ˆï¼‰
        self.prompt_loader = PromptLoader()
        
        # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®š
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        }

    async def analyze_image_phase1(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        optional_text: Optional[str] = None
    ) -> Dict:
        """
        Phase 1: ç”»åƒã‚’åˆ†æã—ã€æ–™ç†ãƒ»é£Ÿæã¨USDAã‚¯ã‚¨ãƒªå€™è£œã‚’æŠ½å‡º (v2.1ä»•æ§˜)
        """
        try:
            system_prompt = self.prompt_loader.get_phase1_system_prompt()
            user_prompt = self.prompt_loader.get_phase1_user_prompt(optional_text)
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            contents = [Part.from_text(full_prompt), Part.from_data(data=image_bytes, mime_type=image_mime_type)]

            generation_config = GenerationConfig(
                temperature=0.3, # å€™è£œã‚’åºƒã’ã‚‹ãŸã‚ã«å°‘ã—ä¸Šã’ã‚‹ã“ã¨ã‚‚æ¤œè¨
                top_p=0.9,
                top_k=20,
                max_output_tokens=16384, # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å¢—ã‚„ã™
                response_mime_type="application/json",
                # NEW: Phase 1 ç”¨ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
                response_schema=PHASE_1_GEMINI_SCHEMA
            )

            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )

            if not response.text:
                raise ValueError("No response returned from Gemini (Phase 1).")

            result = json.loads(response.text)
            logger.info(f"Gemini Phase 1 analysis completed. Found {len(result.get('dishes', []))} dishes.")
            return result

        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error (Phase 1): {e}")
            raise RuntimeError(f"Vertex AI/Gemini (Phase 1) API request failed: {e}") from e

    async def refine_analysis_phase2(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        phase1_output_text: str, # Phase 1 ã®ç”Ÿ JSON å‡ºåŠ›
        usda_results_text: str # æ•´å½¢ã•ã‚ŒãŸå…¨ USDA æ¤œç´¢çµæœ
    ) -> Dict:
        """
        Phase 2: USDAå€™è£œã«åŸºã¥ãã€calculation_strategy ã‚’æ±ºå®šã—ã€FDC ID ã‚’é¸æŠ (v2.1ä»•æ§˜)
        """
        try:
            system_prompt = self.prompt_loader.get_phase2_system_prompt()
            user_prompt = self.prompt_loader.get_phase2_user_prompt(
                initial_ai_output=phase1_output_text,
                usda_candidates=usda_results_text
            )
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            contents = [Part.from_text(full_prompt), Part.from_data(data=image_bytes, mime_type=image_mime_type)]

            generation_config = GenerationConfig(
                temperature=0.1, # æ±ºå®šè«–çš„ãªå‡ºåŠ›ã‚’ç›®æŒ‡ã™ãŸã‚ä½ã‚ã«è¨­å®š
                top_p=0.8,
                top_k=10,
                max_output_tokens=16384, # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å¢—ã‚„ã™
                response_mime_type="application/json",
                # NEW: Phase 2 ç”¨ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
                response_schema=PHASE_2_GEMINI_SCHEMA
            )

            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )

            if not response.text:
                raise ValueError("No response returned from Gemini (Phase 2).")

            result = json.loads(response.text)
            logger.info(f"Gemini Phase 2 analysis completed. Processed {len(result.get('dishes', []))} dishes.")
            return result

        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error (Phase 2): {e}")
            raise RuntimeError(f"Vertex AI/Gemini (Phase 2) API request failed: {e}") from e

    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚ä¿æŒ
    async def analyze_image_and_text(
        self, 
        image_bytes: bytes, 
        image_mime_type: str, 
        optional_text: Optional[str] = None
    ) -> Dict:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆæ—¢å­˜ã®Phase 1ã¨ã—ã¦å‹•ä½œï¼‰
        """
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            system_prompt = self.prompt_loader.get_phase1_system_prompt()
            user_prompt = self.prompt_loader.get_phase1_user_prompt(optional_text)
            
            # å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—¢å­˜ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
            generation_config = GenerationConfig(
                temperature=0.2,
                top_p=0.9,
                top_k=20,
                max_output_tokens=8192,
                response_mime_type="application/json",
                response_schema=MEAL_ANALYSIS_GEMINI_SCHEMA
            )
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆéåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼‰
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if not response.text:
                raise ValueError("No response returned from Gemini.")
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)
            
            logger.info(f"Gemini analysis completed successfully. Found {len(result.get('dishes', []))} dishes.")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error: {e}")
            raise RuntimeError(f"Error processing response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error: {e}")
            raise RuntimeError(f"Vertex AI/Gemini API request failed: {e}") from e
    
    async def analyze_image_with_usda_context(
        self,
        image_bytes: bytes,
        image_mime_type: str,
        usda_candidates_text: str,
        initial_ai_output_text: Optional[str] = None
    ) -> Dict:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆæ—¢å­˜ã®Phase 2ã¨ã—ã¦å‹•ä½œï¼‰
        """
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            system_prompt = self.prompt_loader.get_phase2_system_prompt()
            user_prompt = self.prompt_loader.get_phase2_user_prompt(
                initial_ai_output=initial_ai_output_text or "{}",
                usda_candidates=usda_candidates_text
            )
            
            # å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            contents = [
                Part.from_text(full_prompt),
                Part.from_data(
                    data=image_bytes,
                    mime_type=image_mime_type
                )
            ]
            
            # ãƒ•ã‚§ãƒ¼ã‚º2ç”¨ã®Generation Config
            phase2_generation_config = GenerationConfig(
                temperature=0.2,
                top_p=0.9,
                top_k=20,
                max_output_tokens=8192,
                response_mime_type="application/json",
                response_schema=REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA
            )
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=phase2_generation_config,
                safety_settings=self.safety_settings
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            if not response.text:
                raise ValueError("No response returned from Gemini Phase 2.")
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)
            
            logger.info(f"Gemini Phase 2 refinement completed successfully. Processed {len(result.get('dishes', []))} dishes.")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error in Phase 2: {e}")
            raise RuntimeError(f"Error processing Phase 2 response from Gemini: {e}") from e
        except Exception as e:
            logger.error(f"Vertex AI/Gemini API error in Phase 2: {e}")
            raise RuntimeError(f"Vertex AI/Gemini Phase 2 API request failed: {e}") from e


def get_gemini_analyzer(project_id: str, location: str, model_name: str) -> GeminiMealAnalyzer:
    """GeminiMealAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦è¿”ã™"""
    return GeminiMealAnalyzer(project_id=project_id, location=location, model_name=model_name) 
```

============================================================

ğŸ“„ FILE: app/services/usda_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 13467 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:39:14
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
# app/services/usda_service.py
import httpx
import json
import logging
from typing import List, Optional, Dict, Any
from functools import lru_cache

from ..core.config import get_settings
from ..api.v1.schemas.meal import USDANutrient, USDASearchResultItem

logger = logging.getLogger(__name__)


class USDAService:
    """USDA FoodData Central APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        settings = get_settings()
        self.api_key = settings.USDA_API_KEY
        self.base_url = settings.USDA_API_BASE_URL
        self.timeout = settings.USDA_API_TIMEOUT
        self.key_nutrient_numbers = settings.USDA_KEY_NUTRIENT_NUMBERS
        
        if not self.api_key:
            logger.error("USDA_API_KEY is not configured.")
            raise ValueError("USDA API key not configured.")
        
        # httpx.AsyncClientã®è¨­å®š
        self.client = httpx.AsyncClient(
            timeout=self.timeout,
            headers={"X-Api-Key": self.api_key}
        )
    
    async def search_foods_rich(
        self,
        query: str,
        data_types: Optional[List[str]] = None,
        page_size: int = 10, # å€™è£œæ•°ã‚’å¢—ã‚„ã™ (è¨­å®šå¯èƒ½ã«)
        page_number: int = 1,
        sort_by: str = "score",
        sort_order: str = "desc"
    ) -> List[USDASearchResultItem]:
        """
        USDA FoodData Central APIã§é£Ÿå“ã‚’æ¤œç´¢ã—ã€è©³ç´°ãªæƒ…å ±ã‚’è¿”ã™ (v2.1ä»•æ§˜)
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—
            data_types: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["Foundation", "SR Legacy", "Branded"]ï¼‰
            page_size: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®çµæœæ•°
            page_number: å–å¾—ã™ã‚‹ãƒšãƒ¼ã‚¸ç•ªå·
            sort_by: ã‚½ãƒ¼ãƒˆã‚­ãƒ¼
            sort_order: ã‚½ãƒ¼ãƒˆé †ï¼ˆ"asc" ã¾ãŸã¯ "desc"ï¼‰
            
        Returns:
            USDASearchResultItemã®ãƒªã‚¹ãƒˆï¼ˆæ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ï¼‰
        """
        params = {
            "query": query,
            "api_key": self.api_key,
            "pageSize": page_size,
            "pageNumber": page_number,
            "sortBy": sort_by,
            "sortOrder": sort_order
        }
        
        if data_types:
            # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã¨ã—ã¦æ¸¡ã™
            params["dataType"] = ",".join(data_types)
        
        # NEW: requireAllWords ã‚’ True ã«è¨­å®šã—ã¦ç²¾åº¦ã‚’ä¸Šã’ã‚‹ã“ã¨ã‚‚æ¤œè¨ (ãŸã ã—ãƒ’ãƒƒãƒˆæ•°ãŒæ¸›ã‚‹)
        # params["requireAllWords"] = "true"
        
        try:
            logger.info(f"USDA API rich search: query='{query}', page_size={page_size}")
            response = await self.client.get(f"{self.base_url}/foods/search", params=params)
            
            # ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆæƒ…å ±ã®ãƒ­ã‚°
            if "X-RateLimit-Remaining" in response.headers:
                logger.info(f"USDA API Rate Limit Remaining: {response.headers.get('X-RateLimit-Remaining')}")
            
            response.raise_for_status()
            data = response.json()
            
            results = []
            for food_data in data.get("foods", [])[:page_size]:
                # NEW: foodNutrients ã‚’è©³ç´°ã«å–å¾—ãƒ»ãƒ‘ãƒ¼ã‚¹
                # NOTE: æ¤œç´¢çµæœã® foodNutrients ã¯é™å®šçš„ãªã“ã¨ãŒå¤šã„ã€‚
                # è©³ç´°ãªæ „é¤Šç´ ã¯ get_food_details_for_nutrition ã§å–å¾—ã™ã‚‹ã€‚
                # ã“ã“ã§ã¯ä¸»ã« FDC ID, description, dataType, brandOwner, ingredients ã‚’é‡è¦–ã€‚
                nutrients_extracted = self._extract_key_nutrients(food_data.get("foodNutrients", []))
                
                results.append(USDASearchResultItem(
                    fdc_id=food_data.get("fdcId"),
                    description=food_data.get("description"),
                    data_type=food_data.get("dataType"),
                    brand_owner=food_data.get("brandOwner"),
                    # NEW: ingredientsText ã‚’å–å¾—
                    ingredients_text=food_data.get("ingredients"),
                    food_nutrients=nutrients_extracted,
                    score=food_data.get("score")
                ))
            
            logger.info(f"USDA API rich search returned {len(results)} results for query '{query}'")
            return results
            
        except httpx.HTTPStatusError as e:
            logger.error(f"USDA API HTTP error: {e.response.status_code} - {e.response.text}")
            if e.response.status_code == 429:
                raise RuntimeError(f"USDA API rate limit exceeded. Detail: {e.response.text}") from e
            raise RuntimeError(f"USDA API error: {e.response.status_code} - {e.response.text}") from e
        except httpx.RequestError as e:
            logger.error(f"USDA API request failed: {str(e)}")
            raise RuntimeError(f"USDA API request failed: {str(e)}") from e
        except (json.JSONDecodeError, TypeError, KeyError) as e:
            logger.error(f"USDA API response parsing error: {str(e)}")
            raise RuntimeError(f"USDA API response parsing error: {str(e)}") from e
        except Exception as e:
            logger.error(f"Unexpected error in USDAService.search_foods_rich: {str(e)}")
            raise RuntimeError(f"Unexpected error in USDA service: {str(e)}") from e
    
    def _extract_key_nutrients(self, food_nutrients: List[Dict[str, Any]]) -> List[USDANutrient]:
        """
        foodNutrientsãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸»è¦æ „é¤Šç´ ã‚’æŠ½å‡º (æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ä½¿ç”¨)
        """
        # ä¸»è¦æ „é¤Šç´  (configã‹ã‚‰å–å¾—) ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹
        nutrients_extracted = []
        key_numbers = self.key_nutrient_numbers # Settings ã‹ã‚‰å–å¾—

        for nutrient_entry in food_nutrients:
            nutrient_detail = nutrient_entry.get("nutrient", {})
            amount = nutrient_entry.get("amount")

            if not nutrient_detail and "nutrientId" in nutrient_entry: # Branded abridged
                number = nutrient_entry.get("nutrientNumber")
                name = nutrient_entry.get("nutrientName")
                unit_name = nutrient_entry.get("unitName")
                amount = nutrient_entry.get("value")
                nutrient_id = nutrient_entry.get("nutrientId")
            else: # Standard
                number = nutrient_detail.get("number")
                name = nutrient_detail.get("name")
                unit_name = nutrient_detail.get("unitName")
                nutrient_id = nutrient_detail.get("id")

            if number and str(number) in key_numbers:
                if name and amount is not None and unit_name:
                    nutrients_extracted.append(USDANutrient(
                        name=name,
                        amount=float(amount),
                        unit_name=unit_name,
                        nutrient_id=int(nutrient_id) if nutrient_id else None,
                        nutrient_number=str(number) if number else None
                    ))
        return nutrients_extracted

    async def get_food_details(self, fdc_id: int) -> Optional[USDASearchResultItem]:
        """
        ç‰¹å®šã®FDC IDã®é£Ÿå“è©³ç´°æƒ…å ±ã‚’å–å¾— (æ–°ã—ã„Pydanticãƒ¢ãƒ‡ãƒ«ä½¿ç”¨)
        """
        params = {
            "api_key": self.api_key,
            "format": "full"  # ingredients ã‚‚ç¢ºå®Ÿã«å–å¾—ã™ã‚‹ãŸã‚ã« format="full" ã‚’ä½¿ç”¨
        }
        
        try:
            logger.info(f"Getting USDA food details for FDC ID: {fdc_id}")
            response = await self.client.get(f"{self.base_url}/food/{fdc_id}", params=params)
            
            if "X-RateLimit-Remaining" in response.headers:
                logger.debug(f"USDA API Rate Limit Remaining: {response.headers.get('X-RateLimit-Remaining')}")
            
            response.raise_for_status()
            food_data = response.json()
            
            # _extract_key_nutrients ã‚’ä½¿ç”¨ã—ã¦æ „é¤Šç´ ã‚’ãƒ‘ãƒ¼ã‚¹
            nutrients_extracted = self._extract_key_nutrients(food_data.get("foodNutrients", []))
            
            return USDASearchResultItem(
                fdc_id=food_data.get("fdcId"),
                description=food_data.get("description"),
                data_type=food_data.get("dataType"),
                brand_owner=food_data.get("brandOwner"),
                ingredients_text=food_data.get("ingredients"),
                food_nutrients=nutrients_extracted,
                score=None  # è©³ç´°å–å¾—æ™‚ã¯ã‚¹ã‚³ã‚¢ãªã—
            )
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                logger.warning(f"Food with FDC ID {fdc_id} not found")
                return None
            logger.error(f"USDA API error getting food details: {e.response.status_code} - {e.response.text}")
            raise RuntimeError(f"USDA API error: {e.response.status_code}") from e
        except Exception as e:
            logger.error(f"Error getting food details for FDC ID {fdc_id}: {str(e)}")
            raise RuntimeError(f"Error getting food details: {str(e)}") from e

    async def get_food_details_for_nutrition(self, fdc_id: int) -> Optional[Dict[str, float]]:
        """
        æ „é¤Šè¨ˆç®—ç”¨ã®é£Ÿå“è©³ç´°æƒ…å ±ã‚’å–å¾— (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒãƒ»ç¢ºèª)
        """
        params = {
            "api_key": self.api_key,
            "format": "full",
            # ä¸»è¦æ „é¤Šç´ ã®ã¿å–å¾—
            "nutrients": ",".join(self.key_nutrient_numbers)
        }
        
        try:
            logger.debug(f"Getting nutrition data for FDC ID: {fdc_id}")
            response = await self.client.get(f"{self.base_url}/food/{fdc_id}", params=params)
            
            if "X-RateLimit-Remaining" in response.headers:
                logger.debug(f"USDA API Rate Limit Remaining: {response.headers.get('X-RateLimit-Remaining')}")
            
            response.raise_for_status()
            food_data = response.json()
            
            return self._parse_nutrients_for_calculation(food_data)
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                logger.warning(f"Food with FDC ID {fdc_id} not found for nutrition calculation")
                return None
            logger.error(f"USDA API error getting nutrition data: {e.response.status_code} - {e.response.text}")
            return None
        except Exception as e:
            logger.error(f"Error getting nutrition data for FDC ID {fdc_id}: {str(e)}")
            return None

    def _parse_nutrients_for_calculation(self, food_data_raw: dict) -> Dict[str, float]:
        """
        USDA APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ „é¤Šè¨ˆç®—ç”¨ã®æ „é¤Šç´ è¾æ›¸ã‚’ä½œæˆ
        """
        nutrients_dict = {}
        food_nutrients = food_data_raw.get("foodNutrients", [])
        
        # æ „é¤Šç´ ç•ªå·ã¨æ¨™æº–åã®å¯¾å¿œè¡¨
        nutrient_map = {
            "208": "calories_kcal",      # Energy
            "203": "protein_g",          # Protein  
            "205": "carbohydrates_g",    # Carbohydrate
            "204": "fat_g",              # Total lipid (fat)
            "291": "fiber_g",            # Fiber, total dietary
            "269": "sugars_g",           # Sugars, total
            "307": "sodium_mg"           # Sodium
        }
        
        for nutrient_entry in food_nutrients:
            nutrient_detail = nutrient_entry.get("nutrient", {})
            amount = nutrient_entry.get("amount")
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®é•ã„ã«å¯¾å¿œ
            if not nutrient_detail and "nutrientId" in nutrient_entry:
                # Branded Foods abridged format
                number = nutrient_entry.get("nutrientNumber")
                amount = nutrient_entry.get("value")
            else:
                # Standard format
                number = nutrient_detail.get("number")
            
            if number and str(number) in nutrient_map and amount is not None:
                standard_name = nutrient_map[str(number)]
                nutrients_dict[standard_name] = float(amount)
        
        logger.debug(f"Parsed nutrients for calculation: {nutrients_dict}")
        return nutrients_dict

    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚ä¿æŒ
    async def search_foods(
        self,
        query: str,
        data_types: Optional[List[str]] = None,
        page_size: int = 5,
        page_number: int = 1,
        sort_by: str = "score",
        sort_order: str = "desc"
    ) -> List:
        """
        å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®æ—¢å­˜search_foodsãƒ¡ã‚½ãƒƒãƒ‰
        """
        # æ–°ã—ã„search_foods_richã‚’å‘¼ã³å‡ºã—ã¦ã€å¤ã„å½¢å¼ã«å¤‰æ›
        rich_results = await self.search_foods_rich(
            query=query,
            data_types=data_types,
            page_size=page_size,
            page_number=page_number,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«å¤ã„USDASearchResultItemã‚¯ãƒ©ã‚¹å½¢å¼ã«å¤‰æ›
        # ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€å¿…è¦ã«å¿œã˜ã¦ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä¿æŒã™ã‚‹ï¼‰
        return rich_results
    
    async def close_client(self):
        """HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.client:
            await self.client.aclose()


@lru_cache()
def get_usda_service():
    """USDAServiceã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return USDAService() 
```

============================================================

ğŸ“„ FILE: app/services/nutrition_calculation_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 10114 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:21:23
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
æ „é¤Šç´ è¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ (v2.1å¯¾å¿œ)

ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç´”ç²‹ãªè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ï¼š
1. 100gã‚ãŸã‚Šã®æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®æ „é¤Šç´ ã‚’è¨ˆç®—
2. é£Ÿæãƒªã‚¹ãƒˆã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ
3. æ–™ç†ãƒªã‚¹ãƒˆã‹ã‚‰é£Ÿäº‹å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ
"""

import logging
from typing import List, Optional, Dict
from ..api.v1.schemas.meal import CalculatedNutrients, RefinedIngredientResponse, RefinedDishResponse

logger = logging.getLogger(__name__)


class NutritionCalculationService:
    """æ „é¤Šç´ è¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ (v2.1å¯¾å¿œ)"""
    
    @staticmethod
    def calculate_actual_nutrients(
        key_nutrients_per_100g: Dict[str, float], 
        estimated_weight_g: float
    ) -> CalculatedNutrients:
        """
        100gã‚ãŸã‚Šã®ä¸»è¦æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®æ „é¤Šç´ é‡ã‚’è¨ˆç®— (v2.1ä»•æ§˜)
        
        Args:
            key_nutrients_per_100g: 100gã‚ãŸã‚Šã®ä¸»è¦æ „é¤Šç´ ãƒ‡ãƒ¼ã‚¿
            estimated_weight_g: æ¨å®šã‚°ãƒ©ãƒ æ•°
            
        Returns:
            CalculatedNutrients: è¨ˆç®—æ¸ˆã¿æ „é¤Šç´ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        if not key_nutrients_per_100g or estimated_weight_g <= 0:
            logger.warning(f"Invalid input: key_nutrients_per_100g={key_nutrients_per_100g}, estimated_weight_g={estimated_weight_g}")
            return CalculatedNutrients()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆå…¨ã¦0.0ï¼‰ã‚’è¿”ã™
        
        try:
            # è¨ˆç®—å¼: (Nutrient_Value_per_100g / 100) Ã— estimated_weight_g
            multiplier = estimated_weight_g / 100.0
            
            # å„æ „é¤Šç´ ã‚’è¨ˆç®—ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„/Noneã®å ´åˆã¯0.0ã¨ã—ã¦æ‰±ã†ï¼‰
            calories_kcal = round((key_nutrients_per_100g.get('calories_kcal', 0.0) or 0.0) * multiplier, 2)
            protein_g = round((key_nutrients_per_100g.get('protein_g', 0.0) or 0.0) * multiplier, 2)
            carbohydrates_g = round((key_nutrients_per_100g.get('carbohydrates_g', 0.0) or 0.0) * multiplier, 2)
            fat_g = round((key_nutrients_per_100g.get('fat_g', 0.0) or 0.0) * multiplier, 2)
            
            # v2.1ã§è¿½åŠ ã•ã‚ŒãŸæ „é¤Šç´ ã‚‚è¨ˆç®—
            fiber_g = key_nutrients_per_100g.get('fiber_g')
            fiber_g = round(fiber_g * multiplier, 2) if fiber_g is not None else None
            
            sugars_g = key_nutrients_per_100g.get('sugars_g')
            sugars_g = round(sugars_g * multiplier, 2) if sugars_g is not None else None
            
            sodium_mg = key_nutrients_per_100g.get('sodium_mg')
            sodium_mg = round(sodium_mg * multiplier, 2) if sodium_mg is not None else None
            
            result = CalculatedNutrients(
                calories_kcal=calories_kcal,
                protein_g=protein_g,
                carbohydrates_g=carbohydrates_g,
                fat_g=fat_g,
                fiber_g=fiber_g,
                sugars_g=sugars_g,
                sodium_mg=sodium_mg
            )
            
            logger.debug(f"Calculated nutrients for {estimated_weight_g}g: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error calculating actual nutrients: {e}")
            return CalculatedNutrients()  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
    
    @staticmethod
    def aggregate_nutrients_for_dish_from_ingredients(
        ingredients: List[RefinedIngredientResponse]
    ) -> CalculatedNutrients:
        """
        ææ–™ãƒªã‚¹ãƒˆã‹ã‚‰æ–™ç†å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ (v2.1ä»•æ§˜)
        
        Args:
            ingredients: RefinedIngredientResponseã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¨ˆç®—æ¸ˆã¿ã®actual_nutrientsã‚’æŒã¤ï¼‰
            
        Returns:
            CalculatedNutrients: æ–™ç†ã®é›†è¨ˆæ „é¤Šç´ 
        """
        if not ingredients:
            logger.warning("No ingredients provided for aggregation")
            return CalculatedNutrients()
        
        try:
            total_calories = 0.0
            total_protein = 0.0
            total_carbohydrates = 0.0
            total_fat = 0.0
            total_fiber = 0.0
            total_sugars = 0.0
            total_sodium = 0.0
            
            # Optionalæ „é¤Šç´ ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            fiber_count = 0
            sugars_count = 0
            sodium_count = 0
            calculated_count = 0
            
            for ingredient in ingredients:
                if ingredient.actual_nutrients:
                    total_calories += ingredient.actual_nutrients.calories_kcal
                    total_protein += ingredient.actual_nutrients.protein_g
                    total_carbohydrates += ingredient.actual_nutrients.carbohydrates_g
                    total_fat += ingredient.actual_nutrients.fat_g
                    
                    # Optionalæ „é¤Šç´ ã®å‡¦ç†
                    if ingredient.actual_nutrients.fiber_g is not None:
                        total_fiber += ingredient.actual_nutrients.fiber_g
                        fiber_count += 1
                    
                    if ingredient.actual_nutrients.sugars_g is not None:
                        total_sugars += ingredient.actual_nutrients.sugars_g
                        sugars_count += 1
                    
                    if ingredient.actual_nutrients.sodium_mg is not None:
                        total_sodium += ingredient.actual_nutrients.sodium_mg
                        sodium_count += 1
                    
                    calculated_count += 1
                else:
                    logger.warning(f"Ingredient '{ingredient.ingredient_name}' has no actual_nutrients")
            
            # å°æ•°ç‚¹ä»¥ä¸‹2æ¡ã«ä¸¸ã‚ã‚‹
            result = CalculatedNutrients(
                calories_kcal=round(total_calories, 2),
                protein_g=round(total_protein, 2),
                carbohydrates_g=round(total_carbohydrates, 2),
                fat_g=round(total_fat, 2),
                fiber_g=round(total_fiber, 2) if fiber_count > 0 else None,
                sugars_g=round(total_sugars, 2) if sugars_count > 0 else None,
                sodium_mg=round(total_sodium, 2) if sodium_count > 0 else None
            )
            
            logger.info(f"Aggregated nutrients from {calculated_count}/{len(ingredients)} ingredients: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error aggregating nutrients for dish: {e}")
            return CalculatedNutrients()
    
    @staticmethod
    def aggregate_nutrients_for_meal(
        dishes: List[RefinedDishResponse]
    ) -> CalculatedNutrients:
        """
        æ–™ç†ãƒªã‚¹ãƒˆã‹ã‚‰é£Ÿäº‹å…¨ä½“ã®æ „é¤Šç´ ã‚’é›†è¨ˆ (v2.1ä»•æ§˜)
        
        Args:
            dishes: RefinedDishResponseã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¨ˆç®—æ¸ˆã¿ã®dish_total_actual_nutrientsã‚’æŒã¤ï¼‰
            
        Returns:
            CalculatedNutrients: é£Ÿäº‹å…¨ä½“ã®ç·æ „é¤Šç´ 
        """
        if not dishes:
            logger.warning("No dishes provided for meal aggregation")
            return CalculatedNutrients()
        
        try:
            total_calories = 0.0
            total_protein = 0.0
            total_carbohydrates = 0.0
            total_fat = 0.0
            total_fiber = 0.0
            total_sugars = 0.0
            total_sodium = 0.0
            
            # Optionalæ „é¤Šç´ ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            fiber_count = 0
            sugars_count = 0
            sodium_count = 0
            calculated_count = 0
            
            for dish in dishes:
                if dish.dish_total_actual_nutrients:
                    total_calories += dish.dish_total_actual_nutrients.calories_kcal
                    total_protein += dish.dish_total_actual_nutrients.protein_g
                    total_carbohydrates += dish.dish_total_actual_nutrients.carbohydrates_g
                    total_fat += dish.dish_total_actual_nutrients.fat_g
                    
                    # Optionalæ „é¤Šç´ ã®å‡¦ç†
                    if dish.dish_total_actual_nutrients.fiber_g is not None:
                        total_fiber += dish.dish_total_actual_nutrients.fiber_g
                        fiber_count += 1
                    
                    if dish.dish_total_actual_nutrients.sugars_g is not None:
                        total_sugars += dish.dish_total_actual_nutrients.sugars_g
                        sugars_count += 1
                    
                    if dish.dish_total_actual_nutrients.sodium_mg is not None:
                        total_sodium += dish.dish_total_actual_nutrients.sodium_mg
                        sodium_count += 1
                    
                    calculated_count += 1
                else:
                    logger.warning(f"Dish '{dish.dish_name}' has no dish_total_actual_nutrients")
            
            # å°æ•°ç‚¹ä»¥ä¸‹2æ¡ã«ä¸¸ã‚ã‚‹
            result = CalculatedNutrients(
                calories_kcal=round(total_calories, 2),
                protein_g=round(total_protein, 2),
                carbohydrates_g=round(total_carbohydrates, 2),
                fat_g=round(total_fat, 2),
                fiber_g=round(total_fiber, 2) if fiber_count > 0 else None,
                sugars_g=round(total_sugars, 2) if sugars_count > 0 else None,
                sodium_mg=round(total_sodium, 2) if sodium_count > 0 else None
            )
            
            logger.info(f"Aggregated meal nutrients from {calculated_count}/{len(dishes)} dishes: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Error aggregating nutrients for meal: {e}")
            return CalculatedNutrients()


# ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
def get_nutrition_calculation_service() -> NutritionCalculationService:
    """
    æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
    
    Returns:
        NutritionCalculationService: æ „é¤Šè¨ˆç®—ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return NutritionCalculationService() 
```

============================================================

ğŸ“„ FILE: app/services/logging_service.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 13198 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:54:52
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import json
import logging
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)

class LogLevel(str, Enum):
    """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«å®šç¾©"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class ProcessingPhase(str, Enum):
    """å‡¦ç†ãƒ•ã‚§ãƒ¼ã‚ºå®šç¾©"""
    REQUEST_RECEIVED = "REQUEST_RECEIVED"
    PHASE1_START = "PHASE1_START"
    PHASE1_COMPLETE = "PHASE1_COMPLETE"
    USDA_SEARCH_START = "USDA_SEARCH_START"
    USDA_SEARCH_COMPLETE = "USDA_SEARCH_COMPLETE"
    PHASE2_START = "PHASE2_START"
    PHASE2_COMPLETE = "PHASE2_COMPLETE"
    NUTRITION_CALC_START = "NUTRITION_CALC_START"
    NUTRITION_CALC_COMPLETE = "NUTRITION_CALC_COMPLETE"
    RESPONSE_SENT = "RESPONSE_SENT"
    ERROR_OCCURRED = "ERROR_OCCURRED"

@dataclass
class LogEntry:
    """ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®æ¨™æº–æ§‹é€ """
    timestamp: str
    request_id: str
    log_level: LogLevel
    phase: ProcessingPhase
    message: str
    data: Optional[Dict[str, Any]] = None
    execution_time_ms: Optional[float] = None
    error_details: Optional[str] = None

@dataclass
class MealAnalysisSession:
    """é£Ÿäº‹åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®ãƒ­ã‚°"""
    session_id: str
    start_time: str
    end_time: Optional[str] = None
    endpoint: str = ""
    image_filename: Optional[str] = None
    image_size_bytes: Optional[int] = None
    
    # ãƒ•ã‚§ãƒ¼ã‚º1çµæœ
    phase1_duration_ms: Optional[float] = None
    phase1_dishes_count: Optional[int] = None
    phase1_usda_queries_count: Optional[int] = None
    phase1_output: Optional[Dict[str, Any]] = None
    
    # USDAæ¤œç´¢çµæœ
    usda_search_duration_ms: Optional[float] = None
    usda_queries_executed: Optional[int] = None
    usda_results_found: Optional[int] = None
    usda_search_details: Optional[List[Dict[str, Any]]] = None
    
    # ãƒ•ã‚§ãƒ¼ã‚º2çµæœ
    phase2_duration_ms: Optional[float] = None
    phase2_strategy_decisions: Optional[Dict[str, Any]] = None
    phase2_fdc_selections: Optional[Dict[str, Any]] = None
    phase2_output: Optional[Dict[str, Any]] = None
    
    # æ „é¤Šè¨ˆç®—çµæœ
    nutrition_calc_duration_ms: Optional[float] = None
    total_calories: Optional[float] = None
    final_nutrition: Optional[Dict[str, Any]] = None
    
    # ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Š
    warnings: Optional[List[str]] = None
    errors: Optional[List[str]] = None
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    total_duration_ms: Optional[float] = None
    gemini_api_calls: Optional[int] = None
    usda_api_calls: Optional[int] = None

class MealAnalysisLogger:
    """é£Ÿäº‹åˆ†æå°‚ç”¨ãƒ­ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        self.active_sessions: Dict[str, MealAnalysisSession] = {}
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
        self.setup_file_logging()
    
    def setup_file_logging(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚°ã®è¨­å®š"""
        # è©³ç´°ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        detailed_log_file = self.log_dir / "meal_analysis_detailed.jsonl"
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        session_log_file = self.log_dir / "meal_analysis_sessions.jsonl"
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        error_log_file = self.log_dir / "meal_analysis_errors.log"
        
        self.detailed_log_file = detailed_log_file
        self.session_log_file = session_log_file
        self.error_log_file = error_log_file
    
    def start_session(
        self, 
        endpoint: str,
        image_filename: Optional[str] = None,
        image_size_bytes: Optional[int] = None
    ) -> str:
        """æ–°ã—ã„åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        session_id = str(uuid.uuid4())
        
        session = MealAnalysisSession(
            session_id=session_id,
            start_time=datetime.now(timezone.utc).isoformat(),
            endpoint=endpoint,
            image_filename=image_filename,
            image_size_bytes=image_size_bytes
        )
        
        self.active_sessions[session_id] = session
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.REQUEST_RECEIVED,
            message=f"Started meal analysis session for endpoint: {endpoint}",
            data={
                "endpoint": endpoint,
                "image_filename": image_filename,
                "image_size_bytes": image_size_bytes
            }
        )
        
        return session_id
    
    def log_entry(
        self,
        session_id: str,
        level: LogLevel,
        phase: ProcessingPhase,
        message: str,
        data: Optional[Dict[str, Any]] = None,
        execution_time_ms: Optional[float] = None,
        error_details: Optional[str] = None
    ):
        """å€‹åˆ¥ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’è¨˜éŒ²"""
        entry = LogEntry(
            timestamp=datetime.now(timezone.utc).isoformat(),
            request_id=session_id,
            log_level=level,
            phase=phase,
            message=message,
            data=data,
            execution_time_ms=execution_time_ms,
            error_details=error_details
        )
        
        # JSONLãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
        try:
            with open(self.detailed_log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(entry), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write detailed log: {e}")
        
        # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã®å ´åˆã¯å°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚è¨˜éŒ²
        if level in [LogLevel.ERROR, LogLevel.CRITICAL]:
            try:
                with open(self.error_log_file, "a", encoding="utf-8") as f:
                    f.write(f"[{entry.timestamp}] {session_id} - {message}\n")
                    if error_details:
                        f.write(f"  Error Details: {error_details}\n")
                    if data:
                        f.write(f"  Data: {json.dumps(data, ensure_ascii=False)}\n")
                    f.write("\n")
            except Exception as e:
                logger.error(f"Failed to write error log: {e}")
    
    def update_phase1_results(
        self,
        session_id: str,
        duration_ms: float,
        dishes_count: int,
        usda_queries_count: int,
        phase1_output: Dict[str, Any]
    ):
        """ãƒ•ã‚§ãƒ¼ã‚º1çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.phase1_duration_ms = duration_ms
            session.phase1_dishes_count = dishes_count
            session.phase1_usda_queries_count = usda_queries_count
            session.phase1_output = phase1_output
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE1_COMPLETE,
            message=f"Phase 1 completed: {dishes_count} dishes, {usda_queries_count} USDA queries",
            data={
                "duration_ms": duration_ms,
                "dishes_count": dishes_count,
                "usda_queries_count": usda_queries_count,
                "phase1_output": phase1_output
            },
            execution_time_ms=duration_ms
        )
    
    def update_usda_search_results(
        self,
        session_id: str,
        duration_ms: float,
        queries_executed: int,
        results_found: int,
        search_details: List[Dict[str, Any]]
    ):
        """USDAæ¤œç´¢çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.usda_search_duration_ms = duration_ms
            session.usda_queries_executed = queries_executed
            session.usda_results_found = results_found
            session.usda_search_details = search_details
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.USDA_SEARCH_COMPLETE,
            message=f"USDA search completed: {queries_executed} queries, {results_found} results",
            data={
                "duration_ms": duration_ms,
                "queries_executed": queries_executed,
                "results_found": results_found,
                "search_summary": search_details
            },
            execution_time_ms=duration_ms
        )
    
    def update_phase2_results(
        self,
        session_id: str,
        duration_ms: float,
        strategy_decisions: Dict[str, Any],
        fdc_selections: Dict[str, Any],
        phase2_output: Dict[str, Any]
    ):
        """ãƒ•ã‚§ãƒ¼ã‚º2çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.phase2_duration_ms = duration_ms
            session.phase2_strategy_decisions = strategy_decisions
            session.phase2_fdc_selections = fdc_selections
            session.phase2_output = phase2_output
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.PHASE2_COMPLETE,
            message="Phase 2 completed: Strategy decisions and FDC ID selections made",
            data={
                "duration_ms": duration_ms,
                "strategy_decisions": strategy_decisions,
                "fdc_selections": fdc_selections,
                "phase2_output": phase2_output
            },
            execution_time_ms=duration_ms
        )
    
    def update_nutrition_results(
        self,
        session_id: str,
        duration_ms: float,
        total_calories: float,
        final_nutrition: Dict[str, Any]
    ):
        """æ „é¤Šè¨ˆç®—çµæœã‚’è¨˜éŒ²"""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.nutrition_calc_duration_ms = duration_ms
            session.total_calories = total_calories
            session.final_nutrition = final_nutrition
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.NUTRITION_CALC_COMPLETE,
            message=f"Nutrition calculation completed: {total_calories:.1f} kcal total",
            data={
                "duration_ms": duration_ms,
                "total_calories": total_calories,
                "final_nutrition": final_nutrition
            },
            execution_time_ms=duration_ms
        )
    
    def end_session(
        self,
        session_id: str,
        warnings: Optional[List[str]] = None,
        errors: Optional[List[str]] = None
    ):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã€å®Œå…¨ãªãƒ­ã‚°ã‚’ä¿å­˜"""
        if session_id not in self.active_sessions:
            return
        
        session = self.active_sessions[session_id]
        session.end_time = datetime.now(timezone.utc).isoformat()
        session.warnings = warnings
        session.errors = errors
        
        # ç·å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
        if session.start_time and session.end_time:
            start = datetime.fromisoformat(session.start_time.replace('Z', '+00:00'))
            end = datetime.fromisoformat(session.end_time.replace('Z', '+00:00'))
            session.total_duration_ms = (end - start).total_seconds() * 1000
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        try:
            with open(self.session_log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(session), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to write session log: {e}")
        
        self.log_entry(
            session_id=session_id,
            level=LogLevel.INFO,
            phase=ProcessingPhase.RESPONSE_SENT,
            message=f"Session completed in {session.total_duration_ms:.1f}ms",
            data={
                "total_duration_ms": session.total_duration_ms,
                "warnings_count": len(warnings) if warnings else 0,
                "errors_count": len(errors) if errors else 0
            },
            execution_time_ms=session.total_duration_ms
        )
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å‰Šé™¤
        del self.active_sessions[session_id]
    
    def log_error(
        self,
        session_id: str,
        phase: ProcessingPhase,
        error_message: str,
        error_details: str,
        data: Optional[Dict[str, Any]] = None
    ):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        self.log_entry(
            session_id=session_id,
            level=LogLevel.ERROR,
            phase=phase,
            message=error_message,
            data=data,
            error_details=error_details
        )

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
meal_analysis_logger = MealAnalysisLogger()

def get_meal_analysis_logger() -> MealAnalysisLogger:
    """ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return meal_analysis_logger 
```

============================================================

ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤ (v2.1ã‚¹ã‚­ãƒ¼ãƒ)
============================================================

ğŸ“„ FILE: app/api/v1/schemas/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/api/v1/schemas/meal.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 17460 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:37:41
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from typing import List, Optional, Dict, Literal
from pydantic import BaseModel, Field, field_validator

# --- å…±é€šãƒ¢ãƒ‡ãƒ« ---

class CalculatedNutrients(BaseModel):
    """è¨ˆç®—æ¸ˆã¿æ „é¤Šç´ ãƒ¢ãƒ‡ãƒ«"""
    calories_kcal: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ã‚«ãƒ­ãƒªãƒ¼ (kcal)")
    protein_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ã‚¿ãƒ³ãƒ‘ã‚¯è³ª (g)")
    carbohydrates_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·ç‚­æ°´åŒ–ç‰© (g)")
    fat_g: float = Field(0.0, description="è¨ˆç®—ã•ã‚ŒãŸç·è„‚è³ª (g)")
    fiber_g: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·é£Ÿç‰©ç¹Šç¶­ (g)")
    sugars_g: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·ç³–è³ª (g)")
    sodium_mg: Optional[float] = Field(None, description="è¨ˆç®—ã•ã‚ŒãŸç·ãƒŠãƒˆãƒªã‚¦ãƒ  (mg)")

class USDANutrient(BaseModel):
    """USDAæ „é¤Šç´ æƒ…å ±ãƒ¢ãƒ‡ãƒ« (USDA ServiceãŒè¿”ã™)"""
    name: str = Field(..., description="æ „é¤Šç´ å")
    amount: float = Field(..., description="100gã¾ãŸã¯100mlã‚ãŸã‚Šã®é‡")
    unit_name: str = Field(..., description="å˜ä½å (ä¾‹: g, mg, kcal)")
    nutrient_id: Optional[int] = Field(None, description="USDAæ „é¤Šç´ ID")
    nutrient_number: Optional[str] = Field(None, description="USDAæ „é¤Šç´ ç•ªå·")

class USDASearchResultItem(BaseModel):
    """USDAæ¤œç´¢çµæœã‚¢ã‚¤ãƒ†ãƒ ãƒ¢ãƒ‡ãƒ« (USDA ServiceãŒè¿”ã™)"""
    fdc_id: int = Field(..., description="USDA FoodData Central ID")
    description: str = Field(..., description="é£Ÿå“ã®å…¬å¼åç§°")
    data_type: Optional[str] = Field(None, description="USDAãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— (ä¾‹: SR Legacy, Branded)")
    brand_owner: Optional[str] = Field(None, description="ãƒ–ãƒ©ãƒ³ãƒ‰æ‰€æœ‰è€… (Branded Foodsã®å ´åˆ)")
    ingredients_text: Optional[str] = Field(None, description="åŸææ–™ãƒªã‚¹ãƒˆæ–‡å­—åˆ— (Branded/FNDDSã®å ´åˆ, **Assumption: String**)")
    food_nutrients: List[USDANutrient] = Field(default_factory=list, description="ä¸»è¦ãªæ „é¤Šç´ æƒ…å ±ã®ãƒªã‚¹ãƒˆ")
    score: Optional[float] = Field(None, description="æ¤œç´¢çµæœã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢")

# --- Phase 1 Gemini å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« ---

class USDACandidateQuery(BaseModel):
    """Phase 1ã§GeminiãŒå‡ºåŠ›ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œ"""
    query_term: str = Field(..., description="USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)")
    granularity_level: Literal["dish", "ingredient", "branded_product"] = Field(..., description="ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«")
    original_term: str = Field("", description="ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå")
    reason_for_query: str = Field("", description="ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±")

class Phase1Ingredient(BaseModel):
    """Phase 1 ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§° (è‹±èª)")
    weight_g: float = Field(..., description="æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰", ge=0.1)

class Phase1Dish(BaseModel):
    """Phase 1 æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str = Field(..., description="ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§° (è‹±èª)")
    type: str = Field(..., description="æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: Main course, Side dishï¼‰")
    quantity_on_plate: str = Field(..., description="çš¿ã®ä¸Šã®é‡ã‚„å€‹æ•°")
    ingredients: List[Phase1Ingredient] = Field(..., description="å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ")
    # NEW: Phase 1ã§ã‚¯ã‚¨ãƒªå€™è£œã‚’å‡ºåŠ›
    usda_query_candidates: List[USDACandidateQuery] = Field(..., description="ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆ")

class Phase1AnalysisResponse(BaseModel):
    """Phase 1 é£Ÿäº‹åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[Phase1Dish] = Field(..., description="ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ")

# --- Phase 2 Gemini å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« (Geminiå‘ã‘ã‚¹ã‚­ãƒ¼ãƒ) ---

class RefinedIngredientGeminiOutput(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚")
    fdc_id: Optional[int] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã€‚ingredient_levelã®å ´åˆã€ã¾ãŸã¯dish_levelã®Fallbackæ™‚ã«è¨­å®šã€‚")
    usda_source_description: Optional[str] = Field(None, description="é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°ã€‚")
    reason_for_choice: Optional[str] = Field(None, description="ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€ã¾ãŸã¯é¸æŠã—ãªã‹ã£ãŸç†ç”±ã€‚")

class RefinedDishGeminiOutput(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str = Field(..., description="æ–™ç†ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚")
    calculation_strategy: Literal["dish_level", "ingredient_level"] = Field(..., description="ã“ã®æ–™ç†ã®æ „é¤Šè¨ˆç®—æ–¹é‡ã€‚")
    reason_for_strategy: str = Field(..., description="ã“ã®è¨ˆç®—æˆ¦ç•¥ã‚’é¸æŠã—ãŸç†ç”±ã€‚")
    fdc_id: Optional[int] = Field(None, description="dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC IDã€‚")
    usda_source_description: Optional[str] = Field(None, description="dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°ã€‚")
    reason_for_choice: Optional[str] = Field(None, description="dish_levelã®å ´åˆã€ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€‚")
    ingredients: List[RefinedIngredientGeminiOutput] = Field(..., description="ææ–™ãƒªã‚¹ãƒˆã€‚å„ææ–™ã«ã¤ã„ã¦FDC IDã¨é¸æŠç†ç”±ã‚’è¨˜è¿°ã€‚")

class Phase2GeminiResponse(BaseModel):
    """Phase 2 Geminiå‡ºåŠ›ç”¨ - å…¨ä½“ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[RefinedDishGeminiOutput] = Field(..., description="ç²¾ç·»åŒ–ã•ã‚ŒãŸæ–™ç†ãƒªã‚¹ãƒˆã€‚")

# --- Phase 2 API å‡ºåŠ›ãƒ¢ãƒ‡ãƒ« (æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹) ---

class RefinedIngredientResponse(BaseModel):
    """Phase 2 APIå‡ºåŠ›ç”¨ - ææ–™ãƒ¢ãƒ‡ãƒ«"""
    ingredient_name: str
    weight_g: float
    fdc_id: Optional[int]
    usda_source_description: Optional[str]
    reason_for_choice: Optional[str] # From Gemini
    key_nutrients_per_100g: Optional[Dict[str, float]] # From USDA Service
    actual_nutrients: Optional[CalculatedNutrients] # From Nutrition Calculation

class RefinedDishResponse(BaseModel):
    """Phase 2 APIå‡ºåŠ›ç”¨ - æ–™ç†ãƒ¢ãƒ‡ãƒ«"""
    dish_name: str
    type: str # From Phase 1
    quantity_on_plate: str # From Phase 1
    calculation_strategy: Literal["dish_level", "ingredient_level"] # From Gemini
    reason_for_strategy: Optional[str] # From Gemini
    fdc_id: Optional[int] # From Gemini (dish_level)
    usda_source_description: Optional[str] # From Gemini (dish_level)
    reason_for_choice: Optional[str] # From Gemini (dish_level)
    key_nutrients_per_100g: Optional[Dict[str, float]] # From USDA Service (dish_level)
    ingredients: List[RefinedIngredientResponse]
    dish_total_actual_nutrients: Optional[CalculatedNutrients] # From Nutrition Calculation

class MealAnalysisRefinementResponse(BaseModel):
    """Phase 2 é£Ÿäº‹åˆ†æç²¾ç·»åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    dishes: List[RefinedDishResponse]
    total_meal_nutrients: Optional[CalculatedNutrients]
    warnings: Optional[List[str]] = Field(None, description="å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸè­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚")
    errors: Optional[List[str]] = Field(None, description="å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚")

# --- å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚‚ä¿æŒ ---

class Ingredient(BaseModel):
    """ææ–™æƒ…å ±ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    ingredient_name: str = Field(..., description="ææ–™ã®åç§°")
    weight_g: float = Field(..., description="æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰", ge=0.1)

class Dish(BaseModel):
    """æ–™ç†æƒ…å ±ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    dish_name: str = Field(..., description="ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°")
    type: str = Field(..., description="æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—ï¼‰")
    quantity_on_plate: str = Field(..., description="çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°")
    ingredients: List[Ingredient] = Field(..., description="ãã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ")

class MealAnalysisResponse(BaseModel):
    """é£Ÿäº‹åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜APIç”¨)"""
    dishes: List[Dish] = Field(..., description="ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ")

class ErrorResponse(BaseModel):
    """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    error: dict = Field(..., description="ã‚¨ãƒ©ãƒ¼æƒ…å ±")
    
    class Config:
        json_schema_extra = {
            "example": {
                "error": {
                    "code": "INVALID_INPUT", 
                    "message": "æä¾›ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                }
            }
        }

# --- å¾Œæ–¹äº’æ›æ€§ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ ---
InitialAnalysisIngredient = Ingredient  
InitialAnalysisDish = Dish  
InitialAnalysisData = MealAnalysisResponse  

# --- RefinedIngredient/RefinedDish ã¯ RefinedIngredientResponse/RefinedDishResponse ã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ ---
RefinedIngredient = RefinedIngredientResponse
RefinedDish = RefinedDishResponse

# --- Geminiå‘ã‘JSONã‚¹ã‚­ãƒ¼ãƒå®šç¾© (æ‰‹å‹•ã§ä¿®æ­£) ---

# Phase 1 Schema - æ‰‹å‹•ã§å®šç¾©ã—ã¦Gemini APIäº’æ›ã«ã™ã‚‹
PHASE_1_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆ",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§° (è‹±èª)"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: Main course, Side dishï¼‰"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã®é‡ã‚„å€‹æ•°"},
                    "ingredients": {
                        "type": "array",
                        "description": "å«ã¾ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆ",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§° (è‹±èª)"},
                                "weight_g": {"type": "number", "description": "æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰", "minimum": 0.1}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    },
                    "usda_query_candidates": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆ",
                        "items": {
                            "type": "object",
                            "properties": {
                                "query_term": {"type": "string", "description": "USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)"},
                                "granularity_level": {
                                    "type": "string",
                                    "enum": ["dish", "ingredient", "branded_product"],
                                    "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«"
                                },
                                "original_term": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå"},
                                "reason_for_query": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±"}
                            },
                            "required": ["query_term", "granularity_level", "original_term", "reason_for_query"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients", "usda_query_candidates"]
            }
        }
    },
    "required": ["dishes"]
}

# Phase 2 Schema - æ‰‹å‹•ã§å®šç¾©ã—ã¦Gemini APIäº’æ›ã«ã™ã‚‹
PHASE_2_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç²¾ç·»åŒ–ã•ã‚ŒãŸæ–™ç†ãƒªã‚¹ãƒˆ",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "æ–™ç†ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£ã€‚"},
                    "calculation_strategy": {
                        "type": "string",
                        "enum": ["dish_level", "ingredient_level"],
                        "description": "ã“ã®æ–™ç†ã®æ „é¤Šè¨ˆç®—æ–¹é‡"
                    },
                    "reason_for_strategy": {"type": "string", "description": "ã“ã®è¨ˆç®—æˆ¦ç•¥ã‚’é¸æŠã—ãŸç†ç”±"},
                    "fdc_id": {"type": "integer", "description": "dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC ID"},
                    "usda_source_description": {"type": "string", "description": "dish_levelã®å ´åˆã«é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°"},
                    "reason_for_choice": {"type": "string", "description": "dish_levelã®å ´åˆã€ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±"},
                    "ingredients": {
                        "type": "array",
                        "description": "ææ–™ãƒªã‚¹ãƒˆã€‚å„ææ–™ã«ã¤ã„ã¦FDC IDã¨é¸æŠç†ç”±ã‚’è¨˜è¿°",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§° (è‹±èª)ã€‚Phase 1ã‹ã‚‰å¼•ãç¶™ãã€å¿…è¦ãªã‚‰ä¿®æ­£"},
                                "fdc_id": {"type": "integer", "description": "é¸æŠã•ã‚ŒãŸFDC IDã€‚ingredient_levelã®å ´åˆã€ã¾ãŸã¯dish_levelã®Fallbackæ™‚ã«è¨­å®š"},
                                "usda_source_description": {"type": "string", "description": "é¸æŠã•ã‚ŒãŸFDC IDã®å…¬å¼åç§°"},
                                "reason_for_choice": {"type": "string", "description": "ã“ã®FDC IDã‚’é¸æŠã—ãŸç†ç”±ã€ã¾ãŸã¯é¸æŠã—ãªã‹ã£ãŸç†ç”±"}
                            },
                            "required": ["ingredient_name"]
                        }
                    }
                },
                "required": ["dish_name", "calculation_strategy", "reason_for_strategy", "ingredients"]
            }
        }
    },
    "required": ["dishes"]
}

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ã‚¹ã‚­ãƒ¼ãƒã‚‚ä¿æŒ
MEAL_ANALYSIS_GEMINI_SCHEMA = {
    "type": "object",
    "properties": {
        "dishes": {
            "type": "array",
            "description": "ç”»åƒã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®ãƒªã‚¹ãƒˆã€‚",
            "items": {
                "type": "object",
                "properties": {
                    "dish_name": {"type": "string", "description": "ç‰¹å®šã•ã‚ŒãŸæ–™ç†ã®åç§°ã€‚"},
                    "type": {"type": "string", "description": "æ–™ç†ã®ç¨®é¡ï¼ˆä¾‹: ä¸»èœ, å‰¯èœ, ã‚¹ãƒ¼ãƒ—, ãƒ‡ã‚¶ãƒ¼ãƒˆï¼‰ã€‚"},
                    "quantity_on_plate": {"type": "string", "description": "çš¿ã®ä¸Šã«è¼‰ã£ã¦ã„ã‚‹æ–™ç†ã®ãŠãŠã‚ˆãã®é‡ã‚„å€‹æ•°ï¼ˆä¾‹: '1æ¯', '2åˆ‡ã‚Œ', 'ç´„200g'ï¼‰ã€‚"},
                    "ingredients": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†ã«å«ã¾ã‚Œã‚‹ã¨æ¨å®šã•ã‚Œã‚‹ææ–™ã®ãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "ingredient_name": {"type": "string", "description": "ææ–™ã®åç§°ã€‚"},
                                "weight_g": {"type": "number", "description": "ãã®ææ–™ã®æ¨å®šé‡é‡ï¼ˆã‚°ãƒ©ãƒ å˜ä½ï¼‰ã€‚"}
                            },
                            "required": ["ingredient_name", "weight_g"]
                        }
                    },
                    "usda_query_candidates": {
                        "type": "array",
                        "description": "ã“ã®æ–™ç†/é£Ÿæã«é–¢é€£ã™ã‚‹USDAã‚¯ã‚¨ãƒªå€™è£œãƒªã‚¹ãƒˆã€‚",
                        "items": {
                            "type": "object",
                            "properties": {
                                "query_term": {"type": "string", "description": "USDAæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹å…·ä½“çš„ãªã‚¯ã‚¨ãƒªæ–‡å­—åˆ— (è‹±èª)"},
                                "granularity_level": {
                                    "type": "string", 
                                    "enum": ["dish", "ingredient", "branded_product"],
                                    "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒå¯¾è±¡ã¨ã™ã‚‹ç²’åº¦ãƒ¬ãƒ™ãƒ«"
                                },
                                "original_term": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªãŒç”±æ¥ã™ã‚‹å…ƒã®æ–™ç†åã¾ãŸã¯é£Ÿæå"},
                                "reason_for_query": {"type": "string", "description": "ã“ã®ã‚¯ã‚¨ãƒªå€™è£œã‚’ç”Ÿæˆã—ãŸç°¡å˜ãªç†ç”±"}
                            },
                            "required": ["query_term", "granularity_level"]
                        }
                    }
                },
                "required": ["dish_name", "type", "quantity_on_plate", "ingredients", "usda_query_candidates"]
            }
        }
    },
    "required": ["dishes"]
}

REFINED_MEAL_ANALYSIS_GEMINI_SCHEMA = PHASE_2_GEMINI_SCHEMA 
```

============================================================

ğŸ“ è¨­å®šç®¡ç†
============================================================

ğŸ“„ FILE: app/core/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 0 bytes
æœ€çµ‚æ›´æ–°: 2025-05-27 15:03:55
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```

```

============================================================

ğŸ“„ FILE: app/core/config.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 2180 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
from typing import Optional, List
from pydantic_settings import BaseSettings
from functools import lru_cache


class Settings(BaseSettings):
    """
    APIè¨­å®šã‚¯ãƒ©ã‚¹
    ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå€¤ã‚’èª­ã¿è¾¼ã‚€
    """
    # Vertex AIè¨­å®š
    GEMINI_PROJECT_ID: str  # GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDï¼ˆå¿…é ˆï¼‰
    GEMINI_LOCATION: str = "us-central1"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    GEMINI_MODEL_NAME: str = "gemini-1.5-flash"
    
    # USDA APIè¨­å®š
    USDA_API_KEY: str  # USDA FoodData Central APIã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
    USDA_API_BASE_URL: str = "https://api.nal.usda.gov/fdc/v1"
    USDA_API_TIMEOUT: float = 10.0  # APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°
    USDA_SEARCH_CANDIDATES_LIMIT: int = 5  # 1å›ã®æ¤œç´¢ã§å–å¾—ã™ã‚‹æœ€å¤§å€™è£œæ•°
    # ä¸»è¦æ „é¤Šç´ ç•ªå·ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã¨ã—ã¦ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼‰
    USDA_KEY_NUTRIENT_NUMBERS_STR: str = "208,203,204,205,291,269,307"
    # 208: Energy (kcal), 203: Protein, 204: Total lipid (fat), 
    # 205: Carbohydrate, 291: Fiber, 269: Total sugars, 307: Sodium
    
    @property
    def USDA_KEY_NUTRIENT_NUMBERS(self) -> List[str]:
        """ä¸»è¦æ „é¤Šç´ ç•ªå·ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
        return self.USDA_KEY_NUTRIENT_NUMBERS_STR.split(",")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
    CACHE_TYPE: str = "simple"  # "simple", "redis", "memcached"
    CACHE_REDIS_URL: Optional[str] = None  # Redisã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®URL
    USDA_CACHE_TTL_SECONDS: int = 3600  # USDAãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé–“ï¼ˆ1æ™‚é–“ï¼‰
    
    # APIè¨­å®š
    API_LOG_LEVEL: str = "INFO"
    FASTAPI_ENV: str = "development"
    
    # ã‚µãƒ¼ãƒãƒ¼è¨­å®š
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    
    # APIãƒãƒ¼ã‚¸ãƒ§ãƒ³
    API_VERSION: str = "v1"
    
    # Google Cloudèªè¨¼è¨­å®š
    # GOOGLE_APPLICATION_CREDENTIALSã¯é€šå¸¸ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä¸è¦
    # gcloud auth application-default login ã§ã‚‚å¯
    
    class Config:
        env_file = ".env"
        case_sensitive = True


@lru_cache()
def get_settings() -> Settings:
    """
    è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ï¼‰
    """
    return Settings() 
```

============================================================

ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†å±¤ (v2.1)
============================================================

ğŸ“„ FILE: app/prompts/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 114 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:07:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

from .prompt_loader import PromptLoader

__all__ = ['PromptLoader'] 
```

============================================================

ğŸ“„ FILE: app/prompts/prompt_loader.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 4029 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:41:19
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import os
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class PromptLoader:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, prompts_dir: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            prompts_dir: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
                        Noneã®å ´åˆã¯ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
        """
        if prompts_dir is None:
            self.prompts_dir = Path(__file__).parent
        else:
            self.prompts_dir = Path(prompts_dir)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._prompt_cache = {}
    
    def _load_prompt_file(self, filename: str) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            filename: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
            IOError: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
        """
        if filename in self._prompt_cache:
            return self._prompt_cache[filename]
        
        file_path = self.prompts_dir / filename
        
        if not file_path.exists():
            raise FileNotFoundError(f"Prompt file not found: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            self._prompt_cache[filename] = content
            logger.debug(f"Loaded prompt file: {filename}")
            return content
        
        except Exception as e:
            logger.error(f"Error loading prompt file {filename}: {e}")
            raise IOError(f"Failed to load prompt file {filename}: {e}") from e
    
    def get_phase1_system_prompt(self) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚º1ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
        return self._load_prompt_file("phase1_system_prompt.txt")
    
    def get_phase1_user_prompt(self, optional_text: Optional[str] = None) -> str:
        """
        ãƒ•ã‚§ãƒ¼ã‚º1ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        
        Args:
            optional_text: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        template = self._load_prompt_file("phase1_user_prompt_template.txt")
        
        if optional_text and optional_text.strip():
            optional_text_section = f" Additional information from user: {optional_text}"
        else:
            optional_text_section = ""
        
        return template.format(optional_text_section=optional_text_section)
    
    def get_phase2_system_prompt(self) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚º2ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
        return self._load_prompt_file("phase2_system_prompt.txt")
    
    def get_phase2_user_prompt(
        self, 
        initial_ai_output: str,
        usda_candidates: str
    ) -> str:
        """
        ãƒ•ã‚§ãƒ¼ã‚º2ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        
        Args:
            initial_ai_output: ãƒ•ã‚§ãƒ¼ã‚º1ã®AIå‡ºåŠ›ï¼ˆJSONæ–‡å­—åˆ—ï¼‰
            usda_candidates: USDAå€™è£œæƒ…å ±
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        template = self._load_prompt_file("phase2_user_prompt_template.txt")
        
        return template.format(
            initial_ai_output=initial_ai_output,
            usda_candidates=usda_candidates
        )
    
    def reload_prompts(self):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦å†èª­ã¿è¾¼ã¿ã‚’ä¿ƒã™"""
        self._prompt_cache.clear()
        logger.info("Prompt cache cleared. Prompts will be reloaded on next access.") 
```

============================================================

ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ (v2.1)
============================================================

ğŸ“„ FILE: app/prompts/phase1_system_prompt.txt
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 2004 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:15:57
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

CONTENT:
```
You are an expert culinary analyst and food database specialist. Your primary task is to analyze meal images and identify potential dishes and ingredients, focusing on generating *effective query terms for the USDA FoodData Central database*.

**Your Goals:**

1.  **Identify Dishes & Ingredients:** Recognize distinct dishes and their likely core ingredients from the image.
2.  **Estimate Weights:** Provide a reasonable weight estimate (in grams) for each ingredient.
3.  **Generate USDA Query Candidates:** This is CRITICAL. For each identified dish AND its key ingredients, suggest *multiple, plausible query terms* in English that are likely to yield good results in the USDA FoodData Central database.
    * **Think like a database search:** Consider common names, specific names, and *especially Branded Food names* if recognizable packaging or product types are visible.
    * **Consider Granularity:** Provide queries at different levels:
        * `dish`: For the whole dish (e.g., "Lasagna", "Tuna Salad Sandwich").
        * `ingredient`: For core components (e.g., "Ground Beef", "Cheddar Cheese", "Tuna, canned in oil", "Whole wheat bread").
        * `branded_product`: If a specific brand or product is likely (e.g., "Kraft Macaroni & Cheese", "Hellmann's Real Mayonnaise", "StarKist Chunk Light Tuna in Oil").
    * **Prioritize USDA Likelihood:** Avoid overly generic terms ("Sauce", "Seasoning") or terms unlikely to be in USDA (e.g., "Homemade Dashi Broth"). Focus on searchable food items.
    * **Provide Reasons:** Briefly explain why each query term is suggested.
4.  **Output Format:** Strictly adhere to the provided JSON schema (`Phase1AnalysisResponse`).
5.  **Language:** ALL text outputs MUST be in English.

**Instructions:**

* Analyze the provided image carefully.
* For each dish, list its name, type, quantity, and ingredients (with weights).
* For each dish, provide a list of `USDACandidateQuery` objects.
* Ensure your JSON output is valid according to the schema. 
```

============================================================

ğŸ“„ FILE: app/prompts/phase1_user_prompt_template.txt
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 86 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 16:53:14
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

CONTENT:
```
Please analyze the provided meal image and respond in English.{optional_text_section} 
```

============================================================

ğŸ“„ FILE: app/prompts/phase2_system_prompt.txt
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 3717 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:18:17
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

CONTENT:
```
You are an advanced Nutritional Analysis Strategist and USDA Data Matcher. Your mission is to analyze an initial meal assessment and a comprehensive list of USDA FoodData Central (FDC) search results to determine the *optimal strategy for nutritional calculation* for each dish and select the *most accurate FDC IDs*. Your decisions must be **deterministic** and aimed at maximizing **accuracy and stability**.

**Your Core Tasks for EACH Dish:**

1.  **Determine `calculation_strategy`:** Choose either `"dish_level"` or `"ingredient_level"`.
    * **`dish_level`:** Use when a *single, representative FDC ID* accurately describes the *entire dish* and its likely nutritional profile. This is often suitable for:
        * **Specific Branded Products:** If a high-confidence match exists (e.g., "McDonald's Big Mac", "Stouffer's Lasagna"). **Prioritize Branded Foods if a strong match exists.**
        * **Simple, Standardized Items:** If a good Foundation or SR Legacy match exists (e.g., "Apple", "Chicken Breast, grilled", "Milk, 2%").
        * **Standardized Recipes in FNDDS/SR Legacy:** If a *good* FNDDS or SR Legacy entry exists for a common prepared dish (e.g., "Macaroni and Cheese, prepared").
    * **`ingredient_level`:** Use when the dish is complex, highly variable, homemade, or lacks a suitable single FDC ID. This is often suitable for:
        * **Salads, Stir-fries, Stews, Casseroles:** Dishes with many variable components.
        * **Standardized dishes *without* a good FDC match:** If the available dish-level FDC IDs seem inaccurate.
        * When *breaking down* provides higher accuracy (e.g., a specific sandwich where you can identify bread, meat, cheese, and sauce FDC IDs).
    * **Provide `reason_for_strategy`:** Clearly explain *why* you chose this strategy based on the dish and the available USDA data.

2.  **Select FDC IDs:**
    * **If `dish_level`:**
        * Select the *single best FDC ID* for the *entire dish* from the provided USDA candidates.
        * Provide this as the dish `fdc_id` and `usda_source_description`.
        * Provide `reason_for_choice` for this FDC ID.
        * For *each ingredient* listed in the initial analysis, *still attempt to find a plausible FDC ID* and list it. This serves as a **fallback/verification** mechanism, but these FDC IDs *won't* be used for the primary calculation in this strategy. Provide a reason for each ingredient FDC ID selection.
    * **If `ingredient_level`:**
        * Set the dish `fdc_id` and `usda_source_description` to `null`.
        * For *each ingredient*, select the *single best FDC ID* from the provided USDA candidates for that ingredient.
        * Provide these as the `fdc_id` and `usda_source_description` for each ingredient.
        * Provide `reason_for_choice` for each FDC ID selection. If no good match exists, set FDC ID to `null` and explain why.

**FDC ID Selection Guidelines:**

* **Prioritize:** 1. Branded (if strong match) -> 2. Foundation -> 3. SR Legacy -> 4. FNDDS.
* **Relevance:** Choose the ID that best matches the *context* (image, initial name) and has a high score/good description.
* **Data Type:** Consider the nature of the USDA type. Foundation is analytical, SR/FNDDS can be averaged/calculated, Branded is label-based.
* **Ingredients Text (Branded/FNDDS):** Use this to verify if a Branded/FNDDS entry is a reasonable match.

**Output Requirements:**

* Strictly adhere to the provided JSON schema (`Phase2GeminiResponse`).
* Include all required fields, especially `calculation_strategy`, `reason_for_strategy`, `fdc_id`, `usda_source_description`, and `reason_for_choice`.
* ALL text outputs MUST be in English.
* DO NOT perform any nutritional calculations. 
```

============================================================

ğŸ“„ FILE: app/prompts/phase2_user_prompt_template.txt
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 820 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:18:37
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

CONTENT:
```
Here is the initial meal analysis (Phase 1 Output):
```json
{initial_ai_output}
```

Here are the potential USDA FDC ID candidates based on queries from Phase 1. Review these carefully, noting the FDC ID, Name, Data Type, Brand, and Score:

{usda_candidates}

Based on the initial analysis, the image context (implicitly known from Phase 1), and ALL the provided USDA candidates, please perform the Phase 2 refinement as per the system instructions. For each dish:

1. Decide the calculation_strategy.
2. Provide the reason_for_strategy.
3. Select the best FDC ID(s) according to the chosen strategy.
4. Provide the usda_source_description for each selected FDC ID.
5. Provide the reason_for_choice for each selected FDC ID.

Ensure your response is in English and strictly follows the Phase2GeminiResponse JSON schema. 
```

============================================================

ğŸ“ ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ« (v2.1æ–°æ©Ÿèƒ½)
============================================================

ğŸ“„ FILE: app/utils/__init__.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 16 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:37:01
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
# utils package 
```

============================================================

ğŸ“„ FILE: app/utils/log_analyzer.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 10723 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:02:35
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
from collections import defaultdict
import pandas as pd

logger = logging.getLogger(__name__)

@dataclass
class AnalysisStats:
    """åˆ†æçµ±è¨ˆæƒ…å ±"""
    total_sessions: int
    successful_sessions: int
    failed_sessions: int
    avg_duration_ms: float
    avg_phase1_duration_ms: float
    avg_usda_search_duration_ms: float
    avg_phase2_duration_ms: float
    avg_nutrition_calc_duration_ms: float
    
    # æˆ¦ç•¥çµ±è¨ˆ
    dish_level_count: int
    ingredient_level_count: int
    
    # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
    common_errors: Dict[str, int]
    warning_counts: Dict[str, int]

class MealAnalysisLogAnalyzer:
    """é£Ÿäº‹åˆ†æãƒ­ã‚°ã®åˆ†æãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        if not self.log_dir.exists():
            raise ValueError(f"Log directory does not exist: {log_dir}")
    
    def load_session_logs(self, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None) -> List[Dict[str, Any]]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿"""
        session_log_file = self.log_dir / "meal_analysis_sessions.jsonl"
        
        if not session_log_file.exists():
            logger.warning(f"Session log file not found: {session_log_file}")
            return []
        
        sessions = []
        with open(session_log_file, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    session = json.loads(line.strip())
                    
                    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if start_date or end_date:
                        session_time = datetime.fromisoformat(session['start_time'].replace('Z', '+00:00'))
                        if start_date and session_time < start_date:
                            continue
                        if end_date and session_time > end_date:
                            continue
                    
                    sessions.append(session)
                except json.JSONDecodeError as e:
                    logger.warning(f"Failed to parse session log line: {e}")
        
        return sessions
    
    def analyze_sessions(self, sessions: List[Dict[str, Any]]) -> AnalysisStats:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¾¤ã‚’åˆ†æ"""
        if not sessions:
            return AnalysisStats(
                total_sessions=0, successful_sessions=0, failed_sessions=0,
                avg_duration_ms=0, avg_phase1_duration_ms=0,
                avg_usda_search_duration_ms=0, avg_phase2_duration_ms=0,
                avg_nutrition_calc_duration_ms=0,
                dish_level_count=0, ingredient_level_count=0,
                common_errors={}, warning_counts={}
            )
        
        total_sessions = len(sessions)
        successful_sessions = sum(1 for s in sessions if not s.get('errors'))
        failed_sessions = total_sessions - successful_sessions
        
        # å®Ÿè¡Œæ™‚é–“çµ±è¨ˆ
        durations = [s.get('total_duration_ms', 0) for s in sessions if s.get('total_duration_ms')]
        phase1_durations = [s.get('phase1_duration_ms', 0) for s in sessions if s.get('phase1_duration_ms')]
        usda_durations = [s.get('usda_search_duration_ms', 0) for s in sessions if s.get('usda_search_duration_ms')]
        phase2_durations = [s.get('phase2_duration_ms', 0) for s in sessions if s.get('phase2_duration_ms')]
        nutrition_durations = [s.get('nutrition_calc_duration_ms', 0) for s in sessions if s.get('nutrition_calc_duration_ms')]
        
        # æˆ¦ç•¥çµ±è¨ˆ
        dish_level_count = 0
        ingredient_level_count = 0
        
        for session in sessions:
            strategy_decisions = session.get('phase2_strategy_decisions', {})
            for dish_name, decision in strategy_decisions.items():
                if decision.get('strategy') == 'dish_level':
                    dish_level_count += 1
                elif decision.get('strategy') == 'ingredient_level':
                    ingredient_level_count += 1
        
        # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
        error_counts = defaultdict(int)
        warning_counts = defaultdict(int)
        
        for session in sessions:
            errors = session.get('errors', [])
            warnings = session.get('warnings', [])
            
            for error in errors:
                error_counts[error] += 1
            
            for warning in warnings:
                warning_counts[warning] += 1
        
        return AnalysisStats(
            total_sessions=total_sessions,
            successful_sessions=successful_sessions,
            failed_sessions=failed_sessions,
            avg_duration_ms=sum(durations) / len(durations) if durations else 0,
            avg_phase1_duration_ms=sum(phase1_durations) / len(phase1_durations) if phase1_durations else 0,
            avg_usda_search_duration_ms=sum(usda_durations) / len(usda_durations) if usda_durations else 0,
            avg_phase2_duration_ms=sum(phase2_durations) / len(phase2_durations) if phase2_durations else 0,
            avg_nutrition_calc_duration_ms=sum(nutrition_durations) / len(nutrition_durations) if nutrition_durations else 0,
            dish_level_count=dish_level_count,
            ingredient_level_count=ingredient_level_count,
            common_errors=dict(error_counts),
            warning_counts=dict(warning_counts)
        )
    
    def generate_report(self, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None) -> str:
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        sessions = self.load_session_logs(start_date, end_date)
        stats = self.analyze_sessions(sessions)
        
        period_str = ""
        if start_date:
            period_str += f"From: {start_date.strftime('%Y-%m-%d %H:%M:%S')}\n"
        if end_date:
            period_str += f"To: {end_date.strftime('%Y-%m-%d %H:%M:%S')}\n"
        
        report = f"""
# é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

{period_str}

## ğŸ“Š åŸºæœ¬çµ±è¨ˆ

- **ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°**: {stats.total_sessions}
- **æˆåŠŸã‚»ãƒƒã‚·ãƒ§ãƒ³**: {stats.successful_sessions} ({stats.successful_sessions/max(stats.total_sessions,1)*100:.1f}%)
- **å¤±æ•—ã‚»ãƒƒã‚·ãƒ§ãƒ³**: {stats.failed_sessions} ({stats.failed_sessions/max(stats.total_sessions,1)*100:.1f}%)

## â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ

- **å¹³å‡ç·å®Ÿè¡Œæ™‚é–“**: {stats.avg_duration_ms:.1f}ms
- **å¹³å‡Phase1æ™‚é–“**: {stats.avg_phase1_duration_ms:.1f}ms
- **å¹³å‡USDAæ¤œç´¢æ™‚é–“**: {stats.avg_usda_search_duration_ms:.1f}ms
- **å¹³å‡Phase2æ™‚é–“**: {stats.avg_phase2_duration_ms:.1f}ms
- **å¹³å‡æ „é¤Šè¨ˆç®—æ™‚é–“**: {stats.avg_nutrition_calc_duration_ms:.1f}ms

## ğŸ¯ æˆ¦ç•¥çµ±è¨ˆ

- **Dish Levelæˆ¦ç•¥**: {stats.dish_level_count}å›
- **Ingredient Levelæˆ¦ç•¥**: {stats.ingredient_level_count}å›
- **æˆ¦ç•¥æ¯”ç‡**: Dish {stats.dish_level_count/(max(stats.dish_level_count+stats.ingredient_level_count,1))*100:.1f}% vs Ingredient {stats.ingredient_level_count/(max(stats.dish_level_count+stats.ingredient_level_count,1))*100:.1f}%

## âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šçµ±è¨ˆ

### ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼:
"""
        
        for error, count in sorted(stats.common_errors.items(), key=lambda x: x[1], reverse=True)[:10]:
            report += f"- {error}: {count}å›\n"
        
        report += "\n### ã‚ˆãã‚ã‚‹è­¦å‘Š:\n"
        for warning, count in sorted(stats.warning_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
            report += f"- {warning}: {count}å›\n"
        
        return report
    
    def export_to_csv(self, output_file: str, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        sessions = self.load_session_logs(start_date, end_date)
        
        if not sessions:
            logger.warning("No sessions to export")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’å¹³å¦åŒ–
        rows = []
        for session in sessions:
            row = {
                'session_id': session.get('session_id'),
                'start_time': session.get('start_time'),
                'end_time': session.get('end_time'),
                'endpoint': session.get('endpoint'),
                'image_filename': session.get('image_filename'),
                'image_size_bytes': session.get('image_size_bytes'),
                'total_duration_ms': session.get('total_duration_ms'),
                'phase1_duration_ms': session.get('phase1_duration_ms'),
                'usda_search_duration_ms': session.get('usda_search_duration_ms'),
                'phase2_duration_ms': session.get('phase2_duration_ms'),
                'nutrition_calc_duration_ms': session.get('nutrition_calc_duration_ms'),
                'dishes_count': session.get('phase1_dishes_count'),
                'usda_queries_count': session.get('phase1_usda_queries_count'),
                'usda_results_found': session.get('usda_results_found'),
                'total_calories': session.get('total_calories'),
                'has_errors': bool(session.get('errors')),
                'has_warnings': bool(session.get('warnings')),
                'error_count': len(session.get('errors', [])),
                'warning_count': len(session.get('warnings', []))
            }
            rows.append(row)
        
        df = pd.DataFrame(rows)
        df.to_csv(output_file, index=False)
        logger.info(f"Exported {len(rows)} sessions to {output_file}")
    
    def find_slow_sessions(self, threshold_ms: float = 10000) -> List[Dict[str, Any]]:
        """é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç‰¹å®š"""
        sessions = self.load_session_logs()
        slow_sessions = [
            s for s in sessions 
            if s.get('total_duration_ms', 0) > threshold_ms
        ]
        return sorted(slow_sessions, key=lambda x: x.get('total_duration_ms', 0), reverse=True)
    
    def find_error_patterns(self) -> Dict[str, List[str]]:
        """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        sessions = self.load_session_logs()
        error_patterns = defaultdict(list)
        
        for session in sessions:
            errors = session.get('errors', [])
            session_id = session.get('session_id', 'unknown')
            
            for error in errors:
                error_patterns[error].append(session_id)
        
        return dict(error_patterns)

def create_log_analyzer(log_dir: str = "logs") -> MealAnalysisLogAnalyzer:
    """ãƒ­ã‚°ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°"""
    return MealAnalysisLogAnalyzer(log_dir) 
```

============================================================

ğŸ“„ FILE: analyze_logs.py
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 6771 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:03:24
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CONTENT:
```
#!/usr/bin/env python3
"""
é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«

ä½¿ç”¨ä¾‹:
python analyze_logs.py --report                    # åŸºæœ¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
python analyze_logs.py --export sessions.csv       # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
python analyze_logs.py --slow --threshold 5000     # 5ç§’ä»¥ä¸Šã®é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆ†æ
python analyze_logs.py --errors                    # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
python analyze_logs.py --days 7                    # éå»7æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿åˆ†æ
"""

import argparse
import sys
from datetime import datetime, timedelta
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from app.utils.log_analyzer import create_log_analyzer

def main():
    parser = argparse.ArgumentParser(
        description="é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        "--log-dir", 
        default="logs", 
        help="ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: logs)"
    )
    
    # åˆ†æã‚¿ã‚¤ãƒ—
    parser.add_argument(
        "--report", 
        action="store_true", 
        help="åŸºæœ¬åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"
    )
    
    parser.add_argument(
        "--export", 
        metavar="FILE", 
        help="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
    )
    
    parser.add_argument(
        "--slow", 
        action="store_true", 
        help="é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆ†æ"
    )
    
    parser.add_argument(
        "--threshold", 
        type=float, 
        default=10000, 
        help="é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–¾å€¤ (ãƒŸãƒªç§’, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10000)"
    )
    
    parser.add_argument(
        "--errors", 
        action="store_true", 
        help="ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"
    )
    
    # æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿
    parser.add_argument(
        "--days", 
        type=int, 
        help="éå»Næ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿åˆ†æ"
    )
    
    parser.add_argument(
        "--start-date", 
        help="é–‹å§‹æ—¥æ™‚ (ISOå½¢å¼: YYYY-MM-DD ã¾ãŸã¯ YYYY-MM-DD HH:MM:SS)"
    )
    
    parser.add_argument(
        "--end-date", 
        help="çµ‚äº†æ—¥æ™‚ (ISOå½¢å¼: YYYY-MM-DD ã¾ãŸã¯ YYYY-MM-DD HH:MM:SS)"
    )
    
    args = parser.parse_args()
    
    # æœ€ä½1ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦
    if not any([args.report, args.export, args.slow, args.errors]):
        args.report = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
    
    try:
        analyzer = create_log_analyzer(args.log_dir)
    except ValueError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã®æº–å‚™
    start_date = None
    end_date = None
    
    if args.days:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=args.days)
        print(f"ğŸ“… éå»{args.days}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ ({start_date.strftime('%Y-%m-%d')} ã€œ {end_date.strftime('%Y-%m-%d')})")
    
    if args.start_date:
        try:
            # YYYY-MM-DD HH:MM:SS ã¾ãŸã¯ YYYY-MM-DD ã®å½¢å¼ã‚’å—ã‘å…¥ã‚Œ
            if len(args.start_date) == 10:  # YYYY-MM-DD
                start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
            else:  # YYYY-MM-DD HH:MM:SS
                start_date = datetime.strptime(args.start_date, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            print(f"âŒ ç„¡åŠ¹ãªé–‹å§‹æ—¥æ™‚å½¢å¼: {args.start_date}")
            return 1
    
    if args.end_date:
        try:
            if len(args.end_date) == 10:  # YYYY-MM-DD
                end_date = datetime.strptime(args.end_date + " 23:59:59", "%Y-%m-%d %H:%M:%S")
            else:  # YYYY-MM-DD HH:MM:SS
                end_date = datetime.strptime(args.end_date, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            print(f"âŒ ç„¡åŠ¹ãªçµ‚äº†æ—¥æ™‚å½¢å¼: {args.end_date}")
            return 1
    
    # å„åˆ†æå®Ÿè¡Œ
    if args.report:
        print("\n" + "="*60)
        print("ğŸ“Š é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*60)
        
        report = analyzer.generate_report(start_date, end_date)
        print(report)
    
    if args.export:
        print("\nğŸ“ CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­: {args.export}")
        try:
            analyzer.export_to_csv(args.export, start_date, end_date)
            print(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {args.export}")
        except Exception as e:
            print(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    if args.slow:
        print("\nğŸŒ é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†æ (é–¾å€¤: {args.threshold}ms)")
        slow_sessions = analyzer.find_slow_sessions(args.threshold)
        
        if not slow_sessions:
            print("âœ… é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            print(f"âš ï¸  {len(slow_sessions)}å€‹ã®é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            
            for i, session in enumerate(slow_sessions[:10], 1):
                duration = session.get('total_duration_ms', 0)
                session_id = session.get('session_id', 'unknown')
                start_time = session.get('start_time', 'unknown')
                
                print(f"  {i}. ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id[:8]}... - {duration:.1f}ms ({start_time})")
                
                # å„ãƒ•ã‚§ãƒ¼ã‚ºã®æ™‚é–“å†…è¨³ã‚’è¡¨ç¤º
                phase1 = session.get('phase1_duration_ms', 0)
                usda = session.get('usda_search_duration_ms', 0)
                phase2 = session.get('phase2_duration_ms', 0)
                nutrition = session.get('nutrition_calc_duration_ms', 0)
                
                print(f"     â”” Phase1: {phase1:.1f}ms, USDA: {usda:.1f}ms, Phase2: {phase2:.1f}ms, æ „é¤Šè¨ˆç®—: {nutrition:.1f}ms")
    
    if args.errors:
        print("\nğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        error_patterns = analyzer.find_error_patterns()
        
        if not error_patterns:
            print("âœ… ã‚¨ãƒ©ãƒ¼ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            print(f"âš ï¸  {len(error_patterns)}ç¨®é¡ã®ã‚¨ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            
            for error, session_ids in sorted(error_patterns.items(), key=lambda x: len(x[1]), reverse=True):
                count = len(session_ids)
                print(f"\n  ğŸ“Œ {error} ({count}å›)")
                
                # æœ€åˆã®5ã¤ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’è¡¨ç¤º
                for session_id in session_ids[:5]:
                    print(f"     - ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_id}")
                
                if len(session_ids) > 5:
                    print(f"     ... ãŠã‚ˆã³ä»–{len(session_ids) - 5}ä»¶")
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 
```

============================================================

ğŸ“ ä¾å­˜é–¢ä¿‚ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
============================================================

ğŸ“„ FILE: requirements.txt
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 1627 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:05:35
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

CONTENT:
```
aiohappyeyeballs==2.6.1
aiohttp==3.12.2
aiosignal==1.3.2
annotated-types==0.7.0
anyio==3.7.1
async-timeout==5.0.1
attrs==25.3.0
cachetools==5.5.2
certifi==2025.4.26
cffi==1.17.1
charset-normalizer==3.4.2
click==8.1.8
cryptography==45.0.3
docstring-parser==0.16
ecdsa==0.19.1
exceptiongroup==1.3.0
fastapi==0.104.1
frozenlist==1.6.0
google-ai-generativelanguage==0.6.15
google-api-core==2.24.2
google-api-python-client==2.170.0
google-auth==2.40.2
google-auth-httplib2==0.2.0
google-cloud-aiplatform==1.94.0
google-cloud-bigquery==3.33.0
google-cloud-core==2.4.3
google-cloud-resource-manager==1.14.2
google-cloud-storage==2.19.0
google-crc32c==1.7.1
google-genai==1.4.0
google-generativeai==0.8.5
google-resumable-media==2.7.2
googleapis-common-protos==1.70.0
grpc-google-iam-v1==0.14.2
grpcio==1.71.0
grpcio-status==1.62.3
h11==0.16.0
httpcore==1.0.9
httplib2==0.22.0
httptools==0.6.4
httpx==0.28.1
idna==3.10
iniconfig==2.1.0
multidict==6.4.4
numpy==2.0.2
packaging==25.0
pandas==2.2.3
pillow==11.2.1
pluggy==1.6.0
propcache==0.3.1
proto-plus==1.26.1
protobuf==4.25.7
pyasn1==0.6.1
pyasn1-modules==0.4.2
pycparser==2.22
pydantic==2.5.0
pydantic-core==2.14.1
pydantic-settings==2.1.0
pyparsing==3.2.3
pytest==7.4.3
pytest-asyncio==0.21.1
python-dateutil==2.9.0.post0
python-dotenv==1.0.0
python-jose==3.3.0
python-multipart==0.0.6
pytz==2025.2
PyYAML==6.0.2
requests==2.32.3
rsa==4.9.1
shapely==2.0.7
six==1.17.0
sniffio==1.3.1
starlette==0.27.0
tomli==2.2.1
tqdm==4.67.1
typing-extensions==4.13.2
tzdata==2025.2
uritemplate==4.1.1
urllib3==2.4.0
uvicorn==0.24.0
uvloop==0.21.0
watchfiles==1.0.5
websockets==14.2
yarl==1.20.0

```

============================================================

ğŸ“„ FILE: .gitignore
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 1533 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:01:42
å­˜åœ¨: âœ…

CONTENT:
```
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Service Account Key
service-account-key.json

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
logs/
*.log
*.jsonl

# Test images upload cache
test_images_uploaded/

# Test images (actual image files)
test_images/*.jpg
test_images/*.jpeg
test_images/*.png
test_images/*.webp
test_images/*.heic
test_images/*.heif 
```

============================================================

ğŸ“„ FILE: README.md
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 14979 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:10:36
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“– ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«

CONTENT:
```
# é£Ÿäº‹åˆ†æ API (Meal Analysis API) v2.1

## æ¦‚è¦

ã“ã® API ã¯ã€**Google Gemini AI** ã¨ **USDA ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**ã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªé£Ÿäº‹ç”»åƒåˆ†æã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚**å‹•çš„æ „é¤Šè¨ˆç®—æ©Ÿèƒ½**ã«ã‚ˆã‚Šã€æ–™ç†ã®ç‰¹æ€§ã«å¿œã˜ã¦æœ€é©ãªæ „é¤Šè¨ˆç®—æˆ¦ç•¥ã‚’è‡ªå‹•é¸æŠã—ã€æ­£ç¢ºãªæ „é¤Šä¾¡æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚

## ğŸŒŸ ä¸»ãªæ©Ÿèƒ½

### **æ–°æ©Ÿèƒ½: å‹•çš„æ „é¤Šè¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ  v2.0**

- **ğŸ§  AI é§†å‹•ã®è¨ˆç®—æˆ¦ç•¥æ±ºå®š**: Gemini AI ãŒå„æ–™ç†ã«å¯¾ã—ã¦æœ€é©ãªæ „é¤Šè¨ˆç®—æ–¹æ³•ã‚’è‡ªå‹•é¸æŠ
  - `dish_level`: ã‚·ãƒ³ãƒ—ãƒ«ãªé£Ÿå“ï¼ˆç·‘èŒ¶ã€æœç‰©ãªã©ï¼‰ã¯æ–™ç†å…¨ä½“ã® USDA ID ã§è¨ˆç®—
  - `ingredient_level`: è¤‡é›‘ãªæ–™ç†ï¼ˆã‚µãƒ©ãƒ€ã€ç‚’ã‚ç‰©ãªã©ï¼‰ã¯é£Ÿæã”ã¨ã«è©³ç´°è¨ˆç®—ã—ã¦é›†è¨ˆ
- **ğŸ¯ é«˜ç²¾åº¦æ „é¤Šè¨ˆç®—**: é£Ÿæé‡é‡ Ã— 100g ã‚ãŸã‚Šæ „é¤Šä¾¡ã§æ­£ç¢ºãªå®Ÿæ „é¤Šä¾¡ã‚’ç®—å‡º
- **ğŸ“Š 3 å±¤é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ **: é£Ÿæ â†’ æ–™ç† â†’ é£Ÿäº‹å…¨ä½“ã®è‡ªå‹•æ „é¤Šé›†è¨ˆ
- **âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  USDA çµ±åˆ**: 20,000+ é£Ÿå“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®å³åº§ãªç…§åˆ

### **ã‚³ã‚¢æ©Ÿèƒ½**

- **ãƒ•ã‚§ãƒ¼ã‚º 1**: Gemini AI ã«ã‚ˆã‚‹é£Ÿäº‹ç”»åƒã®åˆ†æï¼ˆæ–™ç†è­˜åˆ¥ã€é£ŸææŠ½å‡ºã€é‡é‡æ¨å®šï¼‰
- **ãƒ•ã‚§ãƒ¼ã‚º 2**: USDA ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚ˆã‚‹æ „é¤Šæˆåˆ†ã®ç²¾ç·»åŒ–ã¨å‹•çš„è¨ˆç®—
- **è¤‡æ•°æ–™ç†å¯¾å¿œ**: 1 æšã®ç”»åƒã§è¤‡æ•°ã®æ–™ç†ã‚’åŒæ™‚åˆ†æ
- **è‹±èªãƒ»æ—¥æœ¬èªå¯¾å¿œ**: å¤šè¨€èªã§ã®é£Ÿæãƒ»æ–™ç†èªè­˜
- **OpenAPI 3.0 æº–æ‹ **: å®Œå…¨ãª API æ–‡æ›¸åŒ–ã¨ã‚¿ã‚¤ãƒ—å®‰å…¨æ€§

## ğŸ— ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
meal_analysis_api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ meal_analyses.py          # ãƒ•ã‚§ãƒ¼ã‚º1: åŸºæœ¬åˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚   â”‚   â””â”€â”€ meal_analyses_refine.py   # ãƒ•ã‚§ãƒ¼ã‚º2: å‹•çš„æ „é¤Šè¨ˆç®—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚   â””â”€â”€ schemas/
â”‚   â”‚       â””â”€â”€ meal.py                   # Pydanticãƒ¢ãƒ‡ãƒ«ï¼ˆæ „é¤Šè¨ˆç®—å¯¾å¿œï¼‰
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py                     # è¨­å®šç®¡ç†
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ gemini_service.py             # Gemini AIçµ±åˆï¼ˆ2ãƒ•ã‚§ãƒ¼ã‚ºå¯¾å¿œï¼‰
â”‚   â”‚   â”œâ”€â”€ usda_service.py               # USDA API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
â”‚   â”‚   â””â”€â”€ nutrition_calculation_service.py # æ „é¤Šè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â”œâ”€â”€ prompts/                          # AI ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”‚   â”‚   â”œâ”€â”€ phase1_system_prompt.txt      # ãƒ•ã‚§ãƒ¼ã‚º1ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
â”‚   â”‚   â”œâ”€â”€ phase1_user_prompt_template.txt
â”‚   â”‚   â”œâ”€â”€ phase2_system_prompt.txt      # ãƒ•ã‚§ãƒ¼ã‚º2ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæˆ¦ç•¥æ±ºå®šç”¨ï¼‰
â”‚   â”‚   â””â”€â”€ phase2_user_prompt_template.txt
â”‚   â””â”€â”€ main.py                           # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ test_images/                          # ãƒ†ã‚¹ãƒˆç”¨ç”»åƒ
â”œâ”€â”€ test_english_phase2.py                # çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (v2.0)
â”œâ”€â”€ test_english_phase2_v2.py             # é«˜åº¦æˆ¦ç•¥ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (v2.1)
â”œâ”€â”€ analyze_logs.py                       # ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«
â”œâ”€â”€ logs/                                 # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
â”œâ”€â”€ requirements.txt                      # Pythonä¾å­˜é–¢ä¿‚
â””â”€â”€ service-account-key.json             # GCPèªè¨¼ã‚­ãƒ¼
```

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ä»®æƒ³ç’°å¢ƒã®ä½œæˆ
python -m venv venv

# ä»®æƒ³ç’°å¢ƒã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source venv/bin/activate  # macOS/Linux
# ã¾ãŸã¯
venv\Scripts\activate     # Windows

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

### 2. Google Cloud è¨­å®š

#### Google Cloud SDK ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ã¾ã ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š
https://cloud.google.com/sdk/docs/install

#### Google Cloud èªè¨¼ã®è¨­å®š

é–‹ç™ºç’°å¢ƒã§ã¯ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§èªè¨¼ã‚’è¨­å®šï¼š

```bash
# Google Cloudã«ãƒ­ã‚°ã‚¤ãƒ³
gcloud auth login

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèªè¨¼æƒ…å ±ã‚’è¨­å®š
gcloud auth application-default login

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’è¨­å®š
gcloud config set project YOUR_PROJECT_ID
```

æœ¬ç•ªç’°å¢ƒã§ã¯ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã‚’ä½¿ç”¨ï¼š

```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your-service-account-key.json"
```

#### Vertex AI API ã®æœ‰åŠ¹åŒ–

```bash
# Vertex AI APIã‚’æœ‰åŠ¹åŒ–
gcloud services enable aiplatform.googleapis.com
```

### 3. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š

```bash
# USDA APIè¨­å®š
export USDA_API_KEY="your-usda-api-key"

# Vertex AIè¨­å®š
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account-key.json"
export GEMINI_PROJECT_ID="your-gcp-project-id"
export GEMINI_LOCATION="us-central1"
export GEMINI_MODEL_NAME="gemini-2.5-flash-preview-05-20"
```

## ğŸ–¥ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•

### é–‹ç™ºç’°å¢ƒã§ã®èµ·å‹•

æä¾›ã•ã‚ŒãŸå®Œå…¨ãªã‚³ãƒãƒ³ãƒ‰ã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼š

```bash
export USDA_API_KEY="vSWtKJ3jYD0Cn9LRyVJUFkuyCt9p8rEtVXz74PZg" && export GOOGLE_APPLICATION_CREDENTIALS="/Users/odasoya/meal_analysis_api /service-account-key.json" && export GEMINI_PROJECT_ID=recording-diet-ai-3e7cf && export GEMINI_LOCATION=us-central1 && export GEMINI_MODEL_NAME=gemini-2.5-flash-preview-05-20 && uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

ã¾ãŸã¯ã€ç’°å¢ƒå¤‰æ•°ã‚’å€‹åˆ¥ã«è¨­å®šã—ã¦ã‹ã‚‰èµ·å‹•ï¼š

```bash
# ç’°å¢ƒå¤‰æ•°è¨­å®š
export USDA_API_KEY="vSWtKJ3jYD0Cn9LRyVJUFkuyCt9p8rEtVXz74PZg"
export GOOGLE_APPLICATION_CREDENTIALS="/Users/odasoya/meal_analysis_api /service-account-key.json"
export GEMINI_PROJECT_ID="recording-diet-ai-3e7cf"
export GEMINI_LOCATION="us-central1"
export GEMINI_MODEL_NAME="gemini-2.5-flash-preview-05-20"

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã™ã‚‹ã¨ã€ä»¥ä¸‹ã® URL ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ãªã‚Šã¾ã™ï¼š

- **API**: http://localhost:8000
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: http://localhost:8000/docs
- **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯**: http://localhost:8000/health

## ğŸ§ª ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

### 1. åŸºæœ¬ãƒ†ã‚¹ãƒˆï¼ˆãƒ•ã‚§ãƒ¼ã‚º 1 ã®ã¿ï¼‰

```bash
python test_phase1_only.py
```

### 2. **ğŸ”¥ çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆå‹•çš„æ „é¤Šè¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ï¼‰**

**é‡è¦**: ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹çŠ¶æ…‹ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

#### v2.0 çµ±åˆãƒ†ã‚¹ãƒˆ

```bash
# åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œ
python test_english_phase2.py
```

#### v2.1 é«˜åº¦æˆ¦ç•¥ãƒ†ã‚¹ãƒˆï¼ˆæ¨å¥¨ï¼‰

```bash
# v2.1ä»•æ§˜ã®é«˜åº¦ãªæˆ¦ç•¥æ±ºå®šã¨FDC IDé¸æŠã‚’ãƒ†ã‚¹ãƒˆ
python test_english_phase2_v2.py
```

ã“ã®ãƒ†ã‚¹ãƒˆã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š

1. **ãƒ•ã‚§ãƒ¼ã‚º 1**: é£Ÿäº‹ç”»åƒã®åˆ†æï¼ˆè‹±èªã®é£Ÿæåã§å‡ºåŠ›ï¼‰+ USDA ã‚¯ã‚¨ãƒªå€™è£œç”Ÿæˆ
2. **ãƒ•ã‚§ãƒ¼ã‚º 2**:
   - 25+å€‹ã® USDA ã‚¯ã‚¨ãƒªå€™è£œã‚’ä¸¦åˆ—æ¤œç´¢
   - Gemini AI ã«ã‚ˆã‚‹æœ€é©è¨ˆç®—æˆ¦ç•¥ã®æ±ºå®šï¼ˆdish_level/ingredient_levelï¼‰
   - æˆ¦ç•¥ç†ç”±ã¨ FDC ID é¸æŠç†ç”±ã®è©³ç´°å‡ºåŠ›
   - å‹•çš„æ „é¤Šè¨ˆç®—ã¨é£Ÿäº‹å…¨ä½“ã®æ „é¤Šé›†è¨ˆ

**æœŸå¾…ã•ã‚Œã‚‹çµæœä¾‹**:

```
ğŸ“Š Response status: 200
ğŸ½ï¸  Found 7 dishes
ğŸ“Œ DISH 1: White Rice
   ğŸ¯ Calculation Strategy: dish_level
   ğŸ“ Strategy Reason: Simple ingredient with accurate FDC ID available
   ğŸ·ï¸  Dish FDC ID: 168932
   ğŸ“„ USDA Source: Rice, white, short-grain, cooked, unenriched
   ğŸ§® Nutrition (Total): 260.0 kcal, 4.7g protein, 57.5g carbs, 0.4g fat

ğŸ½ï¸  MEAL TOTAL NUTRITION:
   Energy: 777.1 kcal
   Protein: 38.2g
   Carbohydrates: 81.5g
   Fat: 31.8g
```

### 3. ãã®ä»–ã®ãƒ†ã‚¹ãƒˆ

```bash
# USDA APIã®ã¿ã®ãƒ†ã‚¹ãƒˆ
python test_usda_only.py

# Vertex AIç›´æ¥ãƒ†ã‚¹ãƒˆ
python test_direct_vertexai.py
```

## ğŸ“¡ API ä½¿ç”¨æ–¹æ³•

### ãƒ•ã‚§ãƒ¼ã‚º 1: åŸºæœ¬åˆ†æ

```bash
curl -X POST "http://localhost:8000/api/v1/meal-analyses" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg"
```

### ãƒ•ã‚§ãƒ¼ã‚º 2: å‹•çš„æ „é¤Šè¨ˆç®—

```bash
# æœ€åˆã«ãƒ•ã‚§ãƒ¼ã‚º1ã®çµæœã‚’å–å¾—
initial_result=$(curl -X POST "http://localhost:8000/api/v1/meal-analyses" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg")

# ãƒ•ã‚§ãƒ¼ã‚º2ã§å‹•çš„æ „é¤Šè¨ˆç®—
curl -X POST "http://localhost:8000/api/v1/meal-analyses/refine" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_images/food3.jpg" \
  -F "initial_analysis_data=$initial_result"
```

## ğŸ“‹ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹

### ãƒ•ã‚§ãƒ¼ã‚º 1 ãƒ¬ã‚¹ãƒãƒ³ã‚¹

```json
{
  "dishes": [
    {
      "dish_name": "Fried Fish with Spaghetti and Tomato Sauce",
      "type": "Main Dish",
      "quantity_on_plate": "2 pieces of fish, 1 small serving of spaghetti",
      "ingredients": [
        {
          "ingredient_name": "White Fish Fillet",
          "weight_g": 150.0
        },
        {
          "ingredient_name": "Spaghetti (cooked)",
          "weight_g": 80.0
        }
      ]
    }
  ]
}
```

### ãƒ•ã‚§ãƒ¼ã‚º 2 ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆå‹•çš„æ „é¤Šè¨ˆç®—ï¼‰

```json
{
  "dishes": [
    {
      "dish_name": "Spinach and Daikon Radish Aemono",
      "type": "Side Dish",
      "calculation_strategy": "ingredient_level",
      "fdc_id": null,
      "ingredients": [
        {
          "ingredient_name": "Spinach",
          "weight_g": 80.0,
          "fdc_id": 1905313,
          "usda_source_description": "SPINACH",
          "key_nutrients_per_100g": {
            "calories_kcal": 24.0,
            "protein_g": 3.53,
            "carbohydrates_g": 3.53,
            "fat_g": 0.0
          },
          "actual_nutrients": {
            "calories_kcal": 19.2,
            "protein_g": 2.82,
            "carbohydrates_g": 2.82,
            "fat_g": 0.0
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 57.45,
        "protein_g": 3.85,
        "carbohydrates_g": 4.57,
        "fat_g": 3.31
      }
    },
    {
      "dish_name": "Green Tea",
      "type": "Drink",
      "calculation_strategy": "dish_level",
      "fdc_id": 1810668,
      "usda_source_description": "GREEN TEA",
      "key_nutrients_per_100g": {
        "calories_kcal": 0.0,
        "protein_g": 0.0,
        "carbohydrates_g": 0.0,
        "fat_g": 0.0
      },
      "dish_total_actual_nutrients": {
        "calories_kcal": 0.0,
        "protein_g": 0.0,
        "carbohydrates_g": 0.0,
        "fat_g": 0.0
      }
    }
  ],
  "total_meal_nutrients": {
    "calories_kcal": 337.95,
    "protein_g": 13.32,
    "carbohydrates_g": 56.19,
    "fat_g": 6.67
  },
  "warnings": null,
  "errors": null
}
```

## ğŸ”§ æŠ€è¡“ä»•æ§˜

### å‹•çš„è¨ˆç®—æˆ¦ç•¥ã®æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯

**Dish Level (`dish_level`)**:

- ã‚·ãƒ³ãƒ—ãƒ«ãªå˜å“é£Ÿå“ï¼ˆæœç‰©ã€é£²ã¿ç‰©ã€åŸºæœ¬é£Ÿæï¼‰
- æ¨™æº–åŒ–ã•ã‚ŒãŸæ—¢è£½å“ã§é©åˆ‡ãª USDA ID ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
- ä¾‹: ç·‘èŒ¶ã€ã‚Šã‚“ã”ã€ç™½ç±³

**Ingredient Level (`ingredient_level`)**:

- è¤‡é›‘ãªèª¿ç†æ¸ˆã¿æ–™ç†ï¼ˆç‚’ã‚ç‰©ã€ã‚µãƒ©ãƒ€ã€ã‚¹ãƒ¼ãƒ—ï¼‰
- è¤‡æ•°é£Ÿæã®çµ„ã¿åˆã‚ã›ã§æ–™ç†å…¨ä½“ã® USDA ID ãŒä¸é©åˆ‡ãªå ´åˆ
- ä¾‹: é‡èœç‚’ã‚ã€æ‰‹ä½œã‚Šã‚µãƒ©ãƒ€ã€å‘³å™Œæ±

### æ „é¤Šè¨ˆç®—å¼

```
å®Ÿæ „é¤Šä¾¡ = (100gã‚ãŸã‚Šæ „é¤Šä¾¡ Ã· 100) Ã— æ¨å®šé‡é‡(g)
```

### é›†è¨ˆéšå±¤

1. **é£Ÿæãƒ¬ãƒ™ãƒ«**: å€‹åˆ¥é£Ÿæã®é‡é‡ Ã— 100g æ „é¤Šä¾¡
2. **æ–™ç†ãƒ¬ãƒ™ãƒ«**: é£Ÿæãƒ¬ãƒ™ãƒ«ã®åˆè¨ˆ ã¾ãŸã¯ æ–™ç†å…¨ä½“è¨ˆç®—
3. **é£Ÿäº‹ãƒ¬ãƒ™ãƒ«**: å…¨æ–™ç†ã®æ „é¤Šä¾¡åˆè¨ˆ

## âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

API ã¯ä»¥ä¸‹ã® HTTP ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã—ã¾ã™ï¼š

- `200 OK`: æ­£å¸¸ãªåˆ†æå®Œäº†
- `400 Bad Request`: ä¸æ­£ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆç”»åƒå½¢å¼ã‚¨ãƒ©ãƒ¼ãªã©ï¼‰
- `422 Unprocessable Entity`: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼
- `503 Service Unavailable`: å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆUSDA/Geminiï¼‰ã‚¨ãƒ©ãƒ¼
- `500 Internal Server Error`: ã‚µãƒ¼ãƒãƒ¼å†…éƒ¨ã‚¨ãƒ©ãƒ¼

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### èªè¨¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å ´åˆ

```bash
# ç¾åœ¨ã®èªè¨¼çŠ¶æ…‹ã‚’ç¢ºèª
gcloud auth list

# ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã‚’ç¢ºèª
gcloud config list

# å¿…è¦ã«å¿œã˜ã¦å†åº¦èªè¨¼
gcloud auth application-default login
```

### Vertex AI API ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ãªã„å ´åˆ

```bash
# APIã®æœ‰åŠ¹çŠ¶æ³ã‚’ç¢ºèª
gcloud services list --enabled | grep aiplatform

# æœ‰åŠ¹ã§ãªã„å ´åˆã¯æœ‰åŠ¹åŒ–
gcloud services enable aiplatform.googleapis.com
```

### USDA API ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å ´åˆ

- API ã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
- ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆï¼ˆ3,600 ä»¶/æ™‚ï¼‰ã«é”ã—ã¦ã„ãªã„ã‹ç¢ºèª
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèª

## ğŸ’» é–‹ç™ºæƒ…å ±

- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: FastAPI 0.104+
- **AI ã‚µãƒ¼ãƒ“ã‚¹**: Google Vertex AI (Gemini 2.5 Flash)
- **æ „é¤Šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: USDA FoodData Central API
- **èªè¨¼**: Google Cloud ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ
- **Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 3.9+
- **ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**:
  - `google-cloud-aiplatform` (Vertex AI)
  - `httpx` (éåŒæœŸ HTTP)
  - `pydantic` (ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³)
  - `pillow` (ç”»åƒå‡¦ç†)

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ MIT ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## æ³¨æ„äº‹é …

**ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: API ã‚­ãƒ¼ã‚„ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã¯çµ¶å¯¾ã«ãƒªãƒã‚¸ãƒˆãƒªã«ã‚³ãƒŸãƒƒãƒˆã—ãªã„ã§ãã ã•ã„ã€‚ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦å®‰å…¨ã«ç®¡ç†ã—ã¦ãã ã•ã„ã€‚

## ğŸ“Š ãƒ­ã‚°åˆ†ææ©Ÿèƒ½

API ã®å®Ÿè¡Œãƒ­ã‚°ã‚’è©³ç´°ã«è¨˜éŒ²ãƒ»åˆ†æã™ã‚‹æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚

### ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«

ä»¥ä¸‹ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè‡ªå‹•çš„ã«ç”Ÿæˆã•ã‚Œã¾ã™ï¼š

```
logs/
â”œâ”€â”€ meal_analysis_sessions.jsonl     # ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ãƒ­ã‚°ï¼ˆJSONLå½¢å¼ï¼‰
â”œâ”€â”€ meal_analysis_detailed.jsonl     # è©³ç´°å‡¦ç†ãƒ­ã‚°ï¼ˆJSONLå½¢å¼ï¼‰
â””â”€â”€ *.log                           # å¾“æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
```

### ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«

```bash
# åŸºæœ¬åˆ†æãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
python analyze_logs.py --report

# CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
python analyze_logs.py --export sessions.csv

# é…ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†æï¼ˆ5ç§’ä»¥ä¸Šï¼‰
python analyze_logs.py --slow --threshold 5000

# ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
python analyze_logs.py --errors

# éå»7æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿åˆ†æ
python analyze_logs.py --report --days 7

# æ—¥ä»˜ç¯„å›²æŒ‡å®š
python analyze_logs.py --report --start-date 2025-05-01 --end-date 2025-05-31
```

### ãƒ­ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¾‹

```
ğŸ“Š é£Ÿäº‹åˆ†æAPI ãƒ­ã‚°ãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“Š åŸºæœ¬çµ±è¨ˆ
- **ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°**: 50
- **æˆåŠŸã‚»ãƒƒã‚·ãƒ§ãƒ³**: 48 (96.0%)
- **å¤±æ•—ã‚»ãƒƒã‚·ãƒ§ãƒ³**: 2 (4.0%)

## â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
- **å¹³å‡ç·å®Ÿè¡Œæ™‚é–“**: 8542.3ms
- **å¹³å‡Phase1æ™‚é–“**: 2156.7ms
- **å¹³å‡USDAæ¤œç´¢æ™‚é–“**: 1834.2ms
- **å¹³å‡Phase2æ™‚é–“**: 3251.8ms
- **å¹³å‡æ „é¤Šè¨ˆç®—æ™‚é–“**: 1299.6ms

## ğŸ¯ æˆ¦ç•¥çµ±è¨ˆ
- **Dish Levelæˆ¦ç•¥**: 85å›
- **Ingredient Levelæˆ¦ç•¥**: 127å›
- **æˆ¦ç•¥æ¯”ç‡**: Dish 40.1% vs Ingredient 59.9%
```

## ğŸš€ æœ¬ç•ªç’°å¢ƒã§ã®ä½¿ç”¨

```

============================================================

ğŸ“ ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
============================================================

ğŸ“„ FILE: test_images/food1.jpg
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 91360 bytes
æœ€çµ‚æ›´æ–°: 2024-09-25 18:43:38
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ–¼ï¸ ãƒ†ã‚¹ãƒˆç”»åƒãƒ•ã‚¡ã‚¤ãƒ«

CONTENT: [ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ« - å†…å®¹ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“]

============================================================

ğŸ“„ FILE: phase1_analysis_result_v2.json
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 8935 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 17:35:50
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“‹ JSONãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«

CONTENT:
```
{
  "dishes": [
    {
      "dish_name": "White Rice",
      "type": "Main course",
      "quantity_on_plate": "One bowl, approximately 200g",
      "ingredients": [
        {
          "ingredient_name": "Cooked White Rice",
          "weight_g": 200.0
        }
      ],
      "usda_query_candidates": [
        {
          "query_term": "Cooked white rice",
          "granularity_level": "ingredient",
          "original_term": "White Rice",
          "reason_for_query": "Direct query for cooked white rice, a common staple."
        },
        {
          "query_term": "Short grain rice, cooked",
          "granularity_level": "ingredient",
          "original_term": "White Rice",
          "reason_for_query": "More specific type of rice commonly used in Japanese cuisine."
        }
      ]
    },
    {
      "dish_name": "Miso Soup",
      "type": "Side dish",
      "quantity_on_plate": "One bowl, approximately 200ml",
      "ingredients": [
        {
          "ingredient_name": "Miso Paste",
          "weight_g": 15.0
        },
        {
          "ingredient_name": "Tofu",
          "weight_g": 30.0
        },
        {
          "ingredient_name": "Wakame Seaweed",
          "weight_g": 5.0
        },
        {
          "ingredient_name": "Dashi Broth",
          "weight_g": 150.0
        }
      ],
      "usda_query_candidates": [
        {
          "query_term": "Miso soup",
          "granularity_level": "dish",
          "original_term": "Miso Soup",
          "reason_for_query": "Direct query for the complete dish."
        },
        {
          "query_term": "Miso paste",
          "granularity_level": "ingredient",
          "original_term": "Miso Paste",
          "reason_for_query": "Key ingredient in miso soup."
        },
        {
          "query_term": "Tofu, firm",
          "granularity_level": "ingredient",
          "original_term": "Tofu",
          "reason_for_query": "Common type of tofu used in soup."
        },
        {
          "query_term": "Wakame seaweed",
          "granularity_level": "ingredient",
          "original_term": "Wakame Seaweed",
          "reason_for_query": "Specific type of seaweed visible."
        },
        {
          "query_term": "Fish broth",
          "granularity_level": "ingredient",
          "original_term": "Dashi Broth",
          "reason_for_query": "Common base for dashi, more likely to be found in USDA than 'dashi'."
        }
      ]
    },
    {
      "dish_name": "Mixed Salad",
      "type": "Side dish",
      "quantity_on_plate": "One bowl",
      "ingredients": [
        {
          "ingredient_name": "Green Leaf Lettuce",
          "weight_g": 50.0
        },
        {
          "ingredient_name": "Tomato",
          "weight_g": 80.0
        },
        {
          "ingredient_name": "Boiled Egg",
          "weight_g": 50.0
        },
        {
          "ingredient_name": "Deli Ham",
          "weight_g": 30.0
        },
        {
          "ingredient_name": "Salad Dressing",
          "weight_g": 30.0
        }
      ],
      "usda_query_candidates": [
        {
          "query_term": "Mixed green salad",
          "granularity_level": "dish",
          "original_term": "Mixed Salad",
          "reason_for_query": "General query for a common salad type."
        },
        {
          "query_term": "Green leaf lettuce",
          "granularity_level": "ingredient",
          "original_term": "Green Leaf Lettuce",
          "reason_for_query": "Primary leafy green in the salad."
        },
        {
          "query_term": "Tomato, raw",
          "granularity_level": "ingredient",
          "original_term": "Tomato",
          "reason_for_query": "Visible vegetable component."
        },
        {
          "query_term": "Egg, hard-boiled",
          "granularity_level": "ingredient",
          "original_term": "Boiled Egg",
          "reason_for_query": "Protein component."
        },
        {
          "query_term": "Ham, sliced",
          "granularity_level": "ingredient",
          "original_term": "Deli Ham",
          "reason_for_query": "Visible meat component."
        },
        {
          "query_term": "Sesame dressing",
          "granularity_level": "ingredient",
          "original_term": "Salad Dressing",
          "reason_for_query": "Likely type of dressing based on appearance in Japanese meal."
        },
        {
          "query_term": "Peanut dressing",
          "granularity_level": "ingredient",
          "original_term": "Salad Dressing",
          "reason_for_query": "Alternative likely dressing type."
        }
      ]
    },
    {
      "dish_name": "Shirasu (Boiled Whitebait)",
      "type": "Side dish",
      "quantity_on_plate": "One small bowl, approximately 50g",
      "ingredients": [
        {
          "ingredient_name": "Boiled Whitebait",
          "weight_g": 50.0
        }
      ],
      "usda_query_candidates": [
        {
          "query_term": "Whitebait, boiled",
          "granularity_level": "ingredient",
          "original_term": "Boiled Whitebait",
          "reason_for_query": "Direct query for the specific fish."
        },
        {
          "query_term": "Sardine, canned in water",
          "granularity_level": "ingredient",
          "original_term": "Boiled Whitebait",
          "reason_for_query": "Similar small fish if 'whitebait' is not found directly."
        }
      ]
    },
    {
      "dish_name": "Hijiki Nimono (Simmered Hijiki)",
      "type": "Side dish",
      "quantity_on_plate": "One small bowl, approximately 50g",
      "ingredients": [
        {
          "ingredient_name": "Hijiki Seaweed",
          "weight_g": 30.0
        },
        {
          "ingredient_name": "Carrot",
          "weight_g": 10.0
        },
        {
          "ingredient_name": "Fried Tofu Pouch (Aburaage)",
          "weight_g": 10.0
        },
        {
          "ingredient_name": "Soy Sauce",
          "weight_g": 5.0
        },
        {
          "ingredient_name": "Mirin",
          "weight_g": 5.0
        }
      ],
      "usda_query_candidates": [
        {
          "query_term": "Hijiki seaweed, cooked",
          "granularity_level": "ingredient",
          "original_term": "Hijiki Seaweed",
          "reason_for_query": "Direct query for the main ingredient."
        },
        {
          "query_term": "Carrot, cooked",
          "granularity_level": "ingredient",
          "original_term": "Carrot",
          "reason_for_query": "Visible vegetable component."
        },
        {
          "query_term": "Fried tofu",
          "granularity_level": "ingredient",
          "original_term": "Fried Tofu Pouch (Aburaage)",
          "reason_for_query": "Common ingredient in nimono dishes."
        },
        {
          "query_term": "Soy sauce",
          "granularity_level": "ingredient",
          "original_term": "Soy Sauce",
          "reason_for_query": "Key seasoning."
        },
        {
          "query_term": "Mirin",
          "granularity_level": "ingredient",
          "original_term": "Mirin",
          "reason_for_query": "Common Japanese cooking wine, may or may not be in USDA."
        }
      ]
    },
    {
      "dish_name": "Assorted Pickles (Tsukemono)",
      "type": "Side dish",
      "quantity_on_plate": "One small plate, assorted",
      "ingredients": [
        {
          "ingredient_name": "Pickled Cucumber",
          "weight_g": 30.0
        },
        {
          "ingredient_name": "Pickled Daikon Radish",
          "weight_g": 30.0
        },
        {
          "ingredient_name": "Pickled Napa Cabbage",
          "weight_g": 20.0
        }
      ],
      "usda_query_candidates": [
        {
          "query_term": "Pickled cucumber",
          "granularity_level": "ingredient",
          "original_term": "Pickled Cucumber",
          "reason_for_query": "Direct query for a visible pickled vegetable."
        },
        {
          "query_term": "Pickled daikon",
          "granularity_level": "ingredient",
          "original_term": "Pickled Daikon Radish",
          "reason_for_query": "Direct query for a visible pickled vegetable."
        },
        {
          "query_term": "Kimchi",
          "granularity_level": "ingredient",
          "original_term": "Pickled Napa Cabbage",
          "reason_for_query": "Similar fermented cabbage product, if specific pickled napa cabbage is not found."
        }
      ]
    },
    {
      "dish_name": "Water",
      "type": "Drink",
      "quantity_on_plate": "One glass, approximately 200ml",
      "ingredients": [
        {
          "ingredient_name": "Water",
          "weight_g": 200.0
        }
      ],
      "usda_query_candidates": [
        {
          "query_term": "Water, tap",
          "granularity_level": "ingredient",
          "original_term": "Water",
          "reason_for_query": "Direct query for water."
        }
      ]
    }
  ]
}
```

============================================================

ğŸ“„ FILE: phase2_analysis_result_v2.json
--------------------------------------------------
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 22541 bytes
æœ€çµ‚æ›´æ–°: 2025-05-29 18:29:34
å­˜åœ¨: âœ…
ã‚¿ã‚¤ãƒ—: ğŸ“‹ JSONãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«

CONTENT:
```
{
  "dishes": [
    {
      "dish_name": "White Rice",
      "type": "Main course",
      "quantity_on_plate": "One bowl, approximately 200g",
      "calculation_strategy": "ingredient_level",
      "reason_for_strategy": "The dish consists of a single ingredient, 'Cooked White Rice,' which can be accurately represented by a specific FDC ID for cooked rice.",
      "fdc_id": 0,
      "usda_source_description": "null",
      "reason_for_choice": "null",
      "key_nutrients_per_100g": null,
      "ingredients": [
        {
          "ingredient_name": "Cooked White Rice",
          "weight_g": 200.0,
          "fdc_id": 168932,
          "usda_source_description": "Rice, white, short-grain, cooked, unenriched",
          "reason_for_choice": "This SR Legacy entry specifically describes cooked white short-grain rice, which is typical for Japanese meals, and is unenriched, representing a common form. It has a high score and is more specific than general 'cooked white rice' FNDDS entries.",
          "key_nutrients_per_100g": {
            "calories_kcal": 130.0,
            "protein_g": 2.36,
            "fat_g": 0.19,
            "carbohydrates_g": 28.73,
            "sodium_mg": 0.0
          },
          "actual_nutrients": {
            "calories_kcal": 260.0,
            "protein_g": 4.72,
            "carbohydrates_g": 57.46,
            "fat_g": 0.38,
            "fiber_g": null,
            "sugars_g": null,
            "sodium_mg": 0.0
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 260.0,
        "protein_g": 4.72,
        "carbohydrates_g": 57.46,
        "fat_g": 0.38,
        "fiber_g": null,
        "sugars_g": null,
        "sodium_mg": 0.0
      }
    },
    {
      "dish_name": "Miso Soup",
      "type": "Side dish",
      "quantity_on_plate": "One bowl, approximately 200ml",
      "calculation_strategy": "dish_level",
      "reason_for_strategy": "A highly relevant branded FDC ID exists that accurately represents the common ingredients of miso soup (miso, tofu, wakame, fish broth), providing a more holistic and likely accurate nutritional profile than summing individual ingredients.",
      "fdc_id": 2147271,
      "usda_source_description": "MISO SOUP",
      "reason_for_choice": "This branded FDC entry explicitly lists 'MISO (WATER, SOYBEANS, RICE, SALT), TOFU (WATER, SOYBEANS, CALCIUM SULFATE), WAKAME (SEAWEED), FISH BROTH (DRIED CRUSHED BONITO, KELP, BONITO EXTRACT' in its ingredients, which perfectly matches the components of the Miso Soup in the meal. It has a high score and is a direct match for the dish.",
      "key_nutrients_per_100g": {
        "calories_kcal": 26.0,
        "sugars_g": 1.12,
        "protein_g": 1.92,
        "fat_g": 0.8,
        "sodium_mg": 358.0,
        "carbohydrates_g": 2.08,
        "fiber_g": 0.5
      },
      "ingredients": [
        {
          "ingredient_name": "Miso Paste",
          "weight_g": 15.0,
          "fdc_id": 2027667,
          "usda_source_description": "MISO PASTE",
          "reason_for_choice": "This branded miso paste is a good specific match for miso paste, listing common ingredients.",
          "key_nutrients_per_100g": {
            "calories_kcal": 167.0,
            "fat_g": 5.56,
            "sugars_g": 11.11,
            "carbohydrates_g": 22.22,
            "protein_g": 11.11,
            "sodium_mg": 4611.0,
            "fiber_g": 5.6
          },
          "actual_nutrients": null
        },
        {
          "ingredient_name": "Tofu",
          "weight_g": 30.0,
          "fdc_id": 172475,
          "usda_source_description": "Tofu, raw, firm, prepared with calcium sulfate",
          "reason_for_choice": "This SR Legacy entry for firm tofu is a good generic representation of the tofu likely used in miso soup.",
          "key_nutrients_per_100g": {
            "calories_kcal": 144.0,
            "protein_g": 17.27,
            "fat_g": 8.72,
            "carbohydrates_g": 2.78,
            "fiber_g": 2.3,
            "sodium_mg": 14.0
          },
          "actual_nutrients": null
        },
        {
          "ingredient_name": "Wakame Seaweed",
          "weight_g": 5.0,
          "fdc_id": 170496,
          "usda_source_description": "Seaweed, wakame, raw",
          "reason_for_choice": "This SR Legacy entry is a direct and accurate match for wakame seaweed.",
          "key_nutrients_per_100g": {
            "calories_kcal": 45.0,
            "protein_g": 3.03,
            "fat_g": 0.64,
            "carbohydrates_g": 9.14,
            "fiber_g": 0.5,
            "sugars_g": 0.65,
            "sodium_mg": 872.0
          },
          "actual_nutrients": null
        },
        {
          "ingredient_name": "Dashi Broth",
          "weight_g": 150.0,
          "fdc_id": 171606,
          "usda_source_description": "Fish broth",
          "reason_for_choice": "This SR Legacy entry for fish broth is the closest and most appropriate match for dashi broth, which is typically fish-based.",
          "key_nutrients_per_100g": {
            "calories_kcal": 16.0,
            "protein_g": 2.0,
            "fat_g": 0.6,
            "carbohydrates_g": 0.4,
            "fiber_g": 0.0,
            "sugars_g": 0.09,
            "sodium_mg": 200.0
          },
          "actual_nutrients": null
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 52.0,
        "protein_g": 3.84,
        "carbohydrates_g": 4.16,
        "fat_g": 1.6,
        "fiber_g": 1.0,
        "sugars_g": 2.24,
        "sodium_mg": 716.0
      }
    },
    {
      "dish_name": "Mixed Salad",
      "type": "Side dish",
      "quantity_on_plate": "One bowl",
      "calculation_strategy": "ingredient_level",
      "reason_for_strategy": "The dish is a complex mixture of several distinct ingredients (vegetables, protein, dressing) for which no single, representative FDC ID exists. Calculating at the ingredient level allows for greater accuracy by accounting for each component individually.",
      "fdc_id": 0,
      "usda_source_description": "null",
      "reason_for_choice": "null",
      "key_nutrients_per_100g": null,
      "ingredients": [
        {
          "ingredient_name": "Green Leaf Lettuce",
          "weight_g": 50.0,
          "fdc_id": 2346391,
          "usda_source_description": "Lettuce, leaf, green, raw",
          "reason_for_choice": "This Foundation data entry is a direct and accurate match for raw green leaf lettuce, providing high-quality data.",
          "key_nutrients_per_100g": {
            "protein_g": 1.09375,
            "fat_g": 0.1563,
            "carbohydrates_g": 4.06615,
            "sodium_mg": 28.88
          },
          "actual_nutrients": {
            "calories_kcal": 0.0,
            "protein_g": 0.55,
            "carbohydrates_g": 2.03,
            "fat_g": 0.08,
            "fiber_g": null,
            "sugars_g": null,
            "sodium_mg": 14.44
          }
        },
        {
          "ingredient_name": "Tomato",
          "weight_g": 80.0,
          "fdc_id": 170457,
          "usda_source_description": "Tomatoes, red, ripe, raw, year round average",
          "reason_for_choice": "This SR Legacy entry provides a good general representation of raw red tomatoes, which are visible in the salad.",
          "key_nutrients_per_100g": {
            "calories_kcal": 18.0,
            "protein_g": 0.88,
            "fat_g": 0.2,
            "carbohydrates_g": 3.89,
            "fiber_g": 1.2,
            "sugars_g": 2.63,
            "sodium_mg": 5.0
          },
          "actual_nutrients": {
            "calories_kcal": 14.4,
            "protein_g": 0.7,
            "carbohydrates_g": 3.11,
            "fat_g": 0.16,
            "fiber_g": 0.96,
            "sugars_g": 2.1,
            "sodium_mg": 4.0
          }
        },
        {
          "ingredient_name": "Boiled Egg",
          "weight_g": 50.0,
          "fdc_id": 173424,
          "usda_source_description": "Egg, whole, cooked, hard-boiled",
          "reason_for_choice": "This SR Legacy entry is a perfect match for a hard-boiled egg, which is clearly visible in the salad.",
          "key_nutrients_per_100g": {
            "calories_kcal": 155.0,
            "protein_g": 12.58,
            "fat_g": 10.61,
            "carbohydrates_g": 1.12,
            "fiber_g": 0.0,
            "sugars_g": 1.12,
            "sodium_mg": 124.0
          },
          "actual_nutrients": {
            "calories_kcal": 77.5,
            "protein_g": 6.29,
            "carbohydrates_g": 0.56,
            "fat_g": 5.3,
            "fiber_g": 0.0,
            "sugars_g": 0.56,
            "sodium_mg": 62.0
          }
        },
        {
          "ingredient_name": "Deli Ham",
          "weight_g": 30.0,
          "fdc_id": 746952,
          "usda_source_description": "Ham, sliced, restaurant",
          "reason_for_choice": "This Foundation data entry for sliced ham is a good general representation of deli ham, which is a common protein addition to salads.",
          "key_nutrients_per_100g": null,
          "actual_nutrients": null
        },
        {
          "ingredient_name": "Salad Dressing",
          "weight_g": 30.0,
          "fdc_id": 2710211,
          "usda_source_description": "Sesame dressing",
          "reason_for_choice": "Given the context of a Japanese meal and the appearance of the dressing, sesame dressing is a highly plausible choice. This FNDDS entry is a direct match for 'Sesame dressing' and has the highest score among relevant dressing options.",
          "key_nutrients_per_100g": {
            "protein_g": 3.1,
            "fat_g": 45.2,
            "carbohydrates_g": 8.6,
            "calories_kcal": 443.0,
            "sugars_g": 8.32,
            "fiber_g": 1.0,
            "sodium_mg": 1000.0
          },
          "actual_nutrients": {
            "calories_kcal": 132.9,
            "protein_g": 0.93,
            "carbohydrates_g": 2.58,
            "fat_g": 13.56,
            "fiber_g": 0.3,
            "sugars_g": 2.5,
            "sodium_mg": 300.0
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 224.8,
        "protein_g": 8.47,
        "carbohydrates_g": 8.28,
        "fat_g": 19.1,
        "fiber_g": 1.26,
        "sugars_g": 5.16,
        "sodium_mg": 380.44
      }
    },
    {
      "dish_name": "Shirasu (Boiled Whitebait)",
      "type": "Side dish",
      "quantity_on_plate": "One small bowl, approximately 50g",
      "calculation_strategy": "ingredient_level",
      "reason_for_strategy": "The dish consists of a single ingredient, 'Boiled Whitebait.' While a direct FDC ID for whitebait was not found, a suitable proxy (sardines) can be used at the ingredient level.",
      "fdc_id": 0,
      "usda_source_description": "null",
      "reason_for_choice": "null",
      "key_nutrients_per_100g": null,
      "ingredients": [
        {
          "ingredient_name": "Boiled Whitebait",
          "weight_g": 50.0,
          "fdc_id": 2706293,
          "usda_source_description": "Fish, sardines, canned",
          "reason_for_choice": "No direct FDC ID for 'whitebait' was found. Sardines are a small, oily fish, similar in nutritional profile to whitebait, making this FNDDS entry a reasonable proxy for the boiled whitebait.",
          "key_nutrients_per_100g": {
            "protein_g": 24.6,
            "fat_g": 11.4,
            "carbohydrates_g": 0.0,
            "calories_kcal": 208.0,
            "sugars_g": 0.0,
            "fiber_g": 0.0,
            "sodium_mg": 307.0
          },
          "actual_nutrients": {
            "calories_kcal": 104.0,
            "protein_g": 12.3,
            "carbohydrates_g": 0.0,
            "fat_g": 5.7,
            "fiber_g": 0.0,
            "sugars_g": 0.0,
            "sodium_mg": 153.5
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 104.0,
        "protein_g": 12.3,
        "carbohydrates_g": 0.0,
        "fat_g": 5.7,
        "fiber_g": 0.0,
        "sugars_g": 0.0,
        "sodium_mg": 153.5
      }
    },
    {
      "dish_name": "Hijiki Nimono (Simmered Hijiki)",
      "type": "Side dish",
      "quantity_on_plate": "One small bowl, approximately 50g",
      "calculation_strategy": "ingredient_level",
      "reason_for_strategy": "This is a prepared dish with multiple distinct ingredients and specific seasonings. No single FDC ID accurately represents the entire dish, making an ingredient-level calculation essential for precise nutritional analysis.",
      "fdc_id": 0,
      "usda_source_description": "null",
      "reason_for_choice": "null",
      "key_nutrients_per_100g": null,
      "ingredients": [
        {
          "ingredient_name": "Hijiki Seaweed",
          "weight_g": 30.0,
          "fdc_id": 2709989,
          "usda_source_description": "Seaweed, cooked, no added fat",
          "reason_for_choice": "While not specifically 'hijiki,' this FNDDS entry for generic cooked seaweed without added fat is the most appropriate available option for cooked hijiki, which is typically simmered.",
          "key_nutrients_per_100g": {
            "protein_g": 3.51,
            "fat_g": 0.49,
            "carbohydrates_g": 7.94,
            "calories_kcal": 41.0,
            "sugars_g": 0.58,
            "fiber_g": 0.7,
            "sodium_mg": 384.0
          },
          "actual_nutrients": {
            "calories_kcal": 12.3,
            "protein_g": 1.05,
            "carbohydrates_g": 2.38,
            "fat_g": 0.15,
            "fiber_g": 0.21,
            "sugars_g": 0.17,
            "sodium_mg": 115.2
          }
        },
        {
          "ingredient_name": "Carrot",
          "weight_g": 10.0,
          "fdc_id": 2710793,
          "usda_source_description": "Carrots, cooked, as ingredient",
          "reason_for_choice": "This FNDDS entry is a good general match for cooked carrots used as an ingredient in a dish.",
          "key_nutrients_per_100g": {
            "protein_g": 0.98,
            "fat_g": 0.36,
            "carbohydrates_g": 10.7,
            "calories_kcal": 50.0,
            "sugars_g": 4.94,
            "fiber_g": 3.2,
            "sodium_mg": 91.0
          },
          "actual_nutrients": {
            "calories_kcal": 5.0,
            "protein_g": 0.1,
            "carbohydrates_g": 1.07,
            "fat_g": 0.04,
            "fiber_g": 0.32,
            "sugars_g": 0.49,
            "sodium_mg": 9.1
          }
        },
        {
          "ingredient_name": "Fried Tofu Pouch (Aburaage)",
          "weight_g": 10.0,
          "fdc_id": 172451,
          "usda_source_description": "Tofu, fried",
          "reason_for_choice": "This SR Legacy entry is a direct and accurate match for fried tofu, which is what 'Aburaage' is.",
          "key_nutrients_per_100g": {
            "calories_kcal": 270.0,
            "protein_g": 18.82,
            "fat_g": 20.18,
            "carbohydrates_g": 8.86,
            "fiber_g": 3.9,
            "sugars_g": 2.72,
            "sodium_mg": 16.0
          },
          "actual_nutrients": {
            "calories_kcal": 27.0,
            "protein_g": 1.88,
            "carbohydrates_g": 0.89,
            "fat_g": 2.02,
            "fiber_g": 0.39,
            "sugars_g": 0.27,
            "sodium_mg": 1.6
          }
        },
        {
          "ingredient_name": "Soy Sauce",
          "weight_g": 5.0,
          "fdc_id": 2707442,
          "usda_source_description": "Soy sauce",
          "reason_for_choice": "This FNDDS entry provides a general and highly relevant FDC ID for soy sauce, a key seasoning.",
          "key_nutrients_per_100g": {
            "protein_g": 8.14,
            "fat_g": 0.57,
            "carbohydrates_g": 4.93,
            "calories_kcal": 53.0,
            "sugars_g": 0.4,
            "fiber_g": 0.8,
            "sodium_mg": 5490.0
          },
          "actual_nutrients": {
            "calories_kcal": 2.65,
            "protein_g": 0.41,
            "carbohydrates_g": 0.25,
            "fat_g": 0.03,
            "fiber_g": 0.04,
            "sugars_g": 0.02,
            "sodium_mg": 274.5
          }
        },
        {
          "ingredient_name": "Mirin",
          "weight_g": 5.0,
          "fdc_id": 2114521,
          "usda_source_description": "MIRIN SWEET COOKING SEASONING, MIRIN",
          "reason_for_choice": "This branded FDC entry is a direct match for Mirin, a common Japanese cooking seasoning.",
          "key_nutrients_per_100g": {
            "sugars_g": 33.33,
            "protein_g": 0.0,
            "calories_kcal": 300.0,
            "fat_g": 0.0,
            "carbohydrates_g": 60.0,
            "sodium_mg": 667.0
          },
          "actual_nutrients": {
            "calories_kcal": 15.0,
            "protein_g": 0.0,
            "carbohydrates_g": 3.0,
            "fat_g": 0.0,
            "fiber_g": null,
            "sugars_g": 1.67,
            "sodium_mg": 33.35
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 61.95,
        "protein_g": 3.44,
        "carbohydrates_g": 7.59,
        "fat_g": 2.24,
        "fiber_g": 0.96,
        "sugars_g": 2.62,
        "sodium_mg": 433.75
      }
    },
    {
      "dish_name": "Assorted Pickles (Tsukemono)",
      "type": "Side dish",
      "quantity_on_plate": "One small plate, assorted",
      "calculation_strategy": "ingredient_level",
      "reason_for_strategy": "The dish consists of multiple distinct types of pickled vegetables. No single FDC ID exists for 'assorted pickles,' necessitating an ingredient-level calculation for accuracy.",
      "fdc_id": 0,
      "usda_source_description": "null",
      "reason_for_choice": "null",
      "key_nutrients_per_100g": null,
      "ingredients": [
        {
          "ingredient_name": "Pickled Cucumber",
          "weight_g": 30.0,
          "fdc_id": 581890,
          "usda_source_description": "PICKLED CUCUMBER",
          "reason_for_choice": "This branded FDC entry is a direct and highly relevant match for pickled cucumber.",
          "key_nutrients_per_100g": {
            "fat_g": 0.0,
            "protein_g": 0.0,
            "fiber_g": 4.8,
            "sugars_g": 4.76,
            "sodium_mg": 57.0,
            "carbohydrates_g": 14.29,
            "calories_kcal": 57.0
          },
          "actual_nutrients": {
            "calories_kcal": 17.1,
            "protein_g": 0.0,
            "carbohydrates_g": 4.29,
            "fat_g": 0.0,
            "fiber_g": 1.44,
            "sugars_g": 1.43,
            "sodium_mg": 17.1
          }
        },
        {
          "ingredient_name": "Pickled Daikon Radish",
          "weight_g": 30.0,
          "fdc_id": 2109917,
          "usda_source_description": "DAIKON RADISH PICKLED WITH RICE BRAN",
          "reason_for_choice": "This branded FDC entry is a direct and accurate match for pickled daikon radish, which is a common Japanese pickle.",
          "key_nutrients_per_100g": {
            "protein_g": 0.0,
            "sodium_mg": 1923.0,
            "fat_g": 0.0,
            "carbohydrates_g": 7.69,
            "calories_kcal": 38.0
          },
          "actual_nutrients": {
            "calories_kcal": 11.4,
            "protein_g": 0.0,
            "carbohydrates_g": 2.31,
            "fat_g": 0.0,
            "fiber_g": null,
            "sugars_g": null,
            "sodium_mg": 576.9
          }
        },
        {
          "ingredient_name": "Pickled Napa Cabbage",
          "weight_g": 20.0,
          "fdc_id": 2710077,
          "usda_source_description": "Kimchi",
          "reason_for_choice": "While not explicitly 'pickled napa cabbage,' Kimchi is a well-known fermented napa cabbage product and serves as the best available FNDDS proxy for general pickled napa cabbage.",
          "key_nutrients_per_100g": {
            "protein_g": 1.1,
            "fat_g": 0.5,
            "carbohydrates_g": 2.4,
            "calories_kcal": 15.0,
            "sugars_g": 1.06,
            "fiber_g": 1.6,
            "sodium_mg": 498.0
          },
          "actual_nutrients": {
            "calories_kcal": 3.0,
            "protein_g": 0.22,
            "carbohydrates_g": 0.48,
            "fat_g": 0.1,
            "fiber_g": 0.32,
            "sugars_g": 0.21,
            "sodium_mg": 99.6
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 31.5,
        "protein_g": 0.22,
        "carbohydrates_g": 7.08,
        "fat_g": 0.1,
        "fiber_g": 1.76,
        "sugars_g": 1.64,
        "sodium_mg": 693.6
      }
    },
    {
      "dish_name": "Water",
      "type": "Drink",
      "quantity_on_plate": "One glass, approximately 200ml",
      "calculation_strategy": "ingredient_level",
      "reason_for_strategy": "The dish consists of a single, simple ingredient for which a direct and accurate FDC ID is available.",
      "fdc_id": 0,
      "usda_source_description": "null",
      "reason_for_choice": "null",
      "key_nutrients_per_100g": null,
      "ingredients": [
        {
          "ingredient_name": "Water",
          "weight_g": 200.0,
          "fdc_id": 2710707,
          "usda_source_description": "Water, tap",
          "reason_for_choice": "This FNDDS entry is a direct and highly relevant match for tap water, which is the most common form of drinking water.",
          "key_nutrients_per_100g": {
            "protein_g": 0.0,
            "fat_g": 0.0,
            "carbohydrates_g": 0.0,
            "calories_kcal": 0.0,
            "sugars_g": 0.0,
            "fiber_g": 0.0,
            "sodium_mg": 4.0
          },
          "actual_nutrients": {
            "calories_kcal": 0.0,
            "protein_g": 0.0,
            "carbohydrates_g": 0.0,
            "fat_g": 0.0,
            "fiber_g": 0.0,
            "sugars_g": 0.0,
            "sodium_mg": 8.0
          }
        }
      ],
      "dish_total_actual_nutrients": {
        "calories_kcal": 0.0,
        "protein_g": 0.0,
        "carbohydrates_g": 0.0,
        "fat_g": 0.0,
        "fiber_g": 0.0,
        "sugars_g": 0.0,
        "sodium_mg": 8.0
      }
    }
  ],
  "total_meal_nutrients": {
    "calories_kcal": 0.0,
    "protein_g": 0.0,
    "carbohydrates_g": 0.0,
    "fat_g": 0.0,
    "fiber_g": null,
    "sugars_g": null,
    "sodium_mg": null
  },
  "warnings": [
    "Could not get nutrition for ingredient 'Deli Ham' (FDC ID: 746952)"
  ],
  "errors": null
}
```

============================================================

ğŸ¯ SUMMARY v2.1
----------------------------------------
ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 32
å­˜åœ¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 32
åˆ†æå®Œäº†æ™‚åˆ»: 2025-05-29 18:37:19

ğŸ“‹ v2.1ã®ä¸»è¦æ”¹å–„ç‚¹:
âœ… USDAã‚¯ã‚¨ãƒªå€™è£œã®è‡ªå‹•ç”Ÿæˆ
âœ… é«˜åº¦ãªæˆ¦ç•¥æ±ºå®šã‚·ã‚¹ãƒ†ãƒ 
âœ… å‹•çš„æ „é¤Šè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
âœ… åŒ…æ‹¬çš„ãƒ­ã‚°æ©Ÿèƒ½
âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ„ãƒ¼ãƒ«

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€test_english_phase1_v2.py ãŠã‚ˆã³
test_english_phase2_v2.pyå®Ÿè¡Œæ™‚ã«é–¢ã‚ã‚‹å…¨ã¦ã®
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãªå†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
