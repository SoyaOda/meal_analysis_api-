#!/usr/bin/env python3
"""
Advanced Elasticsearch Strategic Search Test - Standalone Edition v3.0
APIã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ã‚ãšã«ç›´æ¥MealAnalysisPipelineã§food1.jpgã‚’åˆ†æã—ã€
test_advanced_elasticsearch_search.pyã¨åŒæ§˜ã®Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import asyncio
import os
import sys
import logging
import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app_v2.pipeline import MealAnalysisPipeline
from app_v2.components.elasticsearch_nutrition_search_component import ElasticsearchNutritionSearchComponent
from app_v2.models.nutrition_search_models import NutritionQueryInput

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def setup_environment():
    """ç’°å¢ƒå¤‰æ•°ã®è¨­å®š"""
    os.environ.setdefault("GOOGLE_APPLICATION_CREDENTIALS", "/Users/odasoya/meal_analysis_api_2/service-account-key.json")
    os.environ.setdefault("GEMINI_PROJECT_ID", "recording-diet-ai-3e7cf")
    os.environ.setdefault("GEMINI_LOCATION", "us-central1")
    os.environ.setdefault("GEMINI_MODEL_NAME", "gemini-2.5-flash-preview-05-20")


def get_image_mime_type(file_path: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰MIMEã‚¿ã‚¤ãƒ—ã‚’æ¨å®š"""
    ext = Path(file_path).suffix.lower()
    mime_types = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.bmp': 'image/bmp',
        '.webp': 'image/webp'
    }
    return mime_types.get(ext, 'image/jpeg')


async def analyze_food1_image_with_detailed_search():
    """food1.jpgã®åˆ†æã‚’å®Ÿè¡Œã—ã€è©³ç´°ãªæ¤œç´¢çµæœåˆ†æã‚‚è¡Œã†"""
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    image_path = "test_images/food1.jpg"
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(image_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
        return None
    
    # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with open(image_path, 'rb') as f:
        image_bytes = f.read()
    
    image_mime_type = get_image_mime_type(image_path)
    
    print(f"ğŸš€ Advanced Elasticsearch Strategic Search Test (Standalone) é–‹å§‹")
    print(f"ğŸ“ åˆ†æå¯¾è±¡: {image_path}")
    print(f"ğŸ“Š ç”»åƒã‚µã‚¤ã‚º: {len(image_bytes):,} bytes")
    print(f"ğŸ” MIMEã‚¿ã‚¤ãƒ—: {image_mime_type}")
    print(f"ğŸ”§ æ¤œç´¢æ–¹æ³•: Advanced Elasticsearch Strategic Search (APIã‚µãƒ¼ãƒãƒ¼ä¸è¦)")
    print("=" * 60)
    
    # çµæœä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆtest_advanced_elasticsearch_search.pyã¨åŒæ§˜ã®æ§‹é€ ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    main_results_dir = f"analysis_results/elasticsearch_test_{timestamp}"
    os.makedirs(main_results_dir, exist_ok=True)
    
    # å®Œå…¨åˆ†æçµæœä¿å­˜ç”¨ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    api_calls_dir = f"{main_results_dir}/api_calls"
    os.makedirs(api_calls_dir, exist_ok=True)
    
    print(f"ğŸ“ ãƒ¡ã‚¤ãƒ³çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {main_results_dir}")
    print(f"ğŸ“ å®Œå…¨åˆ†æçµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {api_calls_dir}")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–ï¼ˆElasticsearchæ¤œç´¢ã‚’ä½¿ç”¨ï¼‰
    pipeline = MealAnalysisPipeline(
        use_elasticsearch_search=True,
        use_local_nutrition_search=False
    )
    
    try:
        # Step 1: å®Œå…¨åˆ†æå®Ÿè¡Œ
        print(f"\nğŸ”„ Step 1: å®Œå…¨é£Ÿäº‹åˆ†æå®Ÿè¡Œä¸­...")
        analysis_start_time = time.time()
        
        result = await pipeline.execute_complete_analysis(
            image_bytes=image_bytes,
            image_mime_type=image_mime_type,
            save_detailed_logs=False
        )
        
        analysis_end_time = time.time()
        analysis_time = analysis_end_time - analysis_start_time
        
        print(f"âœ… å®Œå…¨åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼ ({analysis_time:.2f}ç§’)")
        
        # åŸºæœ¬çµæœã®è¡¨ç¤º
        print_basic_analysis_summary(result)
        
        # Step 2: Phase1çµæœã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡º
        print(f"\nğŸ”„ Step 2: Phase1çµæœã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡ºä¸­...")
        
        phase1_result = result.get("phase1_result", {})
        dishes = phase1_result.get("dishes", [])
        
        all_queries = []
        dish_names = []
        ingredient_names = []
        
        for dish in dishes:
            dish_name = dish.get("dish_name")
            if dish_name:
                dish_names.append(dish_name)
                all_queries.append(dish_name)
            
            ingredients = dish.get("ingredients", [])
            for ingredient in ingredients:
                ingredient_name = ingredient.get("ingredient_name")
                if ingredient_name:
                    ingredient_names.append(ingredient_name)
                    all_queries.append(ingredient_name)
        
        # é‡è¤‡ã‚’é™¤å»
        all_queries = list(set(all_queries))
        dish_names = list(set(dish_names))
        ingredient_names = list(set(ingredient_names))
        
        print(f"ğŸ“Š æŠ½å‡ºã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª:")
        print(f"   - æ–™ç†å: {len(dish_names)}å€‹")
        print(f"   - é£Ÿæå: {len(ingredient_names)}å€‹")
        print(f"   - ç·ã‚¯ã‚¨ãƒªæ•°: {len(all_queries)}å€‹")
        
        if len(all_queries) == 0:
            print("âŒ Phase1çµæœã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼")
            return None
        
        # Step 3: Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢å®Ÿè¡Œ
        print(f"\nğŸ”„ Step 3: Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢å®Ÿè¡Œä¸­...")
        
        # ElasticsearchNutritionSearchComponentã‚’è¦‹å‡ºã—èªåŒ–å¯¾å¿œãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–
        es_component = ElasticsearchNutritionSearchComponent(
            strategic_search_mode=False,   # çµ±åˆæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆã§ã®è¦‹å‡ºã—èªåŒ–æ¤œç´¢ï¼‰
            results_per_db=5,             # å„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰5ã¤ãšã¤çµæœã‚’å–å¾—
            enable_advanced_features=False # æ§‹é€ åŒ–æ¤œç´¢ã¯ç„¡åŠ¹åŒ–ã€è¦‹å‡ºã—èªåŒ–æ¤œç´¢ã«é›†ä¸­
        )
        
        print(f"âœ… Elasticsearchæ¤œç´¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†:")
        print(f"   - è¦‹å‡ºã—èªåŒ–å®Œå…¨ä¸€è‡´ãƒ–ãƒ¼ã‚¹ãƒˆ: {es_component.lemmatized_exact_match_boost}")
        print(f"   - è¤‡åˆèªãƒšãƒŠãƒ«ãƒ†ã‚£: {es_component.compound_word_penalty}")
        print(f"   - è¦‹å‡ºã—èªåŒ–æœ‰åŠ¹: {es_component.enable_lemmatization}")
        
        # æ¤œç´¢å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        nutrition_query_input = NutritionQueryInput(
            ingredient_names=ingredient_names,
            dish_names=dish_names,
            preferred_source="elasticsearch"
        )
        
        print(f"ğŸ“ æ¤œç´¢å…¥åŠ›ãƒ‡ãƒ¼ã‚¿:")
        print(f"   - é£Ÿæå: {len(ingredient_names)}å€‹")
        print(f"   - æ–™ç†å: {len(dish_names)}å€‹")
        print(f"   - ç·æ¤œç´¢èªæ•°: {len(nutrition_query_input.get_all_search_terms())}å€‹")
        
        # è©³ç´°Elasticsearchæ¤œç´¢ã‚’å®Ÿè¡Œ
        search_start_time = time.time()
        
        search_results = await es_component.execute(nutrition_query_input)
        
        search_end_time = time.time()
        search_time = search_end_time - search_start_time
        
        print(f"âœ… Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢å®Œäº† ({search_time:.3f}ç§’)")
        
        # Step 4: æˆ¦ç•¥çš„æ¤œç´¢çµæœã®åˆ†æã¨è¡¨ç¤º
        print(f"\nğŸ”„ Step 4: æˆ¦ç•¥çš„æ¤œç´¢çµæœåˆ†æä¸­...")
        
        search_summary = search_results.search_summary
        
        print(f"\nğŸ“ˆ Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼:")
        print(f"   - ç·æ¤œç´¢æ•°: {search_summary.get('total_searches', 0)}")
        print(f"   - æˆåŠŸãƒãƒƒãƒ: {search_summary.get('successful_matches', 0)}")
        print(f"   - å¤±æ•—æ¤œç´¢: {search_summary.get('failed_searches', 0)}")
        print(f"   - ãƒãƒƒãƒç‡: {search_summary.get('match_rate_percent', 0):.1f}%")
        print(f"   - æ¤œç´¢æ–¹æ³•: {search_summary.get('search_method', 'N/A')}")
        print(f"   - æ¤œç´¢æ™‚é–“: {search_summary.get('search_time_ms', 0)}ms")
        print(f"   - ç·çµæœæ•°: {search_summary.get('total_results', 0)}")
        
        # è¦‹å‡ºã—èªåŒ–ã®åŠ¹æœã‚’è¡¨ç¤º
        if hasattr(search_results, 'advanced_search_metadata') and search_results.advanced_search_metadata:
            metadata = search_results.advanced_search_metadata
            if 'lemmatization_enabled' in metadata:
                print(f"   - è¦‹å‡ºã—èªåŒ–æœ‰åŠ¹: {metadata['lemmatization_enabled']}")
            if 'scoring_parameters' in metadata:
                params = metadata['scoring_parameters']
                print(f"   - å®Œå…¨ä¸€è‡´ãƒ–ãƒ¼ã‚¹ãƒˆ: {params.get('exact_match_boost', 'N/A')}")
                print(f"   - è¤‡åˆèªãƒšãƒŠãƒ«ãƒ†ã‚£: {params.get('compound_word_penalty', 'N/A')}")
        
        # Step 5: çµæœä¿å­˜ï¼ˆtest_advanced_elasticsearch_search.pyã¨åŒæ§˜ã®æ§‹é€ ï¼‰
        print(f"\nğŸ”„ Step 5: æˆ¦ç•¥çš„æ¤œç´¢çµæœä¿å­˜ä¸­...")
        
        analysis_id = result.get("analysis_id", "unknown")
        
        # å®Œå…¨åˆ†æçµæœã‚’ä¿å­˜ï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œçµæœï¼‰
        await save_api_call_results(
            analysis_id=analysis_id,
            complete_analysis_result=result,
            image_filename=os.path.basename(image_path),
            api_calls_dir=api_calls_dir,
            analysis_time=analysis_time
        )
        
        # æˆ¦ç•¥çš„æ¤œç´¢çµæœã‚’ä¿å­˜ï¼ˆtest_advanced_elasticsearch_search.pyã¨åŒæ§˜ï¼‰
        await save_advanced_elasticsearch_results(
            analysis_id=analysis_id,
            search_results=search_results,
            all_queries=all_queries,
            dish_names=dish_names,
            ingredient_names=ingredient_names,
            image_filename=os.path.basename(image_path),
            main_results_dir=main_results_dir
        )
        
        # åŒ…æ‹¬çš„çµæœã‚’ä¿å­˜
        await save_comprehensive_results(
            analysis_id=analysis_id,
            complete_analysis_result=result,
            search_results=search_results,
            all_queries=all_queries,
            dish_names=dish_names,
            ingredient_names=ingredient_names,
            image_filename=os.path.basename(image_path),
            main_results_dir=main_results_dir,
            analysis_time=analysis_time,
            search_time=search_time
        )
        
        print(f"âœ… æˆ¦ç•¥çš„æ¤œç´¢çµæœä¿å­˜å®Œäº†ï¼")
        
        # æœ€çµ‚ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print_detailed_analysis_summary(result, search_results, analysis_time, search_time)
        
        return {
            "complete_analysis": result,
            "detailed_search": search_results,
            "analysis_time": analysis_time,
            "search_time": search_time,
            "saved_to": main_results_dir,
            "api_calls_dir": api_calls_dir
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None


def print_basic_analysis_summary(result: dict):
    """åŸºæœ¬åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    if not result or 'error' in result:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        return
    
    print(f"\nğŸ“‹ åŸºæœ¬åˆ†æçµæœã‚µãƒãƒªãƒ¼ (ID: {result.get('analysis_id', 'N/A')})")
    print("-" * 40)
    
    # Phase1çµæœ
    phase1 = result.get('phase1_result', {})
    dishes = phase1.get('dishes', [])
    detected_items = phase1.get('detected_food_items', [])
    
    print(f"ğŸ½ï¸  æ¤œå‡ºã•ã‚ŒãŸæ–™ç†: {len(dishes)}å€‹")
    for i, dish in enumerate(dishes, 1):
        confidence = dish.get('confidence', 0)
        print(f"   {i}. {dish.get('dish_name', 'N/A')} (ä¿¡é ¼åº¦: {confidence:.2f})")
    
    print(f"\nğŸ¥• æ¤œå‡ºã•ã‚ŒãŸé£Ÿæ: {len(detected_items)}å€‹")
    for i, item in enumerate(detected_items, 1):
        confidence = item.get('confidence', 0)
        print(f"   {i}. {item.get('item_name', 'N/A')} (ä¿¡é ¼åº¦: {confidence:.2f})")
    
    # æ „é¤Šæ¤œç´¢çµæœ
    nutrition_search = result.get('nutrition_search_result', {})
    match_rate = nutrition_search.get('match_rate', 0)
    matches_count = nutrition_search.get('matches_count', 0)
    
    print(f"\nğŸ” åŸºæœ¬æ „é¤Šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç…§åˆçµæœ:")
    print(f"   - ãƒãƒƒãƒä»¶æ•°: {matches_count}ä»¶")
    print(f"   - æˆåŠŸç‡: {match_rate:.1%}")
    print(f"   - æ¤œç´¢æ–¹æ³•: {nutrition_search.get('search_summary', {}).get('search_method', 'elasticsearch')}")


def print_detailed_analysis_summary(complete_result: dict, search_results, analysis_time: float, search_time: float):
    """Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢çµæœã®æœ€çµ‚ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    
    print(f"\n{'='*80}")
    print(f"ğŸ¯ Advanced Elasticsearch Strategic Search Test å®Œäº†ã‚µãƒãƒªãƒ¼")
    print(f"{'='*80}")
    
    analysis_id = complete_result.get('analysis_id', 'N/A')
    print(f"ğŸ“‹ åˆ†æID: {analysis_id}")
    
    # å‡¦ç†æ™‚é–“ã‚µãƒãƒªãƒ¼
    print(f"\nâ±ï¸  å‡¦ç†æ™‚é–“ã‚µãƒãƒªãƒ¼:")
    print(f"   - å®Œå…¨åˆ†ææ™‚é–“: {analysis_time:.2f}ç§’")
    print(f"   - æˆ¦ç•¥çš„æ¤œç´¢æ™‚é–“: {search_time:.3f}ç§’")
    print(f"   - ç·å‡¦ç†æ™‚é–“: {analysis_time + search_time:.2f}ç§’")
    
    # æˆ¦ç•¥çš„æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼
    search_summary = search_results.search_summary
    print(f"\nğŸ” æˆ¦ç•¥çš„æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼:")
    print(f"   - ç·æ¤œç´¢æ•°: {search_summary.get('total_searches', 0)}")
    print(f"   - æˆåŠŸãƒãƒƒãƒ: {search_summary.get('successful_matches', 0)}")
    print(f"   - ãƒãƒƒãƒç‡: {search_summary.get('match_rate_percent', 0):.1f}%")
    print(f"   - ç·çµæœæ•°: {search_summary.get('total_results', 0)}")
    
    # æ „é¤Šä¾¡è¨ˆç®—ã¯æœªå®Ÿè£…ï¼ˆPhase2ã¨NutritionCalculationComponentã§å®Ÿè£…äºˆå®šï¼‰
    
    print(f"\nâœ… Advanced Elasticsearch Strategic Search Test å®Œäº†ï¼")
    print(f"ğŸ¯ ç·åˆæˆåŠŸç‡: {search_summary.get('match_rate_percent', 0):.1f}%")


async def save_api_call_results(
    analysis_id: str,
    complete_analysis_result: dict,
    image_filename: str,
    api_calls_dir: str,
    analysis_time: float
):
    """å®Œå…¨åˆ†æçµæœã‚’ä¿å­˜ï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œçµæœï¼‰"""
    
    # å®Œå…¨åˆ†æçµæœç”¨ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    api_analysis_dir = f"{api_calls_dir}/api_analysis_{timestamp}"
    os.makedirs(api_analysis_dir, exist_ok=True)
    
    # å®Œå…¨åˆ†æçµæœã‚’JSONã§ä¿å­˜
    api_result_file = f"{api_analysis_dir}/meal_analysis_{analysis_id}.json"
    with open(api_result_file, 'w', encoding='utf-8') as f:
        json.dump(complete_analysis_result, f, indent=2, ensure_ascii=False)
    
    print(f"   ğŸ’¾ å®Œå…¨åˆ†æçµæœä¿å­˜: {api_analysis_dir}/")


async def save_advanced_elasticsearch_results(
    analysis_id: str,
    search_results,
    all_queries: List[str],
    dish_names: List[str],
    ingredient_names: List[str],
    image_filename: str,
    main_results_dir: str
):
    """Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆtest_advanced_elasticsearch_search.pyã¨åŒæ§˜ï¼‰"""
    
    # ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    image_base = os.path.splitext(image_filename)[0]  # food1, food2, etc.
    results_dir = f"{main_results_dir}/{image_base}"
    os.makedirs(results_dir, exist_ok=True)
    
    # æ¤œç´¢çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
    matches_dict = {}
    for query, match_results in search_results.matches.items():
        if isinstance(match_results, list):
            matches_dict[query] = [
                {
                    "id": match.id,
                    "search_name": match.search_name,
                    "description": match.description,
                    "data_type": match.data_type,
                    "source": match.source,
                    "nutrition": match.nutrition,
                    "weight": match.weight,
                    "score": match.score,
                    "search_metadata": match.search_metadata
                } for match in match_results
            ]
        else:
            matches_dict[query] = {
                "id": match_results.id,
                "search_name": match_results.search_name,
                "description": match_results.description,
                "data_type": match_results.data_type,
                "source": match_results.source,
                "nutrition": match_results.nutrition,
                "weight": match_results.weight,
                "score": match_results.score,
                "search_metadata": match_results.search_metadata
            }
    
    # 1. å…¨æ¤œç´¢çµæœã‚’JSONã§ä¿å­˜
    results_file = os.path.join(results_dir, "advanced_elasticsearch_search_results.json")
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            "analysis_id": analysis_id,
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "image_filename": image_filename,
            "search_method": "elasticsearch_strategic",
            "input_queries": {
                "all_queries": all_queries,
                "dish_names": dish_names,
                "ingredient_names": ingredient_names
            },
            "search_summary": search_results.search_summary,
            "matches": matches_dict,
            "warnings": search_results.warnings,
            "errors": search_results.errors
        }, f, indent=2, ensure_ascii=False)
    
    # 2. æ¤œç´¢ã‚µãƒãƒªãƒ¼ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§ä¿å­˜
    summary_file = os.path.join(results_dir, "advanced_elasticsearch_summary.md")
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(f"# Advanced Elasticsearch Strategic Search Results\n\n")
        f.write(f"**Analysis ID:** {analysis_id}\n")
        f.write(f"**Image:** {image_filename}\n")
        f.write(f"**Timestamp:** {datetime.now().strftime('%Y%m%d_%H%M%S')}\n")
        f.write(f"**Search Method:** Advanced Elasticsearch Strategic Search\n")
        f.write(f"**Total Queries:** {len(all_queries)}\n\n")
        
        # æ¤œç´¢ã‚µãƒãƒªãƒ¼
        summary = search_results.search_summary
        f.write(f"## Search Summary\n\n")
        f.write(f"- **Total searches:** {summary.get('total_searches', 0)}\n")
        f.write(f"- **Successful matches:** {summary.get('successful_matches', 0)}\n")
        f.write(f"- **Failed searches:** {summary.get('failed_searches', 0)}\n")
        f.write(f"- **Match rate:** {summary.get('match_rate_percent', 0):.1f}%\n")
        f.write(f"- **Search time:** {summary.get('search_time_ms', 0)}ms\n")
        f.write(f"- **Total results:** {summary.get('total_results', 0)}\n\n")
    
    print(f"   ğŸ’¾ æ¤œç´¢çµæœä¿å­˜: {results_dir}/")


async def save_comprehensive_results(
    analysis_id: str,
    complete_analysis_result: dict,
    search_results,
    all_queries: List[str],
    dish_names: List[str],
    ingredient_names: List[str],
    image_filename: str,
    main_results_dir: str,
    analysis_time: float,
    search_time: float
):
    """åŒ…æ‹¬çš„çµæœã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§ä¿å­˜ï¼ˆtest_advanced_elasticsearch_search.pyã¨åŒæ§˜ï¼‰"""
    
    # æ¤œç´¢çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
    matches_dict = {}
    for query, match_results in search_results.matches.items():
        if isinstance(match_results, list):
            matches_dict[query] = [
                {
                    "id": match.id,
                    "search_name": match.search_name,
                    "description": match.description,
                    "data_type": match.data_type,
                    "source": match.source,
                    "nutrition": match.nutrition,
                    "weight": match.weight,
                    "score": match.score,
                    "search_metadata": match.search_metadata
                } for match in match_results
            ]
        else:
            matches_dict[query] = {
                "id": match_results.id,
                "search_name": match_results.search_name,
                "description": match_results.description,
                "data_type": match_results.data_type,
                "source": match_results.source,
                "nutrition": match_results.nutrition,
                "weight": match_results.weight,
                "score": match_results.score,
                "search_metadata": match_results.search_metadata
            }
    
    # åŒ…æ‹¬çš„çµæœã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§ä¿å­˜
    comprehensive_md_file = os.path.join(main_results_dir, "comprehensive_multi_image_results.md")
    with open(comprehensive_md_file, 'w', encoding='utf-8') as f:
        f.write(f"# Comprehensive Multi-Image Advanced Elasticsearch Strategic Search Results\n\n")
        f.write(f"**Test Type:** Standalone Advanced Elasticsearch Strategic Search\n")
        f.write(f"**Timestamp:** {datetime.now().strftime('%Y%m%d_%H%M%S')}\n")
        f.write(f"**Images Tested:** 1 ({image_filename})\n\n")
        
        # å…¨ä½“ã‚µãƒãƒªãƒ¼
        f.write(f"## Overall Summary\n\n")
        f.write(f"- **Images tested:** 1/1\n")
        f.write(f"- **Total queries:** {len(all_queries)}\n")
        f.write(f"- **Total successful matches:** {search_results.search_summary.get('successful_matches', 0)}\n")
        f.write(f"- **Total failed searches:** {search_results.search_summary.get('failed_searches', 0)}\n")
        f.write(f"- **Overall match rate:** {search_results.search_summary.get('match_rate_percent', 0):.1f}%\n")
        f.write(f"- **Total search time:** {search_results.search_summary.get('search_time_ms', 0)}ms\n")
        f.write(f"- **Total results found:** {search_results.search_summary.get('total_results', 0)}\n")
        f.write(f"- **Complete analysis time:** {analysis_time:.2f}s\n")
        f.write(f"- **Detailed search time:** {search_time:.3f}s\n\n")
        
        # ç”»åƒåˆ¥çµæœ
        f.write(f"## Per-Image Results Breakdown\n\n")
        f.write(f"### {image_filename}\n\n")
        f.write(f"- **Queries:** {len(all_queries)} | **Matches:** {search_results.search_summary.get('successful_matches', 0)} | **Success:** {search_results.search_summary.get('match_rate_percent', 0):.1f}%\n")
        f.write(f"- **Time:** {search_results.search_summary.get('search_time_ms', 0)}ms | **Results:** {search_results.search_summary.get('total_results', 0)}\n")
        f.write(f"- **Dishes:** {len(dish_names)} | **Ingredients:** {len(ingredient_names)}\n\n")
        
        # æ¤œå‡ºã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ 
        f.write(f"## Detected Items\n\n")
        f.write(f"**Dishes ({len(dish_names)}):** {', '.join(dish_names)}\n\n")
        f.write(f"**Ingredients ({len(ingredient_names)}):** {', '.join(ingredient_names)}\n\n")
        
        # è©³ç´°æ¤œç´¢çµæœ
        f.write(f"## Detailed Search Results\n\n")
        
        # æ–™ç†æ¤œç´¢çµæœ
        f.write(f"### Dish Search Results\n\n")
        for dish_name in dish_names:
            if dish_name in matches_dict:
                matches = matches_dict[dish_name]
                if isinstance(matches, list) and len(matches) > 0:
                    f.write(f"**{dish_name} (Dish)**\n\n")
                    f.write(f"Found {len(matches)} results:\n\n")
                    for i, match in enumerate(matches, 1):
                        f.write(f"   {i}. **{match['search_name']}** (Score: {match['score']:.2f})\n")
                        f.write(f"      - Source: {match['source']}\n")
                        f.write(f"      - Data Type: {match['data_type']}\n")
                        if match['nutrition']:
                            nutrition = match['nutrition']
                            f.write(f"      - Nutrition (100g): {nutrition.get('calories_kcal', 0):.1f} kcal, ")
                            f.write(f"P:{nutrition.get('protein_g', 0):.1f}g, ")
                            f.write(f"F:{nutrition.get('fat_g', 0):.1f}g, ")
                            f.write(f"C:{nutrition.get('carbohydrates_g', 0):.1f}g\n")
                        f.write(f"\n")
                    f.write(f"\n")
        
        # é£Ÿææ¤œç´¢çµæœ
        f.write(f"### Ingredient Search Results\n\n")
        for ingredient_name in ingredient_names:
            if ingredient_name in matches_dict:
                matches = matches_dict[ingredient_name]
                if isinstance(matches, list) and len(matches) > 0:
                    f.write(f"**{ingredient_name} (Ingredient)**\n\n")
                    f.write(f"Found {len(matches)} results:\n\n")
                    for i, match in enumerate(matches, 1):
                        f.write(f"   {i}. **{match['search_name']}** (Score: {match['score']:.2f})\n")
                        f.write(f"      - Source: {match['source']}\n")
                        f.write(f"      - Data Type: {match['data_type']}\n")
                        if match['nutrition']:
                            nutrition = match['nutrition']
                            f.write(f"      - Nutrition (100g): {nutrition.get('calories_kcal', 0):.1f} kcal, ")
                            f.write(f"P:{nutrition.get('protein_g', 0):.1f}g, ")
                            f.write(f"F:{nutrition.get('fat_g', 0):.1f}g, ")
                            f.write(f"C:{nutrition.get('carbohydrates_g', 0):.1f}g\n")
                        f.write(f"\n")
                    f.write(f"\n")
    
    print(f"   ğŸ’¾ åŒ…æ‹¬çš„çµæœä¿å­˜: {main_results_dir}/comprehensive_multi_image_results.md")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ Advanced Elasticsearch Strategic Search Test - Standalone Edition v3.0")
    print("ğŸ“ APIã‚µãƒ¼ãƒãƒ¼ä¸è¦ã®ç›´æ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ + Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢")
    print()
    
    # ç’°å¢ƒè¨­å®š
    setup_environment()
    
    try:
        # Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢å®Ÿè¡Œ
        result = asyncio.run(analyze_food1_image_with_detailed_search())
        
        if result:
            print("âœ… Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
            print(f"ğŸ’¾ ãƒ¡ã‚¤ãƒ³çµæœä¿å­˜å…ˆ: {result['saved_to']}")
            print(f"ğŸ’¾ å®Œå…¨åˆ†æçµæœä¿å­˜å…ˆ: {result['api_calls_dir']}")
            return 0
        else:
            print("âŒ Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢ãƒ†ã‚¹ãƒˆå¤±æ•—")
            return 1
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 1
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logger.error(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 