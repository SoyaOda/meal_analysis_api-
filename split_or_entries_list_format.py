#!/usr/bin/env python3
"""
MyNetDiary JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ã€Œorã€ã‚¨ãƒ³ãƒˆãƒªåˆ†å‰²ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒªã‚¹ãƒˆå½¢å¼ç‰ˆï¼‰

search_nameã«ã€Œorã€ãŒå«ã¾ã‚Œã‚‹ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›ã—ã¦ã€
æ¤œç´¢æ™‚ã«å„é …ç›®ã‚’ç‹¬ç«‹è©•ä¾¡ã—æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’æ¡ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

ä¾‹:
"Chickpeas or garbanzo beans" â†’ ["Chickpeas", "garbanzo beans"]
"""

import json
import time
import re
from typing import List, Dict, Any, Union

def clean_food_name(name: str) -> str:
    """é£Ÿå“åã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    # å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
    name = name.strip()
    
    # è¤‡æ•°ã®ç©ºç™½ã‚’å˜ä¸€ã®ç©ºç™½ã«å¤‰æ›
    name = re.sub(r'\s+', ' ', name)
    
    # ä¸è¦ãªè¨˜å·ã‚’é™¤å»ï¼ˆå¿…è¦ã«å¿œã˜ã¦èª¿æ•´ï¼‰
    name = name.replace('  ', ' ')
    
    return name

def convert_or_entries_to_list(data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ã€Œorã€ã‚’å«ã‚€ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›"""
    
    new_data = []
    or_entries_processed = 0
    total_list_entries = 0
    
    for item in data:
        search_name = item.get('search_name', '')
        
        # ã€Œorã€ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ãã®ã¾ã¾è¿½åŠ ï¼ˆæ–‡å­—åˆ—ã®ã¾ã¾ï¼‰
        if ' or ' not in search_name.lower():
            new_data.append(item)
            continue
        
        # ã€Œorã€ã§åˆ†å‰²
        parts = re.split(r'\s+or\s+', search_name, flags=re.IGNORECASE)
        
        if len(parts) <= 1:
            # åˆ†å‰²ã§ããªã„å ´åˆã¯ãã®ã¾ã¾è¿½åŠ 
            new_data.append(item)
            continue
        
        or_entries_processed += 1
        
        # åˆ†å‰²ã•ã‚ŒãŸéƒ¨åˆ†ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§ä¿å­˜
        cleaned_parts = []
        for part in parts:
            cleaned_part = clean_food_name(part)
            if cleaned_part:
                cleaned_parts.append(cleaned_part)
        
        if cleaned_parts:
            # æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆï¼ˆsearch_nameã‚’ãƒªã‚¹ãƒˆå½¢å¼ã«ï¼‰
            new_entry = item.copy()
            new_entry['search_name'] = cleaned_parts  # ãƒªã‚¹ãƒˆå½¢å¼
            
            # å…ƒã®æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            new_entry['original_search_name'] = search_name
            new_entry['search_name_type'] = 'list'
            new_entry['alternative_names_count'] = len(cleaned_parts)
            
            new_data.append(new_entry)
            total_list_entries += 1
            
            print(f"å¤‰æ›: '{search_name}' â†’ {cleaned_parts}")
        else:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œã«ä½•ã‚‚æ®‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ã¾ã¾
            new_data.append(item)
    
    print(f"\nğŸ“Š å¤‰æ›çµæœ:")
    print(f"   ğŸ”„ å¤‰æ›ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒª: {or_entries_processed}")
    print(f"   ğŸ“ ãƒªã‚¹ãƒˆå½¢å¼ã‚¨ãƒ³ãƒˆãƒª: {total_list_entries}")
    print(f"   ğŸ“¦ ç·ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(new_data)}")
    
    return new_data

def validate_conversion_results(original_data: List[Dict[str, Any]], new_data: List[Dict[str, Any]]):
    """å¤‰æ›çµæœã‚’æ¤œè¨¼"""
    
    print(f"\nğŸ” æ¤œè¨¼çµæœ:")
    
    # ãƒªã‚¹ãƒˆå½¢å¼ã‚¨ãƒ³ãƒˆãƒªã®ãƒã‚§ãƒƒã‚¯
    list_entries = [item for item in new_data if isinstance(item.get('search_name'), list)]
    string_entries = [item for item in new_data if isinstance(item.get('search_name'), str)]
    
    print(f"   ğŸ“ ãƒªã‚¹ãƒˆå½¢å¼ã‚¨ãƒ³ãƒˆãƒª: {len(list_entries)}")
    print(f"   ğŸ“„ æ–‡å­—åˆ—å½¢å¼ã‚¨ãƒ³ãƒˆãƒª: {len(string_entries)}")
    
    # æ®‹å­˜ã€Œorã€ã‚¨ãƒ³ãƒˆãƒªã®ç¢ºèª
    remaining_or_entries = []
    for item in new_data:
        search_name = item.get('search_name', '')
        if isinstance(search_name, str) and ' or ' in search_name.lower():
            remaining_or_entries.append(item)
    
    print(f"   ğŸ”„ æ®‹å­˜ã€Œorã€ã‚¨ãƒ³ãƒˆãƒª: {len(remaining_or_entries)}")
    
    if remaining_or_entries:
        print("   âš ï¸ ä»¥ä¸‹ã®ã‚¨ãƒ³ãƒˆãƒªãŒã¾ã å¤‰æ›ã•ã‚Œã¦ã„ã¾ã›ã‚“:")
        for entry in remaining_or_entries[:5]:
            print(f"      - {entry['search_name']}")
    
    # ãƒªã‚¹ãƒˆå½¢å¼ã‚¨ãƒ³ãƒˆãƒªã®ä¾‹ã‚’è¡¨ç¤º
    if list_entries:
        print("   ğŸ“ ãƒªã‚¹ãƒˆå½¢å¼ã®ä¾‹:")
        for i, entry in enumerate(list_entries[:5]):
            print(f"      {i+1}. {entry['search_name']} (åŸå: {entry.get('original_search_name', 'N/A')})")

def analyze_search_name_distribution(data: List[Dict[str, Any]]):
    """search_nameã®åˆ†å¸ƒã‚’åˆ†æ"""
    
    list_count = 0
    string_count = 0
    max_alternatives = 0
    alternative_counts = {}
    
    for item in data:
        search_name = item.get('search_name', '')
        if isinstance(search_name, list):
            list_count += 1
            alt_count = len(search_name)
            max_alternatives = max(max_alternatives, alt_count)
            alternative_counts[alt_count] = alternative_counts.get(alt_count, 0) + 1
        else:
            string_count += 1
    
    print(f"\nğŸ“ˆ search_nameåˆ†å¸ƒåˆ†æ:")
    print(f"   ğŸ“„ æ–‡å­—åˆ—å½¢å¼: {string_count}")
    print(f"   ğŸ“ ãƒªã‚¹ãƒˆå½¢å¼: {list_count}")
    print(f"   ğŸ”¢ æœ€å¤§ä»£æ›¿åæ•°: {max_alternatives}")
    
    if alternative_counts:
        print(f"   ğŸ“Š ä»£æ›¿åæ•°åˆ¥åˆ†å¸ƒ:")
        for count, freq in sorted(alternative_counts.items()):
            print(f"      {count}å€‹: {freq}ã‚¨ãƒ³ãƒˆãƒª")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    print("ğŸš€ MyNetDiary ã€Œorã€ã‚¨ãƒ³ãƒˆãƒªãƒªã‚¹ãƒˆå½¢å¼å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 65)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    with open('db/mynetdiary_converted_tool_calls.json', 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    print(f"âœ… {len(original_data)} ã‚¨ãƒ³ãƒˆãƒªã‚’èª­ã¿è¾¼ã¿å®Œäº†")
    
    # ã€Œorã€ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
    print(f"\nğŸ”„ ã€Œorã€ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›ä¸­...")
    new_data = convert_or_entries_to_list(original_data)
    
    # çµæœã‚’æ¤œè¨¼
    validate_conversion_results(original_data, new_data)
    
    # search_nameåˆ†å¸ƒã‚’åˆ†æ
    analyze_search_name_distribution(new_data)
    
    # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = 'db/mynetdiary_converted_tool_calls_list.json'
    print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­: {output_file}")
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
    for item in new_data:
        if 'conversion_timestamp' not in item:
            item['conversion_timestamp'] = time.time()
        if 'search_name_type' in item:
            item['list_conversion_timestamp'] = time.time()
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(new_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å®Œäº†! {len(new_data)} ã‚¨ãƒ³ãƒˆãƒªãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print(f"\nğŸ“Š æœ€çµ‚ã‚µãƒãƒªãƒ¼:")
    print(f"   ğŸ“ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: db/mynetdiary_converted_tool_calls.json")
    print(f"   ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
    print(f"   ğŸ“¦ ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(original_data)} â†’ {len(new_data)} (å¤‰åŒ–ãªã—)")
    print(f"   ğŸ¯ æ¤œç´¢ç²¾åº¦å‘ä¸Š: ã€Œorã€ã‚¨ãƒ³ãƒˆãƒªãŒãƒªã‚¹ãƒˆå½¢å¼ã«ãªã‚Šã€ç‹¬ç«‹è©•ä¾¡ãŒå¯èƒ½")
    print(f"   ğŸ” ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : å„ä»£æ›¿åã‚’ç‹¬ç«‹è©•ä¾¡ã—ã€æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’æ¡ç”¨")

if __name__ == "__main__":
    main() 