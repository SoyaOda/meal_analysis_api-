#!/usr/bin/env python3
"""
Advanced Elasticsearch Search Test v2.0 - Lemmatized Enhanced Search Edition (Multi-Image)

ElasticsearchNutritionSearchComponentã®è¦‹å‡ºã—èªåŒ–å¯¾å¿œæ¤œç´¢æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
test_imageså†…ã®å…¨JPGç”»åƒã‚’å¯¾è±¡ã¨ã—ã€Phase1è§£æçµæœã‹ã‚‰æŠ½å‡ºã—ãŸã‚¯ã‚¨ãƒªã§
è¦‹å‡ºã—èªåŒ–æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸé«˜ç²¾åº¦Elasticsearchæ¤œç´¢ã‚’ãƒ†ã‚¹ãƒˆ
"""

import requests
import json
import time
import os
import glob
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional

# Elasticsearch Nutrition Search Component
from app_v2.components.elasticsearch_nutrition_search_component import ElasticsearchNutritionSearchComponent
from app_v2.models.nutrition_search_models import NutritionQueryInput

# APIè¨­å®š
BASE_URL = "http://localhost:8000/api/v1"

# ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ï¼ˆå…¨ã¦ã®food*.jpgãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
test_images_dir = "test_images"
image_files = sorted(glob.glob(os.path.join(test_images_dir, "food*.jpg")))

async def test_single_image_advanced_elasticsearch_search(image_path: str, main_results_dir: str) -> Optional[Dict[str, Any]]:
    """å˜ä¸€ç”»åƒã§Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print(f"\n{'='*60}")
    print(f"ğŸ–¼ï¸  Testing image: {os.path.basename(image_path)}")
    print(f"{'='*60}")
    
    try:
        # å®Œå…¨åˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã—ã¦Phase1çµæœã‚’å–å¾—
        with open(image_path, "rb") as f:
            files = {"image": (os.path.basename(image_path), f, "image/jpeg")}
            data = {
                "save_results": True,
                "test_execution": True,  # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã§ã‚ã‚‹ã“ã¨ã‚’é€šçŸ¥
                "test_results_dir": main_results_dir  # ãƒ†ã‚¹ãƒˆçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
            }
            
            print("Starting complete analysis to get Phase1 results...")
            start_time = time.time()
            response = requests.post(f"{BASE_URL}/meal-analyses/complete", files=files, data=data)
            end_time = time.time()
        
        print(f"Status Code: {response.status_code}")
        print(f"Response Time: {end_time - start_time:.2f}s")
        
        if response.status_code != 200:
            print("âŒ Failed to get Phase1 results!")
            print(f"Error: {response.text}")
            return None
        
        result = response.json()
        analysis_id = result.get("analysis_id")
        print(f"Analysis ID: {analysis_id}")
        
        # Phase1çµæœã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡º
        phase1_result = result.get("phase1_result", {})
        dishes = phase1_result.get("dishes", [])
        
        all_queries = []
        dish_names = []
        ingredient_names = []
        
        for dish in dishes:
            dish_name = dish.get("dish_name")
            if dish_name:
                dish_names.append(dish_name)
                all_queries.append(dish_name)
            
            ingredients = dish.get("ingredients", [])
            for ingredient in ingredients:
                ingredient_name = ingredient.get("ingredient_name")
                if ingredient_name:
                    ingredient_names.append(ingredient_name)
                    all_queries.append(ingredient_name)
        
        # é‡è¤‡ã‚’é™¤å»
        all_queries = list(set(all_queries))
        dish_names = list(set(dish_names))
        ingredient_names = list(set(ingredient_names))
        
        print(f"\nğŸ“Š Extracted Search Queries from Phase1:")
        print(f"- Total dishes: {len(dish_names)}")
        print(f"- Total ingredients: {len(ingredient_names)}")
        print(f"- Total unique queries: {len(all_queries)}")
        
        if len(all_queries) == 0:
            print("âŒ No search queries extracted from Phase1 results!")
            return None
        
        # ElasticsearchNutritionSearchComponentã‚’è¦‹å‡ºã—èªåŒ–å¯¾å¿œãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–
        print(f"\nğŸ”§ Initializing ElasticsearchNutritionSearchComponent (Lemmatized Enhanced Search Mode)...")
        es_component = ElasticsearchNutritionSearchComponent(
            multi_db_search_mode=False,   # è¦‹å‡ºã—èªåŒ–æ¤œç´¢ã‚’å„ªå…ˆï¼ˆæˆ¦ç•¥çš„æ¤œç´¢ã¯ç„¡åŠ¹ï¼‰
            results_per_db=5,             # å„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰5ã¤ãšã¤çµæœã‚’å–å¾—
            enable_advanced_features=False # æ§‹é€ åŒ–æ¤œç´¢ã¯ç„¡åŠ¹åŒ–ã€è¦‹å‡ºã—èªåŒ–æ¤œç´¢ã«é›†ä¸­
        )
        
        print(f"âœ… Lemmatization features enabled:")
        print(f"   - Lemmatized exact match boost: {es_component.lemmatized_exact_match_boost}")
        print(f"   - Compound word penalty: {es_component.compound_word_penalty}")
        print(f"   - Enable lemmatization: {es_component.enable_lemmatization}")
        
        # æ¤œç´¢å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        nutrition_query_input = NutritionQueryInput(
            ingredient_names=ingredient_names,
            dish_names=dish_names,
            preferred_source="elasticsearch"
        )
        
        print(f"ğŸ“ Strategic Query Input:")
        print(f"- Ingredient names: {len(ingredient_names)} items")
        print(f"- Dish names: {len(dish_names)} items")
        print(f"- Total search terms: {len(nutrition_query_input.get_all_search_terms())}")
        
        # Advanced Elasticsearchè¦‹å‡ºã—èªåŒ–å¯¾å¿œæ¤œç´¢ã‚’å®Ÿè¡Œ
        print(f"\nğŸ” Starting Advanced Elasticsearch lemmatized enhanced search...")
        search_start_time = time.time()
        
        search_results = await es_component.execute(nutrition_query_input)
        
        search_end_time = time.time()
        search_time = search_end_time - search_start_time
        
        print(f"âœ… Advanced Elasticsearch lemmatized enhanced search completed in {search_time:.3f}s")
        
        # çµæœã®åˆ†æ
        matches = search_results.matches
        search_summary = search_results.search_summary
        
        print(f"\nğŸ“ˆ Advanced Elasticsearch Lemmatized Enhanced Search Results Summary:")
        print(f"- Total queries: {search_summary.get('total_searches', 0)}")
        print(f"- Successful matches: {search_summary.get('successful_matches', 0)}")
        print(f"- Failed searches: {search_summary.get('failed_searches', 0)}")
        print(f"- Match rate: {search_summary.get('match_rate_percent', 0):.1f}%")
        print(f"- Search method: {search_summary.get('search_method', 'N/A')}")
        print(f"- Search time: {search_summary.get('search_time_ms', 0)}ms")
        print(f"- Total results: {search_summary.get('total_results', 0)}")
        
        # è¦‹å‡ºã—èªåŒ–ã®åŠ¹æœã‚’è¡¨ç¤º
        if hasattr(search_results, 'advanced_search_metadata') and search_results.advanced_search_metadata:
            metadata = search_results.advanced_search_metadata
            if 'lemmatization_enabled' in metadata:
                print(f"- Lemmatization enabled: {metadata['lemmatization_enabled']}")
            if 'scoring_parameters' in metadata:
                params = metadata['scoring_parameters']
                print(f"- Exact match boost: {params.get('exact_match_boost', 'N/A')}")
                print(f"- Compound word penalty: {params.get('compound_word_penalty', 'N/A')}")
        
        # çµæœã‚’ä¿å­˜
        await save_advanced_elasticsearch_results(
            analysis_id, search_results, all_queries, dish_names, ingredient_names, 
            image_filename=os.path.basename(image_path), main_results_dir=main_results_dir
        )
        
        # ã“ã®ç”»åƒã®çµæœã‚’ã‚µãƒãƒªãƒ¼ç”¨ã«è¿”ã™
        summary_result = {
            "image_name": os.path.basename(image_path),
            "analysis_id": analysis_id,
            "total_queries": search_summary.get('total_searches', 0),
            "successful_matches": search_summary.get('successful_matches', 0),
            "failed_searches": search_summary.get('failed_searches', 0),
            "match_rate_percent": search_summary.get('match_rate_percent', 0),
            "search_time_ms": search_summary.get('search_time_ms', 0),
            "total_results": search_summary.get('total_results', 0),
            "dish_names": dish_names,
            "ingredient_names": ingredient_names,
            "all_queries": all_queries
        }
        
        # è©³ç´°çµæœã‚‚å«ã‚ã¦è¿”ã™
        detailed_result = {
            "analysis_id": analysis_id,
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "image_filename": os.path.basename(image_path),
            "input_queries": {
                "all_queries": all_queries,
                "dish_names": dish_names,
                "ingredient_names": ingredient_names
            },
            "search_summary": search_results.search_summary,
            "matches": {},
            "warnings": search_results.warnings,
            "errors": search_results.errors
        }
        
        # æ¤œç´¢çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        matches_dict = {}
        for query, match_results in search_results.matches.items():
            if isinstance(match_results, list):
                matches_dict[query] = [
                    {
                        "id": match.id,
                        "search_name": match.search_name,
                        "description": match.description,
                        "data_type": match.data_type,
                        "source": match.source,
                        "nutrition": match.nutrition,
                        "weight": match.weight,
                        "score": match.score,
                        "is_exact_match": match.is_exact_match,
                        "match_details": match.match_details,
                        "search_metadata": match.search_metadata
                    } for match in match_results
                ]
            else:
                matches_dict[query] = {
                    "id": match_results.id,
                    "search_name": match_results.search_name,
                    "description": match_results.description,
                    "data_type": match_results.data_type,
                    "source": match_results.source,
                    "nutrition": match_results.nutrition,
                    "weight": match_results.weight,
                    "score": match_results.score,
                    "is_exact_match": match_results.is_exact_match,
                    "match_details": match_results.match_details,
                    "search_metadata": match_results.search_metadata
                }
        
        return summary_result, detailed_result
        
    except Exception as e:
        print(f"âŒ Error testing {os.path.basename(image_path)}: {str(e)}")
        return None

async def test_advanced_elasticsearch_search():
    """å…¨ç”»åƒã§Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸš€ Starting Advanced Elasticsearch Strategic Search Test (Multi-Image)")
    print("=== Advanced Elasticsearch Search Test v1.0 - Strategic Search Edition ===")
    print(f"ğŸ“ Testing {len(image_files)} images: {[os.path.basename(f) for f in image_files]}")
    print("ğŸ” Testing Advanced Elasticsearch strategic search (dish/ingredient optimization)")
    print("ğŸ“Š Strategic database targeting: EatThisMuch dishes/ingredients + fallback optimization")
    
    if not image_files:
        print("âŒ No food*.jpg images found in test_images directory!")
        return False
    
    # å®Ÿè¡Œç”¨ã®ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    main_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    main_results_dir = f"analysis_results/elasticsearch_test_{main_timestamp}"
    os.makedirs(main_results_dir, exist_ok=True)
    print(f"ğŸ“ Created main results directory: {main_results_dir}")
    
    # å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ç”¨å¤‰æ•°
    all_results = []
    all_detailed_results = []  # è©³ç´°æ¤œç´¢çµæœã‚’ä¿å­˜
    total_queries = 0
    total_successful = 0
    total_failed = 0
    total_search_time = 0
    total_results_count = 0
    
    # å„ç”»åƒã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    for image_path in image_files:
        result = await test_single_image_advanced_elasticsearch_search(image_path, main_results_dir)
        if result:
            summary_result, detailed_result = result
            all_results.append(summary_result)
            all_detailed_results.append(detailed_result)
            
            total_queries += summary_result["total_queries"]
            total_successful += summary_result["successful_matches"]
            total_failed += summary_result["failed_searches"]
            total_search_time += summary_result["search_time_ms"]
            total_results_count += summary_result["total_results"]
    
    # å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    print(f"\n{'='*80}")
    print(f"ğŸ¯ OVERALL MULTI-IMAGE TEST SUMMARY")
    print(f"{'='*80}")
    print(f"ğŸ“Š Images tested: {len(all_results)}/{len(image_files)}")
    print(f"ğŸ“ˆ Overall Statistics:")
    print(f"   - Total queries across all images: {total_queries}")
    print(f"   - Total successful matches: {total_successful}")
    print(f"   - Total failed searches: {total_failed}")
    print(f"   - Overall match rate: {(total_successful/total_queries*100) if total_queries > 0 else 0:.1f}%")
    print(f"   - Total search time: {total_search_time}ms")
    print(f"   - Average search time per image: {total_search_time/len(all_results) if all_results else 0:.1f}ms")
    print(f"   - Total results found: {total_results_count}")
    print(f"   - Average results per image: {total_results_count/len(all_results) if all_results else 0:.1f}")
    
    print(f"\nğŸ“‹ Per-Image Results Breakdown:")
    for i, result in enumerate(all_results, 1):
        print(f"   {i}. {result['image_name']}:")
        print(f"      - Queries: {result['total_queries']} | Matches: {result['successful_matches']} | Success: {result['match_rate_percent']:.1f}%")
        print(f"      - Time: {result['search_time_ms']}ms | Results: {result['total_results']}")
        print(f"      - Dishes: {len(result['dish_names'])} | Ingredients: {len(result['ingredient_names'])}")
    
    # é›†ç´„çµæœã‚’ä¿å­˜ï¼ˆè©³ç´°çµæœã‚‚å«ã‚ã‚‹ï¼‰
    await save_multi_image_summary(all_results, total_queries, total_successful, total_failed, total_search_time, total_results_count, all_detailed_results, main_results_dir)
    
    print(f"\nâœ… Multi-image Advanced Elasticsearch strategic search test completed!")
    print(f"ğŸ¯ Overall success rate: {(total_successful/total_queries*100) if total_queries > 0 else 0:.1f}%")
    
    return len(all_results) > 0

async def save_advanced_elasticsearch_results(analysis_id: str, search_results, all_queries: List[str], dish_names: List[str], ingredient_names: List[str], image_filename: str, main_results_dir: str):
    """Advanced Elasticsearchæˆ¦ç•¥çš„æ¤œç´¢çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    
    # ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    image_base = os.path.splitext(image_filename)[0]  # food1, food2, etc.
    results_dir = f"{main_results_dir}/{image_base}"
    os.makedirs(results_dir, exist_ok=True)
    
    # æ¤œç´¢çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
    matches_dict = {}
    for query, match_results in search_results.matches.items():
        if isinstance(match_results, list):
            matches_dict[query] = [
                {
                    "id": match.id,
                    "search_name": match.search_name,
                    "description": match.description,
                    "data_type": match.data_type,
                    "source": match.source,
                    "nutrition": match.nutrition,
                    "weight": match.weight,
                    "score": match.score,
                    "is_exact_match": match.is_exact_match,
                    "match_details": match.match_details,
                    "search_metadata": match.search_metadata
                } for match in match_results
            ]
        else:
            matches_dict[query] = {
                "id": match_results.id,
                "search_name": match_results.search_name,
                "description": match_results.description,
                "data_type": match_results.data_type,
                "source": match_results.source,
                "nutrition": match_results.nutrition,
                "weight": match_results.weight,
                "score": match_results.score,
                "is_exact_match": match_results.is_exact_match,
                "match_details": match_results.match_details,
                "search_metadata": match_results.search_metadata
            }
    
    # 1. å…¨æ¤œç´¢çµæœã‚’JSONã§ä¿å­˜
    results_file = os.path.join(results_dir, "advanced_elasticsearch_search_results.json")
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            "analysis_id": analysis_id,
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "image_filename": image_filename,
            "search_method": "elasticsearch_strategic",
            "input_queries": {
                "all_queries": all_queries,
                "dish_names": dish_names,
                "ingredient_names": ingredient_names
            },
            "search_summary": search_results.search_summary,
            "matches": matches_dict,
            "warnings": search_results.warnings,
            "errors": search_results.errors
        }, f, indent=2, ensure_ascii=False)
    
    # 2. æ¤œç´¢ã‚µãƒãƒªãƒ¼ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§ä¿å­˜
    summary_file = os.path.join(results_dir, "advanced_elasticsearch_summary.md")
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(f"# Advanced Elasticsearch Strategic Search Results\n\n")
        f.write(f"**Analysis ID:** {analysis_id}\n")
        f.write(f"**Image:** {image_filename}\n")
        f.write(f"**Timestamp:** {datetime.now().strftime('%Y%m%d_%H%M%S')}\n")
        f.write(f"**Search Method:** Advanced Elasticsearch Strategic Search\n")
        f.write(f"**Total Queries:** {len(all_queries)}\n\n")
        
        # æ¤œç´¢ã‚µãƒãƒªãƒ¼
        summary = search_results.search_summary
        f.write(f"## Search Summary\n\n")
        f.write(f"- **Total searches:** {summary.get('total_searches', 0)}\n")
        f.write(f"- **Successful matches:** {summary.get('successful_matches', 0)}\n")
        f.write(f"- **Failed searches:** {summary.get('failed_searches', 0)}\n")
        f.write(f"- **Match rate:** {summary.get('match_rate_percent', 0):.1f}%\n")
        f.write(f"- **Search time:** {summary.get('search_time_ms', 0)}ms\n")
        f.write(f"- **Total results:** {summary.get('total_results', 0)}\n\n")
    
    print(f"   ğŸ’¾ Results saved: {results_dir}/")

async def save_multi_image_summary(all_results: List[Dict[str, Any]], total_queries: int, total_successful: int, total_failed: int, total_search_time: int, total_results_count: int, detailed_results: List[Dict[str, Any]], main_results_dir: str):
    """ãƒãƒ«ãƒç”»åƒãƒ†ã‚¹ãƒˆã®å…¨ä½“ã‚µãƒãƒªãƒ¼ã¨è©³ç´°çµæœã‚’1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    
    # ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç›´æ¥ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. å…¨ä½“ã‚µãƒãƒªãƒ¼ã¨è©³ç´°çµæœã‚’JSONã§ä¿å­˜
    comprehensive_file = os.path.join(main_results_dir, "comprehensive_multi_image_results.json")
    with open(comprehensive_file, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": timestamp,
            "test_type": "comprehensive_multi_image_advanced_elasticsearch_strategic",
            "overall_summary": {
                "images_tested": len(all_results),
                "total_queries": total_queries,
                "total_successful": total_successful,
                "total_failed": total_failed,
                "overall_match_rate_percent": (total_successful/total_queries*100) if total_queries > 0 else 0,
                "total_search_time_ms": total_search_time,
                "average_search_time_per_image_ms": total_search_time/len(all_results) if all_results else 0,
                "total_results_found": total_results_count,
                "average_results_per_image": total_results_count/len(all_results) if all_results else 0
            },
            "per_image_summary": all_results,
            "detailed_search_results": detailed_results or []
        }, f, indent=2, ensure_ascii=False)
    
    # 2. åŒ…æ‹¬çš„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
    comprehensive_md_file = os.path.join(main_results_dir, "comprehensive_multi_image_results.md")
    with open(comprehensive_md_file, 'w', encoding='utf-8') as f:
        f.write(f"# Comprehensive Multi-Image Advanced Elasticsearch Strategic Search Results\n\n")
        f.write(f"**Test Date:** {timestamp}\n")
        f.write(f"**Test Type:** Comprehensive Multi-Image Advanced Elasticsearch Strategic Search\n")
        f.write(f"**Images Tested:** {len(all_results)}\n\n")
        
        # å…¨ä½“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        f.write(f"## Overall Performance Summary\n\n")
        f.write(f"- **Total Queries:** {total_queries}\n")
        f.write(f"- **Successful Matches:** {total_successful}\n")
        f.write(f"- **Failed Searches:** {total_failed}\n")
        f.write(f"- **Overall Success Rate:** {(total_successful/total_queries*100) if total_queries > 0 else 0:.1f}%\n")
        f.write(f"- **Total Search Time:** {total_search_time}ms\n")
        f.write(f"- **Average Time per Image:** {total_search_time/len(all_results) if all_results else 0:.1f}ms\n")
        f.write(f"- **Total Results Found:** {total_results_count}\n")
        f.write(f"- **Average Results per Image:** {total_results_count/len(all_results) if all_results else 0:.1f}\n\n")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒè¡¨
        f.write(f"## Performance Comparison Table\n\n")
        f.write(f"| Image | Queries | Matches | Success % | Time (ms) | Results | Dishes | Ingredients |\n")
        f.write(f"|-------|---------|---------|-----------|-----------|---------|--------|-------------|\n")
        for result in all_results:
            f.write(f"| {result['image_name']} | {result['total_queries']} | {result['successful_matches']} | {result['match_rate_percent']:.1f}% | {result['search_time_ms']} | {result['total_results']} | {len(result['dish_names'])} | {len(result['ingredient_names'])} |\n")
        
        f.write(f"\n**Average Performance:** {(total_successful/total_queries*100) if total_queries > 0 else 0:.1f}% success rate, {total_search_time/len(all_results) if all_results else 0:.1f}ms per image\n\n")
        
        # å„ç”»åƒã®è©³ç´°çµæœ
        if detailed_results:
            f.write(f"## Detailed Search Results by Image\n\n")
            
            for i, detail in enumerate(detailed_results):
                image_info = all_results[i]
                f.write(f"### {i+1}. {image_info['image_name']}\n\n")
                f.write(f"- **Analysis ID:** {image_info['analysis_id']}\n")
                f.write(f"- **Success Rate:** {image_info['match_rate_percent']:.1f}% ({image_info['successful_matches']}/{image_info['total_queries']})\n")
                f.write(f"- **Search Time:** {image_info['search_time_ms']}ms\n")
                f.write(f"- **Total Results:** {image_info['total_results']}\n\n")
                
                # æ¤œå‡ºã•ã‚ŒãŸæ–™ç†ã¨ææ–™
                f.write(f"#### Detected Items\n\n")
                if image_info['dish_names']:
                    f.write(f"**Dishes ({len(image_info['dish_names'])}):** {', '.join(image_info['dish_names'])}\n\n")
                if image_info['ingredient_names']:
                    f.write(f"**Ingredients ({len(image_info['ingredient_names'])}):** {', '.join(image_info['ingredient_names'])}\n\n")
                
                # æ¤œç´¢çµæœè©³ç´°
                f.write(f"#### Search Results Detail\n\n")
                matches = detail.get('matches', {})
                dish_names = image_info['dish_names']
                
                # æ–™ç†çµæœã‚’å…ˆã«è¡¨ç¤º
                dish_results = {k: v for k, v in matches.items() if k in dish_names}
                ingredient_results = {k: v for k, v in matches.items() if k not in dish_names}
                
                if dish_results:
                    f.write(f"##### Dish Search Results\n\n")
                    for j, (query, match_results) in enumerate(dish_results.items(), 1):
                        f.write(f"**{j}. {query} (dish)**\n\n")
                        if isinstance(match_results, list):
                            f.write(f"Found {len(match_results)} results:\n\n")
                            for k, match in enumerate(match_results[:3], 1):  # ä¸Šä½3ä»¶ã®ã¿è¡¨ç¤º
                                f.write(f"   {k}. **{match.get('search_name', 'Unknown')}** (score: {match.get('score', 0):.2f})\n")
                                f.write(f"      - Source: {match.get('source', 'Unknown')}\n")
                                f.write(f"      - Data Type: {match.get('data_type', 'Unknown')}\n")
                                if match.get('nutrition'):
                                    nutrition = match['nutrition']
                                    calories = nutrition.get('calories', 0)
                                    protein = nutrition.get('protein', 0)
                                    fat = nutrition.get('fat', 0)
                                    carbs = nutrition.get('carbs', nutrition.get('carbohydrates', 0))
                                    f.write(f"      - Nutrition (100g): {calories:.1f} kcal, P:{protein:.1f}g, F:{fat:.1f}g, C:{carbs:.1f}g\n")
                                f.write(f"\n")
                            if len(match_results) > 3:
                                f.write(f"   ... and {len(match_results) - 3} more results\n\n")
                        f.write(f"\n")
                
                if ingredient_results:
                    f.write(f"##### Ingredient Search Results\n\n")
                    for j, (query, match_results) in enumerate(ingredient_results.items(), 1):
                        f.write(f"**{j}. {query} (ingredient)**\n\n")
                        if isinstance(match_results, list):
                            f.write(f"Found {len(match_results)} results:\n\n")
                            for k, match in enumerate(match_results[:2], 1):  # ä¸Šä½2ä»¶ã®ã¿è¡¨ç¤º
                                f.write(f"   {k}. **{match.get('search_name', 'Unknown')}** (score: {match.get('score', 0):.2f})\n")
                                f.write(f"      - Source: {match.get('source', 'Unknown')}\n")
                                f.write(f"      - Data Type: {match.get('data_type', 'Unknown')}\n")
                                if match.get('nutrition'):
                                    nutrition = match['nutrition']
                                    calories = nutrition.get('calories', 0)
                                    protein = nutrition.get('protein', 0)
                                    fat = nutrition.get('fat', 0)
                                    carbs = nutrition.get('carbs', nutrition.get('carbohydrates', 0))
                                    f.write(f"      - Nutrition (100g): {calories:.1f} kcal, P:{protein:.1f}g, F:{fat:.1f}g, C:{carbs:.1f}g\n")
                                f.write(f"\n")
                            if len(match_results) > 2:
                                f.write(f"   ... and {len(match_results) - 2} more results\n\n")
                        f.write(f"\n")
                
                f.write(f"---\n\n")
        
        # æˆ¦ç•¥çš„æ¤œç´¢çµ±è¨ˆï¼ˆå…¨ç”»åƒçµ±åˆï¼‰
        if detailed_results:
            f.write(f"## Strategic Search Statistics (All Images)\n\n")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†å¸ƒçµ±è¨ˆ
            total_db_stats = {"elasticsearch_eatthismuch": 0, "elasticsearch_yazio": 0, "elasticsearch_mynetdiary": 0}
            strategy_stats = {"dish_primary": 0, "dish_fallback": 0, "ingredient_primary": 0, "ingredient_fallback": 0}
            total_individual_results = 0
            
            for detail in detailed_results:
                matches = detail.get('matches', {})
                dish_names = set(detail.get('input_queries', {}).get('dish_names', []))
                
                for query, match_results in matches.items():
                    if isinstance(match_results, list):
                        total_individual_results += len(match_results)
                        for match in match_results:
                            source = match.get('source', '')
                            if source in total_db_stats:
                                total_db_stats[source] += 1
                            
                            # æˆ¦ç•¥çµ±è¨ˆ
                            metadata = match.get('search_metadata', {})
                            strategy_type = metadata.get('strategy_type', '')
                            if strategy_type in strategy_stats:
                                strategy_stats[strategy_type] += 1
            
            f.write(f"### Database Distribution\n\n")
            for db, count in total_db_stats.items():
                if count > 0:
                    percentage = (count / total_individual_results) * 100 if total_individual_results > 0 else 0
                    db_name = db.replace('elasticsearch_', '').title()
                    f.write(f"- **{db_name}:** {count} results ({percentage:.1f}%)\n")
            
            f.write(f"\n### Strategy Distribution\n\n")
            total_strategy_results = sum(strategy_stats.values())
            for strategy, count in strategy_stats.items():
                if count > 0:
                    percentage = (count / total_strategy_results) * 100 if total_strategy_results > 0 else 0
                    strategy_name = strategy.replace('_', ' ').title()
                    f.write(f"- **{strategy_name}:** {count} results ({percentage:.1f}%)\n")
    
    print(f"\nğŸ“Š Comprehensive multi-image results saved to:")
    print(f"   ğŸ“ {main_results_dir}/")
    print(f"   ğŸ“„ comprehensive_multi_image_results.json")
    print(f"   ğŸ“„ comprehensive_multi_image_results.md")

if __name__ == "__main__":
    print("ğŸš€ Starting Advanced Elasticsearch Strategic Search Test")
    success = asyncio.run(test_advanced_elasticsearch_search())
    
    if success:
        print("\nâœ… Advanced Elasticsearch strategic search test completed successfully!")
        print("ğŸ¯ Strategic search optimization: dish/ingredient targeting with fallback strategies")
    else:
        print("\nâŒ Advanced Elasticsearch strategic search test failed!") 