#!/usr/bin/env python3
"""
èªå¹¹åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å«ã‚€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°

æ‰‹é †:
1. æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å‰Šé™¤
2. æ–°ã—ã„è¨­å®šã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
3. èªå¹¹åŒ–ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
"""

import json
import requests
import time
from typing import Dict, Any, List

# Production Elasticsearch VMè¨­å®š
ELASTICSEARCH_URL = "http://35.193.16.212:9200"
SETTINGS_FILE = "elasticsearch_settings.json"
DATA_FILE = "db/mynetdiary_converted_tool_calls_list_stemmed.json"

# JSONãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å‹•çš„ã«INDEX_NAMEã‚’ç”Ÿæˆ
import os
def get_dynamic_index_name(data_file_path: str) -> str:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åã‚’å‹•çš„ç”Ÿæˆ"""
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿å–å¾—ï¼ˆãƒ‘ã‚¹é™¤å»ï¼‰
    filename = os.path.basename(data_file_path)
    # æ‹¡å¼µå­é™¤å»
    index_name = os.path.splitext(filename)[0]
    return index_name

INDEX_NAME = get_dynamic_index_name(DATA_FILE)

def check_elasticsearch_connection():
    """Elasticsearchã®æ¥ç¶šç¢ºèª"""
    try:
        response = requests.get(f"{ELASTICSEARCH_URL}/_cluster/health", timeout=5)
        if response.status_code == 200:
            health = response.json()
            print(f"âœ… Elasticsearchæ¥ç¶šç¢ºèª: {health.get('status', 'unknown')} status")
            return True
        else:
            print(f"âŒ Elasticsearchæ¥ç¶šã‚¨ãƒ©ãƒ¼: status {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Elasticsearchæ¥ç¶šå¤±æ•—: {e}")
        return False

def delete_existing_index():
    """æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å‰Šé™¤"""
    print(f"ğŸ—‘ï¸ æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{INDEX_NAME}' ã‚’å‰Šé™¤ä¸­...")

    try:
        response = requests.delete(f"{ELASTICSEARCH_URL}/{INDEX_NAME}")
        if response.status_code in [200, 404]:
            print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤å®Œäº†")
            return True
        else:
            print(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤è­¦å‘Š: status {response.status_code}")
            return True  # 404ã¯æ­£å¸¸ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã—ãªã„ï¼‰
    except Exception as e:
        print(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def create_index_with_settings():
    """æ–°ã—ã„è¨­å®šã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
    print(f"ğŸ—ï¸ æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{INDEX_NAME}' ã‚’ä½œæˆä¸­...")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    try:
        with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
            settings = json.load(f)
    except Exception as e:
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    try:
        response = requests.put(
            f"{ELASTICSEARCH_URL}/{INDEX_NAME}",
            headers={"Content-Type": "application/json"},
            data=json.dumps(settings),
            timeout=120
        )

        if response.status_code == 200:
            print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†")
            return True
        else:
            print(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: status {response.status_code}")
            print(f"Response: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå¤±æ•—: {e}")
        return False

def bulk_import_data():
    """ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    import os

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã¨ã‚¿ã‚¤ãƒ—åˆ¤å®š
    if not os.path.exists(DATA_FILE):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DATA_FILE}")
        return False

    file_type = "èªå¹¹åŒ–ãƒ‡ãƒ¼ã‚¿" if "stemmed" in DATA_FILE else "é€šå¸¸ãƒ‡ãƒ¼ã‚¿"
    print(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹: {DATA_FILE}")
    print(f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {file_type}")

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"ğŸ“Š èª­ã¿è¾¼ã¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(data)}")

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        if len(data) > 0:
            sample = data[0]
            has_stemmed_fields = 'stemmed_search_name' in sample and 'stemmed_description' in sample
            if has_stemmed_fields:
                print(f"âœ… èªå¹¹åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¢ºèªæ¸ˆã¿: stemmed_search_name, stemmed_description")
            else:
                print(f"âš ï¸ æ³¨æ„: èªå¹¹åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

    # ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®š
    batch_size = 100
    total_batches = (len(data) + batch_size - 1) // batch_size

    print(f"ğŸ”„ ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {total_batches}ãƒãƒƒãƒï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}ï¼‰")

    success_count = 0
    error_count = 0

    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min(start_idx + batch_size, len(data))
        batch_data = data[start_idx:end_idx]

        # Bulk APIãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä½œæˆ
        bulk_body = []
        for record in batch_data:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ“ä½œ
            index_action = {
                "index": {
                    "_index": INDEX_NAME,
                    "_id": record.get("id", "")
                }
            }
            bulk_body.append(json.dumps(index_action))
            bulk_body.append(json.dumps(record))

        bulk_data = "\n".join(bulk_body) + "\n"

        # Bulk APIå®Ÿè¡Œ
        try:
            response = requests.post(
                f"{ELASTICSEARCH_URL}/_bulk",
                headers={"Content-Type": "application/x-ndjson"},
                data=bulk_data,
                timeout=600
            )

            if response.status_code == 200:
                result = response.json()
                batch_errors = [item for item in result.get("items", []) if "error" in item.get("index", {})]

                if not batch_errors:
                    success_count += len(batch_data)
                    print(f"âš¡ ãƒãƒƒãƒ {batch_idx + 1}/{total_batches} å®Œäº† ({len(batch_data)}ä»¶)")
                else:
                    error_count += len(batch_errors)
                    success_count += len(batch_data) - len(batch_errors)
                    print(f"âš ï¸ ãƒãƒƒãƒ {batch_idx + 1}/{total_batches} éƒ¨åˆ†å®Œäº†: {len(batch_errors)}ä»¶ã‚¨ãƒ©ãƒ¼")

                    # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’è¡¨ç¤ºï¼ˆæœ€åˆã®5ã¤ã¾ã§ï¼‰
                    print("ğŸ“‹ ã‚¨ãƒ©ãƒ¼è©³ç´°:")
                    for i, error_item in enumerate(batch_errors[:5]):
                        error_detail = error_item.get("index", {}).get("error", {})
                        error_type = error_detail.get("type", "unknown")
                        error_reason = error_detail.get("reason", "unknown reason")
                        print(f"   ã‚¨ãƒ©ãƒ¼ {i+1}: {error_type} - {error_reason}")

                    if len(batch_errors) > 5:
                        print(f"   ... ä»– {len(batch_errors) - 5} ä»¶ã®ã‚¨ãƒ©ãƒ¼")
            else:
                error_count += len(batch_data)
                print(f"âŒ ãƒãƒƒãƒ {batch_idx + 1}/{total_batches} å¤±æ•—: status {response.status_code}")

        except Exception as e:
            error_count += len(batch_data)
            print(f"âŒ ãƒãƒƒãƒ {batch_idx + 1}/{total_batches} ä¾‹å¤–: {e}")

        # å°‘ã—å¾…æ©Ÿï¼ˆElasticsearchã®è² è·è»½æ¸›ï¼‰
        time.sleep(0.1)

    print(f"\nğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœ:")
    print(f"   âœ… æˆåŠŸ: {success_count}ä»¶")
    print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
    print(f"   ğŸ“ˆ ç·ä»¶æ•°: {len(data)}ä»¶")

    return error_count == 0

def verify_import():
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœã®ç¢ºèª"""
    print(f"ğŸ” ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœç¢ºèªä¸­...")

    try:
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ç¢ºèª
        response = requests.get(f"{ELASTICSEARCH_URL}/{INDEX_NAME}/_count")
        if response.status_code == 200:
            count = response.json().get("count", 0)
            print(f"ğŸ“Š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {count}")

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        response = requests.get(f"{ELASTICSEARCH_URL}/{INDEX_NAME}/_search?size=1")
        if response.status_code == 200:
            result = response.json()
            hits = result.get("hits", {}).get("hits", [])
            if hits:
                sample = hits[0]["_source"]
                print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ã‚³ãƒ¼ãƒ‰ç¢ºèª:")
                print(f"   original_name: {sample.get('original_name', 'N/A')}")
                print(f"   stemmed_search_name: {sample.get('stemmed_search_name', 'N/A')}")
                print(f"   stemmed_description: {sample.get('stemmed_description', 'N/A')}")
                return True

        return False

    except Exception as e:
        print(f"âŒ ç¢ºèªå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import os

    # å‹•çš„ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    file_type = "èªå¹¹åŒ–ãƒ‡ãƒ¼ã‚¿" if "stemmed" in DATA_FILE else "é€šå¸¸ãƒ‡ãƒ¼ã‚¿"
    index_type = "èªå¹¹åŒ–å¯¾å¿œ" if "stemmed" in DATA_FILE else "æ¨™æº–"

    print(f"ğŸš€ Elasticsearch {index_type}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é–‹å§‹")
    print(f"ğŸ“„ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {DATA_FILE}")
    print(f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {file_type}")
    print(f"ğŸ·ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å: {INDEX_NAME}")
    print("=" * 70)

    # Step 1: æ¥ç¶šç¢ºèª
    if not check_elasticsearch_connection():
        print("âŒ å‡¦ç†ä¸­æ­¢: Elasticsearchæ¥ç¶šä¸å¯")
        return False

    # Step 2: æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤
    if not delete_existing_index():
        print("âŒ å‡¦ç†ä¸­æ­¢: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤å¤±æ•—")
        return False

    # Step 3: æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    if not create_index_with_settings():
        print("âŒ å‡¦ç†ä¸­æ­¢: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå¤±æ•—")
        return False

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ã¨ã‚·ãƒ£ãƒ¼ãƒ‰æº–å‚™ã‚’å¾…ã¤
    print("â³ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ã¨ã‚·ãƒ£ãƒ¼ãƒ‰æº–å‚™å¾…æ©Ÿä¸­...")

    # ã‚·ãƒ£ãƒ¼ãƒ‰ãŒæº–å‚™ã§ãã‚‹ã¾ã§å¾…æ©Ÿ
    max_wait_time = 60  # æœ€å¤§60ç§’å¾…æ©Ÿ
    wait_interval = 5   # 5ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
    waited_time = 0

    while waited_time < max_wait_time:
        try:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å¥åº·çŠ¶æ…‹ã‚’ç¢ºèª
            health_response = requests.get(f"{ELASTICSEARCH_URL}/_cluster/health/{INDEX_NAME}?wait_for_status=yellow&timeout=10s")
            if health_response.status_code == 200:
                health = health_response.json()
                status = health.get('status', 'unknown')
                print(f"ğŸ“Š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹: {status}")

                if status in ['yellow', 'green']:
                    print("âœ… ã‚·ãƒ£ãƒ¼ãƒ‰æº–å‚™å®Œäº†")
                    break

            print(f"â³ ã‚·ãƒ£ãƒ¼ãƒ‰æº–å‚™ä¸­... ({waited_time + wait_interval}/{max_wait_time}ç§’)")
            time.sleep(wait_interval)
            waited_time += wait_interval

        except Exception as e:
            print(f"âš ï¸ å¥åº·çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(wait_interval)
            waited_time += wait_interval

    if waited_time >= max_wait_time:
        print("âš ï¸ è­¦å‘Š: ã‚·ãƒ£ãƒ¼ãƒ‰æº–å‚™ã®ç¢ºèªãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ç¶šè¡Œã—ã¾ã™...")

    # Step 4: ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    if not bulk_import_data():
        print("âŒ å‡¦ç†ä¸­æ­¢: ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—")
        return False

    # å°‘ã—å¾…æ©Ÿï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã‚’å¾…ã¤ï¼‰
    print("â³ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°å®Œäº†å¾…æ©Ÿä¸­...")
    time.sleep(5)

    # Step 5: ç¢ºèª
    if not verify_import():
        print("âš ï¸ è­¦å‘Š: ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèªã§å•é¡Œç™ºç”Ÿ")

    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚å‹•çš„ã«
    completion_type = "èªå¹¹åŒ–å¯¾å¿œ" if "stemmed" in DATA_FILE else "æ¨™æº–"
    print(f"\nğŸ‰ Elasticsearch {completion_type}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°å®Œäº†ï¼")
    print("=" * 70)

    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)