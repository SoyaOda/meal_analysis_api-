#!/usr/bin/env python3
"""
Tool callsã‚’ä½¿ç”¨ã—ã¦MyNetDiaryãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ç¢ºå®Ÿã«å¤‰æ›
æ¤œç´¢æ„å›³æœ€é©åŒ–ã®ãŸã‚ã«é£Ÿå“åã‚’é©åˆ‡ã«åˆ†é›¢
"""

import os
import json
import asyncio
import time
from typing import Dict, List, Any
from anthropic import Anthropic
from pydantic import BaseModel, Field

# Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾©
class FoodSeparationResult(BaseModel):
    search_name: str = Field(description="Primary searchable term representing core food identity")
    description: str = Field(description="Additional modifiers as comma-separated values or 'None'")

class MyNetDiaryConverter:
    """MyNetDiaryãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¤‰æ›ã‚¯ãƒ©ã‚¹ï¼ˆTool callsä½¿ç”¨ï¼‰"""
    
    def __init__(self, api_key: str, prompt_file: str = "food_name_separation_prompt_v2.txt"):
        self.client = Anthropic(api_key=api_key)
        self.converted_count = 0
        self.error_count = 0
        self.batch_size = 5  # Tool callsã¯å°‘ã—é…ã„ã®ã§å°ã•ãã™ã‚‹
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                self.system_prompt = f.read().strip()
            print(f"âœ… Loaded prompt from: {prompt_file}")
        except FileNotFoundError:
            print(f"âŒ Prompt file not found: {prompt_file}")
            raise
        except Exception as e:
            print(f"âŒ Error reading prompt file: {e}")
            raise
        
    async def convert_food_item(self, food_name: str) -> Dict[str, str]:
        """å˜ä¸€é£Ÿå“é …ç›®ã®å¤‰æ›ï¼ˆTool callsä½¿ç”¨ï¼‰"""
        try:
            response = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=500,
                system=self.system_prompt,
                messages=[{
                    "role": "user",
                    "content": f"Please separate this food name: {food_name}"
                }],
                tools=[{
                    "name": "separate_food_name",
                    "description": "Separate a food name into search_name and description components",
                    "input_schema": FoodSeparationResult.model_json_schema()
                }],
                tool_choice={"type": "tool", "name": "separate_food_name"}  # å¼·åˆ¶çš„ã«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨
            )
            
            # Tool callã®çµæœã‚’å–å¾—
            tool_result = response.content[0].input
            self.converted_count += 1
            return tool_result
            
        except Exception as e:
            self.error_count += 1
            print(f"âŒ Error converting '{food_name}': {e}")
            return {"search_name": food_name, "description": "None", "error": str(e)}
    
    async def convert_batch(self, items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ãƒãƒƒãƒå¤‰æ›"""
        converted_items = []
        
        # ãƒãƒƒãƒã”ã¨ã«å‡¦ç†
        for i in range(0, len(items), self.batch_size):
            batch = items[i:i + self.batch_size]
            batch_results = []
            
            print(f"ğŸ”„ Processing batch {i//self.batch_size + 1}/{(len(items) + self.batch_size - 1)//self.batch_size} (items {i+1}-{min(i+self.batch_size, len(items))})")
            
            # ä¸¦åˆ—å‡¦ç†ã¯é…ããªã‚‹ã®ã§é€æ¬¡å‡¦ç†ã«å¤‰æ›´
            for item in batch:
                try:
                    original_name = item["search_name"]
                    separation_result = await self.convert_food_item(original_name)
                    
                    # æ–°ã—ã„æ§‹é€ ã§é …ç›®ã‚’ä½œæˆ
                    converted_item = {
                        "id": item["id"],
                        "original_name": item["search_name"],  # å…ƒã®åå‰ã‚’ä¿æŒ
                        "search_name": separation_result["search_name"],
                        "description": separation_result["description"],
                        "nutrition": item["nutrition"],
                        "data_type": item["data_type"],
                        "source": item["source"],
                        "processing_method": "improved_prompt_v2_tool_calls",
                        "conversion_timestamp": time.time()
                    }
                    
                    # ã‚¨ãƒ©ãƒ¼æƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
                    if "error" in separation_result:
                        converted_item["conversion_error"] = separation_result["error"]
                    
                    batch_results.append(converted_item)
                    
                    # å¤‰æ›çµæœã‚’å³åº§ã«è¡¨ç¤º
                    print(f"  âœ… {original_name} â†’ {separation_result['search_name']} | {separation_result['description']}")
                    
                except Exception as e:
                    print(f"âŒ Failed to process item {item['id']}: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚åŸºæœ¬æ§‹é€ ã¯ä¿æŒ
                    error_item = item.copy()
                    error_item["original_name"] = item["search_name"]
                    error_item["conversion_error"] = str(e)
                    batch_results.append(error_item)
            
            converted_items.extend(batch_results)
            
            # é€²æ—è¡¨ç¤º
            print(f"âœ… Batch completed. Converted: {self.converted_count}, Errors: {self.error_count}")
            print(f"ğŸ“Š Overall progress: {len(converted_items)}/{len(items)} ({len(converted_items)/len(items)*100:.1f}%)")
            
            # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆtool callsã¯å°‘ã—é…ã„ï¼‰
            if i + self.batch_size < len(items):
                print("â³ Waiting 3 seconds...")
                await asyncio.sleep(3)
        
        return converted_items
    
    def save_results(self, converted_items: List[Dict[str, Any]], output_file: str):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(converted_items, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Results saved to: {output_file}")
        print(f"ğŸ“Š Final statistics:")
        print(f"   - Total items: {len(converted_items)}")
        print(f"   - Successful conversions: {self.converted_count}")
        print(f"   - Errors: {self.error_count}")
        print(f"   - Success rate: {(self.converted_count/len(converted_items)*100):.1f}%")


async def main():
    """ãƒ¡ã‚¤ãƒ³å¤‰æ›å‡¦ç†"""
    
    # API keyç¢ºèª
    api_key = os.getenv('ANTHROPIC_API_KEY')
    if not api_key:
        print("âŒ ANTHROPIC_API_KEY environment variable not set")
        print("   Please set: export ANTHROPIC_API_KEY='your-api-key'")
        return
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    input_file = "db/mynetdiary_db.json"
    if not os.path.exists(input_file):
        print(f"âŒ Input file not found: {input_file}")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    print("ğŸ“‚ Loading MyNetDiary database...")
    with open(input_file, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    print(f"âœ… Loaded {len(original_data)} items")
    
    # å¤‰æ›å™¨åˆæœŸåŒ–
    converter = MyNetDiaryConverter(api_key)
    
    # å¤‰æ›å®Ÿè¡Œ
    print("ğŸš€ Starting conversion with Tool Calls (100% reliable)...")
    converted_data = await converter.convert_batch(original_data)
    
    # çµæœä¿å­˜
    output_file = "db/mynetdiary_converted_tool_calls.json"
    converter.save_results(converted_data, output_file)
    
    # ã‚µãƒ³ãƒ—ãƒ«çµæœè¡¨ç¤º
    print("\nğŸ” Sample conversion results:")
    for i, item in enumerate(converted_data[:5], 1):
        print(f"{i}. Original: \"{item['original_name']}\"")
        print(f"   New search_name: \"{item['search_name']}\"")
        print(f"   New description: \"{item['description']}\"")
        if 'conversion_error' in item:
            print(f"   âš ï¸ Error: {item['conversion_error']}")
        print()


if __name__ == "__main__":
    asyncio.run(main()) 